2023-01-27 20:23:56,996 [Time-limited test] WARN  util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(60)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-01-27 20:23:57,111 [Time-limited test] INFO  util.log (Log.java:initialized(170)) - Logging initialized @2132ms to org.eclipse.jetty.util.log.Slf4jLog
2023-01-27 20:23:57,492 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:23:57,496 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context kms
2023-01-27 20:23:57,496 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:23:57,497 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:23:57,505 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:23:57,565 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 32929
2023-01-27 20:23:57,567 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:23:57,616 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:23:57,617 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:23:57,620 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:23:57,651 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@60abd414{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:23:57,653 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2b171682{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-27 20:23:57,803 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(94)) - -------------------------------------------------------------
2023-01-27 20:23:57,804 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(95)) -   Java runtime version : 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:23:57,807 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(97)) -   User: rizky
2023-01-27 20:23:57,810 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(98)) -   KMS Hadoop Version: 3.4.0-SNAPSHOT
2023-01-27 20:23:57,811 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(99)) - -------------------------------------------------------------
2023-01-27 20:23:57,825 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'CREATE' ACL '*'
2023-01-27 20:23:57,825 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DELETE' ACL '*'
2023-01-27 20:23:57,826 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'ROLLOVER' ACL '*'
2023-01-27 20:23:57,826 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET' ACL '*'
2023-01-27 20:23:57,826 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_KEYS' ACL '*'
2023-01-27 20:23:57,826 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_METADATA' ACL '*'
2023-01-27 20:23:57,827 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'SET_KEY_MATERIAL' ACL '*'
2023-01-27 20:23:57,827 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GENERATE_EEK' ACL '*'
2023-01-27 20:23:57,827 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DECRYPT_EEK' ACL '*'
2023-01-27 20:23:57,829 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2023-01-27 20:23:57,829 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2023-01-27 20:23:57,830 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2023-01-27 20:23:57,830 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2023-01-27 20:23:57,938 [Time-limited test] INFO  server.KMSAudit (KMSAudit.java:initializeAuditLoggers(157)) - Initializing audit logger class org.apache.hadoop.crypto.key.kms.server.SimpleKMSAuditLogger
2023-01-27 20:23:58,700 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(149)) - Initialized KeyProvider CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/bb4a148e-509c-425a-86d3-55c0877659f8/kms.keystore
2023-01-27 20:23:58,713 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(163)) - Initialized KeyProviderCryptoExtension org.apache.hadoop.crypto.key.kms.server.KeyAuthorizationKeyProvider: EagerKeyGeneratorKeyProviderCryptoExtension: KeyProviderCryptoExtension: CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/bb4a148e-509c-425a-86d3-55c0877659f8/kms.keystore
2023-01-27 20:23:58,714 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(168)) - Default key bitlength is 128
2023-01-27 20:23:58,714 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(169)) - KMS Started
2023-01-27 20:23:58,811 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:23:58,814 [Thread[Thread-12,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:23:58,815 [Thread[Thread-12,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:23:58,966 [Time-limited test] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.crypto.key.kms.server
2023-01-27 20:23:59,054 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMS
2023-01-27 20:23:59,055 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
  class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
2023-01-27 20:23:59,167 [Time-limited test] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:24:00,638 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@64e7ea77{kms,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/2/kms/webapp/,AVAILABLE}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:00,669 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@26ad06fe{HTTP/1.1, (http/1.1)}{localhost:32929}
2023-01-27 20:24:00,670 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @5692ms
2023-01-27 20:24:00,868 [Time-limited test] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(120)) - Loaded properties from hadoop-metrics2.properties
2023-01-27 20:24:00,895 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 0 second(s).
2023-01-27 20:24:00,895 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - KMS metrics system started
2023-01-27 20:24:00,951 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d7f3a84] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:00,986 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(566)) - starting cluster: numNameNodes=1, numDataNodes=1
2023-01-27 20:24:01,963 [Time-limited test] INFO  namenode.NameNode (NameNode.java:format(1366)) - Formatting using clusterid: testClusterID
2023-01-27 20:24:01,990 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:02,052 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@13ad8b9d
2023-01-27 20:24:02,054 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:02,061 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:02,062 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:02,062 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:02,062 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:02,062 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:02,071 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:02,172 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:02,186 [Time-limited test] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1460)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2023-01-27 20:24:02,187 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:02,187 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:02,192 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:02,192 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:02
2023-01-27 20:24:02,195 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:02,196 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:02,198 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:02,198 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:02,214 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:02,214 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:02,223 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:02,224 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:02,224 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:02,225 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:02,226 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:02,226 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:02,226 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:02,226 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:02,226 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:02,227 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:02,227 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:02,263 [Time-limited test] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2023-01-27 20:24:02,263 [Time-limited test] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2023-01-27 20:24:02,264 [Time-limited test] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2023-01-27 20:24:02,264 [Time-limited test] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2023-01-27 20:24:02,285 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:02,285 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:02,286 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:02,286 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:02,287 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:02,288 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:02,288 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:02,288 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:02,297 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:02,309 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:02,309 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:02,311 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:02,317 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:02,317 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:02,318 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:02,318 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:02,331 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:02,331 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:02,332 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:02,338 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:02,339 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:02,342 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:02,342 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:02,342 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:02,342 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:02,376 [Time-limited test] INFO  namenode.FSImage (FSImage.java:format(186)) - Allocated new BlockPoolId: BP-608817330-127.0.1.1-1674825842369
2023-01-27 20:24:02,385 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 has been successfully formatted.
2023-01-27 20:24:02,389 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 has been successfully formatted.
2023-01-27 20:24:02,427 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:02,427 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:02,619 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 400 bytes saved in 0 seconds .
2023-01-27 20:24:02,619 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 400 bytes saved in 0 seconds .
2023-01-27 20:24:02,628 [Time-limited test] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(202)) - Going to retain 1 images with txid >= 0
2023-01-27 20:24:02,679 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:02,680 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:02,681 [Time-limited test] INFO  namenode.NameNode (NameNode.java:createNameNode(1824)) - createNameNode []
2023-01-27 20:24:02,691 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2023-01-27 20:24:02,693 [Time-limited test] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2023-01-27 20:24:02,741 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6d0ae94] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:02,743 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1736)) - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2023-01-27 20:24:02,744 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1758)) - Starting Web-server for hdfs at: http://localhost:0
2023-01-27 20:24:02,744 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:02,746 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:02,750 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:02,753 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:02,754 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-01-27 20:24:02,755 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:02,755 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:02,758 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2023-01-27 20:24:02,758 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2023-01-27 20:24:02,758 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2023-01-27 20:24:02,759 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:02,766 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(1018)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-01-27 20:24:02,772 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 41729
2023-01-27 20:24:02,772 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:02,774 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:02,775 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:02,775 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:24:02,778 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:02,780 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@65499e48{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:02,781 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@217e7f49{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:02,788 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@108bbcb{hdfs,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:02,792 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@53a63af2{HTTP/1.1, (http/1.1)}{localhost:41729}
2023-01-27 20:24:02,793 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @7815ms
2023-01-27 20:24:02,804 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:02,818 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@30deaa1a
2023-01-27 20:24:02,819 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:02,819 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:02,819 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:02,819 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:02,819 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:02,819 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:02,820 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:02,820 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:02,821 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:02,821 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:02,821 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:02,822 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:02
2023-01-27 20:24:02,822 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:02,822 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:02,823 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:02,823 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:02,825 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:02,825 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:02,825 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:02,825 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:02,826 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:02,826 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:02,826 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:02,826 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:02,826 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:02,826 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:02,826 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:02,826 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:02,827 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:02,827 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:02,827 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:02,828 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:02,828 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:02,828 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:02,829 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:02,829 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:02,829 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:02,829 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:02,829 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:02,830 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:02,830 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:02,830 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:02,830 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:02,830 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:02,830 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:02,832 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:02,832 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:02,832 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:02,833 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:02,833 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:02,833 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:02,833 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:02,834 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:02,834 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:02,839 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:02,842 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:02,845 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current
2023-01-27 20:24:02,845 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current
2023-01-27 20:24:02,846 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(734)) - No edit log streams selected.
2023-01-27 20:24:02,847 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(800)) - Planning to load image: FSImageFile(file=/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-01-27 20:24:02,884 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSectionHeader(411)) - Loading 1 INodes.
2023-01-27 20:24:02,886 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(369)) - Successfully loaded 1 inodes
2023-01-27 20:24:02,892 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:waitBlocksMapAndNameCacheUpdateFinished(342)) - Completed update blocks map and name cache, total waiting duration 1ms.
2023-01-27 20:24:02,895 [Time-limited test] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(255)) - Loaded FSImage in 0 seconds.
2023-01-27 20:24:02,895 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(980)) - Loaded image for txid 0 from /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000
2023-01-27 20:24:02,902 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1271)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-01-27 20:24:02,903 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1417)) - Starting log segment at 1
2023-01-27 20:24:02,944 [Time-limited test] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2023-01-27 20:24:02,945 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(836)) - Finished loading FSImage in 110 msecs
2023-01-27 20:24:03,305 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(451)) - RPC server is binding to localhost:0
2023-01-27 20:24:03,305 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(456)) - Enable NameNode state context:false
2023-01-27 20:24:03,323 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:03,346 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:33277
2023-01-27 20:24:03,348 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:03,448 [Time-limited test] INFO  namenode.NameNode (NameNode.java:initialize(893)) - Clients are to use localhost:33277 to access this namenode/service.
2023-01-27 20:24:03,468 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5607)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2023-01-27 20:24:03,493 [Time-limited test] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(166)) - Number of blocks under construction: 0
2023-01-27 20:24:03,512 [Time-limited test] INFO  blockmanagement.DatanodeAdminDefaultMonitor (DatanodeAdminDefaultMonitor.java:processConf(126)) - Initialized the Default Decommission and Maintenance monitor
2023-01-27 20:24:03,514 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5102)) - Start MarkedDeleteBlockScrubber thread
2023-01-27 20:24:03,519 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(5310)) - initializing replication queues
2023-01-27 20:24:03,519 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(409)) - STATE* Leaving safe mode after 0 secs
2023-01-27 20:24:03,520 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(415)) - STATE* Network topology has 0 racks and 0 datanodes
2023-01-27 20:24:03,520 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(417)) - STATE* UnderReplicatedBlocks has 0 blocks
2023-01-27 20:24:03,525 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:03,531 [Thread[Thread-45,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:03,533 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3870)) - Total number of blocks            = 0
2023-01-27 20:24:03,537 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3871)) - Number of invalid blocks          = 0
2023-01-27 20:24:03,536 [Thread[Thread-45,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:03,537 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3872)) - Number of under-replicated blocks = 0
2023-01-27 20:24:03,545 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3873)) - Number of  over-replicated blocks = 0
2023-01-27 20:24:03,545 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3875)) - Number of blocks being written    = 0
2023-01-27 20:24:03,545 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3878)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 26 msec
2023-01-27 20:24:03,604 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:03,604 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:03,610 [Time-limited test] INFO  namenode.NameNode (NameNode.java:startCommonServices(1010)) - NameNode RPC up at: localhost/127.0.0.1:33277
2023-01-27 20:24:03,614 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1383)) - Starting services required for active state
2023-01-27 20:24:03,614 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(857)) - Initializing quota with 12 thread(s)
2023-01-27 20:24:03,622 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(866)) - Quota initialization completed in 7 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2023-01-27 20:24:03,623 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(326)) - Starting up re-encrypt thread with interval=60000 millisecond.
2023-01-27 20:24:03,630 [CacheReplicationMonitor(1001607580)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-01-27 20:24:03,634 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2023-01-27 20:24:03,646 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1769)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1,[DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:03,674 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:03,698 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:03,757 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2023-01-27 20:24:03,767 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:03,775 [Time-limited test] INFO  datanode.BlockScanner (BlockScanner.java:<init>(201)) - Initialized block scanner with targetBytesPerSec 1048576
2023-01-27 20:24:03,781 [Time-limited test] INFO  datanode.DataNode (DataNode.java:<init>(571)) - Configured hostname is 127.0.0.1
2023-01-27 20:24:03,783 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:03,792 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1788)) - Starting DataNode with maxLockedMemory = 0
2023-01-27 20:24:03,802 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1551)) - Opened streaming server at /127.0.0.1:32951
2023-01-27 20:24:03,806 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(93)) - Balancing bandwidth is 104857600 bytes/s
2023-01-27 20:24:03,806 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(94)) - Number threads for balancing is 100
2023-01-27 20:24:03,818 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:03,820 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:03,823 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:03,827 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:03,829 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-01-27 20:24:03,830 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:03,830 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:03,830 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:03,836 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 32995
2023-01-27 20:24:03,836 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:03,838 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:03,838 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:03,839 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:24:03,840 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@581ce324{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:03,842 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@731d00a{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:03,850 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3b53e487{datanode,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:03,855 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@55d522c1{HTTP/1.1, (http/1.1)}{localhost:32995}
2023-01-27 20:24:03,856 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @8878ms
2023-01-27 20:24:04,134 [Time-limited test] WARN  web.DatanodeHttpServer (RestCsrfPreventionFilterHandler.java:<init>(75)) - Got null for restCsrfPreventionFilter - will not do any filtering.
2023-01-27 20:24:04,341 [Time-limited test] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(306)) - Listening HTTP traffic on /127.0.0.1:45597
2023-01-27 20:24:04,341 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@27a65c03] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:04,343 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1816)) - dnUserName = rizky
2023-01-27 20:24:04,343 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1817)) - supergroup = supergroup
2023-01-27 20:24:04,367 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:04,367 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:32923
2023-01-27 20:24:04,368 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:04,376 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initIpcServer(1438)) - Opened IPC server at /127.0.0.1:32923
2023-01-27 20:24:04,409 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(150)) - Refresh request received for nameservices: null
2023-01-27 20:24:04,410 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(211)) - Starting BPOfferServices for nameservices: <default>
2023-01-27 20:24:04,425 [Thread-79] INFO  datanode.DataNode (BPServiceActor.java:run(877)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33277 starting to offer service
2023-01-27 20:24:04,437 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:04,437 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:04,815 [Thread-79] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(382)) - Acknowledging ACTIVE Namenode during handshake Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33277
2023-01-27 20:24:04,818 [Thread-79] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(356)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2023-01-27 20:24:04,819 [Thread-79] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:04,820 [Thread-79] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 is not formatted for namespace 471274485. Formatting...
2023-01-27 20:24:04,824 [Thread-79] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4600e1a5-eade-41cf-ab95-7ca943057c64 for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 
2023-01-27 20:24:04,838 [Thread-79] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:04,839 [Thread-79] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 is not formatted for namespace 471274485. Formatting...
2023-01-27 20:24:04,839 [Thread-79] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-006df044-f214-4e86-8fea-6798955a6c2e for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 
2023-01-27 20:24:04,886 [Thread-79] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-608817330-127.0.1.1-1674825842369
2023-01-27 20:24:04,886 [Thread-79] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-608817330-127.0.1.1-1674825842369
2023-01-27 20:24:04,887 [Thread-79] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 and block pool id BP-608817330-127.0.1.1-1674825842369 is not formatted. Formatting ...
2023-01-27 20:24:04,887 [Thread-79] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-608817330-127.0.1.1-1674825842369 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-608817330-127.0.1.1-1674825842369/current
2023-01-27 20:24:04,936 [Thread-79] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-608817330-127.0.1.1-1674825842369
2023-01-27 20:24:04,937 [Thread-79] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-608817330-127.0.1.1-1674825842369
2023-01-27 20:24:04,937 [Thread-79] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 and block pool id BP-608817330-127.0.1.1-1674825842369 is not formatted. Formatting ...
2023-01-27 20:24:04,937 [Thread-79] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-608817330-127.0.1.1-1674825842369 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-608817330-127.0.1.1-1674825842369/current
2023-01-27 20:24:04,940 [Thread-79] INFO  datanode.DataNode (DataNode.java:initStorage(2136)) - Setting up storage: nsid=471274485;bpid=BP-608817330-127.0.1.1-1674825842369;lv=-57;nsInfo=lv=-67;cid=testClusterID;nsid=471274485;c=1674825842369;bpid=BP-608817330-127.0.1.1-1674825842369;dnuuid=null
2023-01-27 20:24:04,942 [Thread-79] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1934)) - Generated and persisted new Datanode UUID 659d8427-17ad-48b7-8c97-5818fdcaad27
2023-01-27 20:24:04,985 [Thread-79] INFO  fsdataset.RoundRobinVolumeChoosingPolicy (RoundRobinVolumeChoosingPolicy.java:setConf(67)) - Round robin volume choosing policy initialized: dfs.datanode.round-robin-volume-choosing-policy.additional-available-space = 0
2023-01-27 20:24:05,223 [Thread-79] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-4600e1a5-eade-41cf-ab95-7ca943057c64
2023-01-27 20:24:05,223 [Thread-79] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, StorageType: DISK
2023-01-27 20:24:05,240 [Thread-79] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-006df044-f214-4e86-8fea-6798955a6c2e
2023-01-27 20:24:05,240 [Thread-79] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, StorageType: DISK
2023-01-27 20:24:05,278 [Thread-79] INFO  impl.MemoryMappableBlockLoader (MemoryMappableBlockLoader.java:initialize(47)) - Initializing cache loader: MemoryMappableBlockLoader.
2023-01-27 20:24:05,287 [Thread-79] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2611)) - Registered FSDatasetState MBean
2023-01-27 20:24:05,310 [Thread-79] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(3188)) - Adding block pool BP-608817330-127.0.1.1-1674825842369
2023-01-27 20:24:05,315 [Thread-98] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-608817330-127.0.1.1-1674825842369 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:05,337 [Thread-99] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-608817330-127.0.1.1-1674825842369 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:05,341 [Thread-98] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-608817330-127.0.1.1-1674825842369/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:05,342 [Thread-99] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-608817330-127.0.1.1-1674825842369/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:05,375 [IPC Server handler 5 on default port 33277] INFO  lib.Interns (Interns.java:removeEldestEntry(50)) - Metrics intern cache overflow at 2011 for MetricsSystem={MetricsSystem=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem}, MetricsSystem record=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem record}}
2023-01-27 20:24:05,430 [Thread-99] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-608817330-127.0.1.1-1674825842369 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 93ms
2023-01-27 20:24:05,438 [Thread-98] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-608817330-127.0.1.1-1674825842369 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 121ms
2023-01-27 20:24:05,439 [Thread-79] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(538)) - Total time to scan all replicas for block pool BP-608817330-127.0.1.1-1674825842369: 125ms
2023-01-27 20:24:05,442 [Thread-102] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-608817330-127.0.1.1-1674825842369 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:05,445 [Thread-103] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-608817330-127.0.1.1-1674825842369 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:05,445 [Thread-102] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-608817330-127.0.1.1-1674825842369/current/replicas doesn't exist 
2023-01-27 20:24:05,446 [Thread-103] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-608817330-127.0.1.1-1674825842369/current/replicas doesn't exist 
2023-01-27 20:24:05,464 [Thread-103] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-608817330-127.0.1.1-1674825842369 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 19ms
2023-01-27 20:24:05,464 [Thread-102] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-608817330-127.0.1.1-1674825842369 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 22ms
2023-01-27 20:24:05,476 [Thread-79] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(292)) - Total time to add all replicas to map for block pool BP-608817330-127.0.1.1-1674825842369: 35ms
2023-01-27 20:24:05,477 [Thread-79] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:05,516 [IPC Server handler 5 on default port 33277] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:05,528 [Thread-79] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:05,530 [Thread-79] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:05,530 [Thread-79] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:05,543 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:05,543 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:05,545 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-608817330-127.0.1.1-1674825842369 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:05,547 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-006df044-f214-4e86-8fea-6798955a6c2e): finished scanning block pool BP-608817330-127.0.1.1-1674825842369
2023-01-27 20:24:05,549 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-608817330-127.0.1.1-1674825842369 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:05,551 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-4600e1a5-eade-41cf-ab95-7ca943057c64): finished scanning block pool BP-608817330-127.0.1.1-1674825842369
2023-01-27 20:24:05,554 [Thread-79] WARN  datanode.DirectoryScanner (DirectoryScanner.java:<init>(302)) - dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2023-01-27 20:24:05,576 [Thread-79] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(367)) - Periodic Directory Tree Verification scan starting in 3366852ms with interval of 21600000ms and throttle limit of -1ms/s
2023-01-27 20:24:05,595 [BP-608817330-127.0.1.1-1674825842369 heartbeating to localhost/127.0.0.1:33277] INFO  datanode.DataNode (BPServiceActor.java:register(819)) - Block pool BP-608817330-127.0.1.1-1674825842369 (Datanode Uuid 659d8427-17ad-48b7-8c97-5818fdcaad27) service to localhost/127.0.0.1:33277 beginning handshake with NN: localhost/127.0.0.1:33277.
2023-01-27 20:24:05,595 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-4600e1a5-eade-41cf-ab95-7ca943057c64): no suitable block pools found to scan.  Waiting 1814399954 ms.
2023-01-27 20:24:05,595 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-006df044-f214-4e86-8fea-6798955a6c2e): no suitable block pools found to scan.  Waiting 1814399950 ms.
2023-01-27 20:24:05,624 [IPC Server handler 0 on default port 33277] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1166)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32951, datanodeUuid=659d8427-17ad-48b7-8c97-5818fdcaad27, infoPort=45597, infoSecurePort=0, ipcPort=32923, storageInfo=lv=-57;cid=testClusterID;nsid=471274485;c=1674825842369) storage 659d8427-17ad-48b7-8c97-5818fdcaad27
2023-01-27 20:24:05,628 [IPC Server handler 0 on default port 33277] INFO  net.NetworkTopology (NetworkTopology.java:add(156)) - Adding a new node: /default-rack/127.0.0.1:32951
2023-01-27 20:24:05,629 [IPC Server handler 0 on default port 33277] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(200)) - Registered DN 659d8427-17ad-48b7-8c97-5818fdcaad27 (127.0.0.1:32951).
2023-01-27 20:24:05,645 [BP-608817330-127.0.1.1-1674825842369 heartbeating to localhost/127.0.0.1:33277] INFO  datanode.DataNode (BPServiceActor.java:register(846)) - Block pool BP-608817330-127.0.1.1-1674825842369 (Datanode Uuid 659d8427-17ad-48b7-8c97-5818fdcaad27) service to localhost/127.0.0.1:33277 successfully registered with NN: localhost/127.0.0.1:33277.
2023-01-27 20:24:05,648 [BP-608817330-127.0.1.1-1674825842369 heartbeating to localhost/127.0.0.1:33277] INFO  datanode.DataNode (BPServiceActor.java:offerService(680)) - For namenode localhost/127.0.0.1:33277 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2023-01-27 20:24:05,651 [ibr-executor-0] INFO  datanode.DataNode (BPServiceActor.java:run(1145)) - Starting IBR Task Handler.
2023-01-27 20:24:05,648 [IPC Server handler 0 on default port 33277] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:06,167 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2922)) - No heartbeat from DataNode: 127.0.0.1:32951
2023-01-27 20:24:06,167 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:06,174 [IPC Server handler 8 on default port 33277] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-4600e1a5-eade-41cf-ab95-7ca943057c64 for DN 127.0.0.1:32951
2023-01-27 20:24:06,175 [IPC Server handler 8 on default port 33277] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-006df044-f214-4e86-8fea-6798955a6c2e for DN 127.0.0.1:32951
2023-01-27 20:24:06,224 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0x6cba01e95095f341 with lease ID 0x436279b5d6817f1f: Processing first storage report for DS-4600e1a5-eade-41cf-ab95-7ca943057c64 from datanode DatanodeRegistration(127.0.0.1:32951, datanodeUuid=659d8427-17ad-48b7-8c97-5818fdcaad27, infoPort=45597, infoSecurePort=0, ipcPort=32923, storageInfo=lv=-57;cid=testClusterID;nsid=471274485;c=1674825842369)
2023-01-27 20:24:06,228 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0x6cba01e95095f341 with lease ID 0x436279b5d6817f1f: from storage DS-4600e1a5-eade-41cf-ab95-7ca943057c64 node DatanodeRegistration(127.0.0.1:32951, datanodeUuid=659d8427-17ad-48b7-8c97-5818fdcaad27, infoPort=45597, infoSecurePort=0, ipcPort=32923, storageInfo=lv=-57;cid=testClusterID;nsid=471274485;c=1674825842369), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2023-01-27 20:24:06,228 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0x6cba01e95095f341 with lease ID 0x436279b5d6817f1f: Processing first storage report for DS-006df044-f214-4e86-8fea-6798955a6c2e from datanode DatanodeRegistration(127.0.0.1:32951, datanodeUuid=659d8427-17ad-48b7-8c97-5818fdcaad27, infoPort=45597, infoSecurePort=0, ipcPort=32923, storageInfo=lv=-57;cid=testClusterID;nsid=471274485;c=1674825842369)
2023-01-27 20:24:06,229 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0x6cba01e95095f341 with lease ID 0x436279b5d6817f1f: from storage DS-006df044-f214-4e86-8fea-6798955a6c2e node DatanodeRegistration(127.0.0.1:32951, datanodeUuid=659d8427-17ad-48b7-8c97-5818fdcaad27, infoPort=45597, infoSecurePort=0, ipcPort=32923, storageInfo=lv=-57;cid=testClusterID;nsid=471274485;c=1674825842369), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:06,254 [BP-608817330-127.0.1.1-1674825842369 heartbeating to localhost/127.0.0.1:33277] INFO  datanode.DataNode (BPServiceActor.java:blockReport(464)) - Successfully sent block report 0x6cba01e95095f341 with lease ID 0x436279b5d6817f1f to namenode: localhost/127.0.0.1:33277,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msecs to generate and 49 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-01-27 20:24:06,256 [Command processor] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(763)) - Got finalize command for block pool BP-608817330-127.0.1.1-1674825842369
2023-01-27 20:24:06,270 [IPC Server handler 4 on default port 33277] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:06,273 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:06,313 [IPC Server handler 2 on default port 33277] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:06,315 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:06,635 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(589)) - Successfully warmed up 0 EDEKs.
2023-01-27 20:24:06,762 [qtp1774621510-24] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:06 +0000] "OPTIONS /kms/v1/keys HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:06,848 [qtp1774621510-24] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:06,850 [qtp1774621510-24] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:06,851 [qtp1774621510-24] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:06,851 [qtp1774621510-24] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:06,851 [qtp1774621510-24] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:06,852 [qtp1774621510-24] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:06,852 [qtp1774621510-24] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:06,853 [qtp1774621510-24] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:06,903 [qtp1774621510-24] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:06 +0000] "OPTIONS /kms/v1/keys?user.name=rizky HTTP/1.1" 200 520 "-" "Java/1.8.0_352"
2023-01-27 20:24:07,709 [qtp1774621510-19] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=CREATE_KEY, key=test_key, user=rizky] UserProvidedMaterial:false Description:test_key
2023-01-27 20:24:07,717 [qtp1774621510-19] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:06 +0000] "POST /kms/v1/keys HTTP/1.1" 201 98 "-" "Java/1.8.0_352"
2023-01-27 20:24:07,735 [IPC Server handler 0 on default port 33277] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2023-01-27 20:24:07,766 [IPC Server handler 8 on default port 33277] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/TestEncryptionZone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:07,819 [qtp1774621510-24] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=GET_METADATA, key=test_key, user=rizky] 
2023-01-27 20:24:07,823 [qtp1774621510-24] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:07 +0000] "GET /kms/v1/key/test_key/_metadata HTTP/1.1" 200 210 "-" "Java/1.8.0_352"
2023-01-27 20:24:08,114 [qtp1774621510-23] WARN  crypto.OpensslCipher (OpensslCipher.java:<clinit>(94)) - Failed to load OpenSSL Cipher.
java.lang.UnsatisfiedLinkError: org.apache.hadoop.util.NativeCodeLoader.buildSupportsOpenssl()Z
	at org.apache.hadoop.util.NativeCodeLoader.buildSupportsOpenssl(Native Method)
	at org.apache.hadoop.crypto.OpensslCipher.<clinit>(OpensslCipher.java:86)
	at org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec.<init>(OpensslAesCtrCryptoCodec.java:36)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:156)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:127)
	at org.apache.hadoop.crypto.CryptoCodec.getInstance(CryptoCodec.java:69)
	at org.apache.hadoop.crypto.CryptoCodec.getInstance(CryptoCodec.java:102)
	at org.apache.hadoop.crypto.key.KeyProviderCryptoExtension$DefaultCryptoExtension.generateEncryptedKey(KeyProviderCryptoExtension.java:294)
	at org.apache.hadoop.crypto.key.KeyProviderCryptoExtension.generateEncryptedKey(KeyProviderCryptoExtension.java:513)
	at org.apache.hadoop.crypto.key.kms.server.EagerKeyGeneratorKeyProviderCryptoExtension$CryptoExtension$EncryptedQueueRefiller.fillQueueForKey(EagerKeyGeneratorKeyProviderCryptoExtension.java:76)
	at org.apache.hadoop.crypto.key.kms.ValueQueue$1.load(ValueQueue.java:249)
	at org.apache.hadoop.crypto.key.kms.ValueQueue$1.load(ValueQueue.java:243)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache.get(LocalCache.java:3962)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3985)
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4946)
	at org.apache.hadoop.crypto.key.kms.ValueQueue.getAtMost(ValueQueue.java:352)
	at org.apache.hadoop.crypto.key.kms.ValueQueue.getNext(ValueQueue.java:293)
	at org.apache.hadoop.crypto.key.kms.server.EagerKeyGeneratorKeyProviderCryptoExtension$CryptoExtension.generateEncryptedKey(EagerKeyGeneratorKeyProviderCryptoExtension.java:125)
	at org.apache.hadoop.crypto.key.KeyProviderCryptoExtension.generateEncryptedKey(KeyProviderCryptoExtension.java:513)
	at org.apache.hadoop.crypto.key.kms.server.KeyAuthorizationKeyProvider.generateEncryptedKey(KeyAuthorizationKeyProvider.java:243)
	at org.apache.hadoop.crypto.key.kms.server.KMS$10.run(KMS.java:517)
	at org.apache.hadoop.crypto.key.kms.server.KMS$10.run(KMS.java:511)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.crypto.key.kms.server.KMS.generateEncryptedKeys(KMS.java:510)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)
	at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205)
	at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)
	at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)
	at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1459)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
	at org.apache.hadoop.crypto.key.kms.server.KMSMDCFilter.doFilter(KMSMDCFilter.java:98)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:652)
	at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter(DelegationTokenAuthenticationFilter.java:305)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:592)
	at org.apache.hadoop.crypto.key.kms.server.KMSAuthenticationFilter.doFilter(KMSAuthenticationFilter.java:162)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:110)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1874)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:600)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.lang.Thread.run(Thread.java:750)
2023-01-27 20:24:08,300 [qtp1774621510-23] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditEvent(59)) - OK[op=GENERATE_EEK, key=test_key, user=rizky, accessCount=1, interval=0ms] 
2023-01-27 20:24:08,324 [qtp1774621510-23] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:07 +0000] "GET /kms/v1/key/test_key/_eek?num_keys=150&eek_op=generate HTTP/1.1" 200 29702 "-" "Java/1.8.0_352"
2023-01-27 20:24:08,368 [IPC Server handler 6 on default port 33277] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=createEncryptionZone	src=/TestEncryptionZone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:09,150 [qtp1774621510-24] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=CREATE_KEY, key=k2, user=rizky] UserProvidedMaterial:false Description:k2
2023-01-27 20:24:09,152 [qtp1774621510-24] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:08 +0000] "POST /kms/v1/keys HTTP/1.1" 201 86 "-" "Java/1.8.0_352"
2023-01-27 20:24:09,157 [IPC Server handler 4 on default port 33277] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2023-01-27 20:24:09,162 [IPC Server handler 2 on default port 33277] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/TestEncryptionZone2	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:09,171 [qtp1774621510-23] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=GET_METADATA, key=k2, user=rizky] 
2023-01-27 20:24:09,172 [qtp1774621510-23] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:09 +0000] "GET /kms/v1/key/k2/_metadata HTTP/1.1" 200 192 "-" "Java/1.8.0_352"
2023-01-27 20:24:09,514 [qtp1774621510-23] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditEvent(59)) - OK[op=GENERATE_EEK, key=k2, user=rizky, accessCount=1, interval=0ms] 
2023-01-27 20:24:09,522 [qtp1774621510-23] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:09 +0000] "GET /kms/v1/key/k2/_eek?num_keys=150&eek_op=generate HTTP/1.1" 200 27902 "-" "Java/1.8.0_352"
2023-01-27 20:24:09,530 [IPC Server handler 6 on default port 33277] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=createEncryptionZone	src=/TestEncryptionZone2	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:09,537 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2241)) - Shutting down the namenode
2023-01-27 20:24:09,537 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:09,538 [Thread[Thread-45,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:09,540 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@64d65691] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4658)) - LazyPersistFileScrubber was interrupted, exiting
2023-01-27 20:24:09,540 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1467)) - Ending log segment 1, 7
2023-01-27 20:24:09,542 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@6f47ef47] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4561)) - NameNodeEditLogRoller was interrupted, exiting
2023-01-27 20:24:09,544 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(801)) - Number of transactions: 8 Total time for transactions(ms): 40 Number of transactions batched in Syncs: 0 Number of syncs: 9 SyncTimes(ms): 15 12 
2023-01-27 20:24:09,547 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008
2023-01-27 20:24:09,548 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008
2023-01-27 20:24:09,549 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(276)) - FSEditLogAsync was interrupted, exiting
2023-01-27 20:24:09,550 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(267)) - Re-encryption updater thread interrupted. Exiting.
2023-01-27 20:24:09,550 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(335)) - Re-encrypt handler interrupted. Exiting
2023-01-27 20:24:09,550 [CacheReplicationMonitor(1001607580)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2023-01-27 20:24:09,553 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 33277
2023-01-27 20:24:09,555 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:09,555 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:09,562 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(5160)) - Stopping RedundancyMonitor.
2023-01-27 20:24:09,562 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5134)) - Stopping MarkedDeleteBlockScrubber.
2023-01-27 20:24:09,579 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:09,579 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:09,592 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@108bbcb{hdfs,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:09,600 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@53a63af2{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:09,601 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:09,602 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@217e7f49{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:09,603 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@65499e48{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:09,614 [Time-limited test] INFO  namenode.NameNode (NameNode.java:createNameNode(1824)) - createNameNode []
2023-01-27 20:24:09,615 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2023-01-27 20:24:09,628 [Time-limited test] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:33277
2023-01-27 20:24:09,629 [Time-limited test] INFO  namenode.NameNode (NameNode.java:<init>(1126)) - Clients should use localhost:33277 to access this namenode/service.
2023-01-27 20:24:09,648 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@46d7264b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:09,648 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1736)) - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2023-01-27 20:24:09,653 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1758)) - Starting Web-server for hdfs at: http://localhost:41729
2023-01-27 20:24:09,653 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:09,656 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:09,667 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:09,670 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:09,671 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-01-27 20:24:09,672 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:09,672 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:09,673 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2023-01-27 20:24:09,674 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2023-01-27 20:24:09,674 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2023-01-27 20:24:09,674 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:09,675 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(1018)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-01-27 20:24:09,676 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 41729
2023-01-27 20:24:09,676 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:09,699 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:09,699 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:09,700 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:09,702 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:09,706 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@534a59bd{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:09,708 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5014f8d4{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:09,715 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7beef6fb{hdfs,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:09,723 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@37700d33{HTTP/1.1, (http/1.1)}{localhost:41729}
2023-01-27 20:24:09,724 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @14745ms
2023-01-27 20:24:09,727 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:09,745 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@32330e95
2023-01-27 20:24:09,746 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:09,746 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:09,746 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:09,746 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:09,746 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:09,746 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:09,748 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:09,753 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:09,755 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:09,755 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:09,756 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:09,756 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:09
2023-01-27 20:24:09,756 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:09,757 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:09,757 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:09,757 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:09,763 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:09,764 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:09,764 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:09,764 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:09,764 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:09,779 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:09,779 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:09,780 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:09,780 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:09,780 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:09,780 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:09,780 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:09,780 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:09,781 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:09,781 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:09,781 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:09,782 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:09,782 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:09,783 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:09,783 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:09,783 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:09,783 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:09,784 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:09,784 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:09,784 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:09,784 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:09,784 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:09,785 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:09,785 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:09,785 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:09,785 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:09,786 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:09,786 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:09,786 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:09,786 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:09,786 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:09,786 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:09,787 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:09,789 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:09,791 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:09,796 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current
2023-01-27 20:24:09,800 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current
2023-01-27 20:24:09,810 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(800)) - Planning to load image: FSImageFile(file=/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-01-27 20:24:09,813 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSectionHeader(411)) - Loading 1 INodes.
2023-01-27 20:24:09,815 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(369)) - Successfully loaded 1 inodes
2023-01-27 20:24:09,815 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:waitBlocksMapAndNameCacheUpdateFinished(342)) - Completed update blocks map and name cache, total waiting duration 0ms.
2023-01-27 20:24:09,815 [Time-limited test] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(255)) - Loaded FSImage in 0 seconds.
2023-01-27 20:24:09,816 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(980)) - Loaded image for txid 0 from /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000
2023-01-27 20:24:09,819 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadEdits(913)) - Reading /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008, /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008 expecting start txid #1
2023-01-27 20:24:09,819 [Time-limited test] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(179)) - Start loading edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008, /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008 maxTxnsToRead = 9223372036854775807
2023-01-27 20:24:09,820 [Time-limited test] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(187)) - Fast-forwarding stream '/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008' to transaction ID 1
2023-01-27 20:24:09,888 [Time-limited test] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(189)) - Loaded 1 edits file(s) (the last named /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008, /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008) of total size 498.0, total edits 8.0, total load time 19.0 ms
2023-01-27 20:24:09,888 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1271)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-01-27 20:24:09,889 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1417)) - Starting log segment at 9
2023-01-27 20:24:09,921 [Time-limited test] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2023-01-27 20:24:09,921 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(836)) - Finished loading FSImage in 134 msecs
2023-01-27 20:24:09,922 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(451)) - RPC server is binding to localhost:33277
2023-01-27 20:24:09,922 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(456)) - Enable NameNode state context:false
2023-01-27 20:24:09,922 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:09,923 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:33277
2023-01-27 20:24:09,924 [Socket Reader #1 for port 33277] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 33277
2023-01-27 20:24:09,930 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5607)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2023-01-27 20:24:09,949 [Time-limited test] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(166)) - Number of blocks under construction: 0
2023-01-27 20:24:09,950 [Time-limited test] INFO  blockmanagement.DatanodeAdminDefaultMonitor (DatanodeAdminDefaultMonitor.java:processConf(126)) - Initialized the Default Decommission and Maintenance monitor
2023-01-27 20:24:09,951 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5102)) - Start MarkedDeleteBlockScrubber thread
2023-01-27 20:24:09,952 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(5310)) - initializing replication queues
2023-01-27 20:24:09,952 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(409)) - STATE* Leaving safe mode after 0 secs
2023-01-27 20:24:09,952 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(415)) - STATE* Network topology has 0 racks and 0 datanodes
2023-01-27 20:24:09,952 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(417)) - STATE* UnderReplicatedBlocks has 0 blocks
2023-01-27 20:24:09,957 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:09,961 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3870)) - Total number of blocks            = 0
2023-01-27 20:24:09,961 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3871)) - Number of invalid blocks          = 0
2023-01-27 20:24:09,961 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3872)) - Number of under-replicated blocks = 0
2023-01-27 20:24:09,961 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3873)) - Number of  over-replicated blocks = 0
2023-01-27 20:24:09,962 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3875)) - Number of blocks being written    = 0
2023-01-27 20:24:09,962 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3878)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2023-01-27 20:24:09,966 [Thread[Thread-139,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:09,966 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:09,975 [IPC Server listener on 33277] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 33277: starting
2023-01-27 20:24:09,983 [Thread[Thread-139,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:10,000 [Time-limited test] INFO  namenode.NameNode (NameNode.java:startCommonServices(1010)) - NameNode RPC up at: localhost/127.0.0.1:33277
2023-01-27 20:24:10,005 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1383)) - Starting services required for active state
2023-01-27 20:24:10,006 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(857)) - Initializing quota with 12 thread(s)
2023-01-27 20:24:10,007 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:10,007 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:10,007 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:10,007 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:10,007 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INode.getStoragePolicyIDForQuota(INode.java:811)
2023-01-27 20:24:10,007 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory$InitQuotaTask.compute(FSDirectory.java:906)
2023-01-27 20:24:10,007 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
2023-01-27 20:24:10,007 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
2023-01-27 20:24:10,007 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
2023-01-27 20:24:10,008 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
2023-01-27 20:24:10,008 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)
2023-01-27 20:24:10,008 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:10,008 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:10,008 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:10,008 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:10,008 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:10,008 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INode.getStoragePolicyIDForQuota(INode.java:811)
2023-01-27 20:24:10,008 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory$InitQuotaTask.compute(FSDirectory.java:906)
2023-01-27 20:24:10,008 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
2023-01-27 20:24:10,008 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
2023-01-27 20:24:10,008 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
2023-01-27 20:24:10,008 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
2023-01-27 20:24:10,008 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INode.getStoragePolicyIDForQuota(INode.java:811)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory$InitQuotaTask.compute(FSDirectory.java:906)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INode.getStoragePolicyIDForQuota(INode.java:811)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory$InitQuotaTask.compute(FSDirectory.java:906)
2023-01-27 20:24:10,009 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.util.concurrent.RecursiveAction.exec(RecursiveAction.java:189)
2023-01-27 20:24:10,010 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
2023-01-27 20:24:10,010 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
2023-01-27 20:24:10,010 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
2023-01-27 20:24:10,010 [ForkJoinPool-3-worker-9] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)
2023-01-27 20:24:10,011 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(866)) - Quota initialization completed in 5 milliseconds
name space=3
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2023-01-27 20:24:10,012 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(326)) - Starting up re-encrypt thread with interval=60000 millisecond.
2023-01-27 20:24:10,022 [CacheReplicationMonitor(163983968)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-01-27 20:24:10,023 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 2 EDEKs... (initialDelay=3000, retryInterval=1000)
2023-01-27 20:24:10,023 [Time-limited test] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitNameNodeUp(1504)) - Waiting for namenode at 0 to start...
2023-01-27 20:24:11,024 [Time-limited test] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitNameNodeUp(1504)) - Waiting for namenode at 0 to start...
2023-01-27 20:24:11,650 [BP-608817330-127.0.1.1-1674825842369 heartbeating to localhost/127.0.0.1:33277] WARN  datanode.DataNode (BPServiceActor.java:offerService(783)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "rizky/127.0.1.1"; destination host is: "localhost":33277; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:948)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:897)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1583)
	at org.apache.hadoop.ipc.Client.call(Client.java:1524)
	at org.apache.hadoop.ipc.Client.call(Client.java:1421)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:258)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:139)
	at com.sun.proxy.$Proxy72.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:570)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:712)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:913)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1918)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1198)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1096)
2023-01-27 20:24:12,024 [Time-limited test] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitNameNodeUp(1504)) - Waiting for namenode at 0 to start...
2023-01-27 20:24:13,025 [Time-limited test] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitNameNodeUp(1504)) - Waiting for namenode at 0 to start...
2023-01-27 20:24:13,027 [qtp1774621510-24] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:13 +0000] "OPTIONS /kms/v1/key/test_key/_eek?num_keys=150&eek_op=generate HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:13,034 [qtp1774621510-23] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:13,035 [qtp1774621510-23] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:13,035 [qtp1774621510-23] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:13,035 [qtp1774621510-23] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:13,035 [qtp1774621510-23] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:13,035 [qtp1774621510-23] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:13,036 [qtp1774621510-23] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:13,039 [qtp1774621510-23] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:13 +0000] "OPTIONS /kms/v1/key/test_key/_eek?num_keys=150&eek_op=generate&user.name=rizky HTTP/1.1" 200 703 "-" "Java/1.8.0_352"
2023-01-27 20:24:13,105 [qtp1774621510-20] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:13 +0000] "GET /kms/v1/key/test_key/_eek?num_keys=150&eek_op=generate HTTP/1.1" 200 29702 "-" "Java/1.8.0_352"
2023-01-27 20:24:13,185 [qtp1774621510-22] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:13 +0000] "GET /kms/v1/key/k2/_eek?num_keys=150&eek_op=generate HTTP/1.1" 200 27902 "-" "Java/1.8.0_352"
2023-01-27 20:24:13,196 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(589)) - Successfully warmed up 2 EDEKs.
2023-01-27 20:24:14,026 [Time-limited test] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitNameNodeUp(1504)) - Waiting for namenode at 0 to start...
2023-01-27 20:24:14,656 [Command processor] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(677)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:33277 with active state
2023-01-27 20:24:14,663 [Command processor] INFO  datanode.DataNode (BPServiceActor.java:register(819)) - Block pool BP-608817330-127.0.1.1-1674825842369 (Datanode Uuid 659d8427-17ad-48b7-8c97-5818fdcaad27) service to localhost/127.0.0.1:33277 beginning handshake with NN: localhost/127.0.0.1:33277.
2023-01-27 20:24:14,667 [IPC Server handler 2 on default port 33277] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1166)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32951, datanodeUuid=659d8427-17ad-48b7-8c97-5818fdcaad27, infoPort=45597, infoSecurePort=0, ipcPort=32923, storageInfo=lv=-57;cid=testClusterID;nsid=471274485;c=1674825842369) storage 659d8427-17ad-48b7-8c97-5818fdcaad27
2023-01-27 20:24:14,668 [IPC Server handler 2 on default port 33277] INFO  net.NetworkTopology (NetworkTopology.java:add(156)) - Adding a new node: /default-rack/127.0.0.1:32951
2023-01-27 20:24:14,668 [IPC Server handler 2 on default port 33277] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(200)) - Registered DN 659d8427-17ad-48b7-8c97-5818fdcaad27 (127.0.0.1:32951).
2023-01-27 20:24:14,670 [Command processor] INFO  datanode.DataNode (BPServiceActor.java:register(846)) - Block pool BP-608817330-127.0.1.1-1674825842369 (Datanode Uuid 659d8427-17ad-48b7-8c97-5818fdcaad27) service to localhost/127.0.0.1:33277 successfully registered with NN: localhost/127.0.0.1:33277.
2023-01-27 20:24:15,026 [Time-limited test] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitNameNodeUp(1504)) - Waiting for namenode at 0 to start...
2023-01-27 20:24:16,027 [Time-limited test] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitNameNodeUp(1504)) - Waiting for namenode at 0 to start...
2023-01-27 20:24:17,027 [Time-limited test] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitNameNodeUp(1504)) - Waiting for namenode at 0 to start...
2023-01-27 20:24:17,651 [IPC Server handler 1 on default port 33277] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-4600e1a5-eade-41cf-ab95-7ca943057c64 for DN 127.0.0.1:32951
2023-01-27 20:24:17,651 [IPC Server handler 1 on default port 33277] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-006df044-f214-4e86-8fea-6798955a6c2e for DN 127.0.0.1:32951
2023-01-27 20:24:17,654 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0x6cba01e95095f342 with lease ID 0xfd3f95a3b16a278e: Processing first storage report for DS-4600e1a5-eade-41cf-ab95-7ca943057c64 from datanode DatanodeRegistration(127.0.0.1:32951, datanodeUuid=659d8427-17ad-48b7-8c97-5818fdcaad27, infoPort=45597, infoSecurePort=0, ipcPort=32923, storageInfo=lv=-57;cid=testClusterID;nsid=471274485;c=1674825842369)
2023-01-27 20:24:17,654 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0x6cba01e95095f342 with lease ID 0xfd3f95a3b16a278e: from storage DS-4600e1a5-eade-41cf-ab95-7ca943057c64 node DatanodeRegistration(127.0.0.1:32951, datanodeUuid=659d8427-17ad-48b7-8c97-5818fdcaad27, infoPort=45597, infoSecurePort=0, ipcPort=32923, storageInfo=lv=-57;cid=testClusterID;nsid=471274485;c=1674825842369), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:17,655 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0x6cba01e95095f342 with lease ID 0xfd3f95a3b16a278e: Processing first storage report for DS-006df044-f214-4e86-8fea-6798955a6c2e from datanode DatanodeRegistration(127.0.0.1:32951, datanodeUuid=659d8427-17ad-48b7-8c97-5818fdcaad27, infoPort=45597, infoSecurePort=0, ipcPort=32923, storageInfo=lv=-57;cid=testClusterID;nsid=471274485;c=1674825842369)
2023-01-27 20:24:17,655 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0x6cba01e95095f342 with lease ID 0xfd3f95a3b16a278e: from storage DS-006df044-f214-4e86-8fea-6798955a6c2e node DatanodeRegistration(127.0.0.1:32951, datanodeUuid=659d8427-17ad-48b7-8c97-5818fdcaad27, infoPort=45597, infoSecurePort=0, ipcPort=32923, storageInfo=lv=-57;cid=testClusterID;nsid=471274485;c=1674825842369), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:17,655 [BP-608817330-127.0.1.1-1674825842369 heartbeating to localhost/127.0.0.1:33277] INFO  datanode.DataNode (BPServiceActor.java:blockReport(464)) - Successfully sent block report 0x6cba01e95095f342 with lease ID 0xfd3f95a3b16a278e to namenode: localhost/127.0.0.1:33277,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msecs to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-01-27 20:24:17,656 [Command processor] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(763)) - Got finalize command for block pool BP-608817330-127.0.1.1-1674825842369
2023-01-27 20:24:18,027 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartNameNode(2319)) - Restarted the namenode
2023-01-27 20:24:18,062 [IPC Server handler 1 on default port 33277] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:18,068 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2159)) - Shutting down the Mini HDFS Cluster
2023-01-27 20:24:18,069 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2208)) - Shutting down DataNode 0
2023-01-27 20:24:18,069 [Time-limited test] INFO  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(430)) - Shutdown has been called
2023-01-27 20:24:18,070 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@35bd90ed] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(395)) - Closing all peers.
2023-01-27 20:24:18,072 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-006df044-f214-4e86-8fea-6798955a6c2e) exiting.
2023-01-27 20:24:18,072 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-4600e1a5-eade-41cf-ab95-7ca943057c64) exiting.
2023-01-27 20:24:18,083 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3b53e487{datanode,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:18,084 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@55d522c1{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:18,085 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:18,085 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@731d00a{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:18,085 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@581ce324{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:18,086 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2470)) - Waiting up to 30 seconds for transfer threads to complete
2023-01-27 20:24:18,087 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 32923
2023-01-27 20:24:18,089 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:18,090 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:18,091 [Command processor] ERROR datanode.DataNode (BPServiceActor.java:processQueue(1430)) - Command processor encountered interrupt and exit.
2023-01-27 20:24:18,091 [Command processor] WARN  datanode.DataNode (BPServiceActor.java:run(1414)) - Ending command processor service for: Thread[Command processor,5,main]
2023-01-27 20:24:18,091 [BP-608817330-127.0.1.1-1674825842369 heartbeating to localhost/127.0.0.1:33277] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:18,091 [BP-608817330-127.0.1.1-1674825842369 heartbeating to localhost/127.0.0.1:33277] WARN  datanode.DataNode (BPServiceActor.java:run(924)) - Ending block pool service for: Block pool BP-608817330-127.0.1.1-1674825842369 (Datanode Uuid 659d8427-17ad-48b7-8c97-5818fdcaad27) service to localhost/127.0.0.1:33277
2023-01-27 20:24:18,091 [ibr-executor-0] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:18,092 [BP-608817330-127.0.1.1-1674825842369 heartbeating to localhost/127.0.0.1:33277] INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-608817330-127.0.1.1-1674825842369 (Datanode Uuid 659d8427-17ad-48b7-8c97-5818fdcaad27)
2023-01-27 20:24:18,092 [BP-608817330-127.0.1.1-1674825842369 heartbeating to localhost/127.0.0.1:33277] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(3225)) - Removing block pool BP-608817330-127.0.1.1-1674825842369
2023-01-27 20:24:18,094 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-608817330-127.0.1.1-1674825842369] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:18,095 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-608817330-127.0.1.1-1674825842369] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:18,096 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(208)) - Shutting down all async disk service threads
2023-01-27 20:24:18,096 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(216)) - All async disk service threads have been shut down
2023-01-27 20:24:18,096 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(186)) - Shutting down all async lazy persist service threads
2023-01-27 20:24:18,096 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(193)) - All async lazy persist service threads have been shut down
2023-01-27 20:24:18,097 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2559)) - Shutdown complete.
2023-01-27 20:24:18,097 [Time-limited test] WARN  datanode.DataSetLockManager (DataSetLockManager.java:lockLeakCheck(260)) - not open lock leak check func
2023-01-27 20:24:18,097 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2241)) - Shutting down the namenode
2023-01-27 20:24:18,097 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:18,098 [Thread[Thread-139,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:18,099 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1467)) - Ending log segment 9, 11
2023-01-27 20:24:18,099 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@15c21523] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4561)) - NameNodeEditLogRoller was interrupted, exiting
2023-01-27 20:24:18,099 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3e6113e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4658)) - LazyPersistFileScrubber was interrupted, exiting
2023-01-27 20:24:18,103 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(801)) - Number of transactions: 4 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 8 Number of syncs: 5 SyncTimes(ms): 21 12 
2023-01-27 20:24:18,104 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_inprogress_0000000000000000009 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000009-0000000000000000012
2023-01-27 20:24:18,105 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_inprogress_0000000000000000009 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000009-0000000000000000012
2023-01-27 20:24:18,106 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(276)) - FSEditLogAsync was interrupted, exiting
2023-01-27 20:24:18,106 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(267)) - Re-encryption updater thread interrupted. Exiting.
2023-01-27 20:24:18,107 [CacheReplicationMonitor(163983968)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2023-01-27 20:24:18,106 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(335)) - Re-encrypt handler interrupted. Exiting
2023-01-27 20:24:18,108 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 33277
2023-01-27 20:24:18,110 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:18,110 [IPC Server listener on 33277] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 33277
2023-01-27 20:24:18,111 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(5160)) - Stopping RedundancyMonitor.
2023-01-27 20:24:18,111 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5134)) - Stopping MarkedDeleteBlockScrubber.
2023-01-27 20:24:18,127 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:18,127 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:18,131 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@7beef6fb{hdfs,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:18,132 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@37700d33{HTTP/1.1, (http/1.1)}{localhost:41729}
2023-01-27 20:24:18,133 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:18,133 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5014f8d4{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:18,134 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@534a59bd{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:18,142 [Thread[Thread-12,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:18,143 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextDestroyed(197)) - KMS Stopped
2023-01-27 20:24:18,144 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@64e7ea77{kms,/,null,STOPPED}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:18,149 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@26ad06fe{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:18,149 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:18,149 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2b171682{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-27 20:24:18,150 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@60abd414{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:18,151 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping NameNode metrics system...
2023-01-27 20:24:18,153 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - NameNode metrics system stopped.
2023-01-27 20:24:18,154 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(612)) - NameNode metrics system shutdown complete.
2023-01-27 20:24:18,263 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:18,264 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context kms
2023-01-27 20:24:18,264 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:18,264 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:18,264 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:18,265 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 45997
2023-01-27 20:24:18,267 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:18,311 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:18,312 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:18,312 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:18,316 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@b0b0354{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:18,317 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6289fb40{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-27 20:24:18,422 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(94)) - -------------------------------------------------------------
2023-01-27 20:24:18,423 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(95)) -   Java runtime version : 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:18,423 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(97)) -   User: rizky
2023-01-27 20:24:18,423 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(98)) -   KMS Hadoop Version: 3.4.0-SNAPSHOT
2023-01-27 20:24:18,423 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(99)) - -------------------------------------------------------------
2023-01-27 20:24:18,434 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'CREATE' ACL '*'
2023-01-27 20:24:18,434 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DELETE' ACL '*'
2023-01-27 20:24:18,434 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'ROLLOVER' ACL '*'
2023-01-27 20:24:18,435 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET' ACL '*'
2023-01-27 20:24:18,435 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_KEYS' ACL '*'
2023-01-27 20:24:18,435 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_METADATA' ACL '*'
2023-01-27 20:24:18,435 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'SET_KEY_MATERIAL' ACL '*'
2023-01-27 20:24:18,436 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GENERATE_EEK' ACL '*'
2023-01-27 20:24:18,436 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DECRYPT_EEK' ACL '*'
2023-01-27 20:24:18,436 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2023-01-27 20:24:18,436 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2023-01-27 20:24:18,436 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2023-01-27 20:24:18,437 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2023-01-27 20:24:18,444 [Time-limited test] INFO  server.KMSAudit (KMSAudit.java:initializeAuditLoggers(157)) - Initializing audit logger class org.apache.hadoop.crypto.key.kms.server.SimpleKMSAuditLogger
2023-01-27 20:24:18,446 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(149)) - Initialized KeyProvider CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/efaf8f55-95be-4676-baed-e1cad702f865/kms.keystore
2023-01-27 20:24:18,448 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(163)) - Initialized KeyProviderCryptoExtension org.apache.hadoop.crypto.key.kms.server.KeyAuthorizationKeyProvider: EagerKeyGeneratorKeyProviderCryptoExtension: KeyProviderCryptoExtension: CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/efaf8f55-95be-4676-baed-e1cad702f865/kms.keystore
2023-01-27 20:24:18,449 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(168)) - Default key bitlength is 128
2023-01-27 20:24:18,449 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(169)) - KMS Started
2023-01-27 20:24:18,451 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:18,453 [Thread[Thread-166,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:18,454 [Thread[Thread-166,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:18,456 [Time-limited test] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.crypto.key.kms.server
2023-01-27 20:24:18,485 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMS
2023-01-27 20:24:18,485 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
  class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
2023-01-27 20:24:18,494 [Time-limited test] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:24:18,918 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7bb94a49{kms,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/2/kms/webapp/,AVAILABLE}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:18,956 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@2360fe17{HTTP/1.1, (http/1.1)}{localhost:45997}
2023-01-27 20:24:18,957 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @23979ms
2023-01-27 20:24:18,968 [Time-limited test] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(120)) - Loaded properties from hadoop-metrics2.properties
2023-01-27 20:24:18,973 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 0 second(s).
2023-01-27 20:24:18,973 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - KMS metrics system started
2023-01-27 20:24:18,996 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1ac21fa1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:19,018 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(566)) - starting cluster: numNameNodes=1, numDataNodes=1
2023-01-27 20:24:19,025 [Time-limited test] INFO  namenode.NameNode (NameNode.java:format(1366)) - Formatting using clusterid: testClusterID
2023-01-27 20:24:19,026 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:19,052 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@221f6b91
2023-01-27 20:24:19,052 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:19,052 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:19,052 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:19,053 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:19,053 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:19,053 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:19,053 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:19,070 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:19,071 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:19,072 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:19,077 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:19,079 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:19
2023-01-27 20:24:19,079 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:19,080 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:19,084 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:19,084 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:19,121 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:19,122 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:19,122 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:19,123 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:19,123 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:19,124 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:19,124 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:19,124 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:19,124 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:19,124 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:19,124 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:19,124 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:19,125 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:19,125 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:19,125 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:19,137 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:19,137 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:19,158 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:19,158 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:19,158 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:19,159 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:19,159 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:19,160 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:19,160 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:19,161 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:19,161 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:19,161 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:19,161 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:19,161 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:19,163 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:19,164 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:19,164 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:19,165 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:19,166 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:19,166 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:19,166 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:19,166 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:19,166 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:19,172 [Time-limited test] INFO  namenode.FSImage (FSImage.java:format(186)) - Allocated new BlockPoolId: BP-1179503178-127.0.1.1-1674825859172
2023-01-27 20:24:19,180 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 has been successfully formatted.
2023-01-27 20:24:19,193 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 has been successfully formatted.
2023-01-27 20:24:19,219 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:19,228 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 436 bytes saved in 0 seconds .
2023-01-27 20:24:19,242 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:19,251 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 436 bytes saved in 0 seconds .
2023-01-27 20:24:19,255 [Time-limited test] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(202)) - Going to retain 1 images with txid >= 0
2023-01-27 20:24:19,270 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:19,270 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:19,271 [Time-limited test] INFO  namenode.NameNode (NameNode.java:createNameNode(1824)) - createNameNode []
2023-01-27 20:24:19,272 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2023-01-27 20:24:19,272 [Time-limited test] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2023-01-27 20:24:19,296 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@c1c4d0a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:19,297 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1736)) - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2023-01-27 20:24:19,297 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1758)) - Starting Web-server for hdfs at: http://localhost:0
2023-01-27 20:24:19,297 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:19,299 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:19,302 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:19,305 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:19,306 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-01-27 20:24:19,306 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:19,306 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:19,308 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2023-01-27 20:24:19,308 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2023-01-27 20:24:19,308 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2023-01-27 20:24:19,308 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:19,309 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(1018)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-01-27 20:24:19,309 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 38275
2023-01-27 20:24:19,310 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:19,385 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:19,385 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:19,386 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:19,388 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:19,388 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@69c0816f{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:19,389 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@630440e6{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:19,408 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@1fa77f61{hdfs,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:19,412 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@41aed265{HTTP/1.1, (http/1.1)}{localhost:38275}
2023-01-27 20:24:19,412 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @24434ms
2023-01-27 20:24:19,415 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:19,429 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@33bbfb64
2023-01-27 20:24:19,429 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:19,429 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:19,429 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:19,429 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:19,429 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:19,430 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:19,430 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:19,430 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:19,431 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:19,431 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:19,431 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:19,431 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:19
2023-01-27 20:24:19,431 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:19,431 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:19,432 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:19,432 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:19,434 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:19,434 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:19,434 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:19,434 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:19,434 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:19,434 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:19,434 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:19,435 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:19,435 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:19,435 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:19,435 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:19,435 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:19,435 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:19,435 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:19,435 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:19,436 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:19,436 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:19,437 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:19,437 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:19,437 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:19,437 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:19,437 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:19,437 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:19,438 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:19,438 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:19,438 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:19,438 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:19,438 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:19,438 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:19,439 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:19,439 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:19,439 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:19,439 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:19,439 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:19,439 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:19,439 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:19,440 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:19,440 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:19,443 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:19,444 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:19,446 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current
2023-01-27 20:24:19,447 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current
2023-01-27 20:24:19,447 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(734)) - No edit log streams selected.
2023-01-27 20:24:19,447 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(800)) - Planning to load image: FSImageFile(file=/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-01-27 20:24:19,449 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSectionHeader(411)) - Loading 1 INodes.
2023-01-27 20:24:19,452 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(369)) - Successfully loaded 1 inodes
2023-01-27 20:24:19,452 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:waitBlocksMapAndNameCacheUpdateFinished(342)) - Completed update blocks map and name cache, total waiting duration 0ms.
2023-01-27 20:24:19,453 [Time-limited test] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(255)) - Loaded FSImage in 0 seconds.
2023-01-27 20:24:19,453 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(980)) - Loaded image for txid 0 from /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000
2023-01-27 20:24:19,454 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1271)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-01-27 20:24:19,454 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1417)) - Starting log segment at 1
2023-01-27 20:24:19,471 [Time-limited test] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2023-01-27 20:24:19,472 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(836)) - Finished loading FSImage in 30 msecs
2023-01-27 20:24:19,472 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(451)) - RPC server is binding to localhost:0
2023-01-27 20:24:19,472 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(456)) - Enable NameNode state context:false
2023-01-27 20:24:19,473 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:19,473 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:35295
2023-01-27 20:24:19,474 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:19,479 [Time-limited test] INFO  namenode.NameNode (NameNode.java:initialize(893)) - Clients are to use localhost:35295 to access this namenode/service.
2023-01-27 20:24:19,480 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5607)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2023-01-27 20:24:19,537 [Time-limited test] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(166)) - Number of blocks under construction: 0
2023-01-27 20:24:19,537 [Time-limited test] INFO  blockmanagement.DatanodeAdminDefaultMonitor (DatanodeAdminDefaultMonitor.java:processConf(126)) - Initialized the Default Decommission and Maintenance monitor
2023-01-27 20:24:19,539 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(5310)) - initializing replication queues
2023-01-27 20:24:19,539 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5102)) - Start MarkedDeleteBlockScrubber thread
2023-01-27 20:24:19,539 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(409)) - STATE* Leaving safe mode after 0 secs
2023-01-27 20:24:19,539 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(415)) - STATE* Network topology has 0 racks and 0 datanodes
2023-01-27 20:24:19,539 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(417)) - STATE* UnderReplicatedBlocks has 0 blocks
2023-01-27 20:24:19,543 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:19,546 [Thread[Thread-198,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:19,550 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3870)) - Total number of blocks            = 0
2023-01-27 20:24:19,550 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3871)) - Number of invalid blocks          = 0
2023-01-27 20:24:19,550 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3872)) - Number of under-replicated blocks = 0
2023-01-27 20:24:19,550 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3873)) - Number of  over-replicated blocks = 0
2023-01-27 20:24:19,550 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3875)) - Number of blocks being written    = 0
2023-01-27 20:24:19,550 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3878)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
2023-01-27 20:24:19,551 [Thread[Thread-198,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:19,552 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:19,552 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:19,556 [Time-limited test] INFO  namenode.NameNode (NameNode.java:startCommonServices(1010)) - NameNode RPC up at: localhost/127.0.0.1:35295
2023-01-27 20:24:19,557 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1383)) - Starting services required for active state
2023-01-27 20:24:19,557 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(857)) - Initializing quota with 12 thread(s)
2023-01-27 20:24:19,557 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(866)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2023-01-27 20:24:19,558 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(326)) - Starting up re-encrypt thread with interval=60000 millisecond.
2023-01-27 20:24:19,567 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2023-01-27 20:24:19,568 [CacheReplicationMonitor(630789407)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-01-27 20:24:19,571 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1769)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1,[DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:19,573 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:19,573 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:19,592 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2023-01-27 20:24:19,593 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:19,593 [Time-limited test] INFO  datanode.BlockScanner (BlockScanner.java:<init>(201)) - Initialized block scanner with targetBytesPerSec 1048576
2023-01-27 20:24:19,593 [Time-limited test] INFO  datanode.DataNode (DataNode.java:<init>(571)) - Configured hostname is 127.0.0.1
2023-01-27 20:24:19,593 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:19,593 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1788)) - Starting DataNode with maxLockedMemory = 0
2023-01-27 20:24:19,594 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1551)) - Opened streaming server at /127.0.0.1:33205
2023-01-27 20:24:19,594 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(93)) - Balancing bandwidth is 104857600 bytes/s
2023-01-27 20:24:19,594 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(94)) - Number threads for balancing is 100
2023-01-27 20:24:19,595 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:19,596 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:19,598 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:19,600 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:19,601 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-01-27 20:24:19,601 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:19,601 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:19,601 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:19,602 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 38957
2023-01-27 20:24:19,602 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:19,604 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:19,604 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:19,605 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:19,606 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@670c9eaf{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:19,607 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@38aeb298{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:19,613 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@58805e98{datanode,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:19,615 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@383222fd{HTTP/1.1, (http/1.1)}{localhost:38957}
2023-01-27 20:24:19,615 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @24637ms
2023-01-27 20:24:19,621 [Time-limited test] WARN  web.DatanodeHttpServer (RestCsrfPreventionFilterHandler.java:<init>(75)) - Got null for restCsrfPreventionFilter - will not do any filtering.
2023-01-27 20:24:19,629 [Time-limited test] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(306)) - Listening HTTP traffic on /127.0.0.1:42287
2023-01-27 20:24:19,630 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1816)) - dnUserName = rizky
2023-01-27 20:24:19,630 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1817)) - supergroup = supergroup
2023-01-27 20:24:19,630 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:19,631 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:40161
2023-01-27 20:24:19,630 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@63ecabb4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:19,631 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:19,635 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initIpcServer(1438)) - Opened IPC server at /127.0.0.1:40161
2023-01-27 20:24:19,651 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(150)) - Refresh request received for nameservices: null
2023-01-27 20:24:19,651 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(211)) - Starting BPOfferServices for nameservices: <default>
2023-01-27 20:24:19,652 [Thread-231] INFO  datanode.DataNode (BPServiceActor.java:run(877)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35295 starting to offer service
2023-01-27 20:24:19,654 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:19,654 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:19,666 [Thread-231] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(382)) - Acknowledging ACTIVE Namenode during handshake Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35295
2023-01-27 20:24:19,666 [Thread-231] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(356)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2023-01-27 20:24:19,668 [Thread-231] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:19,668 [Thread-231] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 is not formatted for namespace 838682573. Formatting...
2023-01-27 20:24:19,669 [Thread-231] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d79fa0f2-3bc0-4162-b0ac-a2aba3f5c455 for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 
2023-01-27 20:24:19,670 [IPC Server handler 1 on default port 35295] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:19,671 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:19,672 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:19,673 [Thread-231] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:19,673 [Thread-231] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 is not formatted for namespace 838682573. Formatting...
2023-01-27 20:24:19,673 [Thread-231] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-27aba016-47b3-48f3-926a-62bf4bc4a6b5 for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 
2023-01-27 20:24:19,694 [Thread-231] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-1179503178-127.0.1.1-1674825859172
2023-01-27 20:24:19,694 [Thread-231] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1179503178-127.0.1.1-1674825859172
2023-01-27 20:24:19,694 [Thread-231] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 and block pool id BP-1179503178-127.0.1.1-1674825859172 is not formatted. Formatting ...
2023-01-27 20:24:19,694 [Thread-231] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-1179503178-127.0.1.1-1674825859172 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1179503178-127.0.1.1-1674825859172/current
2023-01-27 20:24:19,718 [Thread-231] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-1179503178-127.0.1.1-1674825859172
2023-01-27 20:24:19,718 [Thread-231] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1179503178-127.0.1.1-1674825859172
2023-01-27 20:24:19,719 [Thread-231] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 and block pool id BP-1179503178-127.0.1.1-1674825859172 is not formatted. Formatting ...
2023-01-27 20:24:19,719 [Thread-231] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-1179503178-127.0.1.1-1674825859172 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1179503178-127.0.1.1-1674825859172/current
2023-01-27 20:24:19,721 [Thread-231] INFO  datanode.DataNode (DataNode.java:initStorage(2136)) - Setting up storage: nsid=838682573;bpid=BP-1179503178-127.0.1.1-1674825859172;lv=-57;nsInfo=lv=-67;cid=testClusterID;nsid=838682573;c=1674825859172;bpid=BP-1179503178-127.0.1.1-1674825859172;dnuuid=null
2023-01-27 20:24:19,723 [Thread-231] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1934)) - Generated and persisted new Datanode UUID 2c5fc81e-3e2b-4aec-a749-6fd7142d4445
2023-01-27 20:24:19,724 [Thread-231] INFO  fsdataset.RoundRobinVolumeChoosingPolicy (RoundRobinVolumeChoosingPolicy.java:setConf(67)) - Round robin volume choosing policy initialized: dfs.datanode.round-robin-volume-choosing-policy.additional-available-space = 0
2023-01-27 20:24:19,725 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-d79fa0f2-3bc0-4162-b0ac-a2aba3f5c455
2023-01-27 20:24:19,726 [Thread-231] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, StorageType: DISK
2023-01-27 20:24:19,728 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-27aba016-47b3-48f3-926a-62bf4bc4a6b5
2023-01-27 20:24:19,729 [Thread-231] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, StorageType: DISK
2023-01-27 20:24:19,729 [Thread-231] INFO  impl.MemoryMappableBlockLoader (MemoryMappableBlockLoader.java:initialize(47)) - Initializing cache loader: MemoryMappableBlockLoader.
2023-01-27 20:24:19,729 [Thread-231] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2611)) - Registered FSDatasetState MBean
2023-01-27 20:24:19,733 [Thread-231] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(3188)) - Adding block pool BP-1179503178-127.0.1.1-1674825859172
2023-01-27 20:24:19,734 [Thread-248] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-1179503178-127.0.1.1-1674825859172 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:19,734 [Thread-249] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-1179503178-127.0.1.1-1674825859172 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:19,735 [Thread-249] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1179503178-127.0.1.1-1674825859172/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:19,735 [Thread-248] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1179503178-127.0.1.1-1674825859172/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:19,752 [Thread-248] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-1179503178-127.0.1.1-1674825859172 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 18ms
2023-01-27 20:24:19,754 [Thread-249] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-1179503178-127.0.1.1-1674825859172 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 19ms
2023-01-27 20:24:19,754 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(538)) - Total time to scan all replicas for block pool BP-1179503178-127.0.1.1-1674825859172: 21ms
2023-01-27 20:24:19,754 [Thread-252] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-1179503178-127.0.1.1-1674825859172 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:19,755 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-1179503178-127.0.1.1-1674825859172 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:19,755 [Thread-252] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1179503178-127.0.1.1-1674825859172/current/replicas doesn't exist 
2023-01-27 20:24:19,755 [Thread-253] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1179503178-127.0.1.1-1674825859172/current/replicas doesn't exist 
2023-01-27 20:24:19,755 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-1179503178-127.0.1.1-1674825859172 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 1ms
2023-01-27 20:24:19,756 [Thread-252] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-1179503178-127.0.1.1-1674825859172 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 2ms
2023-01-27 20:24:19,756 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(292)) - Total time to add all replicas to map for block pool BP-1179503178-127.0.1.1-1674825859172: 2ms
2023-01-27 20:24:19,756 [Thread-231] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:19,757 [Thread-231] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:19,757 [Thread-231] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:19,758 [Thread-231] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:19,759 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-1179503178-127.0.1.1-1674825859172 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:19,759 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-1179503178-127.0.1.1-1674825859172 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:19,759 [Thread-231] WARN  datanode.DirectoryScanner (DirectoryScanner.java:<init>(302)) - dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2023-01-27 20:24:19,760 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-27aba016-47b3-48f3-926a-62bf4bc4a6b5): finished scanning block pool BP-1179503178-127.0.1.1-1674825859172
2023-01-27 20:24:19,760 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-d79fa0f2-3bc0-4162-b0ac-a2aba3f5c455): finished scanning block pool BP-1179503178-127.0.1.1-1674825859172
2023-01-27 20:24:19,760 [Thread-231] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(367)) - Periodic Directory Tree Verification scan starting in 10598021ms with interval of 21600000ms and throttle limit of -1ms/s
2023-01-27 20:24:19,760 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-27aba016-47b3-48f3-926a-62bf4bc4a6b5): no suitable block pools found to scan.  Waiting 1814399999 ms.
2023-01-27 20:24:19,760 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-d79fa0f2-3bc0-4162-b0ac-a2aba3f5c455): no suitable block pools found to scan.  Waiting 1814399999 ms.
2023-01-27 20:24:19,766 [BP-1179503178-127.0.1.1-1674825859172 heartbeating to localhost/127.0.0.1:35295] INFO  datanode.DataNode (BPServiceActor.java:register(819)) - Block pool BP-1179503178-127.0.1.1-1674825859172 (Datanode Uuid 2c5fc81e-3e2b-4aec-a749-6fd7142d4445) service to localhost/127.0.0.1:35295 beginning handshake with NN: localhost/127.0.0.1:35295.
2023-01-27 20:24:19,768 [IPC Server handler 2 on default port 35295] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1166)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33205, datanodeUuid=2c5fc81e-3e2b-4aec-a749-6fd7142d4445, infoPort=42287, infoSecurePort=0, ipcPort=40161, storageInfo=lv=-57;cid=testClusterID;nsid=838682573;c=1674825859172) storage 2c5fc81e-3e2b-4aec-a749-6fd7142d4445
2023-01-27 20:24:19,768 [IPC Server handler 2 on default port 35295] INFO  net.NetworkTopology (NetworkTopology.java:add(156)) - Adding a new node: /default-rack/127.0.0.1:33205
2023-01-27 20:24:19,769 [IPC Server handler 2 on default port 35295] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(200)) - Registered DN 2c5fc81e-3e2b-4aec-a749-6fd7142d4445 (127.0.0.1:33205).
2023-01-27 20:24:19,771 [BP-1179503178-127.0.1.1-1674825859172 heartbeating to localhost/127.0.0.1:35295] INFO  datanode.DataNode (BPServiceActor.java:register(846)) - Block pool BP-1179503178-127.0.1.1-1674825859172 (Datanode Uuid 2c5fc81e-3e2b-4aec-a749-6fd7142d4445) service to localhost/127.0.0.1:35295 successfully registered with NN: localhost/127.0.0.1:35295.
2023-01-27 20:24:19,772 [BP-1179503178-127.0.1.1-1674825859172 heartbeating to localhost/127.0.0.1:35295] INFO  datanode.DataNode (BPServiceActor.java:offerService(680)) - For namenode localhost/127.0.0.1:35295 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2023-01-27 20:24:19,772 [ibr-executor-0] INFO  datanode.DataNode (BPServiceActor.java:run(1145)) - Starting IBR Task Handler.
2023-01-27 20:24:19,775 [IPC Server handler 3 on default port 35295] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:19,776 [IPC Server handler 4 on default port 35295] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-d79fa0f2-3bc0-4162-b0ac-a2aba3f5c455 for DN 127.0.0.1:33205
2023-01-27 20:24:19,777 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2922)) - No heartbeat from DataNode: 127.0.0.1:33205
2023-01-27 20:24:19,777 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:19,777 [IPC Server handler 4 on default port 35295] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-27aba016-47b3-48f3-926a-62bf4bc4a6b5 for DN 127.0.0.1:33205
2023-01-27 20:24:19,782 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0x9d53e710121a2f54 with lease ID 0x82577cd749abd3d4: Processing first storage report for DS-d79fa0f2-3bc0-4162-b0ac-a2aba3f5c455 from datanode DatanodeRegistration(127.0.0.1:33205, datanodeUuid=2c5fc81e-3e2b-4aec-a749-6fd7142d4445, infoPort=42287, infoSecurePort=0, ipcPort=40161, storageInfo=lv=-57;cid=testClusterID;nsid=838682573;c=1674825859172)
2023-01-27 20:24:19,783 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0x9d53e710121a2f54 with lease ID 0x82577cd749abd3d4: from storage DS-d79fa0f2-3bc0-4162-b0ac-a2aba3f5c455 node DatanodeRegistration(127.0.0.1:33205, datanodeUuid=2c5fc81e-3e2b-4aec-a749-6fd7142d4445, infoPort=42287, infoSecurePort=0, ipcPort=40161, storageInfo=lv=-57;cid=testClusterID;nsid=838682573;c=1674825859172), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:19,783 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0x9d53e710121a2f54 with lease ID 0x82577cd749abd3d4: Processing first storage report for DS-27aba016-47b3-48f3-926a-62bf4bc4a6b5 from datanode DatanodeRegistration(127.0.0.1:33205, datanodeUuid=2c5fc81e-3e2b-4aec-a749-6fd7142d4445, infoPort=42287, infoSecurePort=0, ipcPort=40161, storageInfo=lv=-57;cid=testClusterID;nsid=838682573;c=1674825859172)
2023-01-27 20:24:19,783 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0x9d53e710121a2f54 with lease ID 0x82577cd749abd3d4: from storage DS-27aba016-47b3-48f3-926a-62bf4bc4a6b5 node DatanodeRegistration(127.0.0.1:33205, datanodeUuid=2c5fc81e-3e2b-4aec-a749-6fd7142d4445, infoPort=42287, infoSecurePort=0, ipcPort=40161, storageInfo=lv=-57;cid=testClusterID;nsid=838682573;c=1674825859172), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2023-01-27 20:24:19,784 [BP-1179503178-127.0.1.1-1674825859172 heartbeating to localhost/127.0.0.1:35295] INFO  datanode.DataNode (BPServiceActor.java:blockReport(464)) - Successfully sent block report 0x9d53e710121a2f54 with lease ID 0x82577cd749abd3d4 to namenode: localhost/127.0.0.1:35295,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msecs to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-01-27 20:24:19,785 [Command processor] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(763)) - Got finalize command for block pool BP-1179503178-127.0.1.1-1674825859172
2023-01-27 20:24:19,879 [IPC Server handler 6 on default port 35295] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:19,881 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:19,886 [IPC Server handler 7 on default port 35295] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:19,887 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:19,893 [qtp1715639807-278] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:19 +0000] "OPTIONS /kms/v1/keys HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:19,906 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:19,907 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:19,907 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:19,907 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:19,907 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:19,907 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:19,908 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:19,908 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:19,910 [qtp1715639807-271] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:19 +0000] "OPTIONS /kms/v1/keys?user.name=rizky HTTP/1.1" 200 520 "-" "Java/1.8.0_352"
2023-01-27 20:24:20,327 [qtp1715639807-274] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=CREATE_KEY, key=test_key, user=rizky] UserProvidedMaterial:false Description:test_key
2023-01-27 20:24:20,329 [qtp1715639807-274] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:19 +0000] "POST /kms/v1/keys HTTP/1.1" 201 98 "-" "Java/1.8.0_352"
2023-01-27 20:24:20,336 [IPC Server handler 8 on default port 35295] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:createPassword(484)) - Creating password for identifier: (token for rizky: HDFS_DELEGATION_TOKEN owner=rizky, renewer=JobTracker, realUser=, issueDate=1674825860335, maxDate=1675430660335, sequenceNumber=1, masterKeyId=2), currentKey: 2
2023-01-27 20:24:20,340 [IPC Server handler 8 on default port 35295] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDelegationToken	src=HDFS_DELEGATION_TOKEN token 1 for rizky with renewer JobTracker	dst=null	perm=null	proto=rpc
2023-01-27 20:24:20,355 [Time-limited test] INFO  hdfs.DFSClient (DFSClient.java:getDelegationToken(760)) - Created token for rizky: HDFS_DELEGATION_TOKEN owner=rizky, renewer=JobTracker, realUser=, issueDate=1674825860335, maxDate=1675430660335, sequenceNumber=1, masterKeyId=2 on 127.0.0.1:35295
2023-01-27 20:24:20,381 [qtp1715639807-277] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:20 +0000] "OPTIONS /kms/v1/?op=GETDELEGATIONTOKEN&renewer=JobTracker HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:20,386 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:20,387 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:20,387 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:20,388 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:20,388 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:20,388 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:20,388 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:20,389 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:20,390 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:20,390 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:20,390 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:20,390 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:20,391 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:20,391 [qtp1715639807-271] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:20,398 [qtp1715639807-271] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:20 +0000] "OPTIONS /kms/v1/?op=GETDELEGATIONTOKEN&renewer=JobTracker&user.name=rizky HTTP/1.1" 200 4243 "-" "Java/1.8.0_352"
2023-01-27 20:24:20,405 [qtp1715639807-273] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:createPassword(484)) - Creating password for identifier: (kms-dt owner=rizky, renewer=JobTracker, realUser=, issueDate=1674825860405, maxDate=1675430660405, sequenceNumber=1, masterKeyId=2), currentKey: 2
2023-01-27 20:24:20,414 [qtp1715639807-273] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:20 +0000] "GET /kms/v1/?op=GETDELEGATIONTOKEN&renewer=JobTracker HTTP/1.1" 200 113 "-" "Java/1.8.0_352"
2023-01-27 20:24:20,423 [Time-limited test] INFO  kms.KMSClientProvider (KMSClientProvider.java:getDelegationToken(1041)) - New token created: (Kind: kms-dt, Service: kms://http@localhost:45997/kms, Ident: (kms-dt owner=rizky, renewer=JobTracker, realUser=, issueDate=1674825860405, maxDate=1675430660405, sequenceNumber=1, masterKeyId=2))
2023-01-27 20:24:20,424 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2159)) - Shutting down the Mini HDFS Cluster
2023-01-27 20:24:20,425 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2208)) - Shutting down DataNode 0
2023-01-27 20:24:20,425 [Time-limited test] INFO  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(430)) - Shutdown has been called
2023-01-27 20:24:20,425 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1de8da6e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(395)) - Closing all peers.
2023-01-27 20:24:20,426 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-d79fa0f2-3bc0-4162-b0ac-a2aba3f5c455) exiting.
2023-01-27 20:24:20,427 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-27aba016-47b3-48f3-926a-62bf4bc4a6b5) exiting.
2023-01-27 20:24:20,444 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@58805e98{datanode,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:20,445 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@383222fd{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:20,445 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:20,446 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@38aeb298{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:20,446 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@670c9eaf{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:20,448 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2470)) - Waiting up to 30 seconds for transfer threads to complete
2023-01-27 20:24:20,449 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 40161
2023-01-27 20:24:20,455 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:20,456 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:20,457 [BP-1179503178-127.0.1.1-1674825859172 heartbeating to localhost/127.0.0.1:35295] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:20,457 [Command processor] ERROR datanode.DataNode (BPServiceActor.java:processQueue(1430)) - Command processor encountered interrupt and exit.
2023-01-27 20:24:20,457 [BP-1179503178-127.0.1.1-1674825859172 heartbeating to localhost/127.0.0.1:35295] WARN  datanode.DataNode (BPServiceActor.java:run(924)) - Ending block pool service for: Block pool BP-1179503178-127.0.1.1-1674825859172 (Datanode Uuid 2c5fc81e-3e2b-4aec-a749-6fd7142d4445) service to localhost/127.0.0.1:35295
2023-01-27 20:24:20,457 [ibr-executor-0] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:20,457 [BP-1179503178-127.0.1.1-1674825859172 heartbeating to localhost/127.0.0.1:35295] INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-1179503178-127.0.1.1-1674825859172 (Datanode Uuid 2c5fc81e-3e2b-4aec-a749-6fd7142d4445)
2023-01-27 20:24:20,457 [BP-1179503178-127.0.1.1-1674825859172 heartbeating to localhost/127.0.0.1:35295] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(3225)) - Removing block pool BP-1179503178-127.0.1.1-1674825859172
2023-01-27 20:24:20,457 [Command processor] WARN  datanode.DataNode (BPServiceActor.java:run(1414)) - Ending command processor service for: Thread[Command processor,5,main]
2023-01-27 20:24:20,458 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1179503178-127.0.1.1-1674825859172] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:20,458 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1179503178-127.0.1.1-1674825859172] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:20,459 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(208)) - Shutting down all async disk service threads
2023-01-27 20:24:20,459 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(216)) - All async disk service threads have been shut down
2023-01-27 20:24:20,460 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(186)) - Shutting down all async lazy persist service threads
2023-01-27 20:24:20,460 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(193)) - All async lazy persist service threads have been shut down
2023-01-27 20:24:20,461 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2559)) - Shutdown complete.
2023-01-27 20:24:20,461 [Time-limited test] WARN  datanode.DataSetLockManager (DataSetLockManager.java:lockLeakCheck(260)) - not open lock leak check func
2023-01-27 20:24:20,461 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2241)) - Shutting down the namenode
2023-01-27 20:24:20,461 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:20,461 [Thread[Thread-198,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:20,461 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1467)) - Ending log segment 1, 4
2023-01-27 20:24:20,462 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3ea15f6d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4561)) - NameNodeEditLogRoller was interrupted, exiting
2023-01-27 20:24:20,462 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@17ab8a8e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4658)) - LazyPersistFileScrubber was interrupted, exiting
2023-01-27 20:24:20,462 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(576)) - EDEKCacheLoader interrupted before warming up.
2023-01-27 20:24:20,464 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(801)) - Number of transactions: 5 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 11 9 
2023-01-27 20:24:20,464 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000005
2023-01-27 20:24:20,465 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000005
2023-01-27 20:24:20,465 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(276)) - FSEditLogAsync was interrupted, exiting
2023-01-27 20:24:20,465 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(267)) - Re-encryption updater thread interrupted. Exiting.
2023-01-27 20:24:20,465 [CacheReplicationMonitor(630789407)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2023-01-27 20:24:20,465 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(335)) - Re-encrypt handler interrupted. Exiting
2023-01-27 20:24:20,467 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 35295
2023-01-27 20:24:20,470 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:20,472 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:20,472 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5134)) - Stopping MarkedDeleteBlockScrubber.
2023-01-27 20:24:20,472 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(5160)) - Stopping RedundancyMonitor.
2023-01-27 20:24:20,479 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:20,479 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:20,480 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@1fa77f61{hdfs,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:20,481 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@41aed265{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:20,481 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:20,482 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@630440e6{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:20,482 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@69c0816f{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:20,487 [Thread[Thread-166,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:20,489 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextDestroyed(197)) - KMS Stopped
2023-01-27 20:24:20,489 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@7bb94a49{kms,/,null,STOPPED}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:20,490 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@2360fe17{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:20,491 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:20,491 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@6289fb40{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-27 20:24:20,491 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@b0b0354{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:20,492 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2023-01-27 20:24:20,493 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2023-01-27 20:24:20,493 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(612)) - DataNode metrics system shutdown complete.
2023-01-27 20:24:20,531 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:20,532 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context kms
2023-01-27 20:24:20,532 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:20,532 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:20,532 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:20,533 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 36537
2023-01-27 20:24:20,533 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:20,540 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:20,540 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:20,541 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:20,541 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@79c7b99e{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:20,542 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@acc33ef{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-27 20:24:20,572 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(94)) - -------------------------------------------------------------
2023-01-27 20:24:20,573 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(95)) -   Java runtime version : 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:20,573 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(97)) -   User: rizky
2023-01-27 20:24:20,573 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(98)) -   KMS Hadoop Version: 3.4.0-SNAPSHOT
2023-01-27 20:24:20,573 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(99)) - -------------------------------------------------------------
2023-01-27 20:24:20,574 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'CREATE' ACL '*'
2023-01-27 20:24:20,574 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DELETE' ACL '*'
2023-01-27 20:24:20,574 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'ROLLOVER' ACL '*'
2023-01-27 20:24:20,574 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET' ACL '*'
2023-01-27 20:24:20,575 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_KEYS' ACL '*'
2023-01-27 20:24:20,575 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_METADATA' ACL '*'
2023-01-27 20:24:20,575 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'SET_KEY_MATERIAL' ACL '*'
2023-01-27 20:24:20,575 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GENERATE_EEK' ACL '*'
2023-01-27 20:24:20,575 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DECRYPT_EEK' ACL '*'
2023-01-27 20:24:20,575 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2023-01-27 20:24:20,576 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2023-01-27 20:24:20,576 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2023-01-27 20:24:20,576 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2023-01-27 20:24:20,578 [Time-limited test] INFO  server.KMSAudit (KMSAudit.java:initializeAuditLoggers(157)) - Initializing audit logger class org.apache.hadoop.crypto.key.kms.server.SimpleKMSAuditLogger
2023-01-27 20:24:20,579 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(149)) - Initialized KeyProvider CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/c0c89f6d-6904-4a7f-b041-e74254d9170a/kms.keystore
2023-01-27 20:24:20,581 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(163)) - Initialized KeyProviderCryptoExtension org.apache.hadoop.crypto.key.kms.server.KeyAuthorizationKeyProvider: EagerKeyGeneratorKeyProviderCryptoExtension: KeyProviderCryptoExtension: CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/c0c89f6d-6904-4a7f-b041-e74254d9170a/kms.keystore
2023-01-27 20:24:20,581 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(168)) - Default key bitlength is 128
2023-01-27 20:24:20,581 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(169)) - KMS Started
2023-01-27 20:24:20,583 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:20,586 [Thread[Thread-269,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:20,586 [Thread[Thread-269,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:20,590 [Time-limited test] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.crypto.key.kms.server
2023-01-27 20:24:20,616 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMS
2023-01-27 20:24:20,617 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
  class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
2023-01-27 20:24:20,622 [Time-limited test] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:24:20,808 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@25be0fcb{kms,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/2/kms/webapp/,AVAILABLE}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:20,810 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@53ec55ad{HTTP/1.1, (http/1.1)}{localhost:36537}
2023-01-27 20:24:20,811 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @25833ms
2023-01-27 20:24:20,813 [Time-limited test] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(120)) - Loaded properties from hadoop-metrics2.properties
2023-01-27 20:24:20,815 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 0 second(s).
2023-01-27 20:24:20,815 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - KMS metrics system started
2023-01-27 20:24:20,828 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5ea9e5f6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:20,839 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(566)) - starting cluster: numNameNodes=1, numDataNodes=1
2023-01-27 20:24:20,841 [Time-limited test] INFO  namenode.NameNode (NameNode.java:format(1366)) - Formatting using clusterid: testClusterID
2023-01-27 20:24:20,842 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:20,855 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@2b6964a2
2023-01-27 20:24:20,855 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:20,855 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:20,856 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:20,856 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:20,856 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:20,856 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:20,856 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:20,857 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:20,857 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:20,857 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:20,857 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:20,858 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:20
2023-01-27 20:24:20,858 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:20,858 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:20,858 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:20,858 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:20,861 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:20,861 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:20,861 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:20,861 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:20,861 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:20,861 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:20,861 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:20,862 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:20,862 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:20,862 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:20,862 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:20,862 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:20,862 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:20,862 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:20,862 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:20,863 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:20,863 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:20,865 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:20,866 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:20,866 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:20,866 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:20,866 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:20,866 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:20,866 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:20,867 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:20,867 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:20,867 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:20,867 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:20,867 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:20,868 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:20,868 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:20,868 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:20,869 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:20,869 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:20,869 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:20,869 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:20,870 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:20,870 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:20,871 [Time-limited test] INFO  namenode.FSImage (FSImage.java:format(186)) - Allocated new BlockPoolId: BP-1612380037-127.0.1.1-1674825860871
2023-01-27 20:24:20,875 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 has been successfully formatted.
2023-01-27 20:24:20,877 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 has been successfully formatted.
2023-01-27 20:24:20,891 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:20,892 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:20,896 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 436 bytes saved in 0 seconds .
2023-01-27 20:24:20,900 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 436 bytes saved in 0 seconds .
2023-01-27 20:24:20,903 [Time-limited test] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(202)) - Going to retain 1 images with txid >= 0
2023-01-27 20:24:20,913 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:20,913 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:20,920 [Time-limited test] INFO  namenode.NameNode (NameNode.java:createNameNode(1824)) - createNameNode []
2023-01-27 20:24:20,920 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2023-01-27 20:24:20,921 [Time-limited test] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2023-01-27 20:24:20,936 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@16371494] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:20,936 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1736)) - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2023-01-27 20:24:20,936 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1758)) - Starting Web-server for hdfs at: http://localhost:0
2023-01-27 20:24:20,936 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:20,938 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:20,940 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:20,942 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:20,942 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-01-27 20:24:20,943 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:20,943 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:20,944 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2023-01-27 20:24:20,944 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2023-01-27 20:24:20,944 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2023-01-27 20:24:20,944 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:20,945 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(1018)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-01-27 20:24:20,945 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 38121
2023-01-27 20:24:20,945 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:20,946 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:20,947 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:20,947 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:24:20,949 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:20,949 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@14c7492c{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:20,950 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4b629722{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:20,955 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@1746b233{hdfs,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:20,958 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@70d25944{HTTP/1.1, (http/1.1)}{localhost:38121}
2023-01-27 20:24:20,958 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @25980ms
2023-01-27 20:24:20,960 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:20,975 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@16d81f14
2023-01-27 20:24:20,976 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:20,976 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:20,976 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:20,976 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:20,976 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:20,976 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:20,976 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:20,977 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:20,977 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:20,977 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:20,977 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:20,978 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:20
2023-01-27 20:24:20,978 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:20,978 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:20,978 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:20,978 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:20,980 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:20,980 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:20,980 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:20,980 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:20,981 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:20,981 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:20,981 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:20,981 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:20,981 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:20,981 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:20,981 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:20,981 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:20,981 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:20,982 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:20,982 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:20,982 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:20,982 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:20,983 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:20,983 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:20,983 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:20,983 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:20,983 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:20,984 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:20,984 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:20,984 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:20,984 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:20,984 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:20,984 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:20,984 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:20,985 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:20,985 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:20,985 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:20,985 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:20,985 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:20,985 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:20,986 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:20,986 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:20,986 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:20,988 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:20,990 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:20,992 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current
2023-01-27 20:24:20,992 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current
2023-01-27 20:24:20,992 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(734)) - No edit log streams selected.
2023-01-27 20:24:20,993 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(800)) - Planning to load image: FSImageFile(file=/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-01-27 20:24:20,994 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSectionHeader(411)) - Loading 1 INodes.
2023-01-27 20:24:20,994 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(369)) - Successfully loaded 1 inodes
2023-01-27 20:24:20,995 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:waitBlocksMapAndNameCacheUpdateFinished(342)) - Completed update blocks map and name cache, total waiting duration 0ms.
2023-01-27 20:24:20,995 [Time-limited test] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(255)) - Loaded FSImage in 0 seconds.
2023-01-27 20:24:20,995 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(980)) - Loaded image for txid 0 from /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000
2023-01-27 20:24:20,995 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1271)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-01-27 20:24:20,996 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1417)) - Starting log segment at 1
2023-01-27 20:24:21,013 [Time-limited test] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2023-01-27 20:24:21,013 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(836)) - Finished loading FSImage in 26 msecs
2023-01-27 20:24:21,014 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(451)) - RPC server is binding to localhost:0
2023-01-27 20:24:21,014 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(456)) - Enable NameNode state context:false
2023-01-27 20:24:21,014 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:21,014 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:35385
2023-01-27 20:24:21,015 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:21,018 [Time-limited test] INFO  namenode.NameNode (NameNode.java:initialize(893)) - Clients are to use localhost:35385 to access this namenode/service.
2023-01-27 20:24:21,019 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5607)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2023-01-27 20:24:21,038 [Time-limited test] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(166)) - Number of blocks under construction: 0
2023-01-27 20:24:21,039 [Time-limited test] INFO  blockmanagement.DatanodeAdminDefaultMonitor (DatanodeAdminDefaultMonitor.java:processConf(126)) - Initialized the Default Decommission and Maintenance monitor
2023-01-27 20:24:21,040 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(5310)) - initializing replication queues
2023-01-27 20:24:21,040 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(409)) - STATE* Leaving safe mode after 0 secs
2023-01-27 20:24:21,041 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5102)) - Start MarkedDeleteBlockScrubber thread
2023-01-27 20:24:21,041 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(415)) - STATE* Network topology has 0 racks and 0 datanodes
2023-01-27 20:24:21,041 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(417)) - STATE* UnderReplicatedBlocks has 0 blocks
2023-01-27 20:24:21,042 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:21,049 [Thread[Thread-301,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:21,049 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3870)) - Total number of blocks            = 0
2023-01-27 20:24:21,051 [Thread[Thread-301,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:21,051 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3871)) - Number of invalid blocks          = 0
2023-01-27 20:24:21,052 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3872)) - Number of under-replicated blocks = 0
2023-01-27 20:24:21,052 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3873)) - Number of  over-replicated blocks = 0
2023-01-27 20:24:21,052 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3875)) - Number of blocks being written    = 0
2023-01-27 20:24:21,052 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3878)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2023-01-27 20:24:21,054 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:21,054 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:21,068 [Time-limited test] INFO  namenode.NameNode (NameNode.java:startCommonServices(1010)) - NameNode RPC up at: localhost/127.0.0.1:35385
2023-01-27 20:24:21,068 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1383)) - Starting services required for active state
2023-01-27 20:24:21,068 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(857)) - Initializing quota with 12 thread(s)
2023-01-27 20:24:21,069 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(866)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2023-01-27 20:24:21,070 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(326)) - Starting up re-encrypt thread with interval=60000 millisecond.
2023-01-27 20:24:21,074 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1769)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1,[DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:21,072 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2023-01-27 20:24:21,071 [CacheReplicationMonitor(971774911)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-01-27 20:24:21,086 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:21,087 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:21,104 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2023-01-27 20:24:21,104 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:21,104 [Time-limited test] INFO  datanode.BlockScanner (BlockScanner.java:<init>(201)) - Initialized block scanner with targetBytesPerSec 1048576
2023-01-27 20:24:21,105 [Time-limited test] INFO  datanode.DataNode (DataNode.java:<init>(571)) - Configured hostname is 127.0.0.1
2023-01-27 20:24:21,105 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:21,105 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1788)) - Starting DataNode with maxLockedMemory = 0
2023-01-27 20:24:21,106 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1551)) - Opened streaming server at /127.0.0.1:40369
2023-01-27 20:24:21,106 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(93)) - Balancing bandwidth is 104857600 bytes/s
2023-01-27 20:24:21,106 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(94)) - Number threads for balancing is 100
2023-01-27 20:24:21,107 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:21,109 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:21,111 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:21,114 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:21,115 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-01-27 20:24:21,115 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:21,115 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:21,115 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:21,116 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 45275
2023-01-27 20:24:21,117 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:21,118 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:21,118 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:21,118 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:21,119 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@16b15572{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:21,120 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7c33980d{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:21,124 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@6e520c04{datanode,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:21,126 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@27265045{HTTP/1.1, (http/1.1)}{localhost:45275}
2023-01-27 20:24:21,126 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @26148ms
2023-01-27 20:24:21,131 [Time-limited test] WARN  web.DatanodeHttpServer (RestCsrfPreventionFilterHandler.java:<init>(75)) - Got null for restCsrfPreventionFilter - will not do any filtering.
2023-01-27 20:24:21,133 [Time-limited test] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(306)) - Listening HTTP traffic on /127.0.0.1:37147
2023-01-27 20:24:21,133 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1816)) - dnUserName = rizky
2023-01-27 20:24:21,133 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a4efa98] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:21,133 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1817)) - supergroup = supergroup
2023-01-27 20:24:21,134 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:21,134 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:46845
2023-01-27 20:24:21,135 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:21,138 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initIpcServer(1438)) - Opened IPC server at /127.0.0.1:46845
2023-01-27 20:24:21,153 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(150)) - Refresh request received for nameservices: null
2023-01-27 20:24:21,153 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(211)) - Starting BPOfferServices for nameservices: <default>
2023-01-27 20:24:21,155 [Thread-334] INFO  datanode.DataNode (BPServiceActor.java:run(877)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35385 starting to offer service
2023-01-27 20:24:21,156 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:21,156 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:21,168 [Thread-334] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(382)) - Acknowledging ACTIVE Namenode during handshake Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35385
2023-01-27 20:24:21,172 [Thread-334] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(356)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2023-01-27 20:24:21,175 [Thread-334] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:21,175 [Thread-334] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 is not formatted for namespace 746922497. Formatting...
2023-01-27 20:24:21,175 [Thread-334] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ddd6e98a-0994-477d-8a3d-b507800ffaaf for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 
2023-01-27 20:24:21,179 [IPC Server handler 1 on default port 35385] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:21,181 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:21,181 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:21,181 [Thread-334] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:21,181 [Thread-334] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 is not formatted for namespace 746922497. Formatting...
2023-01-27 20:24:21,182 [Thread-334] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-60180925-eccc-4cac-ae5c-e88fac35cde8 for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 
2023-01-27 20:24:21,208 [Thread-334] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-1612380037-127.0.1.1-1674825860871
2023-01-27 20:24:21,208 [Thread-334] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1612380037-127.0.1.1-1674825860871
2023-01-27 20:24:21,208 [Thread-334] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 and block pool id BP-1612380037-127.0.1.1-1674825860871 is not formatted. Formatting ...
2023-01-27 20:24:21,208 [Thread-334] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-1612380037-127.0.1.1-1674825860871 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1612380037-127.0.1.1-1674825860871/current
2023-01-27 20:24:21,225 [Thread-334] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-1612380037-127.0.1.1-1674825860871
2023-01-27 20:24:21,225 [Thread-334] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1612380037-127.0.1.1-1674825860871
2023-01-27 20:24:21,225 [Thread-334] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 and block pool id BP-1612380037-127.0.1.1-1674825860871 is not formatted. Formatting ...
2023-01-27 20:24:21,225 [Thread-334] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-1612380037-127.0.1.1-1674825860871 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1612380037-127.0.1.1-1674825860871/current
2023-01-27 20:24:21,228 [Thread-334] INFO  datanode.DataNode (DataNode.java:initStorage(2136)) - Setting up storage: nsid=746922497;bpid=BP-1612380037-127.0.1.1-1674825860871;lv=-57;nsInfo=lv=-67;cid=testClusterID;nsid=746922497;c=1674825860871;bpid=BP-1612380037-127.0.1.1-1674825860871;dnuuid=null
2023-01-27 20:24:21,230 [Thread-334] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1934)) - Generated and persisted new Datanode UUID 3c23e944-e245-40e2-a566-7fb4ab1309b9
2023-01-27 20:24:21,231 [Thread-334] INFO  fsdataset.RoundRobinVolumeChoosingPolicy (RoundRobinVolumeChoosingPolicy.java:setConf(67)) - Round robin volume choosing policy initialized: dfs.datanode.round-robin-volume-choosing-policy.additional-available-space = 0
2023-01-27 20:24:21,234 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-ddd6e98a-0994-477d-8a3d-b507800ffaaf
2023-01-27 20:24:21,234 [Thread-334] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, StorageType: DISK
2023-01-27 20:24:21,236 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-60180925-eccc-4cac-ae5c-e88fac35cde8
2023-01-27 20:24:21,236 [Thread-334] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, StorageType: DISK
2023-01-27 20:24:21,237 [Thread-334] INFO  impl.MemoryMappableBlockLoader (MemoryMappableBlockLoader.java:initialize(47)) - Initializing cache loader: MemoryMappableBlockLoader.
2023-01-27 20:24:21,237 [Thread-334] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2611)) - Registered FSDatasetState MBean
2023-01-27 20:24:21,238 [Thread-334] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(3188)) - Adding block pool BP-1612380037-127.0.1.1-1674825860871
2023-01-27 20:24:21,239 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-1612380037-127.0.1.1-1674825860871 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:21,239 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-1612380037-127.0.1.1-1674825860871 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:21,239 [Thread-352] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1612380037-127.0.1.1-1674825860871/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:21,239 [Thread-351] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1612380037-127.0.1.1-1674825860871/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:21,255 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-1612380037-127.0.1.1-1674825860871 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 16ms
2023-01-27 20:24:21,261 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-1612380037-127.0.1.1-1674825860871 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 22ms
2023-01-27 20:24:21,261 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(538)) - Total time to scan all replicas for block pool BP-1612380037-127.0.1.1-1674825860871: 23ms
2023-01-27 20:24:21,261 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-1612380037-127.0.1.1-1674825860871 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:21,261 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-1612380037-127.0.1.1-1674825860871 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:21,261 [Thread-355] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1612380037-127.0.1.1-1674825860871/current/replicas doesn't exist 
2023-01-27 20:24:21,262 [Thread-356] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1612380037-127.0.1.1-1674825860871/current/replicas doesn't exist 
2023-01-27 20:24:21,262 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-1612380037-127.0.1.1-1674825860871 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 0ms
2023-01-27 20:24:21,262 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-1612380037-127.0.1.1-1674825860871 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 0ms
2023-01-27 20:24:21,262 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(292)) - Total time to add all replicas to map for block pool BP-1612380037-127.0.1.1-1674825860871: 1ms
2023-01-27 20:24:21,262 [Thread-334] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:21,262 [Thread-334] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:21,262 [Thread-334] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:21,263 [Thread-334] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:21,264 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-1612380037-127.0.1.1-1674825860871 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:21,264 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-1612380037-127.0.1.1-1674825860871 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:21,264 [Thread-334] WARN  datanode.DirectoryScanner (DirectoryScanner.java:<init>(302)) - dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2023-01-27 20:24:21,264 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-60180925-eccc-4cac-ae5c-e88fac35cde8): finished scanning block pool BP-1612380037-127.0.1.1-1674825860871
2023-01-27 20:24:21,264 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-ddd6e98a-0994-477d-8a3d-b507800ffaaf): finished scanning block pool BP-1612380037-127.0.1.1-1674825860871
2023-01-27 20:24:21,264 [Thread-334] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(367)) - Periodic Directory Tree Verification scan starting in 16846864ms with interval of 21600000ms and throttle limit of -1ms/s
2023-01-27 20:24:21,265 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-60180925-eccc-4cac-ae5c-e88fac35cde8): no suitable block pools found to scan.  Waiting 1814399999 ms.
2023-01-27 20:24:21,265 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-ddd6e98a-0994-477d-8a3d-b507800ffaaf): no suitable block pools found to scan.  Waiting 1814399999 ms.
2023-01-27 20:24:21,265 [BP-1612380037-127.0.1.1-1674825860871 heartbeating to localhost/127.0.0.1:35385] INFO  datanode.DataNode (BPServiceActor.java:register(819)) - Block pool BP-1612380037-127.0.1.1-1674825860871 (Datanode Uuid 3c23e944-e245-40e2-a566-7fb4ab1309b9) service to localhost/127.0.0.1:35385 beginning handshake with NN: localhost/127.0.0.1:35385.
2023-01-27 20:24:21,271 [IPC Server handler 2 on default port 35385] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1166)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40369, datanodeUuid=3c23e944-e245-40e2-a566-7fb4ab1309b9, infoPort=37147, infoSecurePort=0, ipcPort=46845, storageInfo=lv=-57;cid=testClusterID;nsid=746922497;c=1674825860871) storage 3c23e944-e245-40e2-a566-7fb4ab1309b9
2023-01-27 20:24:21,271 [IPC Server handler 2 on default port 35385] INFO  net.NetworkTopology (NetworkTopology.java:add(156)) - Adding a new node: /default-rack/127.0.0.1:40369
2023-01-27 20:24:21,271 [IPC Server handler 2 on default port 35385] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(200)) - Registered DN 3c23e944-e245-40e2-a566-7fb4ab1309b9 (127.0.0.1:40369).
2023-01-27 20:24:21,273 [BP-1612380037-127.0.1.1-1674825860871 heartbeating to localhost/127.0.0.1:35385] INFO  datanode.DataNode (BPServiceActor.java:register(846)) - Block pool BP-1612380037-127.0.1.1-1674825860871 (Datanode Uuid 3c23e944-e245-40e2-a566-7fb4ab1309b9) service to localhost/127.0.0.1:35385 successfully registered with NN: localhost/127.0.0.1:35385.
2023-01-27 20:24:21,274 [BP-1612380037-127.0.1.1-1674825860871 heartbeating to localhost/127.0.0.1:35385] INFO  datanode.DataNode (BPServiceActor.java:offerService(680)) - For namenode localhost/127.0.0.1:35385 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2023-01-27 20:24:21,274 [ibr-executor-0] INFO  datanode.DataNode (BPServiceActor.java:run(1145)) - Starting IBR Task Handler.
2023-01-27 20:24:21,276 [IPC Server handler 3 on default port 35385] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-ddd6e98a-0994-477d-8a3d-b507800ffaaf for DN 127.0.0.1:40369
2023-01-27 20:24:21,276 [IPC Server handler 3 on default port 35385] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-60180925-eccc-4cac-ae5c-e88fac35cde8 for DN 127.0.0.1:40369
2023-01-27 20:24:21,279 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0xb49cffa08693a76a with lease ID 0x8cb8ee199c3db7b: Processing first storage report for DS-60180925-eccc-4cac-ae5c-e88fac35cde8 from datanode DatanodeRegistration(127.0.0.1:40369, datanodeUuid=3c23e944-e245-40e2-a566-7fb4ab1309b9, infoPort=37147, infoSecurePort=0, ipcPort=46845, storageInfo=lv=-57;cid=testClusterID;nsid=746922497;c=1674825860871)
2023-01-27 20:24:21,279 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0xb49cffa08693a76a with lease ID 0x8cb8ee199c3db7b: from storage DS-60180925-eccc-4cac-ae5c-e88fac35cde8 node DatanodeRegistration(127.0.0.1:40369, datanodeUuid=3c23e944-e245-40e2-a566-7fb4ab1309b9, infoPort=37147, infoSecurePort=0, ipcPort=46845, storageInfo=lv=-57;cid=testClusterID;nsid=746922497;c=1674825860871), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2023-01-27 20:24:21,280 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0xb49cffa08693a76a with lease ID 0x8cb8ee199c3db7b: Processing first storage report for DS-ddd6e98a-0994-477d-8a3d-b507800ffaaf from datanode DatanodeRegistration(127.0.0.1:40369, datanodeUuid=3c23e944-e245-40e2-a566-7fb4ab1309b9, infoPort=37147, infoSecurePort=0, ipcPort=46845, storageInfo=lv=-57;cid=testClusterID;nsid=746922497;c=1674825860871)
2023-01-27 20:24:21,280 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0xb49cffa08693a76a with lease ID 0x8cb8ee199c3db7b: from storage DS-ddd6e98a-0994-477d-8a3d-b507800ffaaf node DatanodeRegistration(127.0.0.1:40369, datanodeUuid=3c23e944-e245-40e2-a566-7fb4ab1309b9, infoPort=37147, infoSecurePort=0, ipcPort=46845, storageInfo=lv=-57;cid=testClusterID;nsid=746922497;c=1674825860871), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:21,282 [BP-1612380037-127.0.1.1-1674825860871 heartbeating to localhost/127.0.0.1:35385] INFO  datanode.DataNode (BPServiceActor.java:blockReport(464)) - Successfully sent block report 0xb49cffa08693a76a with lease ID 0x8cb8ee199c3db7b to namenode: localhost/127.0.0.1:35385,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msecs to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-01-27 20:24:21,282 [Command processor] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(763)) - Got finalize command for block pool BP-1612380037-127.0.1.1-1674825860871
2023-01-27 20:24:21,284 [IPC Server handler 4 on default port 35385] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:21,285 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:21,288 [IPC Server handler 6 on default port 35385] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:21,289 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:21,295 [qtp812879896-457] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:21 +0000] "OPTIONS /kms/v1/keys HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:21,303 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:21,303 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:21,304 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:21,304 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:21,304 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:21,304 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:21,304 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:21,305 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:21,307 [qtp812879896-451] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:21 +0000] "OPTIONS /kms/v1/keys?user.name=rizky HTTP/1.1" 200 520 "-" "Java/1.8.0_352"
2023-01-27 20:24:21,673 [qtp812879896-452] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=CREATE_KEY, key=test_key, user=rizky] UserProvidedMaterial:false Description:test_key
2023-01-27 20:24:21,675 [qtp812879896-452] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:21 +0000] "POST /kms/v1/keys HTTP/1.1" 201 98 "-" "Java/1.8.0_352"
2023-01-27 20:24:21,696 [qtp1315313072-483] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.namenode.web.resources
  org.apache.hadoop.hdfs.web.resources
2023-01-27 20:24:21,951 [qtp1315313072-483] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods
2023-01-27 20:24:21,952 [qtp1315313072-483] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
  class org.apache.hadoop.hdfs.web.resources.UserProvider
2023-01-27 20:24:21,954 [qtp1315313072-483] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:24:22,201 [qtp1315313072-483] WARN  inject.Errors (Errors.java:processErrorMessages(173)) - The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam,org.apache.hadoop.hdfs.web.resources.NameSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageTypeParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.SnapshotDiffStartPathParam,org.apache.hadoop.hdfs.web.resources.SnapshotDiffIndexParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2023-01-27 20:24:22,218 [IPC Server handler 2 on default port 35385] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:createPassword(484)) - Creating password for identifier: (token for rizky: HDFS_DELEGATION_TOKEN owner=rizky, renewer=JobTracker, realUser=, issueDate=1674825862218, maxDate=1675430662218, sequenceNumber=1, masterKeyId=2), currentKey: 2
2023-01-27 20:24:22,219 [IPC Server handler 2 on default port 35385] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDelegationToken	src=HDFS_DELEGATION_TOKEN token 1 for rizky with renewer JobTracker	dst=null	perm=null	proto=webhdfs
2023-01-27 20:24:22,226 [qtp1315313072-483] INFO  requests.namenode (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:21 +0000] "GET /webhdfs/v1/?op=GETDELEGATIONTOKEN&user.name=rizky&renewer=JobTracker HTTP/1.1" 200 149 "-" "Java/1.8.0_352"
2023-01-27 20:24:22,268 [qtp1315313072-479] INFO  requests.namenode (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:22 +0000] "GET /webhdfs/v1/?op=GETSERVERDEFAULTS&user.name=rizky HTTP/1.1" 200 269 "-" "Java/1.8.0_352"
2023-01-27 20:24:22,424 [qtp812879896-455] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:22 +0000] "OPTIONS /kms/v1/?op=GETDELEGATIONTOKEN&renewer=JobTracker HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:22,442 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:22,443 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:22,443 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:22,444 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:22,444 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:22,444 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:22,444 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:22,446 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:22,446 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:22,448 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:22,448 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:22,449 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:22,449 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:22,450 [qtp812879896-451] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:22,456 [qtp812879896-451] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:22 +0000] "OPTIONS /kms/v1/?op=GETDELEGATIONTOKEN&renewer=JobTracker&user.name=rizky HTTP/1.1" 200 4243 "-" "Java/1.8.0_352"
2023-01-27 20:24:22,472 [qtp812879896-453] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:createPassword(484)) - Creating password for identifier: (kms-dt owner=rizky, renewer=JobTracker, realUser=, issueDate=1674825862472, maxDate=1675430662472, sequenceNumber=1, masterKeyId=2), currentKey: 2
2023-01-27 20:24:22,474 [qtp812879896-453] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:22 +0000] "GET /kms/v1/?op=GETDELEGATIONTOKEN&renewer=JobTracker HTTP/1.1" 200 113 "-" "Java/1.8.0_352"
2023-01-27 20:24:22,477 [Time-limited test] INFO  kms.KMSClientProvider (KMSClientProvider.java:getDelegationToken(1041)) - New token created: (Kind: kms-dt, Service: kms://http@localhost:36537/kms, Ident: (kms-dt owner=rizky, renewer=JobTracker, realUser=, issueDate=1674825862472, maxDate=1675430662472, sequenceNumber=1, masterKeyId=2))
2023-01-27 20:24:22,478 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2159)) - Shutting down the Mini HDFS Cluster
2023-01-27 20:24:22,478 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2208)) - Shutting down DataNode 0
2023-01-27 20:24:22,479 [Time-limited test] INFO  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(430)) - Shutdown has been called
2023-01-27 20:24:22,480 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7602a210] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(395)) - Closing all peers.
2023-01-27 20:24:22,484 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-60180925-eccc-4cac-ae5c-e88fac35cde8) exiting.
2023-01-27 20:24:22,484 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-ddd6e98a-0994-477d-8a3d-b507800ffaaf) exiting.
2023-01-27 20:24:22,521 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@6e520c04{datanode,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:22,525 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@27265045{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:22,525 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:22,525 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7c33980d{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:22,526 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@16b15572{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:22,533 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2470)) - Waiting up to 30 seconds for transfer threads to complete
2023-01-27 20:24:22,533 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 46845
2023-01-27 20:24:22,536 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:22,536 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:22,536 [Command processor] ERROR datanode.DataNode (BPServiceActor.java:processQueue(1430)) - Command processor encountered interrupt and exit.
2023-01-27 20:24:22,537 [Command processor] WARN  datanode.DataNode (BPServiceActor.java:run(1414)) - Ending command processor service for: Thread[Command processor,5,main]
2023-01-27 20:24:22,536 [ibr-executor-0] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:22,537 [BP-1612380037-127.0.1.1-1674825860871 heartbeating to localhost/127.0.0.1:35385] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:22,537 [BP-1612380037-127.0.1.1-1674825860871 heartbeating to localhost/127.0.0.1:35385] WARN  datanode.DataNode (BPServiceActor.java:run(924)) - Ending block pool service for: Block pool BP-1612380037-127.0.1.1-1674825860871 (Datanode Uuid 3c23e944-e245-40e2-a566-7fb4ab1309b9) service to localhost/127.0.0.1:35385
2023-01-27 20:24:22,537 [BP-1612380037-127.0.1.1-1674825860871 heartbeating to localhost/127.0.0.1:35385] INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-1612380037-127.0.1.1-1674825860871 (Datanode Uuid 3c23e944-e245-40e2-a566-7fb4ab1309b9)
2023-01-27 20:24:22,537 [BP-1612380037-127.0.1.1-1674825860871 heartbeating to localhost/127.0.0.1:35385] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(3225)) - Removing block pool BP-1612380037-127.0.1.1-1674825860871
2023-01-27 20:24:22,538 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1612380037-127.0.1.1-1674825860871] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:22,538 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1612380037-127.0.1.1-1674825860871] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:22,541 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(208)) - Shutting down all async disk service threads
2023-01-27 20:24:22,541 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(216)) - All async disk service threads have been shut down
2023-01-27 20:24:22,542 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(186)) - Shutting down all async lazy persist service threads
2023-01-27 20:24:22,542 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(193)) - All async lazy persist service threads have been shut down
2023-01-27 20:24:22,543 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2559)) - Shutdown complete.
2023-01-27 20:24:22,543 [Time-limited test] WARN  datanode.DataSetLockManager (DataSetLockManager.java:lockLeakCheck(260)) - not open lock leak check func
2023-01-27 20:24:22,543 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2241)) - Shutting down the namenode
2023-01-27 20:24:22,543 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:22,543 [Thread[Thread-301,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:22,544 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(576)) - EDEKCacheLoader interrupted before warming up.
2023-01-27 20:24:22,544 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1467)) - Ending log segment 1, 4
2023-01-27 20:24:22,544 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@19791527] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4561)) - NameNodeEditLogRoller was interrupted, exiting
2023-01-27 20:24:22,544 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@714a93a3] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4658)) - LazyPersistFileScrubber was interrupted, exiting
2023-01-27 20:24:22,547 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(801)) - Number of transactions: 5 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 12 12 
2023-01-27 20:24:22,548 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000005
2023-01-27 20:24:22,548 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000005
2023-01-27 20:24:22,548 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(276)) - FSEditLogAsync was interrupted, exiting
2023-01-27 20:24:22,549 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(267)) - Re-encryption updater thread interrupted. Exiting.
2023-01-27 20:24:22,549 [CacheReplicationMonitor(971774911)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2023-01-27 20:24:22,549 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(335)) - Re-encrypt handler interrupted. Exiting
2023-01-27 20:24:22,552 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 35385
2023-01-27 20:24:22,556 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:22,557 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:22,557 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(5160)) - Stopping RedundancyMonitor.
2023-01-27 20:24:22,557 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5134)) - Stopping MarkedDeleteBlockScrubber.
2023-01-27 20:24:22,571 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:22,572 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:22,573 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@1746b233{hdfs,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:22,575 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@70d25944{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:22,575 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:22,576 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4b629722{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:22,576 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@14c7492c{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:22,587 [Thread[Thread-269,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:22,588 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextDestroyed(197)) - KMS Stopped
2023-01-27 20:24:22,589 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@25be0fcb{kms,/,null,STOPPED}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:22,591 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@53ec55ad{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:22,591 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:22,591 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@acc33ef{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-27 20:24:22,592 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@79c7b99e{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:22,593 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2023-01-27 20:24:22,594 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2023-01-27 20:24:22,594 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(612)) - DataNode metrics system shutdown complete.
2023-01-27 20:24:22,656 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:22,657 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context kms
2023-01-27 20:24:22,657 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:22,657 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:22,657 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:22,658 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 38727
2023-01-27 20:24:22,658 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:22,660 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:22,660 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:22,661 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:22,662 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2d67c297{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:22,662 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@20d69df1{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-27 20:24:22,702 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(94)) - -------------------------------------------------------------
2023-01-27 20:24:22,702 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(95)) -   Java runtime version : 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:22,702 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(97)) -   User: rizky
2023-01-27 20:24:22,702 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(98)) -   KMS Hadoop Version: 3.4.0-SNAPSHOT
2023-01-27 20:24:22,702 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(99)) - -------------------------------------------------------------
2023-01-27 20:24:22,703 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'CREATE' ACL '*'
2023-01-27 20:24:22,704 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DELETE' ACL '*'
2023-01-27 20:24:22,704 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'ROLLOVER' ACL '*'
2023-01-27 20:24:22,704 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET' ACL '*'
2023-01-27 20:24:22,704 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_KEYS' ACL '*'
2023-01-27 20:24:22,705 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_METADATA' ACL '*'
2023-01-27 20:24:22,705 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'SET_KEY_MATERIAL' ACL '*'
2023-01-27 20:24:22,705 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GENERATE_EEK' ACL '*'
2023-01-27 20:24:22,705 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DECRYPT_EEK' ACL '*'
2023-01-27 20:24:22,705 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2023-01-27 20:24:22,706 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2023-01-27 20:24:22,706 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2023-01-27 20:24:22,706 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2023-01-27 20:24:22,708 [Time-limited test] INFO  server.KMSAudit (KMSAudit.java:initializeAuditLoggers(157)) - Initializing audit logger class org.apache.hadoop.crypto.key.kms.server.SimpleKMSAuditLogger
2023-01-27 20:24:22,710 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(149)) - Initialized KeyProvider CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/a2aae5c0-cde0-4da8-9d28-02ba59ac90c8/kms.keystore
2023-01-27 20:24:22,711 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(163)) - Initialized KeyProviderCryptoExtension org.apache.hadoop.crypto.key.kms.server.KeyAuthorizationKeyProvider: EagerKeyGeneratorKeyProviderCryptoExtension: KeyProviderCryptoExtension: CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/a2aae5c0-cde0-4da8-9d28-02ba59ac90c8/kms.keystore
2023-01-27 20:24:22,712 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(168)) - Default key bitlength is 128
2023-01-27 20:24:22,712 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(169)) - KMS Started
2023-01-27 20:24:22,714 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:22,716 [Time-limited test] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.crypto.key.kms.server
2023-01-27 20:24:22,719 [Thread[Thread-373,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:22,720 [Thread[Thread-373,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:22,749 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMS
2023-01-27 20:24:22,749 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
  class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
2023-01-27 20:24:22,753 [Time-limited test] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:24:22,942 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@6092f7ff{kms,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/2/kms/webapp/,AVAILABLE}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:22,948 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@303e3250{HTTP/1.1, (http/1.1)}{localhost:38727}
2023-01-27 20:24:22,949 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @27971ms
2023-01-27 20:24:22,952 [Time-limited test] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(120)) - Loaded properties from hadoop-metrics2.properties
2023-01-27 20:24:22,954 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 0 second(s).
2023-01-27 20:24:22,954 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - KMS metrics system started
2023-01-27 20:24:22,992 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@63e57ff0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:22,997 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(566)) - starting cluster: numNameNodes=1, numDataNodes=1
2023-01-27 20:24:23,000 [Time-limited test] INFO  namenode.NameNode (NameNode.java:format(1366)) - Formatting using clusterid: testClusterID
2023-01-27 20:24:23,001 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:23,020 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@36a1ddfa
2023-01-27 20:24:23,020 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:23,020 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:23,021 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:23,021 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:23,021 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:23,021 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:23,021 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:23,021 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:23,022 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:23,022 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:23,022 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:23,023 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:23
2023-01-27 20:24:23,023 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:23,023 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:23,023 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:23,023 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:23,047 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:23,049 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:23,049 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:23,050 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:23,050 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:23,050 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:23,050 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:23,050 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:23,050 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:23,050 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:23,051 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:23,051 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:23,051 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:23,051 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:23,051 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:23,054 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:23,055 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:23,056 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:23,056 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:23,056 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:23,056 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:23,056 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:23,057 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:23,057 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:23,057 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:23,057 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:23,057 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:23,058 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:23,058 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:23,058 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:23,058 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:23,059 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:23,059 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:23,060 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:23,060 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:23,060 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:23,060 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:23,060 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:23,062 [Time-limited test] INFO  namenode.FSImage (FSImage.java:format(186)) - Allocated new BlockPoolId: BP-392685322-127.0.1.1-1674825863062
2023-01-27 20:24:23,066 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 has been successfully formatted.
2023-01-27 20:24:23,069 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 has been successfully formatted.
2023-01-27 20:24:23,086 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:23,092 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 436 bytes saved in 0 seconds .
2023-01-27 20:24:23,094 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:23,102 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 436 bytes saved in 0 seconds .
2023-01-27 20:24:23,108 [Time-limited test] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(202)) - Going to retain 1 images with txid >= 0
2023-01-27 20:24:23,124 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:23,125 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:23,126 [Time-limited test] INFO  namenode.NameNode (NameNode.java:createNameNode(1824)) - createNameNode []
2023-01-27 20:24:23,127 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2023-01-27 20:24:23,127 [Time-limited test] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2023-01-27 20:24:23,149 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6b005da2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:23,149 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1736)) - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2023-01-27 20:24:23,149 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1758)) - Starting Web-server for hdfs at: http://localhost:0
2023-01-27 20:24:23,149 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:23,152 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:23,157 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:23,163 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:23,164 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-01-27 20:24:23,164 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:23,164 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:23,166 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2023-01-27 20:24:23,166 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2023-01-27 20:24:23,167 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2023-01-27 20:24:23,167 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:23,168 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(1018)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-01-27 20:24:23,168 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 32847
2023-01-27 20:24:23,169 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:23,189 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:23,189 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:23,189 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:24:23,191 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:23,192 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@29c01445{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:23,193 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@738964cc{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:23,199 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@221b132{hdfs,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:23,209 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4eea516d{HTTP/1.1, (http/1.1)}{localhost:32847}
2023-01-27 20:24:23,211 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @28233ms
2023-01-27 20:24:23,213 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:23,229 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@5b61ca60
2023-01-27 20:24:23,230 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:23,230 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:23,230 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:23,230 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:23,230 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:23,230 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:23,231 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:23,231 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:23,231 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:23,231 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:23,232 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:23,232 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:23
2023-01-27 20:24:23,232 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:23,232 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:23,233 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:23,233 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:23,234 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:23,234 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:23,235 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:23,235 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:23,235 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:23,235 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:23,235 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:23,235 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:23,236 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:23,236 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:23,236 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:23,236 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:23,236 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:23,237 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:23,237 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:23,237 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:23,238 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:23,238 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:23,239 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:23,239 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:23,239 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:23,239 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:23,239 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:23,239 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:23,239 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:23,240 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:23,240 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:23,240 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:23,240 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:23,241 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:23,241 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:23,241 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:23,241 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:23,241 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:23,241 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:23,241 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:23,242 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:23,242 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:23,244 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:23,246 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:23,248 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current
2023-01-27 20:24:23,248 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current
2023-01-27 20:24:23,248 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(734)) - No edit log streams selected.
2023-01-27 20:24:23,249 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(800)) - Planning to load image: FSImageFile(file=/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-01-27 20:24:23,250 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSectionHeader(411)) - Loading 1 INodes.
2023-01-27 20:24:23,251 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(369)) - Successfully loaded 1 inodes
2023-01-27 20:24:23,251 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:waitBlocksMapAndNameCacheUpdateFinished(342)) - Completed update blocks map and name cache, total waiting duration 0ms.
2023-01-27 20:24:23,251 [Time-limited test] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(255)) - Loaded FSImage in 0 seconds.
2023-01-27 20:24:23,251 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(980)) - Loaded image for txid 0 from /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000
2023-01-27 20:24:23,252 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1271)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-01-27 20:24:23,252 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1417)) - Starting log segment at 1
2023-01-27 20:24:23,268 [Time-limited test] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2023-01-27 20:24:23,268 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(836)) - Finished loading FSImage in 26 msecs
2023-01-27 20:24:23,268 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(451)) - RPC server is binding to localhost:0
2023-01-27 20:24:23,269 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(456)) - Enable NameNode state context:false
2023-01-27 20:24:23,269 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:23,269 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:44249
2023-01-27 20:24:23,269 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:23,274 [Time-limited test] INFO  namenode.NameNode (NameNode.java:initialize(893)) - Clients are to use localhost:44249 to access this namenode/service.
2023-01-27 20:24:23,274 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5607)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2023-01-27 20:24:23,308 [Time-limited test] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(166)) - Number of blocks under construction: 0
2023-01-27 20:24:23,309 [Time-limited test] INFO  blockmanagement.DatanodeAdminDefaultMonitor (DatanodeAdminDefaultMonitor.java:processConf(126)) - Initialized the Default Decommission and Maintenance monitor
2023-01-27 20:24:23,310 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(5310)) - initializing replication queues
2023-01-27 20:24:23,310 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5102)) - Start MarkedDeleteBlockScrubber thread
2023-01-27 20:24:23,310 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(409)) - STATE* Leaving safe mode after 0 secs
2023-01-27 20:24:23,310 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(415)) - STATE* Network topology has 0 racks and 0 datanodes
2023-01-27 20:24:23,310 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(417)) - STATE* UnderReplicatedBlocks has 0 blocks
2023-01-27 20:24:23,316 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:23,322 [Thread[Thread-405,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:23,323 [Thread[Thread-405,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:23,328 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3870)) - Total number of blocks            = 0
2023-01-27 20:24:23,328 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3871)) - Number of invalid blocks          = 0
2023-01-27 20:24:23,328 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3872)) - Number of under-replicated blocks = 0
2023-01-27 20:24:23,328 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3873)) - Number of  over-replicated blocks = 0
2023-01-27 20:24:23,328 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3875)) - Number of blocks being written    = 0
2023-01-27 20:24:23,328 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3878)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 18 msec
2023-01-27 20:24:23,331 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:23,331 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:23,340 [Time-limited test] INFO  namenode.NameNode (NameNode.java:startCommonServices(1010)) - NameNode RPC up at: localhost/127.0.0.1:44249
2023-01-27 20:24:23,341 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1383)) - Starting services required for active state
2023-01-27 20:24:23,341 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(857)) - Initializing quota with 12 thread(s)
2023-01-27 20:24:23,342 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(866)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2023-01-27 20:24:23,343 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(326)) - Starting up re-encrypt thread with interval=60000 millisecond.
2023-01-27 20:24:23,344 [CacheReplicationMonitor(2073159981)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-01-27 20:24:23,344 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2023-01-27 20:24:23,348 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1769)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1,[DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:23,349 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:23,349 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:23,362 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2023-01-27 20:24:23,363 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:23,363 [Time-limited test] INFO  datanode.BlockScanner (BlockScanner.java:<init>(201)) - Initialized block scanner with targetBytesPerSec 1048576
2023-01-27 20:24:23,363 [Time-limited test] INFO  datanode.DataNode (DataNode.java:<init>(571)) - Configured hostname is 127.0.0.1
2023-01-27 20:24:23,363 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:23,363 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1788)) - Starting DataNode with maxLockedMemory = 0
2023-01-27 20:24:23,364 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1551)) - Opened streaming server at /127.0.0.1:43841
2023-01-27 20:24:23,364 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(93)) - Balancing bandwidth is 104857600 bytes/s
2023-01-27 20:24:23,364 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(94)) - Number threads for balancing is 100
2023-01-27 20:24:23,365 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:23,366 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:23,367 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:23,369 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:23,370 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-01-27 20:24:23,370 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:23,370 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:23,370 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:23,370 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 34387
2023-01-27 20:24:23,371 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:23,371 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:23,372 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:23,372 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:23,373 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1ba7da9a{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:23,374 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3d8272c2{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:23,377 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@43118314{datanode,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:23,378 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@10750f43{HTTP/1.1, (http/1.1)}{localhost:34387}
2023-01-27 20:24:23,378 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @28400ms
2023-01-27 20:24:23,382 [Time-limited test] WARN  web.DatanodeHttpServer (RestCsrfPreventionFilterHandler.java:<init>(75)) - Got null for restCsrfPreventionFilter - will not do any filtering.
2023-01-27 20:24:23,383 [Time-limited test] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(306)) - Listening HTTP traffic on /127.0.0.1:35811
2023-01-27 20:24:23,384 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1816)) - dnUserName = rizky
2023-01-27 20:24:23,384 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1817)) - supergroup = supergroup
2023-01-27 20:24:23,384 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@16a1b9f7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:23,384 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:23,385 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:38687
2023-01-27 20:24:23,385 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:23,390 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initIpcServer(1438)) - Opened IPC server at /127.0.0.1:38687
2023-01-27 20:24:23,403 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(150)) - Refresh request received for nameservices: null
2023-01-27 20:24:23,403 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(211)) - Starting BPOfferServices for nameservices: <default>
2023-01-27 20:24:23,404 [Thread-438] INFO  datanode.DataNode (BPServiceActor.java:run(877)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44249 starting to offer service
2023-01-27 20:24:23,405 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:23,405 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:23,423 [Thread-438] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(382)) - Acknowledging ACTIVE Namenode during handshake Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44249
2023-01-27 20:24:23,424 [Thread-438] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(356)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2023-01-27 20:24:23,426 [IPC Server handler 1 on default port 44249] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:23,426 [Thread-438] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:23,426 [Thread-438] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 is not formatted for namespace 1014303918. Formatting...
2023-01-27 20:24:23,426 [Thread-438] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b7a7cf22-9de7-4753-8f8d-e136ef17919c for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 
2023-01-27 20:24:23,426 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:23,427 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:23,449 [Thread-438] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:23,450 [Thread-438] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 is not formatted for namespace 1014303918. Formatting...
2023-01-27 20:24:23,450 [Thread-438] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-aca2646e-cd99-4bb0-a0d4-8c12d9607c60 for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 
2023-01-27 20:24:23,468 [Thread-438] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-392685322-127.0.1.1-1674825863062
2023-01-27 20:24:23,469 [Thread-438] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-392685322-127.0.1.1-1674825863062
2023-01-27 20:24:23,469 [Thread-438] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 and block pool id BP-392685322-127.0.1.1-1674825863062 is not formatted. Formatting ...
2023-01-27 20:24:23,469 [Thread-438] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-392685322-127.0.1.1-1674825863062 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-392685322-127.0.1.1-1674825863062/current
2023-01-27 20:24:23,496 [Thread-438] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-392685322-127.0.1.1-1674825863062
2023-01-27 20:24:23,496 [Thread-438] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-392685322-127.0.1.1-1674825863062
2023-01-27 20:24:23,496 [Thread-438] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 and block pool id BP-392685322-127.0.1.1-1674825863062 is not formatted. Formatting ...
2023-01-27 20:24:23,496 [Thread-438] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-392685322-127.0.1.1-1674825863062 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-392685322-127.0.1.1-1674825863062/current
2023-01-27 20:24:23,499 [Thread-438] INFO  datanode.DataNode (DataNode.java:initStorage(2136)) - Setting up storage: nsid=1014303918;bpid=BP-392685322-127.0.1.1-1674825863062;lv=-57;nsInfo=lv=-67;cid=testClusterID;nsid=1014303918;c=1674825863062;bpid=BP-392685322-127.0.1.1-1674825863062;dnuuid=null
2023-01-27 20:24:23,501 [Thread-438] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1934)) - Generated and persisted new Datanode UUID ce0ea9ef-d965-4358-96e6-3b3e640d31b2
2023-01-27 20:24:23,501 [Thread-438] INFO  fsdataset.RoundRobinVolumeChoosingPolicy (RoundRobinVolumeChoosingPolicy.java:setConf(67)) - Round robin volume choosing policy initialized: dfs.datanode.round-robin-volume-choosing-policy.additional-available-space = 0
2023-01-27 20:24:23,503 [Thread-438] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-b7a7cf22-9de7-4753-8f8d-e136ef17919c
2023-01-27 20:24:23,503 [Thread-438] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, StorageType: DISK
2023-01-27 20:24:23,505 [Thread-438] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-aca2646e-cd99-4bb0-a0d4-8c12d9607c60
2023-01-27 20:24:23,508 [Thread-438] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, StorageType: DISK
2023-01-27 20:24:23,508 [Thread-438] INFO  impl.MemoryMappableBlockLoader (MemoryMappableBlockLoader.java:initialize(47)) - Initializing cache loader: MemoryMappableBlockLoader.
2023-01-27 20:24:23,509 [Thread-438] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2611)) - Registered FSDatasetState MBean
2023-01-27 20:24:23,510 [Thread-438] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(3188)) - Adding block pool BP-392685322-127.0.1.1-1674825863062
2023-01-27 20:24:23,510 [Thread-455] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-392685322-127.0.1.1-1674825863062 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:23,511 [Thread-456] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-392685322-127.0.1.1-1674825863062 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:23,511 [Thread-455] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-392685322-127.0.1.1-1674825863062/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:23,511 [Thread-456] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-392685322-127.0.1.1-1674825863062/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:23,529 [IPC Server handler 2 on default port 44249] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:23,530 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:23,530 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:23,533 [Thread-456] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-392685322-127.0.1.1-1674825863062 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 23ms
2023-01-27 20:24:23,535 [Thread-455] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-392685322-127.0.1.1-1674825863062 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 24ms
2023-01-27 20:24:23,535 [Thread-438] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(538)) - Total time to scan all replicas for block pool BP-392685322-127.0.1.1-1674825863062: 24ms
2023-01-27 20:24:23,535 [Thread-459] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-392685322-127.0.1.1-1674825863062 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:23,535 [Thread-460] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-392685322-127.0.1.1-1674825863062 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:23,535 [Thread-459] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-392685322-127.0.1.1-1674825863062/current/replicas doesn't exist 
2023-01-27 20:24:23,535 [Thread-460] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-392685322-127.0.1.1-1674825863062/current/replicas doesn't exist 
2023-01-27 20:24:23,536 [Thread-459] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-392685322-127.0.1.1-1674825863062 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 0ms
2023-01-27 20:24:23,536 [Thread-460] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-392685322-127.0.1.1-1674825863062 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 0ms
2023-01-27 20:24:23,536 [Thread-438] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(292)) - Total time to add all replicas to map for block pool BP-392685322-127.0.1.1-1674825863062: 0ms
2023-01-27 20:24:23,536 [Thread-438] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:23,536 [Thread-438] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:23,536 [Thread-438] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:23,537 [Thread-438] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:23,538 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-392685322-127.0.1.1-1674825863062 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:23,538 [Thread-438] WARN  datanode.DirectoryScanner (DirectoryScanner.java:<init>(302)) - dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2023-01-27 20:24:23,538 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-392685322-127.0.1.1-1674825863062 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:23,538 [Thread-438] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(367)) - Periodic Directory Tree Verification scan starting in 3697549ms with interval of 21600000ms and throttle limit of -1ms/s
2023-01-27 20:24:23,538 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-aca2646e-cd99-4bb0-a0d4-8c12d9607c60): finished scanning block pool BP-392685322-127.0.1.1-1674825863062
2023-01-27 20:24:23,538 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-b7a7cf22-9de7-4753-8f8d-e136ef17919c): finished scanning block pool BP-392685322-127.0.1.1-1674825863062
2023-01-27 20:24:23,539 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-aca2646e-cd99-4bb0-a0d4-8c12d9607c60): no suitable block pools found to scan.  Waiting 1814399999 ms.
2023-01-27 20:24:23,539 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-b7a7cf22-9de7-4753-8f8d-e136ef17919c): no suitable block pools found to scan.  Waiting 1814399999 ms.
2023-01-27 20:24:23,539 [BP-392685322-127.0.1.1-1674825863062 heartbeating to localhost/127.0.0.1:44249] INFO  datanode.DataNode (BPServiceActor.java:register(819)) - Block pool BP-392685322-127.0.1.1-1674825863062 (Datanode Uuid ce0ea9ef-d965-4358-96e6-3b3e640d31b2) service to localhost/127.0.0.1:44249 beginning handshake with NN: localhost/127.0.0.1:44249.
2023-01-27 20:24:23,540 [IPC Server handler 3 on default port 44249] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1166)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43841, datanodeUuid=ce0ea9ef-d965-4358-96e6-3b3e640d31b2, infoPort=35811, infoSecurePort=0, ipcPort=38687, storageInfo=lv=-57;cid=testClusterID;nsid=1014303918;c=1674825863062) storage ce0ea9ef-d965-4358-96e6-3b3e640d31b2
2023-01-27 20:24:23,540 [IPC Server handler 3 on default port 44249] INFO  net.NetworkTopology (NetworkTopology.java:add(156)) - Adding a new node: /default-rack/127.0.0.1:43841
2023-01-27 20:24:23,541 [IPC Server handler 3 on default port 44249] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(200)) - Registered DN ce0ea9ef-d965-4358-96e6-3b3e640d31b2 (127.0.0.1:43841).
2023-01-27 20:24:23,542 [BP-392685322-127.0.1.1-1674825863062 heartbeating to localhost/127.0.0.1:44249] INFO  datanode.DataNode (BPServiceActor.java:register(846)) - Block pool BP-392685322-127.0.1.1-1674825863062 (Datanode Uuid ce0ea9ef-d965-4358-96e6-3b3e640d31b2) service to localhost/127.0.0.1:44249 successfully registered with NN: localhost/127.0.0.1:44249.
2023-01-27 20:24:23,542 [BP-392685322-127.0.1.1-1674825863062 heartbeating to localhost/127.0.0.1:44249] INFO  datanode.DataNode (BPServiceActor.java:offerService(680)) - For namenode localhost/127.0.0.1:44249 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2023-01-27 20:24:23,543 [ibr-executor-0] INFO  datanode.DataNode (BPServiceActor.java:run(1145)) - Starting IBR Task Handler.
2023-01-27 20:24:23,544 [IPC Server handler 4 on default port 44249] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-b7a7cf22-9de7-4753-8f8d-e136ef17919c for DN 127.0.0.1:43841
2023-01-27 20:24:23,544 [IPC Server handler 4 on default port 44249] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-aca2646e-cd99-4bb0-a0d4-8c12d9607c60 for DN 127.0.0.1:43841
2023-01-27 20:24:23,547 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0xda2e908e8d7ef655 with lease ID 0x2fc4535af6b2a769: Processing first storage report for DS-aca2646e-cd99-4bb0-a0d4-8c12d9607c60 from datanode DatanodeRegistration(127.0.0.1:43841, datanodeUuid=ce0ea9ef-d965-4358-96e6-3b3e640d31b2, infoPort=35811, infoSecurePort=0, ipcPort=38687, storageInfo=lv=-57;cid=testClusterID;nsid=1014303918;c=1674825863062)
2023-01-27 20:24:23,547 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0xda2e908e8d7ef655 with lease ID 0x2fc4535af6b2a769: from storage DS-aca2646e-cd99-4bb0-a0d4-8c12d9607c60 node DatanodeRegistration(127.0.0.1:43841, datanodeUuid=ce0ea9ef-d965-4358-96e6-3b3e640d31b2, infoPort=35811, infoSecurePort=0, ipcPort=38687, storageInfo=lv=-57;cid=testClusterID;nsid=1014303918;c=1674825863062), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2023-01-27 20:24:23,547 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0xda2e908e8d7ef655 with lease ID 0x2fc4535af6b2a769: Processing first storage report for DS-b7a7cf22-9de7-4753-8f8d-e136ef17919c from datanode DatanodeRegistration(127.0.0.1:43841, datanodeUuid=ce0ea9ef-d965-4358-96e6-3b3e640d31b2, infoPort=35811, infoSecurePort=0, ipcPort=38687, storageInfo=lv=-57;cid=testClusterID;nsid=1014303918;c=1674825863062)
2023-01-27 20:24:23,547 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0xda2e908e8d7ef655 with lease ID 0x2fc4535af6b2a769: from storage DS-b7a7cf22-9de7-4753-8f8d-e136ef17919c node DatanodeRegistration(127.0.0.1:43841, datanodeUuid=ce0ea9ef-d965-4358-96e6-3b3e640d31b2, infoPort=35811, infoSecurePort=0, ipcPort=38687, storageInfo=lv=-57;cid=testClusterID;nsid=1014303918;c=1674825863062), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:23,548 [BP-392685322-127.0.1.1-1674825863062 heartbeating to localhost/127.0.0.1:44249] INFO  datanode.DataNode (BPServiceActor.java:blockReport(464)) - Successfully sent block report 0xda2e908e8d7ef655 with lease ID 0x2fc4535af6b2a769 to namenode: localhost/127.0.0.1:44249,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msecs to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-01-27 20:24:23,549 [Command processor] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(763)) - Got finalize command for block pool BP-392685322-127.0.1.1-1674825863062
2023-01-27 20:24:23,632 [IPC Server handler 6 on default port 44249] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:23,635 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:23,640 [IPC Server handler 7 on default port 44249] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:23,641 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:23,655 [qtp1269953165-635] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:23 +0000] "OPTIONS /kms/v1/keys HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:23,673 [qtp1269953165-630] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:23,674 [qtp1269953165-630] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:23,675 [qtp1269953165-630] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:23,676 [qtp1269953165-630] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:23,676 [qtp1269953165-630] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:23,676 [qtp1269953165-630] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:23,677 [qtp1269953165-630] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:23,679 [qtp1269953165-630] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:23,693 [qtp1269953165-630] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:23 +0000] "OPTIONS /kms/v1/keys?user.name=rizky HTTP/1.1" 200 520 "-" "Java/1.8.0_352"
2023-01-27 20:24:24,173 [qtp1269953165-629] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=CREATE_KEY, key=test_key, user=rizky] UserProvidedMaterial:false Description:test_key
2023-01-27 20:24:24,175 [qtp1269953165-629] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:23 +0000] "POST /kms/v1/keys HTTP/1.1" 201 98 "-" "Java/1.8.0_352"
2023-01-27 20:24:24,188 [IPC Server handler 8 on default port 44249] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2023-01-27 20:24:24,191 [IPC Server handler 9 on default port 44249] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/TestEncryptionZone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:24,202 [qtp1269953165-633] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=GET_METADATA, key=test_key, user=rizky] 
2023-01-27 20:24:24,207 [qtp1269953165-633] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:24 +0000] "GET /kms/v1/key/test_key/_metadata HTTP/1.1" 200 210 "-" "Java/1.8.0_352"
2023-01-27 20:24:24,532 [qtp1269953165-633] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditEvent(59)) - OK[op=GENERATE_EEK, key=test_key, user=rizky, accessCount=1, interval=0ms] 
2023-01-27 20:24:24,537 [qtp1269953165-633] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:24 +0000] "GET /kms/v1/key/test_key/_eek?num_keys=150&eek_op=generate HTTP/1.1" 200 29702 "-" "Java/1.8.0_352"
2023-01-27 20:24:24,542 [IPC Server handler 0 on default port 44249] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=createEncryptionZone	src=/TestEncryptionZone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:24,545 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2159)) - Shutting down the Mini HDFS Cluster
2023-01-27 20:24:24,545 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2208)) - Shutting down DataNode 0
2023-01-27 20:24:24,545 [Time-limited test] INFO  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(430)) - Shutdown has been called
2023-01-27 20:24:24,545 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5dea6637] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(395)) - Closing all peers.
2023-01-27 20:24:24,546 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-aca2646e-cd99-4bb0-a0d4-8c12d9607c60) exiting.
2023-01-27 20:24:24,546 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-b7a7cf22-9de7-4753-8f8d-e136ef17919c) exiting.
2023-01-27 20:24:24,632 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@43118314{datanode,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:24,633 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@10750f43{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:24,633 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:24,634 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3d8272c2{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:24,634 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1ba7da9a{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:24,636 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2470)) - Waiting up to 30 seconds for transfer threads to complete
2023-01-27 20:24:24,636 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 38687
2023-01-27 20:24:24,640 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:24,640 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:24,646 [BP-392685322-127.0.1.1-1674825863062 heartbeating to localhost/127.0.0.1:44249] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:24,647 [BP-392685322-127.0.1.1-1674825863062 heartbeating to localhost/127.0.0.1:44249] WARN  datanode.DataNode (BPServiceActor.java:run(924)) - Ending block pool service for: Block pool BP-392685322-127.0.1.1-1674825863062 (Datanode Uuid ce0ea9ef-d965-4358-96e6-3b3e640d31b2) service to localhost/127.0.0.1:44249
2023-01-27 20:24:24,647 [BP-392685322-127.0.1.1-1674825863062 heartbeating to localhost/127.0.0.1:44249] INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-392685322-127.0.1.1-1674825863062 (Datanode Uuid ce0ea9ef-d965-4358-96e6-3b3e640d31b2)
2023-01-27 20:24:24,647 [BP-392685322-127.0.1.1-1674825863062 heartbeating to localhost/127.0.0.1:44249] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(3225)) - Removing block pool BP-392685322-127.0.1.1-1674825863062
2023-01-27 20:24:24,648 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-392685322-127.0.1.1-1674825863062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:24,648 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-392685322-127.0.1.1-1674825863062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:24,649 [Command processor] ERROR datanode.DataNode (BPServiceActor.java:processQueue(1430)) - Command processor encountered interrupt and exit.
2023-01-27 20:24:24,650 [Command processor] WARN  datanode.DataNode (BPServiceActor.java:run(1414)) - Ending command processor service for: Thread[Command processor,5,main]
2023-01-27 20:24:24,649 [ibr-executor-0] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:24,657 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(208)) - Shutting down all async disk service threads
2023-01-27 20:24:24,657 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(216)) - All async disk service threads have been shut down
2023-01-27 20:24:24,658 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(186)) - Shutting down all async lazy persist service threads
2023-01-27 20:24:24,658 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(193)) - All async lazy persist service threads have been shut down
2023-01-27 20:24:24,659 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2559)) - Shutdown complete.
2023-01-27 20:24:24,659 [Time-limited test] WARN  datanode.DataSetLockManager (DataSetLockManager.java:lockLeakCheck(260)) - not open lock leak check func
2023-01-27 20:24:24,660 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2241)) - Shutting down the namenode
2023-01-27 20:24:24,660 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:24,660 [Thread[Thread-405,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:24,660 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1467)) - Ending log segment 1, 5
2023-01-27 20:24:24,660 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@14fa2ba7] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4561)) - NameNodeEditLogRoller was interrupted, exiting
2023-01-27 20:24:24,661 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(576)) - EDEKCacheLoader interrupted before warming up.
2023-01-27 20:24:24,661 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@33cefdb3] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4658)) - LazyPersistFileScrubber was interrupted, exiting
2023-01-27 20:24:24,663 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(801)) - Number of transactions: 6 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 16 8 
2023-01-27 20:24:24,664 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000006
2023-01-27 20:24:24,665 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000006
2023-01-27 20:24:24,665 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(276)) - FSEditLogAsync was interrupted, exiting
2023-01-27 20:24:24,665 [CacheReplicationMonitor(2073159981)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2023-01-27 20:24:24,665 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(267)) - Re-encryption updater thread interrupted. Exiting.
2023-01-27 20:24:24,665 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(335)) - Re-encrypt handler interrupted. Exiting
2023-01-27 20:24:24,667 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 44249
2023-01-27 20:24:24,669 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:24,669 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:24,669 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5134)) - Stopping MarkedDeleteBlockScrubber.
2023-01-27 20:24:24,670 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(5160)) - Stopping RedundancyMonitor.
2023-01-27 20:24:24,689 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:24,689 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:24,719 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@221b132{hdfs,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:24,724 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4eea516d{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:24,724 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:24,724 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@738964cc{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:24,724 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@29c01445{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:24,733 [Thread[Thread-373,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:24,737 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextDestroyed(197)) - KMS Stopped
2023-01-27 20:24:24,738 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@6092f7ff{kms,/,null,STOPPED}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:24,739 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@303e3250{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:24,740 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:24,740 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@20d69df1{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-27 20:24:24,740 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2d67c297{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:24,741 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2023-01-27 20:24:24,742 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2023-01-27 20:24:24,742 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(612)) - DataNode metrics system shutdown complete.
2023-01-27 20:24:24,797 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:24,798 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context kms
2023-01-27 20:24:24,798 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:24,798 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:24,799 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:24,799 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 36521
2023-01-27 20:24:24,799 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:24,810 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:24,810 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:24,810 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:24,812 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@311eb015{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:24,812 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@52f396e9{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-27 20:24:24,846 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(94)) - -------------------------------------------------------------
2023-01-27 20:24:24,846 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(95)) -   Java runtime version : 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:24,847 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(97)) -   User: rizky
2023-01-27 20:24:24,847 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(98)) -   KMS Hadoop Version: 3.4.0-SNAPSHOT
2023-01-27 20:24:24,847 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(99)) - -------------------------------------------------------------
2023-01-27 20:24:24,848 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'CREATE' ACL '*'
2023-01-27 20:24:24,848 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DELETE' ACL '*'
2023-01-27 20:24:24,848 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'ROLLOVER' ACL '*'
2023-01-27 20:24:24,848 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET' ACL '*'
2023-01-27 20:24:24,849 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_KEYS' ACL '*'
2023-01-27 20:24:24,849 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_METADATA' ACL '*'
2023-01-27 20:24:24,849 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'SET_KEY_MATERIAL' ACL '*'
2023-01-27 20:24:24,849 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GENERATE_EEK' ACL '*'
2023-01-27 20:24:24,849 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DECRYPT_EEK' ACL '*'
2023-01-27 20:24:24,849 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2023-01-27 20:24:24,850 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2023-01-27 20:24:24,850 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2023-01-27 20:24:24,850 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2023-01-27 20:24:24,852 [Time-limited test] INFO  server.KMSAudit (KMSAudit.java:initializeAuditLoggers(157)) - Initializing audit logger class org.apache.hadoop.crypto.key.kms.server.SimpleKMSAuditLogger
2023-01-27 20:24:24,853 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(149)) - Initialized KeyProvider CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/e49ffd3e-3261-4a45-9642-737f2a9bfa5c/kms.keystore
2023-01-27 20:24:24,854 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(163)) - Initialized KeyProviderCryptoExtension org.apache.hadoop.crypto.key.kms.server.KeyAuthorizationKeyProvider: EagerKeyGeneratorKeyProviderCryptoExtension: KeyProviderCryptoExtension: CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/e49ffd3e-3261-4a45-9642-737f2a9bfa5c/kms.keystore
2023-01-27 20:24:24,854 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(168)) - Default key bitlength is 128
2023-01-27 20:24:24,854 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(169)) - KMS Started
2023-01-27 20:24:24,856 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:24,856 [Thread[Thread-476,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:24,857 [Thread[Thread-476,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:24,859 [Time-limited test] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.crypto.key.kms.server
2023-01-27 20:24:24,877 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMS
2023-01-27 20:24:24,877 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
  class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
2023-01-27 20:24:24,881 [Time-limited test] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:24:25,081 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@429964db{kms,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/2/kms/webapp/,AVAILABLE}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:25,083 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4ee2a62c{HTTP/1.1, (http/1.1)}{localhost:36521}
2023-01-27 20:24:25,083 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @30105ms
2023-01-27 20:24:25,085 [Time-limited test] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(120)) - Loaded properties from hadoop-metrics2.properties
2023-01-27 20:24:25,087 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 0 second(s).
2023-01-27 20:24:25,087 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - KMS metrics system started
2023-01-27 20:24:25,151 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@50b04622] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:25,152 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(566)) - starting cluster: numNameNodes=1, numDataNodes=1
2023-01-27 20:24:25,155 [Time-limited test] INFO  namenode.NameNode (NameNode.java:format(1366)) - Formatting using clusterid: testClusterID
2023-01-27 20:24:25,155 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:25,170 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@49a3ef32
2023-01-27 20:24:25,170 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:25,171 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:25,171 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:25,171 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:25,171 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:25,171 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:25,171 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:25,172 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:25,172 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:25,172 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:25,172 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:25,173 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:25
2023-01-27 20:24:25,173 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:25,173 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:25,173 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:25,173 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:25,175 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:25,175 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:25,175 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:25,176 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:25,176 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:25,176 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:25,176 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:25,176 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:25,176 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:25,176 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:25,176 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:25,177 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:25,177 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:25,177 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:25,177 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:25,177 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:25,178 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:25,179 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:25,179 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:25,179 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:25,179 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:25,180 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:25,180 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:25,180 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:25,180 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:25,180 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:25,181 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:25,181 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:25,181 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:25,182 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:25,182 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:25,182 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:25,183 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:25,183 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:25,183 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:25,183 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:25,184 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:25,184 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:25,185 [Time-limited test] INFO  namenode.FSImage (FSImage.java:format(186)) - Allocated new BlockPoolId: BP-54392089-127.0.1.1-1674825865185
2023-01-27 20:24:25,188 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 has been successfully formatted.
2023-01-27 20:24:25,191 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 has been successfully formatted.
2023-01-27 20:24:25,211 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:25,218 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:25,219 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 436 bytes saved in 0 seconds .
2023-01-27 20:24:25,225 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 436 bytes saved in 0 seconds .
2023-01-27 20:24:25,228 [Time-limited test] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(202)) - Going to retain 1 images with txid >= 0
2023-01-27 20:24:25,255 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:25,256 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:25,259 [Time-limited test] INFO  namenode.NameNode (NameNode.java:createNameNode(1824)) - createNameNode []
2023-01-27 20:24:25,260 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2023-01-27 20:24:25,260 [Time-limited test] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2023-01-27 20:24:25,280 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@60760544] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:25,280 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1736)) - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2023-01-27 20:24:25,280 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1758)) - Starting Web-server for hdfs at: http://localhost:0
2023-01-27 20:24:25,281 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:25,282 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:25,289 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:25,291 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:25,292 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-01-27 20:24:25,292 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:25,292 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:25,293 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2023-01-27 20:24:25,294 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2023-01-27 20:24:25,294 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2023-01-27 20:24:25,294 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:25,295 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(1018)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-01-27 20:24:25,295 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 33785
2023-01-27 20:24:25,295 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:25,320 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:25,321 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:25,321 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:24:25,324 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:25,325 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@36182254{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:25,326 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7cbeaa28{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:25,332 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@498f9306{hdfs,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:25,336 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5375724c{HTTP/1.1, (http/1.1)}{localhost:33785}
2023-01-27 20:24:25,337 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @30359ms
2023-01-27 20:24:25,339 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:25,356 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@3192651c
2023-01-27 20:24:25,356 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:25,356 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:25,356 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:25,356 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:25,356 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:25,356 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:25,357 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:25,357 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:25,357 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:25,357 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:25,357 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:25,358 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:25
2023-01-27 20:24:25,358 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:25,358 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:25,358 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:25,358 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:25,360 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:25,361 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:25,361 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:25,361 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:25,361 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:25,361 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:25,362 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:25,362 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:25,362 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:25,362 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:25,362 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:25,362 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:25,362 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:25,363 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:25,363 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:25,363 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:25,364 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:25,379 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:25,379 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:25,379 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:25,379 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:25,379 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:25,380 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:25,385 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:25,385 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:25,385 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:25,386 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:25,386 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:25,386 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:25,386 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:25,387 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:25,387 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:25,387 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:25,387 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:25,387 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:25,387 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:25,388 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:25,388 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:25,393 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:25,394 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:25,396 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current
2023-01-27 20:24:25,396 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current
2023-01-27 20:24:25,396 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(734)) - No edit log streams selected.
2023-01-27 20:24:25,396 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(800)) - Planning to load image: FSImageFile(file=/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-01-27 20:24:25,399 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSectionHeader(411)) - Loading 1 INodes.
2023-01-27 20:24:25,399 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(369)) - Successfully loaded 1 inodes
2023-01-27 20:24:25,399 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:waitBlocksMapAndNameCacheUpdateFinished(342)) - Completed update blocks map and name cache, total waiting duration 0ms.
2023-01-27 20:24:25,400 [Time-limited test] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(255)) - Loaded FSImage in 0 seconds.
2023-01-27 20:24:25,400 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(980)) - Loaded image for txid 0 from /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000
2023-01-27 20:24:25,401 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1271)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-01-27 20:24:25,401 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1417)) - Starting log segment at 1
2023-01-27 20:24:25,439 [Time-limited test] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2023-01-27 20:24:25,439 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(836)) - Finished loading FSImage in 51 msecs
2023-01-27 20:24:25,440 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(451)) - RPC server is binding to localhost:0
2023-01-27 20:24:25,440 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(456)) - Enable NameNode state context:false
2023-01-27 20:24:25,440 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:25,441 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:44255
2023-01-27 20:24:25,462 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:25,468 [Time-limited test] INFO  namenode.NameNode (NameNode.java:initialize(893)) - Clients are to use localhost:44255 to access this namenode/service.
2023-01-27 20:24:25,469 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5607)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2023-01-27 20:24:25,499 [Time-limited test] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(166)) - Number of blocks under construction: 0
2023-01-27 20:24:25,500 [Time-limited test] INFO  blockmanagement.DatanodeAdminDefaultMonitor (DatanodeAdminDefaultMonitor.java:processConf(126)) - Initialized the Default Decommission and Maintenance monitor
2023-01-27 20:24:25,507 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5102)) - Start MarkedDeleteBlockScrubber thread
2023-01-27 20:24:25,508 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(5310)) - initializing replication queues
2023-01-27 20:24:25,508 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(409)) - STATE* Leaving safe mode after 0 secs
2023-01-27 20:24:25,508 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(415)) - STATE* Network topology has 0 racks and 0 datanodes
2023-01-27 20:24:25,508 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(417)) - STATE* UnderReplicatedBlocks has 0 blocks
2023-01-27 20:24:25,509 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:25,517 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3870)) - Total number of blocks            = 0
2023-01-27 20:24:25,517 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3871)) - Number of invalid blocks          = 0
2023-01-27 20:24:25,517 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3872)) - Number of under-replicated blocks = 0
2023-01-27 20:24:25,517 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3873)) - Number of  over-replicated blocks = 0
2023-01-27 20:24:25,517 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3875)) - Number of blocks being written    = 0
2023-01-27 20:24:25,518 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3878)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2023-01-27 20:24:25,520 [Thread[Thread-508,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:25,520 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:25,525 [Thread[Thread-508,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:25,534 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:25,548 [Time-limited test] INFO  namenode.NameNode (NameNode.java:startCommonServices(1010)) - NameNode RPC up at: localhost/127.0.0.1:44255
2023-01-27 20:24:25,548 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1383)) - Starting services required for active state
2023-01-27 20:24:25,548 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(857)) - Initializing quota with 12 thread(s)
2023-01-27 20:24:25,550 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(866)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2023-01-27 20:24:25,551 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(326)) - Starting up re-encrypt thread with interval=60000 millisecond.
2023-01-27 20:24:25,552 [CacheReplicationMonitor(768091352)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-01-27 20:24:25,552 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2023-01-27 20:24:25,556 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1769)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1,[DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:25,557 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:25,558 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:25,580 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2023-01-27 20:24:25,581 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:25,581 [Time-limited test] INFO  datanode.BlockScanner (BlockScanner.java:<init>(201)) - Initialized block scanner with targetBytesPerSec 1048576
2023-01-27 20:24:25,581 [Time-limited test] INFO  datanode.DataNode (DataNode.java:<init>(571)) - Configured hostname is 127.0.0.1
2023-01-27 20:24:25,581 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:25,581 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1788)) - Starting DataNode with maxLockedMemory = 0
2023-01-27 20:24:25,582 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1551)) - Opened streaming server at /127.0.0.1:42487
2023-01-27 20:24:25,582 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(93)) - Balancing bandwidth is 104857600 bytes/s
2023-01-27 20:24:25,582 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(94)) - Number threads for balancing is 100
2023-01-27 20:24:25,582 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:25,585 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:25,588 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:25,590 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:25,592 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-01-27 20:24:25,593 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:25,593 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:25,593 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:25,594 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 33911
2023-01-27 20:24:25,594 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:25,595 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:25,596 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:25,596 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:25,598 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@49e06a0a{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:25,599 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6bd07422{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:25,609 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@14a5f00{datanode,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:25,611 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6ea85ddb{HTTP/1.1, (http/1.1)}{localhost:33911}
2023-01-27 20:24:25,612 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @30634ms
2023-01-27 20:24:25,624 [Time-limited test] WARN  web.DatanodeHttpServer (RestCsrfPreventionFilterHandler.java:<init>(75)) - Got null for restCsrfPreventionFilter - will not do any filtering.
2023-01-27 20:24:25,626 [Time-limited test] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(306)) - Listening HTTP traffic on /127.0.0.1:38425
2023-01-27 20:24:25,628 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1816)) - dnUserName = rizky
2023-01-27 20:24:25,628 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1817)) - supergroup = supergroup
2023-01-27 20:24:25,628 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@10884bc9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:25,629 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:25,629 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:37233
2023-01-27 20:24:25,630 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:26,334 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initIpcServer(1438)) - Opened IPC server at /127.0.0.1:37233
2023-01-27 20:24:26,352 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(150)) - Refresh request received for nameservices: null
2023-01-27 20:24:26,353 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(211)) - Starting BPOfferServices for nameservices: <default>
2023-01-27 20:24:26,353 [Thread-541] INFO  datanode.DataNode (BPServiceActor.java:run(877)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44255 starting to offer service
2023-01-27 20:24:26,355 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:26,355 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:26,367 [Thread-541] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(382)) - Acknowledging ACTIVE Namenode during handshake Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44255
2023-01-27 20:24:26,367 [Thread-541] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(356)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2023-01-27 20:24:26,370 [Thread-541] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:26,370 [Thread-541] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 is not formatted for namespace 1639416550. Formatting...
2023-01-27 20:24:26,370 [Thread-541] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d34cd0b5-fe50-469d-a11d-331829523915 for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 
2023-01-27 20:24:26,372 [IPC Server handler 1 on default port 44255] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:26,373 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:26,373 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:26,374 [Thread-541] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:26,374 [Thread-541] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 is not formatted for namespace 1639416550. Formatting...
2023-01-27 20:24:26,374 [Thread-541] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b7a8b03a-3e84-4ab8-8e6a-2927c91a92e0 for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 
2023-01-27 20:24:26,389 [Thread-541] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-54392089-127.0.1.1-1674825865185
2023-01-27 20:24:26,389 [Thread-541] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-54392089-127.0.1.1-1674825865185
2023-01-27 20:24:26,390 [Thread-541] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 and block pool id BP-54392089-127.0.1.1-1674825865185 is not formatted. Formatting ...
2023-01-27 20:24:26,390 [Thread-541] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-54392089-127.0.1.1-1674825865185 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-54392089-127.0.1.1-1674825865185/current
2023-01-27 20:24:26,404 [Thread-541] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-54392089-127.0.1.1-1674825865185
2023-01-27 20:24:26,405 [Thread-541] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-54392089-127.0.1.1-1674825865185
2023-01-27 20:24:26,405 [Thread-541] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 and block pool id BP-54392089-127.0.1.1-1674825865185 is not formatted. Formatting ...
2023-01-27 20:24:26,405 [Thread-541] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-54392089-127.0.1.1-1674825865185 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-54392089-127.0.1.1-1674825865185/current
2023-01-27 20:24:26,408 [Thread-541] INFO  datanode.DataNode (DataNode.java:initStorage(2136)) - Setting up storage: nsid=1639416550;bpid=BP-54392089-127.0.1.1-1674825865185;lv=-57;nsInfo=lv=-67;cid=testClusterID;nsid=1639416550;c=1674825865185;bpid=BP-54392089-127.0.1.1-1674825865185;dnuuid=null
2023-01-27 20:24:26,410 [Thread-541] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1934)) - Generated and persisted new Datanode UUID b7b85fa9-65fd-4b49-964b-347c8614e610
2023-01-27 20:24:26,410 [Thread-541] INFO  fsdataset.RoundRobinVolumeChoosingPolicy (RoundRobinVolumeChoosingPolicy.java:setConf(67)) - Round robin volume choosing policy initialized: dfs.datanode.round-robin-volume-choosing-policy.additional-available-space = 0
2023-01-27 20:24:26,412 [Thread-541] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-d34cd0b5-fe50-469d-a11d-331829523915
2023-01-27 20:24:26,412 [Thread-541] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, StorageType: DISK
2023-01-27 20:24:26,413 [Thread-541] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-b7a8b03a-3e84-4ab8-8e6a-2927c91a92e0
2023-01-27 20:24:26,414 [Thread-541] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, StorageType: DISK
2023-01-27 20:24:26,414 [Thread-541] INFO  impl.MemoryMappableBlockLoader (MemoryMappableBlockLoader.java:initialize(47)) - Initializing cache loader: MemoryMappableBlockLoader.
2023-01-27 20:24:26,415 [Thread-541] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2611)) - Registered FSDatasetState MBean
2023-01-27 20:24:26,416 [Thread-541] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(3188)) - Adding block pool BP-54392089-127.0.1.1-1674825865185
2023-01-27 20:24:26,416 [Thread-558] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-54392089-127.0.1.1-1674825865185 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:26,416 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-54392089-127.0.1.1-1674825865185 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:26,417 [Thread-558] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-54392089-127.0.1.1-1674825865185/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:26,417 [Thread-559] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-54392089-127.0.1.1-1674825865185/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:26,433 [Thread-558] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-54392089-127.0.1.1-1674825865185 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 16ms
2023-01-27 20:24:26,433 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-54392089-127.0.1.1-1674825865185 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 17ms
2023-01-27 20:24:26,434 [Thread-541] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(538)) - Total time to scan all replicas for block pool BP-54392089-127.0.1.1-1674825865185: 17ms
2023-01-27 20:24:26,434 [Thread-562] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-54392089-127.0.1.1-1674825865185 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:26,434 [Thread-563] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-54392089-127.0.1.1-1674825865185 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:26,434 [Thread-562] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-54392089-127.0.1.1-1674825865185/current/replicas doesn't exist 
2023-01-27 20:24:26,434 [Thread-563] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-54392089-127.0.1.1-1674825865185/current/replicas doesn't exist 
2023-01-27 20:24:26,434 [Thread-562] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-54392089-127.0.1.1-1674825865185 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 0ms
2023-01-27 20:24:26,434 [Thread-563] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-54392089-127.0.1.1-1674825865185 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 0ms
2023-01-27 20:24:26,435 [Thread-541] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(292)) - Total time to add all replicas to map for block pool BP-54392089-127.0.1.1-1674825865185: 1ms
2023-01-27 20:24:26,435 [Thread-541] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:26,435 [Thread-541] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:26,435 [Thread-541] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:26,436 [Thread-541] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:26,437 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-54392089-127.0.1.1-1674825865185 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:26,437 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-54392089-127.0.1.1-1674825865185 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:26,437 [Thread-541] WARN  datanode.DirectoryScanner (DirectoryScanner.java:<init>(302)) - dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2023-01-27 20:24:26,437 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-b7a8b03a-3e84-4ab8-8e6a-2927c91a92e0): finished scanning block pool BP-54392089-127.0.1.1-1674825865185
2023-01-27 20:24:26,437 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-d34cd0b5-fe50-469d-a11d-331829523915): finished scanning block pool BP-54392089-127.0.1.1-1674825865185
2023-01-27 20:24:26,437 [Thread-541] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(367)) - Periodic Directory Tree Verification scan starting in 12168958ms with interval of 21600000ms and throttle limit of -1ms/s
2023-01-27 20:24:26,437 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-b7a8b03a-3e84-4ab8-8e6a-2927c91a92e0): no suitable block pools found to scan.  Waiting 1814400000 ms.
2023-01-27 20:24:26,438 [BP-54392089-127.0.1.1-1674825865185 heartbeating to localhost/127.0.0.1:44255] INFO  datanode.DataNode (BPServiceActor.java:register(819)) - Block pool BP-54392089-127.0.1.1-1674825865185 (Datanode Uuid b7b85fa9-65fd-4b49-964b-347c8614e610) service to localhost/127.0.0.1:44255 beginning handshake with NN: localhost/127.0.0.1:44255.
2023-01-27 20:24:26,438 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-d34cd0b5-fe50-469d-a11d-331829523915): no suitable block pools found to scan.  Waiting 1814399999 ms.
2023-01-27 20:24:26,439 [IPC Server handler 2 on default port 44255] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1166)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42487, datanodeUuid=b7b85fa9-65fd-4b49-964b-347c8614e610, infoPort=38425, infoSecurePort=0, ipcPort=37233, storageInfo=lv=-57;cid=testClusterID;nsid=1639416550;c=1674825865185) storage b7b85fa9-65fd-4b49-964b-347c8614e610
2023-01-27 20:24:26,439 [IPC Server handler 2 on default port 44255] INFO  net.NetworkTopology (NetworkTopology.java:add(156)) - Adding a new node: /default-rack/127.0.0.1:42487
2023-01-27 20:24:26,440 [IPC Server handler 2 on default port 44255] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(200)) - Registered DN b7b85fa9-65fd-4b49-964b-347c8614e610 (127.0.0.1:42487).
2023-01-27 20:24:26,441 [BP-54392089-127.0.1.1-1674825865185 heartbeating to localhost/127.0.0.1:44255] INFO  datanode.DataNode (BPServiceActor.java:register(846)) - Block pool BP-54392089-127.0.1.1-1674825865185 (Datanode Uuid b7b85fa9-65fd-4b49-964b-347c8614e610) service to localhost/127.0.0.1:44255 successfully registered with NN: localhost/127.0.0.1:44255.
2023-01-27 20:24:26,441 [BP-54392089-127.0.1.1-1674825865185 heartbeating to localhost/127.0.0.1:44255] INFO  datanode.DataNode (BPServiceActor.java:offerService(680)) - For namenode localhost/127.0.0.1:44255 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2023-01-27 20:24:26,442 [ibr-executor-0] INFO  datanode.DataNode (BPServiceActor.java:run(1145)) - Starting IBR Task Handler.
2023-01-27 20:24:26,443 [IPC Server handler 3 on default port 44255] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-d34cd0b5-fe50-469d-a11d-331829523915 for DN 127.0.0.1:42487
2023-01-27 20:24:26,443 [IPC Server handler 3 on default port 44255] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-b7a8b03a-3e84-4ab8-8e6a-2927c91a92e0 for DN 127.0.0.1:42487
2023-01-27 20:24:26,445 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0xdef4e0f756a6612d with lease ID 0xb40b3224ea6d8902: Processing first storage report for DS-b7a8b03a-3e84-4ab8-8e6a-2927c91a92e0 from datanode DatanodeRegistration(127.0.0.1:42487, datanodeUuid=b7b85fa9-65fd-4b49-964b-347c8614e610, infoPort=38425, infoSecurePort=0, ipcPort=37233, storageInfo=lv=-57;cid=testClusterID;nsid=1639416550;c=1674825865185)
2023-01-27 20:24:26,445 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0xdef4e0f756a6612d with lease ID 0xb40b3224ea6d8902: from storage DS-b7a8b03a-3e84-4ab8-8e6a-2927c91a92e0 node DatanodeRegistration(127.0.0.1:42487, datanodeUuid=b7b85fa9-65fd-4b49-964b-347c8614e610, infoPort=38425, infoSecurePort=0, ipcPort=37233, storageInfo=lv=-57;cid=testClusterID;nsid=1639416550;c=1674825865185), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:26,445 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0xdef4e0f756a6612d with lease ID 0xb40b3224ea6d8902: Processing first storage report for DS-d34cd0b5-fe50-469d-a11d-331829523915 from datanode DatanodeRegistration(127.0.0.1:42487, datanodeUuid=b7b85fa9-65fd-4b49-964b-347c8614e610, infoPort=38425, infoSecurePort=0, ipcPort=37233, storageInfo=lv=-57;cid=testClusterID;nsid=1639416550;c=1674825865185)
2023-01-27 20:24:26,445 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0xdef4e0f756a6612d with lease ID 0xb40b3224ea6d8902: from storage DS-d34cd0b5-fe50-469d-a11d-331829523915 node DatanodeRegistration(127.0.0.1:42487, datanodeUuid=b7b85fa9-65fd-4b49-964b-347c8614e610, infoPort=38425, infoSecurePort=0, ipcPort=37233, storageInfo=lv=-57;cid=testClusterID;nsid=1639416550;c=1674825865185), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:26,446 [BP-54392089-127.0.1.1-1674825865185 heartbeating to localhost/127.0.0.1:44255] INFO  datanode.DataNode (BPServiceActor.java:blockReport(464)) - Successfully sent block report 0xdef4e0f756a6612d with lease ID 0xb40b3224ea6d8902 to namenode: localhost/127.0.0.1:44255,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msecs to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-01-27 20:24:26,446 [Command processor] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(763)) - Got finalize command for block pool BP-54392089-127.0.1.1-1674825865185
2023-01-27 20:24:26,475 [IPC Server handler 5 on default port 44255] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:26,476 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:26,479 [IPC Server handler 6 on default port 44255] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:26,480 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:26,485 [qtp976680841-815] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:26 +0000] "OPTIONS /kms/v1/keys HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:26,492 [qtp976680841-809] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:26,493 [qtp976680841-809] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:26,493 [qtp976680841-809] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:26,493 [qtp976680841-809] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:26,493 [qtp976680841-809] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:26,493 [qtp976680841-809] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:26,493 [qtp976680841-809] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:26,494 [qtp976680841-809] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:26,496 [qtp976680841-809] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:26 +0000] "OPTIONS /kms/v1/keys?user.name=rizky HTTP/1.1" 200 520 "-" "Java/1.8.0_352"
2023-01-27 20:24:26,903 [qtp976680841-810] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=CREATE_KEY, key=test_key, user=rizky] UserProvidedMaterial:false Description:test_key
2023-01-27 20:24:26,904 [qtp976680841-810] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:26 +0000] "POST /kms/v1/keys HTTP/1.1" 201 98 "-" "Java/1.8.0_352"
2023-01-27 20:24:27,860 [qtp1869882554-841] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.namenode.web.resources
  org.apache.hadoop.hdfs.web.resources
2023-01-27 20:24:28,114 [qtp1869882554-841] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods
2023-01-27 20:24:28,114 [qtp1869882554-841] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
  class org.apache.hadoop.hdfs.web.resources.UserProvider
2023-01-27 20:24:28,118 [qtp1869882554-841] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:24:28,284 [qtp1869882554-841] WARN  inject.Errors (Errors.java:processErrorMessages(173)) - The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam,org.apache.hadoop.hdfs.web.resources.NameSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageTypeParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.SnapshotDiffStartPathParam,org.apache.hadoop.hdfs.web.resources.SnapshotDiffIndexParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2023-01-27 20:24:28,287 [IPC Server handler 0 on default port 44255] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:createPassword(484)) - Creating password for identifier: (token for rizky: HDFS_DELEGATION_TOKEN owner=rizky, renewer=JobTracker, realUser=, issueDate=1674825868287, maxDate=1675430668287, sequenceNumber=1, masterKeyId=2), currentKey: 2
2023-01-27 20:24:28,288 [IPC Server handler 0 on default port 44255] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDelegationToken	src=HDFS_DELEGATION_TOKEN token 1 for rizky with renewer JobTracker	dst=null	perm=null	proto=webhdfs
2023-01-27 20:24:28,299 [qtp1869882554-841] INFO  requests.namenode (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:27 +0000] "GET /webhdfs/v1/?op=GETDELEGATIONTOKEN&user.name=rizky&renewer=JobTracker HTTP/1.1" 200 149 "-" "Java/1.8.0_352"
2023-01-27 20:24:28,304 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2159)) - Shutting down the Mini HDFS Cluster
2023-01-27 20:24:28,304 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2208)) - Shutting down DataNode 0
2023-01-27 20:24:28,304 [Time-limited test] INFO  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(430)) - Shutdown has been called
2023-01-27 20:24:28,304 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7c0c4314] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(395)) - Closing all peers.
2023-01-27 20:24:28,305 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-b7a8b03a-3e84-4ab8-8e6a-2927c91a92e0) exiting.
2023-01-27 20:24:28,305 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-d34cd0b5-fe50-469d-a11d-331829523915) exiting.
2023-01-27 20:24:28,308 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@14a5f00{datanode,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:28,309 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6ea85ddb{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:28,309 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:28,310 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@6bd07422{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:28,310 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@49e06a0a{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:28,310 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2470)) - Waiting up to 30 seconds for transfer threads to complete
2023-01-27 20:24:28,311 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 37233
2023-01-27 20:24:28,311 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:28,311 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:28,312 [Command processor] ERROR datanode.DataNode (BPServiceActor.java:processQueue(1430)) - Command processor encountered interrupt and exit.
2023-01-27 20:24:28,312 [BP-54392089-127.0.1.1-1674825865185 heartbeating to localhost/127.0.0.1:44255] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:28,312 [Command processor] WARN  datanode.DataNode (BPServiceActor.java:run(1414)) - Ending command processor service for: Thread[Command processor,5,main]
2023-01-27 20:24:28,312 [ibr-executor-0] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:28,312 [BP-54392089-127.0.1.1-1674825865185 heartbeating to localhost/127.0.0.1:44255] WARN  datanode.DataNode (BPServiceActor.java:run(924)) - Ending block pool service for: Block pool BP-54392089-127.0.1.1-1674825865185 (Datanode Uuid b7b85fa9-65fd-4b49-964b-347c8614e610) service to localhost/127.0.0.1:44255
2023-01-27 20:24:28,313 [BP-54392089-127.0.1.1-1674825865185 heartbeating to localhost/127.0.0.1:44255] INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-54392089-127.0.1.1-1674825865185 (Datanode Uuid b7b85fa9-65fd-4b49-964b-347c8614e610)
2023-01-27 20:24:28,313 [BP-54392089-127.0.1.1-1674825865185 heartbeating to localhost/127.0.0.1:44255] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(3225)) - Removing block pool BP-54392089-127.0.1.1-1674825865185
2023-01-27 20:24:28,314 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-54392089-127.0.1.1-1674825865185] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:28,314 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-54392089-127.0.1.1-1674825865185] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:28,315 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(208)) - Shutting down all async disk service threads
2023-01-27 20:24:28,315 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(216)) - All async disk service threads have been shut down
2023-01-27 20:24:28,316 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(186)) - Shutting down all async lazy persist service threads
2023-01-27 20:24:28,316 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(193)) - All async lazy persist service threads have been shut down
2023-01-27 20:24:28,316 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2559)) - Shutdown complete.
2023-01-27 20:24:28,317 [Time-limited test] WARN  datanode.DataSetLockManager (DataSetLockManager.java:lockLeakCheck(260)) - not open lock leak check func
2023-01-27 20:24:28,317 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2241)) - Shutting down the namenode
2023-01-27 20:24:28,317 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:28,317 [Thread[Thread-508,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:28,317 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1467)) - Ending log segment 1, 4
2023-01-27 20:24:28,317 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@340c3c37] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4561)) - NameNodeEditLogRoller was interrupted, exiting
2023-01-27 20:24:28,317 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(576)) - EDEKCacheLoader interrupted before warming up.
2023-01-27 20:24:28,318 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@274af7ee] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4658)) - LazyPersistFileScrubber was interrupted, exiting
2023-01-27 20:24:28,319 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(801)) - Number of transactions: 5 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 14 11 
2023-01-27 20:24:28,320 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000005
2023-01-27 20:24:28,320 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000005
2023-01-27 20:24:28,320 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(276)) - FSEditLogAsync was interrupted, exiting
2023-01-27 20:24:28,321 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(267)) - Re-encryption updater thread interrupted. Exiting.
2023-01-27 20:24:28,321 [CacheReplicationMonitor(768091352)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2023-01-27 20:24:28,321 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(335)) - Re-encrypt handler interrupted. Exiting
2023-01-27 20:24:28,322 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 44255
2023-01-27 20:24:28,323 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:28,325 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:28,326 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(5160)) - Stopping RedundancyMonitor.
2023-01-27 20:24:28,326 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5134)) - Stopping MarkedDeleteBlockScrubber.
2023-01-27 20:24:28,338 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:28,338 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:28,339 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@498f9306{hdfs,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:28,341 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5375724c{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:28,341 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:28,341 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7cbeaa28{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:28,341 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@36182254{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:28,347 [Thread[Thread-476,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:28,348 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextDestroyed(197)) - KMS Stopped
2023-01-27 20:24:28,348 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@429964db{kms,/,null,STOPPED}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:28,349 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4ee2a62c{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:28,350 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:28,350 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@52f396e9{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-27 20:24:28,350 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@311eb015{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:28,351 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2023-01-27 20:24:28,352 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2023-01-27 20:24:28,353 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(612)) - DataNode metrics system shutdown complete.
2023-01-27 20:24:28,394 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:28,395 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context kms
2023-01-27 20:24:28,395 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:28,395 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:28,395 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:28,395 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 45529
2023-01-27 20:24:28,396 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:28,397 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:28,397 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:28,397 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:24:28,398 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@692c2113{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:28,399 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@54901ade{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-27 20:24:28,437 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(94)) - -------------------------------------------------------------
2023-01-27 20:24:28,437 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(95)) -   Java runtime version : 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:28,437 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(97)) -   User: rizky
2023-01-27 20:24:28,437 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(98)) -   KMS Hadoop Version: 3.4.0-SNAPSHOT
2023-01-27 20:24:28,438 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(99)) - -------------------------------------------------------------
2023-01-27 20:24:28,438 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'CREATE' ACL '*'
2023-01-27 20:24:28,439 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DELETE' ACL '*'
2023-01-27 20:24:28,439 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'ROLLOVER' ACL '*'
2023-01-27 20:24:28,439 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET' ACL '*'
2023-01-27 20:24:28,439 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_KEYS' ACL '*'
2023-01-27 20:24:28,439 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_METADATA' ACL '*'
2023-01-27 20:24:28,439 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'SET_KEY_MATERIAL' ACL '*'
2023-01-27 20:24:28,440 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GENERATE_EEK' ACL '*'
2023-01-27 20:24:28,440 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DECRYPT_EEK' ACL '*'
2023-01-27 20:24:28,440 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2023-01-27 20:24:28,440 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2023-01-27 20:24:28,440 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2023-01-27 20:24:28,440 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2023-01-27 20:24:28,443 [Time-limited test] INFO  server.KMSAudit (KMSAudit.java:initializeAuditLoggers(157)) - Initializing audit logger class org.apache.hadoop.crypto.key.kms.server.SimpleKMSAuditLogger
2023-01-27 20:24:28,444 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(149)) - Initialized KeyProvider CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/8f2ec545-e9ed-4b46-b254-e7af67e396d2/kms.keystore
2023-01-27 20:24:28,446 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(163)) - Initialized KeyProviderCryptoExtension org.apache.hadoop.crypto.key.kms.server.KeyAuthorizationKeyProvider: EagerKeyGeneratorKeyProviderCryptoExtension: KeyProviderCryptoExtension: CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/8f2ec545-e9ed-4b46-b254-e7af67e396d2/kms.keystore
2023-01-27 20:24:28,446 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(168)) - Default key bitlength is 128
2023-01-27 20:24:28,446 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(169)) - KMS Started
2023-01-27 20:24:28,448 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:28,451 [Time-limited test] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.crypto.key.kms.server
2023-01-27 20:24:28,455 [Thread[Thread-580,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:28,456 [Thread[Thread-580,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:28,472 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMS
2023-01-27 20:24:28,472 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
  class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
2023-01-27 20:24:28,476 [Time-limited test] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:24:28,631 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@2ca34181{kms,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/2/kms/webapp/,AVAILABLE}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:28,634 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@38756c84{HTTP/1.1, (http/1.1)}{localhost:45529}
2023-01-27 20:24:28,634 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @33656ms
2023-01-27 20:24:28,642 [Time-limited test] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(120)) - Loaded properties from hadoop-metrics2.properties
2023-01-27 20:24:28,652 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 0 second(s).
2023-01-27 20:24:28,652 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - KMS metrics system started
2023-01-27 20:24:28,674 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1504d080] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:28,684 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(566)) - starting cluster: numNameNodes=1, numDataNodes=1
2023-01-27 20:24:28,687 [Time-limited test] INFO  namenode.NameNode (NameNode.java:format(1366)) - Formatting using clusterid: testClusterID
2023-01-27 20:24:28,687 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:28,702 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@5cbb2fb6
2023-01-27 20:24:28,702 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:28,702 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:28,703 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:28,703 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:28,703 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:28,703 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:28,703 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:28,703 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:28,704 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:28,704 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:28,704 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:28,705 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:28
2023-01-27 20:24:28,705 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:28,705 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:28,705 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:28,705 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:28,707 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:28,707 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:28,708 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:28,708 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:28,708 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:28,708 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:28,708 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:28,708 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:28,708 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:28,708 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:28,708 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:28,709 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:28,709 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:28,709 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:28,709 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:28,709 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:28,710 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:28,710 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:28,711 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:28,711 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:28,711 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:28,711 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:28,711 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:28,712 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:28,712 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:28,712 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:28,712 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:28,712 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:28,712 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:28,713 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:28,713 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:28,713 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:28,714 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:28,714 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:28,714 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:28,714 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:28,715 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:28,715 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:28,716 [Time-limited test] INFO  namenode.FSImage (FSImage.java:format(186)) - Allocated new BlockPoolId: BP-139745935-127.0.1.1-1674825868716
2023-01-27 20:24:28,719 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 has been successfully formatted.
2023-01-27 20:24:28,721 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 has been successfully formatted.
2023-01-27 20:24:28,760 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:28,764 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:28,772 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 436 bytes saved in 0 seconds .
2023-01-27 20:24:28,776 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 436 bytes saved in 0 seconds .
2023-01-27 20:24:28,778 [Time-limited test] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(202)) - Going to retain 1 images with txid >= 0
2023-01-27 20:24:28,797 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:28,797 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:28,798 [Time-limited test] INFO  namenode.NameNode (NameNode.java:createNameNode(1824)) - createNameNode []
2023-01-27 20:24:28,799 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2023-01-27 20:24:28,799 [Time-limited test] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2023-01-27 20:24:28,847 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7db1773a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:28,859 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1736)) - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2023-01-27 20:24:28,860 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1758)) - Starting Web-server for hdfs at: http://localhost:0
2023-01-27 20:24:28,860 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:28,861 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:28,885 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:28,887 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:28,887 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-01-27 20:24:28,888 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:28,888 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:28,889 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2023-01-27 20:24:28,889 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2023-01-27 20:24:28,889 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2023-01-27 20:24:28,893 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:28,893 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(1018)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-01-27 20:24:28,894 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 44439
2023-01-27 20:24:28,894 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:28,984 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:28,984 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:28,984 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:28,987 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:28,987 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@e7afc78{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:28,988 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7eec4ddd{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:28,992 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3d84d4b4{hdfs,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:28,994 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@64d5f973{HTTP/1.1, (http/1.1)}{localhost:44439}
2023-01-27 20:24:28,994 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @34016ms
2023-01-27 20:24:28,995 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:29,006 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@55eb102c
2023-01-27 20:24:29,006 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:29,006 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:29,007 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:29,007 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:29,007 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:29,007 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:29,007 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:29,007 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:29,008 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:29,008 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:29,008 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:29,008 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:29
2023-01-27 20:24:29,008 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:29,008 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:29,008 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:29,009 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:29,010 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:29,010 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:29,010 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:29,010 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:29,011 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:29,011 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:29,011 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:29,011 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:29,011 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:29,011 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:29,011 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:29,011 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:29,011 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:29,012 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:29,012 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:29,012 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:29,012 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:29,013 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:29,013 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:29,013 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:29,013 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:29,013 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:29,013 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:29,013 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:29,014 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:29,014 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:29,014 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:29,014 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:29,014 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:29,015 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:29,015 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:29,015 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:29,015 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:29,015 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:29,015 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:29,015 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:29,016 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:29,016 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:29,027 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:29,029 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:29,030 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current
2023-01-27 20:24:29,030 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current
2023-01-27 20:24:29,031 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(734)) - No edit log streams selected.
2023-01-27 20:24:29,031 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(800)) - Planning to load image: FSImageFile(file=/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-01-27 20:24:29,033 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSectionHeader(411)) - Loading 1 INodes.
2023-01-27 20:24:29,034 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(369)) - Successfully loaded 1 inodes
2023-01-27 20:24:29,034 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:waitBlocksMapAndNameCacheUpdateFinished(342)) - Completed update blocks map and name cache, total waiting duration 0ms.
2023-01-27 20:24:29,036 [Time-limited test] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(255)) - Loaded FSImage in 0 seconds.
2023-01-27 20:24:29,036 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(980)) - Loaded image for txid 0 from /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000
2023-01-27 20:24:29,036 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1271)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-01-27 20:24:29,039 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1417)) - Starting log segment at 1
2023-01-27 20:24:29,053 [Time-limited test] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2023-01-27 20:24:29,054 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(836)) - Finished loading FSImage in 37 msecs
2023-01-27 20:24:29,054 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(451)) - RPC server is binding to localhost:0
2023-01-27 20:24:29,054 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(456)) - Enable NameNode state context:false
2023-01-27 20:24:29,055 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:29,055 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:44837
2023-01-27 20:24:29,058 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:29,070 [Time-limited test] INFO  namenode.NameNode (NameNode.java:initialize(893)) - Clients are to use localhost:44837 to access this namenode/service.
2023-01-27 20:24:29,071 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5607)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2023-01-27 20:24:29,084 [Time-limited test] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(166)) - Number of blocks under construction: 0
2023-01-27 20:24:29,084 [Time-limited test] INFO  blockmanagement.DatanodeAdminDefaultMonitor (DatanodeAdminDefaultMonitor.java:processConf(126)) - Initialized the Default Decommission and Maintenance monitor
2023-01-27 20:24:29,085 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5102)) - Start MarkedDeleteBlockScrubber thread
2023-01-27 20:24:29,085 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(5310)) - initializing replication queues
2023-01-27 20:24:29,085 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(409)) - STATE* Leaving safe mode after 0 secs
2023-01-27 20:24:29,085 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(415)) - STATE* Network topology has 0 racks and 0 datanodes
2023-01-27 20:24:29,086 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(417)) - STATE* UnderReplicatedBlocks has 0 blocks
2023-01-27 20:24:29,089 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:29,092 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3870)) - Total number of blocks            = 0
2023-01-27 20:24:29,092 [Thread[Thread-612,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:29,093 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3871)) - Number of invalid blocks          = 0
2023-01-27 20:24:29,093 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3872)) - Number of under-replicated blocks = 0
2023-01-27 20:24:29,093 [Thread[Thread-612,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:29,093 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3873)) - Number of  over-replicated blocks = 0
2023-01-27 20:24:29,094 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3875)) - Number of blocks being written    = 0
2023-01-27 20:24:29,094 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3878)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2023-01-27 20:24:29,096 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:29,096 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:29,101 [Time-limited test] INFO  namenode.NameNode (NameNode.java:startCommonServices(1010)) - NameNode RPC up at: localhost/127.0.0.1:44837
2023-01-27 20:24:29,102 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1383)) - Starting services required for active state
2023-01-27 20:24:29,102 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(857)) - Initializing quota with 12 thread(s)
2023-01-27 20:24:29,109 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(866)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2023-01-27 20:24:29,125 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(326)) - Starting up re-encrypt thread with interval=60000 millisecond.
2023-01-27 20:24:29,251 [CacheReplicationMonitor(2101366375)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-01-27 20:24:29,252 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2023-01-27 20:24:29,253 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1769)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1,[DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:29,254 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:29,263 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:29,274 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2023-01-27 20:24:29,274 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:29,274 [Time-limited test] INFO  datanode.BlockScanner (BlockScanner.java:<init>(201)) - Initialized block scanner with targetBytesPerSec 1048576
2023-01-27 20:24:29,274 [Time-limited test] INFO  datanode.DataNode (DataNode.java:<init>(571)) - Configured hostname is 127.0.0.1
2023-01-27 20:24:29,274 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:29,275 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1788)) - Starting DataNode with maxLockedMemory = 0
2023-01-27 20:24:29,275 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1551)) - Opened streaming server at /127.0.0.1:46805
2023-01-27 20:24:29,275 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(93)) - Balancing bandwidth is 104857600 bytes/s
2023-01-27 20:24:29,275 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(94)) - Number threads for balancing is 100
2023-01-27 20:24:29,276 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:29,277 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:29,278 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:29,281 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:29,282 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-01-27 20:24:29,282 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:29,282 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:29,283 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:29,283 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 43731
2023-01-27 20:24:29,283 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:29,284 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:29,284 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:29,284 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:29,285 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@76273567{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:29,286 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@262d60f{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:29,290 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@5b845ab6{datanode,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:29,291 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@1bb6fa0c{HTTP/1.1, (http/1.1)}{localhost:43731}
2023-01-27 20:24:29,291 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @34313ms
2023-01-27 20:24:29,295 [Time-limited test] WARN  web.DatanodeHttpServer (RestCsrfPreventionFilterHandler.java:<init>(75)) - Got null for restCsrfPreventionFilter - will not do any filtering.
2023-01-27 20:24:29,299 [Time-limited test] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(306)) - Listening HTTP traffic on /127.0.0.1:33669
2023-01-27 20:24:29,299 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1816)) - dnUserName = rizky
2023-01-27 20:24:29,299 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6b5b0018] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:29,299 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1817)) - supergroup = supergroup
2023-01-27 20:24:29,300 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:29,301 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:39861
2023-01-27 20:24:29,309 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initIpcServer(1438)) - Opened IPC server at /127.0.0.1:39861
2023-01-27 20:24:29,323 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:29,326 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(150)) - Refresh request received for nameservices: null
2023-01-27 20:24:29,327 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(211)) - Starting BPOfferServices for nameservices: <default>
2023-01-27 20:24:29,328 [Thread-645] INFO  datanode.DataNode (BPServiceActor.java:run(877)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44837 starting to offer service
2023-01-27 20:24:29,332 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:29,337 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:29,371 [Thread-645] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(382)) - Acknowledging ACTIVE Namenode during handshake Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44837
2023-01-27 20:24:29,379 [Thread-645] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(356)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2023-01-27 20:24:29,386 [IPC Server handler 1 on default port 44837] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:29,387 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:29,387 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:29,387 [Thread-645] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:29,387 [Thread-645] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 is not formatted for namespace 1221780143. Formatting...
2023-01-27 20:24:29,388 [Thread-645] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-84410a0c-171e-4849-b392-d11d2e76672f for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 
2023-01-27 20:24:29,391 [Thread-645] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:29,391 [Thread-645] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 is not formatted for namespace 1221780143. Formatting...
2023-01-27 20:24:29,392 [Thread-645] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0957806f-d14f-4b4f-9ab9-e0d310dc9142 for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 
2023-01-27 20:24:29,414 [Thread-645] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-139745935-127.0.1.1-1674825868716
2023-01-27 20:24:29,414 [Thread-645] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-139745935-127.0.1.1-1674825868716
2023-01-27 20:24:29,414 [Thread-645] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 and block pool id BP-139745935-127.0.1.1-1674825868716 is not formatted. Formatting ...
2023-01-27 20:24:29,414 [Thread-645] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-139745935-127.0.1.1-1674825868716 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-139745935-127.0.1.1-1674825868716/current
2023-01-27 20:24:29,439 [Thread-645] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-139745935-127.0.1.1-1674825868716
2023-01-27 20:24:29,439 [Thread-645] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-139745935-127.0.1.1-1674825868716
2023-01-27 20:24:29,439 [Thread-645] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 and block pool id BP-139745935-127.0.1.1-1674825868716 is not formatted. Formatting ...
2023-01-27 20:24:29,439 [Thread-645] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-139745935-127.0.1.1-1674825868716 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-139745935-127.0.1.1-1674825868716/current
2023-01-27 20:24:29,442 [Thread-645] INFO  datanode.DataNode (DataNode.java:initStorage(2136)) - Setting up storage: nsid=1221780143;bpid=BP-139745935-127.0.1.1-1674825868716;lv=-57;nsInfo=lv=-67;cid=testClusterID;nsid=1221780143;c=1674825868716;bpid=BP-139745935-127.0.1.1-1674825868716;dnuuid=null
2023-01-27 20:24:29,444 [Thread-645] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1934)) - Generated and persisted new Datanode UUID 797da0cb-1379-4240-a676-95605d211e04
2023-01-27 20:24:29,445 [Thread-645] INFO  fsdataset.RoundRobinVolumeChoosingPolicy (RoundRobinVolumeChoosingPolicy.java:setConf(67)) - Round robin volume choosing policy initialized: dfs.datanode.round-robin-volume-choosing-policy.additional-available-space = 0
2023-01-27 20:24:29,446 [Thread-645] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-84410a0c-171e-4849-b392-d11d2e76672f
2023-01-27 20:24:29,446 [Thread-645] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, StorageType: DISK
2023-01-27 20:24:29,450 [Thread-645] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-0957806f-d14f-4b4f-9ab9-e0d310dc9142
2023-01-27 20:24:29,452 [Thread-645] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, StorageType: DISK
2023-01-27 20:24:29,452 [Thread-645] INFO  impl.MemoryMappableBlockLoader (MemoryMappableBlockLoader.java:initialize(47)) - Initializing cache loader: MemoryMappableBlockLoader.
2023-01-27 20:24:29,452 [Thread-645] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2611)) - Registered FSDatasetState MBean
2023-01-27 20:24:29,453 [Thread-645] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(3188)) - Adding block pool BP-139745935-127.0.1.1-1674825868716
2023-01-27 20:24:29,456 [Thread-662] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-139745935-127.0.1.1-1674825868716 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:29,456 [Thread-663] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-139745935-127.0.1.1-1674825868716 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:29,456 [Thread-662] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-139745935-127.0.1.1-1674825868716/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:29,456 [Thread-663] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-139745935-127.0.1.1-1674825868716/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:29,489 [IPC Server handler 2 on default port 44837] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:29,490 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:29,490 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:29,496 [Thread-662] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-139745935-127.0.1.1-1674825868716 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 40ms
2023-01-27 20:24:29,500 [Thread-663] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-139745935-127.0.1.1-1674825868716 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 43ms
2023-01-27 20:24:29,500 [Thread-645] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(538)) - Total time to scan all replicas for block pool BP-139745935-127.0.1.1-1674825868716: 47ms
2023-01-27 20:24:29,500 [Thread-666] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-139745935-127.0.1.1-1674825868716 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:29,501 [Thread-667] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-139745935-127.0.1.1-1674825868716 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:29,501 [Thread-666] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-139745935-127.0.1.1-1674825868716/current/replicas doesn't exist 
2023-01-27 20:24:29,501 [Thread-667] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-139745935-127.0.1.1-1674825868716/current/replicas doesn't exist 
2023-01-27 20:24:29,502 [Thread-667] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-139745935-127.0.1.1-1674825868716 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 1ms
2023-01-27 20:24:29,503 [Thread-666] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-139745935-127.0.1.1-1674825868716 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 3ms
2023-01-27 20:24:29,504 [Thread-645] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(292)) - Total time to add all replicas to map for block pool BP-139745935-127.0.1.1-1674825868716: 4ms
2023-01-27 20:24:29,505 [Thread-645] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:29,505 [Thread-645] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:29,505 [Thread-645] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:29,506 [Thread-645] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:29,507 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-139745935-127.0.1.1-1674825868716 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:29,507 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-139745935-127.0.1.1-1674825868716 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:29,507 [Thread-645] WARN  datanode.DirectoryScanner (DirectoryScanner.java:<init>(302)) - dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2023-01-27 20:24:29,507 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-0957806f-d14f-4b4f-9ab9-e0d310dc9142): finished scanning block pool BP-139745935-127.0.1.1-1674825868716
2023-01-27 20:24:29,507 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-84410a0c-171e-4849-b392-d11d2e76672f): finished scanning block pool BP-139745935-127.0.1.1-1674825868716
2023-01-27 20:24:29,508 [Thread-645] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(367)) - Periodic Directory Tree Verification scan starting in 578122ms with interval of 21600000ms and throttle limit of -1ms/s
2023-01-27 20:24:29,508 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-0957806f-d14f-4b4f-9ab9-e0d310dc9142): no suitable block pools found to scan.  Waiting 1814399999 ms.
2023-01-27 20:24:29,517 [BP-139745935-127.0.1.1-1674825868716 heartbeating to localhost/127.0.0.1:44837] INFO  datanode.DataNode (BPServiceActor.java:register(819)) - Block pool BP-139745935-127.0.1.1-1674825868716 (Datanode Uuid 797da0cb-1379-4240-a676-95605d211e04) service to localhost/127.0.0.1:44837 beginning handshake with NN: localhost/127.0.0.1:44837.
2023-01-27 20:24:29,518 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-84410a0c-171e-4849-b392-d11d2e76672f): no suitable block pools found to scan.  Waiting 1814399989 ms.
2023-01-27 20:24:29,518 [IPC Server handler 3 on default port 44837] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1166)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46805, datanodeUuid=797da0cb-1379-4240-a676-95605d211e04, infoPort=33669, infoSecurePort=0, ipcPort=39861, storageInfo=lv=-57;cid=testClusterID;nsid=1221780143;c=1674825868716) storage 797da0cb-1379-4240-a676-95605d211e04
2023-01-27 20:24:29,519 [IPC Server handler 3 on default port 44837] INFO  net.NetworkTopology (NetworkTopology.java:add(156)) - Adding a new node: /default-rack/127.0.0.1:46805
2023-01-27 20:24:29,519 [IPC Server handler 3 on default port 44837] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(200)) - Registered DN 797da0cb-1379-4240-a676-95605d211e04 (127.0.0.1:46805).
2023-01-27 20:24:29,521 [BP-139745935-127.0.1.1-1674825868716 heartbeating to localhost/127.0.0.1:44837] INFO  datanode.DataNode (BPServiceActor.java:register(846)) - Block pool BP-139745935-127.0.1.1-1674825868716 (Datanode Uuid 797da0cb-1379-4240-a676-95605d211e04) service to localhost/127.0.0.1:44837 successfully registered with NN: localhost/127.0.0.1:44837.
2023-01-27 20:24:29,521 [BP-139745935-127.0.1.1-1674825868716 heartbeating to localhost/127.0.0.1:44837] INFO  datanode.DataNode (BPServiceActor.java:offerService(680)) - For namenode localhost/127.0.0.1:44837 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2023-01-27 20:24:29,522 [ibr-executor-0] INFO  datanode.DataNode (BPServiceActor.java:run(1145)) - Starting IBR Task Handler.
2023-01-27 20:24:29,523 [IPC Server handler 4 on default port 44837] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-84410a0c-171e-4849-b392-d11d2e76672f for DN 127.0.0.1:46805
2023-01-27 20:24:29,524 [IPC Server handler 4 on default port 44837] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-0957806f-d14f-4b4f-9ab9-e0d310dc9142 for DN 127.0.0.1:46805
2023-01-27 20:24:29,526 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0xf80cdd8c70a8b1ae with lease ID 0xf8468ff90cf29a29: Processing first storage report for DS-0957806f-d14f-4b4f-9ab9-e0d310dc9142 from datanode DatanodeRegistration(127.0.0.1:46805, datanodeUuid=797da0cb-1379-4240-a676-95605d211e04, infoPort=33669, infoSecurePort=0, ipcPort=39861, storageInfo=lv=-57;cid=testClusterID;nsid=1221780143;c=1674825868716)
2023-01-27 20:24:29,527 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0xf80cdd8c70a8b1ae with lease ID 0xf8468ff90cf29a29: from storage DS-0957806f-d14f-4b4f-9ab9-e0d310dc9142 node DatanodeRegistration(127.0.0.1:46805, datanodeUuid=797da0cb-1379-4240-a676-95605d211e04, infoPort=33669, infoSecurePort=0, ipcPort=39861, storageInfo=lv=-57;cid=testClusterID;nsid=1221780143;c=1674825868716), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:29,527 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0xf80cdd8c70a8b1ae with lease ID 0xf8468ff90cf29a29: Processing first storage report for DS-84410a0c-171e-4849-b392-d11d2e76672f from datanode DatanodeRegistration(127.0.0.1:46805, datanodeUuid=797da0cb-1379-4240-a676-95605d211e04, infoPort=33669, infoSecurePort=0, ipcPort=39861, storageInfo=lv=-57;cid=testClusterID;nsid=1221780143;c=1674825868716)
2023-01-27 20:24:29,527 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0xf80cdd8c70a8b1ae with lease ID 0xf8468ff90cf29a29: from storage DS-84410a0c-171e-4849-b392-d11d2e76672f node DatanodeRegistration(127.0.0.1:46805, datanodeUuid=797da0cb-1379-4240-a676-95605d211e04, infoPort=33669, infoSecurePort=0, ipcPort=39861, storageInfo=lv=-57;cid=testClusterID;nsid=1221780143;c=1674825868716), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:29,528 [BP-139745935-127.0.1.1-1674825868716 heartbeating to localhost/127.0.0.1:44837] INFO  datanode.DataNode (BPServiceActor.java:blockReport(464)) - Successfully sent block report 0xf80cdd8c70a8b1ae with lease ID 0xf8468ff90cf29a29 to namenode: localhost/127.0.0.1:44837,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msecs to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-01-27 20:24:29,528 [Command processor] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(763)) - Got finalize command for block pool BP-139745935-127.0.1.1-1674825868716
2023-01-27 20:24:29,592 [IPC Server handler 6 on default port 44837] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:29,593 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:29,597 [IPC Server handler 7 on default port 44837] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:29,597 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:29,603 [qtp517792170-992] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:29 +0000] "OPTIONS /kms/v1/keys HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:29,609 [qtp517792170-992] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:29,609 [qtp517792170-992] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:29,609 [qtp517792170-992] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:29,609 [qtp517792170-992] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:29,609 [qtp517792170-992] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:29,609 [qtp517792170-992] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:29,610 [qtp517792170-992] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:29,610 [qtp517792170-992] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:29,612 [qtp517792170-992] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:29 +0000] "OPTIONS /kms/v1/keys?user.name=rizky HTTP/1.1" 200 520 "-" "Java/1.8.0_352"
2023-01-27 20:24:30,054 [qtp517792170-987] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=CREATE_KEY, key=test_key, user=rizky] UserProvidedMaterial:false Description:test_key
2023-01-27 20:24:30,056 [qtp517792170-987] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:29 +0000] "POST /kms/v1/keys HTTP/1.1" 201 98 "-" "Java/1.8.0_352"
2023-01-27 20:24:30,059 [IPC Server handler 8 on default port 44837] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2023-01-27 20:24:30,061 [IPC Server handler 9 on default port 44837] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/zone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:30,068 [qtp517792170-991] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=GET_METADATA, key=test_key, user=rizky] 
2023-01-27 20:24:30,069 [qtp517792170-991] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:30 +0000] "GET /kms/v1/key/test_key/_metadata HTTP/1.1" 200 210 "-" "Java/1.8.0_352"
2023-01-27 20:24:30,292 [qtp517792170-992] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditEvent(59)) - OK[op=GENERATE_EEK, key=test_key, user=rizky, accessCount=1, interval=0ms] 
2023-01-27 20:24:30,295 [qtp517792170-992] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:30 +0000] "GET /kms/v1/key/test_key/_eek?num_keys=150&eek_op=generate HTTP/1.1" 200 29702 "-" "Java/1.8.0_352"
2023-01-27 20:24:30,299 [IPC Server handler 0 on default port 44837] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=createEncryptionZone	src=/zone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:30,323 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:30,324 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:30,324 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:30,324 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:30,324 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:30,324 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:30,324 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2776)
2023-01-27 20:24:30,324 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:30,324 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:30,324 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:30,324 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:30,324 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:30,324 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:30,324 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:30,325 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:30,325 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:30,325 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:30,325 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:30,325 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:30,325 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:30,325 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:30,325 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:30,325 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:30,325 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:30,326 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:30,326 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:30,326 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:30,326 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:30,326 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2776)
2023-01-27 20:24:30,326 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:30,326 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:30,326 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:30,326 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:30,326 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:30,326 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:30,327 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:30,327 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:30,327 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:30,327 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:30,327 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:30,327 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:30,327 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:30,327 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:30,329 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:30,329 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:30,329 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:30,329 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:30,329 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:30,329 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:30,329 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:564)
2023-01-27 20:24:30,330 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:30,330 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:30,330 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:30,330 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:30,330 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:30,330 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:30,330 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:30,330 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:30,330 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:30,330 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:30,330 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:30,331 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:30,331 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:30,331 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:30,331 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:30,331 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:30,331 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:30,331 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:30,331 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:30,331 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:30,331 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:30,332 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:30,332 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:30,332 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:564)
2023-01-27 20:24:30,332 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:30,332 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:30,332 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:30,332 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:30,332 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:30,332 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:30,332 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:30,333 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:30,333 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:30,333 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:30,333 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:30,333 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:30,333 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:30,333 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:30,333 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:30,333 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:30,338 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1386)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1201)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:579)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:30,339 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1386)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1201)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:579)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:30,340 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:30,341 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:30,341 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:30,341 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:30,341 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:30,341 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:30,341 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:30,341 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:30,341 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:30,341 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:30,341 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:30,341 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:30,341 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:30,341 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:30,343 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:30,343 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:30,343 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:30,343 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:30,343 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:30,343 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:30,343 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.setNewINodeStoragePolicy(FSDirWriteFileOp.java:823)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:413)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:30,344 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.setNewINodeStoragePolicy(FSDirWriteFileOp.java:823)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:413)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:30,345 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:30,346 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:30,346 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:30,346 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:30,346 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:30,346 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:30,346 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:30,346 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:30,347 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:30,347 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:30,347 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:30,347 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:30,347 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:347)
2023-01-27 20:24:30,347 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:30,347 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:30,347 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:30,347 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:30,347 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:30,348 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:30,348 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:30,348 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:30,348 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:30,348 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:30,348 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:30,348 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:30,348 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:30,348 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:30,348 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:30,348 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:30,349 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:30,349 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:30,349 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:30,349 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:30,349 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:30,349 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:30,349 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:30,349 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:30,349 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:347)
2023-01-27 20:24:30,349 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:30,349 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:30,349 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:30,349 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:30,349 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:30,350 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:30,350 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:30,350 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:30,350 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:30,350 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:30,350 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:30,350 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:30,350 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:30,350 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:30,350 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:30,350 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:30,350 [IPC Server handler 1 on default port 44837] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:30,352 [IPC Server handler 1 on default port 44837] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/.reserved/raw/zone/p1	dst=null	perm=rizky:supergroup:rw-r--r--	proto=rpc
2023-01-27 20:24:30,404 [IPC Server handler 2 on default port 44837] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(3229)) - DIR* completeFile: /.reserved/raw/zone/p1 is closed by DFSClient_NONMAPREDUCE_1233158546_983
2023-01-27 20:24:30,416 [IPC Server handler 3 on default port 44837] INFO  ipc.Server (Server.java:logException(3199)) - IPC Server handler 3 on default port 44837, call Call#71 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:58102: org.apache.hadoop.hdfs.protocol.XAttrNotFoundException: At least one of the attributes provided was not found.
2023-01-27 20:24:30,419 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2159)) - Shutting down the Mini HDFS Cluster
2023-01-27 20:24:30,420 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2208)) - Shutting down DataNode 0
2023-01-27 20:24:30,420 [Time-limited test] INFO  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(430)) - Shutdown has been called
2023-01-27 20:24:30,420 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@af808ac] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(395)) - Closing all peers.
2023-01-27 20:24:30,420 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-0957806f-d14f-4b4f-9ab9-e0d310dc9142) exiting.
2023-01-27 20:24:30,420 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-84410a0c-171e-4849-b392-d11d2e76672f) exiting.
2023-01-27 20:24:30,461 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@5b845ab6{datanode,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:30,463 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@1bb6fa0c{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:30,464 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:30,464 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@262d60f{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:30,465 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@76273567{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:30,467 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2470)) - Waiting up to 30 seconds for transfer threads to complete
2023-01-27 20:24:30,468 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 39861
2023-01-27 20:24:30,471 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:30,472 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:30,472 [BP-139745935-127.0.1.1-1674825868716 heartbeating to localhost/127.0.0.1:44837] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:30,473 [BP-139745935-127.0.1.1-1674825868716 heartbeating to localhost/127.0.0.1:44837] WARN  datanode.DataNode (BPServiceActor.java:run(924)) - Ending block pool service for: Block pool BP-139745935-127.0.1.1-1674825868716 (Datanode Uuid 797da0cb-1379-4240-a676-95605d211e04) service to localhost/127.0.0.1:44837
2023-01-27 20:24:30,473 [Command processor] ERROR datanode.DataNode (BPServiceActor.java:processQueue(1430)) - Command processor encountered interrupt and exit.
2023-01-27 20:24:30,473 [Command processor] WARN  datanode.DataNode (BPServiceActor.java:run(1414)) - Ending command processor service for: Thread[Command processor,5,main]
2023-01-27 20:24:30,473 [ibr-executor-0] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:30,473 [BP-139745935-127.0.1.1-1674825868716 heartbeating to localhost/127.0.0.1:44837] INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-139745935-127.0.1.1-1674825868716 (Datanode Uuid 797da0cb-1379-4240-a676-95605d211e04)
2023-01-27 20:24:30,473 [BP-139745935-127.0.1.1-1674825868716 heartbeating to localhost/127.0.0.1:44837] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(3225)) - Removing block pool BP-139745935-127.0.1.1-1674825868716
2023-01-27 20:24:30,474 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-139745935-127.0.1.1-1674825868716] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:30,474 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-139745935-127.0.1.1-1674825868716] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:30,477 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(208)) - Shutting down all async disk service threads
2023-01-27 20:24:30,477 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(216)) - All async disk service threads have been shut down
2023-01-27 20:24:30,478 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(186)) - Shutting down all async lazy persist service threads
2023-01-27 20:24:30,478 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(193)) - All async lazy persist service threads have been shut down
2023-01-27 20:24:30,479 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2559)) - Shutdown complete.
2023-01-27 20:24:30,479 [Time-limited test] WARN  datanode.DataSetLockManager (DataSetLockManager.java:lockLeakCheck(260)) - not open lock leak check func
2023-01-27 20:24:30,479 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2241)) - Shutting down the namenode
2023-01-27 20:24:30,480 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:30,480 [Thread[Thread-612,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:30,480 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1467)) - Ending log segment 1, 7
2023-01-27 20:24:30,480 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@464939b7] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4561)) - NameNodeEditLogRoller was interrupted, exiting
2023-01-27 20:24:30,480 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3c2c7758] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4658)) - LazyPersistFileScrubber was interrupted, exiting
2023-01-27 20:24:30,480 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(576)) - EDEKCacheLoader interrupted before warming up.
2023-01-27 20:24:30,483 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(801)) - Number of transactions: 8 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 9 SyncTimes(ms): 11 10 
2023-01-27 20:24:30,483 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008
2023-01-27 20:24:30,484 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008
2023-01-27 20:24:30,485 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(276)) - FSEditLogAsync was interrupted, exiting
2023-01-27 20:24:30,485 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(267)) - Re-encryption updater thread interrupted. Exiting.
2023-01-27 20:24:30,485 [CacheReplicationMonitor(2101366375)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2023-01-27 20:24:30,485 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(335)) - Re-encrypt handler interrupted. Exiting
2023-01-27 20:24:30,487 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 44837
2023-01-27 20:24:30,489 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:30,489 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:30,489 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(5160)) - Stopping RedundancyMonitor.
2023-01-27 20:24:30,490 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5134)) - Stopping MarkedDeleteBlockScrubber.
2023-01-27 20:24:30,513 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:30,513 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:30,515 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3d84d4b4{hdfs,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:30,516 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@64d5f973{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:30,517 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:30,517 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7eec4ddd{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:30,518 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@e7afc78{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:30,529 [Thread[Thread-580,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:30,529 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextDestroyed(197)) - KMS Stopped
2023-01-27 20:24:30,530 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2ca34181{kms,/,null,STOPPED}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:30,532 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@38756c84{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:30,532 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:30,533 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@54901ade{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-27 20:24:30,533 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@692c2113{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:30,534 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2023-01-27 20:24:30,537 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2023-01-27 20:24:30,537 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(612)) - DataNode metrics system shutdown complete.
2023-01-27 20:24:30,702 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:30,703 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context kms
2023-01-27 20:24:30,703 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:30,703 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:30,704 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:30,704 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 37085
2023-01-27 20:24:30,704 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:30,709 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:30,710 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:30,710 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:30,711 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2a1c9ded{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:30,712 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@591e1dc5{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-27 20:24:30,748 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(94)) - -------------------------------------------------------------
2023-01-27 20:24:30,749 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(95)) -   Java runtime version : 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:30,749 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(97)) -   User: rizky
2023-01-27 20:24:30,749 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(98)) -   KMS Hadoop Version: 3.4.0-SNAPSHOT
2023-01-27 20:24:30,749 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(99)) - -------------------------------------------------------------
2023-01-27 20:24:30,750 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'CREATE' ACL '*'
2023-01-27 20:24:30,750 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DELETE' ACL '*'
2023-01-27 20:24:30,750 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'ROLLOVER' ACL '*'
2023-01-27 20:24:30,751 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET' ACL '*'
2023-01-27 20:24:30,751 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_KEYS' ACL '*'
2023-01-27 20:24:30,751 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_METADATA' ACL '*'
2023-01-27 20:24:30,751 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'SET_KEY_MATERIAL' ACL '*'
2023-01-27 20:24:30,751 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GENERATE_EEK' ACL '*'
2023-01-27 20:24:30,751 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DECRYPT_EEK' ACL '*'
2023-01-27 20:24:30,752 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2023-01-27 20:24:30,752 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2023-01-27 20:24:30,752 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2023-01-27 20:24:30,752 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2023-01-27 20:24:30,754 [Time-limited test] INFO  server.KMSAudit (KMSAudit.java:initializeAuditLoggers(157)) - Initializing audit logger class org.apache.hadoop.crypto.key.kms.server.SimpleKMSAuditLogger
2023-01-27 20:24:30,755 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(149)) - Initialized KeyProvider CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/b6310fd4-7c82-4b19-93d1-f4c5b97931cd/kms.keystore
2023-01-27 20:24:30,756 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(163)) - Initialized KeyProviderCryptoExtension org.apache.hadoop.crypto.key.kms.server.KeyAuthorizationKeyProvider: EagerKeyGeneratorKeyProviderCryptoExtension: KeyProviderCryptoExtension: CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/b6310fd4-7c82-4b19-93d1-f4c5b97931cd/kms.keystore
2023-01-27 20:24:30,757 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(168)) - Default key bitlength is 128
2023-01-27 20:24:30,757 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(169)) - KMS Started
2023-01-27 20:24:30,758 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:30,761 [Time-limited test] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.crypto.key.kms.server
2023-01-27 20:24:30,775 [Thread[Thread-685,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:30,776 [Thread[Thread-685,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:30,782 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMS
2023-01-27 20:24:30,782 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
  class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
2023-01-27 20:24:30,785 [Time-limited test] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:24:30,942 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@665becac{kms,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/2/kms/webapp/,AVAILABLE}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:30,944 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6cfbf4b{HTTP/1.1, (http/1.1)}{localhost:37085}
2023-01-27 20:24:30,944 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @35966ms
2023-01-27 20:24:30,947 [Time-limited test] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(120)) - Loaded properties from hadoop-metrics2.properties
2023-01-27 20:24:30,953 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 0 second(s).
2023-01-27 20:24:30,954 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - KMS metrics system started
2023-01-27 20:24:30,967 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@64dc45ba] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:30,978 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(566)) - starting cluster: numNameNodes=1, numDataNodes=1
2023-01-27 20:24:30,980 [Time-limited test] INFO  namenode.NameNode (NameNode.java:format(1366)) - Formatting using clusterid: testClusterID
2023-01-27 20:24:30,980 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:30,995 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@f964317
2023-01-27 20:24:30,995 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:30,996 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:30,996 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:30,996 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:30,996 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:30,996 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:30,996 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:30,997 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:30,997 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:30,997 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:30,997 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:30,998 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:30
2023-01-27 20:24:30,998 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:30,998 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:30,998 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:30,998 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:31,000 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:31,000 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:31,001 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:31,001 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:31,001 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:31,001 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:31,001 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:31,001 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:31,001 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:31,001 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:31,001 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:31,002 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:31,002 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:31,002 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:31,002 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:31,002 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:31,003 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:31,004 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:31,004 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:31,004 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:31,004 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:31,004 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:31,005 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:31,005 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:31,005 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:31,005 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:31,005 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:31,005 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:31,005 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:31,006 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:31,006 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:31,006 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:31,007 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:31,007 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:31,007 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:31,007 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:31,007 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:31,008 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:31,009 [Time-limited test] INFO  namenode.FSImage (FSImage.java:format(186)) - Allocated new BlockPoolId: BP-788369989-127.0.1.1-1674825871009
2023-01-27 20:24:31,012 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 has been successfully formatted.
2023-01-27 20:24:31,015 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 has been successfully formatted.
2023-01-27 20:24:31,030 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:31,030 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:31,038 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 454 bytes saved in 0 seconds .
2023-01-27 20:24:31,038 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 454 bytes saved in 0 seconds .
2023-01-27 20:24:31,041 [Time-limited test] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(202)) - Going to retain 1 images with txid >= 0
2023-01-27 20:24:31,056 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:31,056 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:31,057 [Time-limited test] INFO  namenode.NameNode (NameNode.java:createNameNode(1824)) - createNameNode []
2023-01-27 20:24:31,058 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2023-01-27 20:24:31,058 [Time-limited test] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2023-01-27 20:24:31,071 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@521b2bc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:31,071 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1736)) - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2023-01-27 20:24:31,072 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1758)) - Starting Web-server for hdfs at: http://localhost:0
2023-01-27 20:24:31,072 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:31,074 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:31,076 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:31,077 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:31,078 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-01-27 20:24:31,078 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:31,078 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:31,079 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2023-01-27 20:24:31,079 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2023-01-27 20:24:31,079 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2023-01-27 20:24:31,080 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:31,080 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(1018)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-01-27 20:24:31,081 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 45639
2023-01-27 20:24:31,081 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:31,090 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:31,090 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:31,094 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:24:31,095 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:31,096 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@c24fda9{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:31,097 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@715672a0{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:31,100 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3e4fbb1c{hdfs,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:31,101 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@78b597c8{HTTP/1.1, (http/1.1)}{localhost:45639}
2023-01-27 20:24:31,101 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @36123ms
2023-01-27 20:24:31,102 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:31,114 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@3575c259
2023-01-27 20:24:31,114 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:31,114 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:31,114 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:31,114 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:31,115 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:31,115 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:31,115 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:31,115 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:31,116 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:31,116 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:31,116 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:31,116 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:31
2023-01-27 20:24:31,117 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:31,117 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:31,117 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:31,117 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:31,119 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:31,119 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:31,119 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:31,119 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:31,120 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:31,120 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:31,120 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:31,120 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:31,120 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:31,120 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:31,120 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:31,120 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:31,121 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:31,121 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:31,121 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:31,121 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:31,121 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:31,122 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:31,122 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:31,122 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:31,122 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:31,123 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:31,123 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:31,123 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:31,123 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:31,123 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:31,123 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:31,124 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:31,124 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:31,124 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:31,124 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:31,124 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:31,125 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:31,125 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:31,125 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:31,125 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:31,125 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:31,125 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:31,127 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:31,128 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:31,130 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current
2023-01-27 20:24:31,130 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current
2023-01-27 20:24:31,130 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(734)) - No edit log streams selected.
2023-01-27 20:24:31,130 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(800)) - Planning to load image: FSImageFile(file=/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-01-27 20:24:31,132 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSectionHeader(411)) - Loading 1 INodes.
2023-01-27 20:24:31,133 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(369)) - Successfully loaded 1 inodes
2023-01-27 20:24:31,133 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:waitBlocksMapAndNameCacheUpdateFinished(342)) - Completed update blocks map and name cache, total waiting duration 0ms.
2023-01-27 20:24:31,133 [Time-limited test] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(255)) - Loaded FSImage in 0 seconds.
2023-01-27 20:24:31,133 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(980)) - Loaded image for txid 0 from /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000
2023-01-27 20:24:31,133 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1271)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-01-27 20:24:31,134 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1417)) - Starting log segment at 1
2023-01-27 20:24:31,150 [Time-limited test] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2023-01-27 20:24:31,150 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(836)) - Finished loading FSImage in 24 msecs
2023-01-27 20:24:31,150 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(451)) - RPC server is binding to localhost:0
2023-01-27 20:24:31,151 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(456)) - Enable NameNode state context:false
2023-01-27 20:24:31,151 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:31,154 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:44583
2023-01-27 20:24:31,154 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:31,166 [Time-limited test] INFO  namenode.NameNode (NameNode.java:initialize(893)) - Clients are to use localhost:44583 to access this namenode/service.
2023-01-27 20:24:31,167 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5607)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2023-01-27 20:24:31,182 [Time-limited test] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(166)) - Number of blocks under construction: 0
2023-01-27 20:24:31,183 [Time-limited test] INFO  blockmanagement.DatanodeAdminDefaultMonitor (DatanodeAdminDefaultMonitor.java:processConf(126)) - Initialized the Default Decommission and Maintenance monitor
2023-01-27 20:24:31,183 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5102)) - Start MarkedDeleteBlockScrubber thread
2023-01-27 20:24:31,184 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(5310)) - initializing replication queues
2023-01-27 20:24:31,184 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(409)) - STATE* Leaving safe mode after 0 secs
2023-01-27 20:24:31,184 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(415)) - STATE* Network topology has 0 racks and 0 datanodes
2023-01-27 20:24:31,184 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(417)) - STATE* UnderReplicatedBlocks has 0 blocks
2023-01-27 20:24:31,188 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:31,192 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3870)) - Total number of blocks            = 0
2023-01-27 20:24:31,192 [Thread[Thread-717,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:31,192 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3871)) - Number of invalid blocks          = 0
2023-01-27 20:24:31,193 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3872)) - Number of under-replicated blocks = 0
2023-01-27 20:24:31,193 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3873)) - Number of  over-replicated blocks = 0
2023-01-27 20:24:31,193 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3875)) - Number of blocks being written    = 0
2023-01-27 20:24:31,193 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3878)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2023-01-27 20:24:31,193 [Thread[Thread-717,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:31,195 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:31,195 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:31,207 [Time-limited test] INFO  namenode.NameNode (NameNode.java:startCommonServices(1010)) - NameNode RPC up at: localhost/127.0.0.1:44583
2023-01-27 20:24:31,208 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1383)) - Starting services required for active state
2023-01-27 20:24:31,208 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(857)) - Initializing quota with 12 thread(s)
2023-01-27 20:24:31,209 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(866)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2023-01-27 20:24:31,210 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(326)) - Starting up re-encrypt thread with interval=60000 millisecond.
2023-01-27 20:24:31,217 [CacheReplicationMonitor(2055187280)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-01-27 20:24:31,219 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2023-01-27 20:24:31,222 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1769)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1,[DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:31,224 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:31,224 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:31,238 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2023-01-27 20:24:31,239 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:31,239 [Time-limited test] INFO  datanode.BlockScanner (BlockScanner.java:<init>(201)) - Initialized block scanner with targetBytesPerSec 1048576
2023-01-27 20:24:31,239 [Time-limited test] INFO  datanode.DataNode (DataNode.java:<init>(571)) - Configured hostname is 127.0.0.1
2023-01-27 20:24:31,239 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:31,240 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1788)) - Starting DataNode with maxLockedMemory = 0
2023-01-27 20:24:31,240 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1551)) - Opened streaming server at /127.0.0.1:39785
2023-01-27 20:24:31,241 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(93)) - Balancing bandwidth is 104857600 bytes/s
2023-01-27 20:24:31,241 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(94)) - Number threads for balancing is 100
2023-01-27 20:24:31,242 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:31,243 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:31,246 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:31,248 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:31,249 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-01-27 20:24:31,249 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:31,249 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:31,249 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:31,250 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 40613
2023-01-27 20:24:31,250 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:31,251 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:31,251 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:31,252 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:31,253 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2a1cada6{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:31,253 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@577a281e{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:31,258 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@25635c38{datanode,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:31,259 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@3daf0472{HTTP/1.1, (http/1.1)}{localhost:40613}
2023-01-27 20:24:31,259 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @36281ms
2023-01-27 20:24:31,263 [Time-limited test] WARN  web.DatanodeHttpServer (RestCsrfPreventionFilterHandler.java:<init>(75)) - Got null for restCsrfPreventionFilter - will not do any filtering.
2023-01-27 20:24:31,265 [Time-limited test] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(306)) - Listening HTTP traffic on /127.0.0.1:38093
2023-01-27 20:24:31,266 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1816)) - dnUserName = rizky
2023-01-27 20:24:31,266 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1817)) - supergroup = supergroup
2023-01-27 20:24:31,266 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4bdf3a93] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:31,266 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:31,267 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:35553
2023-01-27 20:24:31,267 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:31,276 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initIpcServer(1438)) - Opened IPC server at /127.0.0.1:35553
2023-01-27 20:24:31,288 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(150)) - Refresh request received for nameservices: null
2023-01-27 20:24:31,289 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(211)) - Starting BPOfferServices for nameservices: <default>
2023-01-27 20:24:31,290 [Thread-750] INFO  datanode.DataNode (BPServiceActor.java:run(877)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44583 starting to offer service
2023-01-27 20:24:31,312 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:31,317 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:31,335 [Thread-750] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(382)) - Acknowledging ACTIVE Namenode during handshake Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44583
2023-01-27 20:24:31,339 [Thread-750] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(356)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2023-01-27 20:24:31,342 [Thread-750] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:31,342 [Thread-750] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 is not formatted for namespace 2095528922. Formatting...
2023-01-27 20:24:31,342 [Thread-750] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ec83542b-b2b1-4b3a-abe1-3f9fee79e272 for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 
2023-01-27 20:24:31,345 [IPC Server handler 1 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:31,346 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:31,346 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:31,347 [Thread-750] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:31,347 [Thread-750] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 is not formatted for namespace 2095528922. Formatting...
2023-01-27 20:24:31,348 [Thread-750] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4d1b6e72-cb5c-4c90-8eaa-50dc0d553316 for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 
2023-01-27 20:24:31,368 [Thread-750] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-788369989-127.0.1.1-1674825871009
2023-01-27 20:24:31,368 [Thread-750] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-788369989-127.0.1.1-1674825871009
2023-01-27 20:24:31,368 [Thread-750] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 and block pool id BP-788369989-127.0.1.1-1674825871009 is not formatted. Formatting ...
2023-01-27 20:24:31,368 [Thread-750] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-788369989-127.0.1.1-1674825871009 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-788369989-127.0.1.1-1674825871009/current
2023-01-27 20:24:31,389 [Thread-750] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-788369989-127.0.1.1-1674825871009
2023-01-27 20:24:31,390 [Thread-750] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-788369989-127.0.1.1-1674825871009
2023-01-27 20:24:31,390 [Thread-750] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 and block pool id BP-788369989-127.0.1.1-1674825871009 is not formatted. Formatting ...
2023-01-27 20:24:31,390 [Thread-750] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-788369989-127.0.1.1-1674825871009 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-788369989-127.0.1.1-1674825871009/current
2023-01-27 20:24:31,392 [Thread-750] INFO  datanode.DataNode (DataNode.java:initStorage(2136)) - Setting up storage: nsid=2095528922;bpid=BP-788369989-127.0.1.1-1674825871009;lv=-57;nsInfo=lv=-67;cid=testClusterID;nsid=2095528922;c=1674825871009;bpid=BP-788369989-127.0.1.1-1674825871009;dnuuid=null
2023-01-27 20:24:31,394 [Thread-750] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1934)) - Generated and persisted new Datanode UUID 95b26f72-3dca-4769-862c-03bb0edbf375
2023-01-27 20:24:31,395 [Thread-750] INFO  fsdataset.RoundRobinVolumeChoosingPolicy (RoundRobinVolumeChoosingPolicy.java:setConf(67)) - Round robin volume choosing policy initialized: dfs.datanode.round-robin-volume-choosing-policy.additional-available-space = 0
2023-01-27 20:24:31,396 [Thread-750] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-ec83542b-b2b1-4b3a-abe1-3f9fee79e272
2023-01-27 20:24:31,396 [Thread-750] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, StorageType: DISK
2023-01-27 20:24:31,398 [Thread-750] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-4d1b6e72-cb5c-4c90-8eaa-50dc0d553316
2023-01-27 20:24:31,398 [Thread-750] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, StorageType: DISK
2023-01-27 20:24:31,399 [Thread-750] INFO  impl.MemoryMappableBlockLoader (MemoryMappableBlockLoader.java:initialize(47)) - Initializing cache loader: MemoryMappableBlockLoader.
2023-01-27 20:24:31,400 [Thread-750] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2611)) - Registered FSDatasetState MBean
2023-01-27 20:24:31,401 [Thread-750] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(3188)) - Adding block pool BP-788369989-127.0.1.1-1674825871009
2023-01-27 20:24:31,401 [Thread-767] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-788369989-127.0.1.1-1674825871009 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:31,402 [Thread-767] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-788369989-127.0.1.1-1674825871009/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:31,403 [Thread-768] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-788369989-127.0.1.1-1674825871009 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:31,403 [Thread-768] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-788369989-127.0.1.1-1674825871009/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:31,430 [Thread-767] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-788369989-127.0.1.1-1674825871009 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 29ms
2023-01-27 20:24:31,437 [Thread-768] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-788369989-127.0.1.1-1674825871009 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 35ms
2023-01-27 20:24:31,437 [Thread-750] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(538)) - Total time to scan all replicas for block pool BP-788369989-127.0.1.1-1674825871009: 36ms
2023-01-27 20:24:31,438 [Thread-771] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-788369989-127.0.1.1-1674825871009 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:31,438 [Thread-772] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-788369989-127.0.1.1-1674825871009 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:31,438 [Thread-771] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-788369989-127.0.1.1-1674825871009/current/replicas doesn't exist 
2023-01-27 20:24:31,438 [Thread-772] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-788369989-127.0.1.1-1674825871009/current/replicas doesn't exist 
2023-01-27 20:24:31,438 [Thread-771] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-788369989-127.0.1.1-1674825871009 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 0ms
2023-01-27 20:24:31,438 [Thread-772] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-788369989-127.0.1.1-1674825871009 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 0ms
2023-01-27 20:24:31,438 [Thread-750] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(292)) - Total time to add all replicas to map for block pool BP-788369989-127.0.1.1-1674825871009: 1ms
2023-01-27 20:24:31,439 [Thread-750] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:31,439 [Thread-750] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:31,439 [Thread-750] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:31,440 [Thread-750] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:31,441 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-788369989-127.0.1.1-1674825871009 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:31,441 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-788369989-127.0.1.1-1674825871009 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:31,441 [Thread-750] WARN  datanode.DirectoryScanner (DirectoryScanner.java:<init>(302)) - dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2023-01-27 20:24:31,441 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-ec83542b-b2b1-4b3a-abe1-3f9fee79e272): finished scanning block pool BP-788369989-127.0.1.1-1674825871009
2023-01-27 20:24:31,441 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-4d1b6e72-cb5c-4c90-8eaa-50dc0d553316): finished scanning block pool BP-788369989-127.0.1.1-1674825871009
2023-01-27 20:24:31,441 [Thread-750] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(367)) - Periodic Directory Tree Verification scan starting in 7467439ms with interval of 21600000ms and throttle limit of -1ms/s
2023-01-27 20:24:31,441 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-4d1b6e72-cb5c-4c90-8eaa-50dc0d553316): no suitable block pools found to scan.  Waiting 1814400000 ms.
2023-01-27 20:24:31,442 [BP-788369989-127.0.1.1-1674825871009 heartbeating to localhost/127.0.0.1:44583] INFO  datanode.DataNode (BPServiceActor.java:register(819)) - Block pool BP-788369989-127.0.1.1-1674825871009 (Datanode Uuid 95b26f72-3dca-4769-862c-03bb0edbf375) service to localhost/127.0.0.1:44583 beginning handshake with NN: localhost/127.0.0.1:44583.
2023-01-27 20:24:31,441 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-ec83542b-b2b1-4b3a-abe1-3f9fee79e272): no suitable block pools found to scan.  Waiting 1814400000 ms.
2023-01-27 20:24:31,444 [IPC Server handler 2 on default port 44583] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1166)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39785, datanodeUuid=95b26f72-3dca-4769-862c-03bb0edbf375, infoPort=38093, infoSecurePort=0, ipcPort=35553, storageInfo=lv=-57;cid=testClusterID;nsid=2095528922;c=1674825871009) storage 95b26f72-3dca-4769-862c-03bb0edbf375
2023-01-27 20:24:31,444 [IPC Server handler 2 on default port 44583] INFO  net.NetworkTopology (NetworkTopology.java:add(156)) - Adding a new node: /default-rack/127.0.0.1:39785
2023-01-27 20:24:31,444 [IPC Server handler 2 on default port 44583] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(200)) - Registered DN 95b26f72-3dca-4769-862c-03bb0edbf375 (127.0.0.1:39785).
2023-01-27 20:24:31,448 [BP-788369989-127.0.1.1-1674825871009 heartbeating to localhost/127.0.0.1:44583] INFO  datanode.DataNode (BPServiceActor.java:register(846)) - Block pool BP-788369989-127.0.1.1-1674825871009 (Datanode Uuid 95b26f72-3dca-4769-862c-03bb0edbf375) service to localhost/127.0.0.1:44583 successfully registered with NN: localhost/127.0.0.1:44583.
2023-01-27 20:24:31,448 [BP-788369989-127.0.1.1-1674825871009 heartbeating to localhost/127.0.0.1:44583] INFO  datanode.DataNode (BPServiceActor.java:offerService(680)) - For namenode localhost/127.0.0.1:44583 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2023-01-27 20:24:31,448 [ibr-executor-0] INFO  datanode.DataNode (BPServiceActor.java:run(1145)) - Starting IBR Task Handler.
2023-01-27 20:24:31,450 [IPC Server handler 3 on default port 44583] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-ec83542b-b2b1-4b3a-abe1-3f9fee79e272 for DN 127.0.0.1:39785
2023-01-27 20:24:31,450 [IPC Server handler 3 on default port 44583] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-4d1b6e72-cb5c-4c90-8eaa-50dc0d553316 for DN 127.0.0.1:39785
2023-01-27 20:24:31,452 [IPC Server handler 4 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:31,455 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0xf7c3fcd8e2d9672e with lease ID 0xe7401a4ffae3ee0: Processing first storage report for DS-4d1b6e72-cb5c-4c90-8eaa-50dc0d553316 from datanode DatanodeRegistration(127.0.0.1:39785, datanodeUuid=95b26f72-3dca-4769-862c-03bb0edbf375, infoPort=38093, infoSecurePort=0, ipcPort=35553, storageInfo=lv=-57;cid=testClusterID;nsid=2095528922;c=1674825871009)
2023-01-27 20:24:31,455 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0xf7c3fcd8e2d9672e with lease ID 0xe7401a4ffae3ee0: from storage DS-4d1b6e72-cb5c-4c90-8eaa-50dc0d553316 node DatanodeRegistration(127.0.0.1:39785, datanodeUuid=95b26f72-3dca-4769-862c-03bb0edbf375, infoPort=38093, infoSecurePort=0, ipcPort=35553, storageInfo=lv=-57;cid=testClusterID;nsid=2095528922;c=1674825871009), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:31,455 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0xf7c3fcd8e2d9672e with lease ID 0xe7401a4ffae3ee0: Processing first storage report for DS-ec83542b-b2b1-4b3a-abe1-3f9fee79e272 from datanode DatanodeRegistration(127.0.0.1:39785, datanodeUuid=95b26f72-3dca-4769-862c-03bb0edbf375, infoPort=38093, infoSecurePort=0, ipcPort=35553, storageInfo=lv=-57;cid=testClusterID;nsid=2095528922;c=1674825871009)
2023-01-27 20:24:31,455 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0xf7c3fcd8e2d9672e with lease ID 0xe7401a4ffae3ee0: from storage DS-ec83542b-b2b1-4b3a-abe1-3f9fee79e272 node DatanodeRegistration(127.0.0.1:39785, datanodeUuid=95b26f72-3dca-4769-862c-03bb0edbf375, infoPort=38093, infoSecurePort=0, ipcPort=35553, storageInfo=lv=-57;cid=testClusterID;nsid=2095528922;c=1674825871009), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:31,455 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:31,457 [BP-788369989-127.0.1.1-1674825871009 heartbeating to localhost/127.0.0.1:44583] INFO  datanode.DataNode (BPServiceActor.java:blockReport(464)) - Successfully sent block report 0xf7c3fcd8e2d9672e with lease ID 0xe7401a4ffae3ee0 to namenode: localhost/127.0.0.1:44583,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msecs to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-01-27 20:24:31,457 [Command processor] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(763)) - Got finalize command for block pool BP-788369989-127.0.1.1-1674825871009
2023-01-27 20:24:31,461 [IPC Server handler 6 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:31,462 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:31,468 [qtp1428842837-1171] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:31 +0000] "OPTIONS /kms/v1/keys HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:31,477 [qtp1428842837-1165] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:31,477 [qtp1428842837-1165] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:31,477 [qtp1428842837-1165] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:31,477 [qtp1428842837-1165] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:31,477 [qtp1428842837-1165] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:31,477 [qtp1428842837-1165] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:31,478 [qtp1428842837-1165] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:31,478 [qtp1428842837-1165] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:31,481 [qtp1428842837-1165] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:31 +0000] "OPTIONS /kms/v1/keys?user.name=rizky HTTP/1.1" 200 520 "-" "Java/1.8.0_352"
2023-01-27 20:24:32,015 [qtp1428842837-1167] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=CREATE_KEY, key=test_key, user=rizky] UserProvidedMaterial:false Description:test_key
2023-01-27 20:24:32,017 [qtp1428842837-1167] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:31 +0000] "POST /kms/v1/keys HTTP/1.1" 201 98 "-" "Java/1.8.0_352"
2023-01-27 20:24:32,019 [IPC Server handler 7 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/zone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:32,035 [qtp1428842837-1169] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=GET_METADATA, key=test_key, user=rizky] 
2023-01-27 20:24:32,038 [qtp1428842837-1169] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:32 +0000] "GET /kms/v1/key/test_key/_metadata HTTP/1.1" 200 210 "-" "Java/1.8.0_352"
2023-01-27 20:24:32,298 [qtp1428842837-1165] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditEvent(59)) - OK[op=GENERATE_EEK, key=test_key, user=rizky, accessCount=1, interval=0ms] 
2023-01-27 20:24:32,311 [qtp1428842837-1165] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:32 +0000] "GET /kms/v1/key/test_key/_eek?num_keys=150&eek_op=generate HTTP/1.1" 200 29702 "-" "Java/1.8.0_352"
2023-01-27 20:24:32,311 [IPC Server handler 8 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=createEncryptionZone	src=/zone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:32,316 [IPC Server handler 0 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/zone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:32,318 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,319 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,319 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,319 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,319 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,319 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,319 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2776)
2023-01-27 20:24:32,319 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,319 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,319 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,319 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,320 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,320 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,320 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,320 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,320 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,320 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,320 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,320 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,320 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,320 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,320 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,320 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,321 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,321 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,321 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,321 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,321 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,321 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2776)
2023-01-27 20:24:32,321 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,321 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,321 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,321 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,321 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,322 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,322 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,322 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,322 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,322 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,322 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,322 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,322 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,322 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,326 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,327 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,327 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,327 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,327 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,327 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,327 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:564)
2023-01-27 20:24:32,327 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:32,327 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,327 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,328 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,328 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,328 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,328 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,328 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,328 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,328 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,328 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,328 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,328 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,328 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,329 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,329 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,329 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,329 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,329 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,329 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,329 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,329 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,329 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,329 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:564)
2023-01-27 20:24:32,329 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:32,330 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,330 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,330 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,330 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,330 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,330 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,330 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,330 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,330 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,330 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,330 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,331 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,331 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,331 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,331 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,342 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,342 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,342 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,342 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,342 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,342 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1386)
2023-01-27 20:24:32,343 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1201)
2023-01-27 20:24:32,343 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:579)
2023-01-27 20:24:32,343 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:32,343 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,343 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,343 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,343 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,343 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,343 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,343 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,343 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,344 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,344 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,344 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,344 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,344 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,344 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,344 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,344 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,344 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,344 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,345 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,345 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,345 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,345 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1386)
2023-01-27 20:24:32,345 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1201)
2023-01-27 20:24:32,345 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:579)
2023-01-27 20:24:32,345 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:32,345 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,345 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,345 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,346 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,346 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,346 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,346 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,346 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,346 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,346 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,346 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,346 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,346 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,346 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,346 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,356 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,356 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,356 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,356 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,356 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,356 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,356 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.setNewINodeStoragePolicy(FSDirWriteFileOp.java:823)
2023-01-27 20:24:32,356 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:413)
2023-01-27 20:24:32,356 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,356 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,357 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.setNewINodeStoragePolicy(FSDirWriteFileOp.java:823)
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:413)
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,358 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,359 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,359 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,359 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,359 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,359 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,359 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,359 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,359 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,359 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,360 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,360 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,360 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,360 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,360 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:347)
2023-01-27 20:24:32,360 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:32,360 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:32,360 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,361 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,361 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,361 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,361 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,361 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,361 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,361 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,361 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,361 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,361 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,361 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,361 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,362 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,362 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,362 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,362 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,362 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,362 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,362 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,362 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,362 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,362 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:347)
2023-01-27 20:24:32,362 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:32,362 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:32,362 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,362 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,363 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,363 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,363 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,363 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,363 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,363 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,363 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,363 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,363 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,363 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,363 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,363 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,363 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,364 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,364 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,364 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,364 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:32,364 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:32,364 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:32,364 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.createFileStatus(FSDirStatAndListingOp.java:434)
2023-01-27 20:24:32,364 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:349)
2023-01-27 20:24:32,364 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:32,364 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:32,364 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,364 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,364 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,365 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,365 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,365 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,365 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,365 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,365 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,365 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,365 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,365 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,365 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,365 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,365 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,366 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,366 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,366 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,366 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,366 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:32,366 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:32,366 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:32,366 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.createFileStatus(FSDirStatAndListingOp.java:434)
2023-01-27 20:24:32,366 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:349)
2023-01-27 20:24:32,366 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:32,367 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:32,367 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,367 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,367 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,367 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,367 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,367 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,367 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,367 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,367 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,367 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,368 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,368 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,368 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,368 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,368 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,369 [IPC Server handler 1 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/zone/success1	dst=null	perm=rizky:supergroup:rw-r--r--	proto=rpc
2023-01-27 20:24:32,414 [qtp1428842837-1166] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:32 +0000] "OPTIONS /kms/v1/keyversion/test_key%400/_eek?eek_op=decrypt HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:32,421 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:32,421 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:32,421 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:32,421 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:32,422 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:32,422 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:32,422 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:32,423 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:32,428 [qtp1428842837-1171] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:32 +0000] "OPTIONS /kms/v1/keyversion/test_key%400/_eek?eek_op=decrypt&user.name=rizky HTTP/1.1" 200 639 "-" "Java/1.8.0_352"
2023-01-27 20:24:32,429 [qtp1428842837-1169] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:32 +0000] "GET /kms/v1/key/test_key/_eek?num_keys=351&eek_op=generate HTTP/1.1" 200 69500 "-" "Java/1.8.0_352"
2023-01-27 20:24:32,638 [qtp1428842837-1164] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditEvent(59)) - OK[op=DECRYPT_EEK, key=test_key, user=rizky, accessCount=1, interval=0ms] 
2023-01-27 20:24:32,643 [qtp1428842837-1164] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:32 +0000] "POST /kms/v1/keyversion/test_key%400/_eek?eek_op=decrypt HTTP/1.1" 200 90 "-" "Java/1.8.0_352"
2023-01-27 20:24:32,644 [IPC Server handler 7 on default port 44583] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(3229)) - DIR* completeFile: /zone/success1 is closed by DFSClient_NONMAPREDUCE_-1028944470_1162
2023-01-27 20:24:32,657 [IPC Server handler 9 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/zone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:32,659 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,659 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2776)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,660 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2776)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,661 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,662 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,662 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,662 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,662 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,662 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,662 [IPC Server handler 8 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,662 [IPC Server handler 8 on default port 44583] INFO  ipc.Server (Server.java:logException(3206)) - IPC Server handler 8 on default port 44583, call Call#86 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 127.0.0.1:36494
org.apache.hadoop.hdfs.UnknownCryptoProtocolVersionException: No crypto protocol versions provided by the client are supported. Client provided: [] NameNode supports: [CryptoProtocolVersion{description='Unknown', version=1, unknownValue=null}, CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.chooseProtocolVersion(FSNamesystem.java:2684)
	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getEncryptionKeyInfo(FSDirEncryptionZoneOp.java:647)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2791)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,666 [IPC Server handler 0 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/zone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:32,667 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,667 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,667 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,668 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,668 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,668 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,668 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2776)
2023-01-27 20:24:32,668 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,668 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,668 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,668 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,668 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,668 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,668 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,668 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,668 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,668 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,669 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,669 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,669 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,669 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,669 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,669 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,669 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,669 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,669 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,669 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,670 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,670 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2776)
2023-01-27 20:24:32,670 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,670 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,670 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,670 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,670 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,670 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,670 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,670 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,670 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,670 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,671 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,671 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,671 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,671 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,671 [IPC Server handler 1 on default port 44583] INFO  ipc.Server (Server.java:logException(3206)) - IPC Server handler 1 on default port 44583, call Call#88 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 127.0.0.1:36494
org.apache.hadoop.hdfs.UnknownCryptoProtocolVersionException: No crypto protocol versions provided by the client are supported. Client provided: [CryptoProtocolVersion{description='Unknown', version=1, unknownValue=1}, CryptoProtocolVersion{description='Unknown', version=1, unknownValue=1}] NameNode supports: [CryptoProtocolVersion{description='Unknown', version=1, unknownValue=1}, CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.chooseProtocolVersion(FSNamesystem.java:2684)
	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getEncryptionKeyInfo(FSDirEncryptionZoneOp.java:647)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2791)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,674 [IPC Server handler 2 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/zone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:32,676 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,676 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,676 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,676 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,676 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,676 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,676 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2776)
2023-01-27 20:24:32,677 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,677 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,677 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,677 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,677 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,677 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,677 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,677 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,677 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,677 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,677 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,677 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,678 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,678 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,678 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,678 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,678 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,678 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,678 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,678 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,678 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,678 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2776)
2023-01-27 20:24:32,678 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,679 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,679 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,679 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,679 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,679 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,679 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,679 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,679 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,679 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,679 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,679 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,680 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,680 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,680 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,680 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,680 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,681 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,681 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,681 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,681 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:564)
2023-01-27 20:24:32,681 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:32,681 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,681 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,681 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,681 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,681 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,681 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,682 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,682 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,682 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,682 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,682 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,682 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,682 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,682 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,682 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,682 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,682 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,683 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,683 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,683 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,683 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,683 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,683 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:564)
2023-01-27 20:24:32,683 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:32,683 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,683 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,683 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,683 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,684 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,684 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,684 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,684 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,684 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,684 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,684 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,684 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,684 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,684 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,684 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,685 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,685 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,685 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,685 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,685 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,685 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1386)
2023-01-27 20:24:32,685 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1201)
2023-01-27 20:24:32,685 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:579)
2023-01-27 20:24:32,685 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:32,686 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,686 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,686 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,686 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,686 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,686 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,686 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,686 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,686 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,686 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,686 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,687 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,687 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,687 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,687 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,687 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,687 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,687 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,687 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,687 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,687 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,688 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1386)
2023-01-27 20:24:32,688 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1201)
2023-01-27 20:24:32,688 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:579)
2023-01-27 20:24:32,688 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:32,688 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,688 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,688 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,688 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,688 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,688 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,688 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,689 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,689 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,689 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,689 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,689 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,689 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,689 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,689 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,690 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,690 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,690 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,690 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,690 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,690 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,690 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.setNewINodeStoragePolicy(FSDirWriteFileOp.java:823)
2023-01-27 20:24:32,690 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:413)
2023-01-27 20:24:32,691 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,691 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,691 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,691 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,691 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,691 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,691 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,691 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,691 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,692 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,692 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,692 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,692 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,692 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,692 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,692 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,692 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,692 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,692 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,692 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,693 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,693 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,693 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.setNewINodeStoragePolicy(FSDirWriteFileOp.java:823)
2023-01-27 20:24:32,693 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:413)
2023-01-27 20:24:32,693 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,693 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,693 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,693 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,693 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,693 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,693 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,694 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,694 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,694 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,694 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,694 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,694 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,694 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,694 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,694 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,695 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,695 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,695 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,695 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,695 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,695 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:347)
2023-01-27 20:24:32,695 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:32,695 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:32,695 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,695 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,695 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,695 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,695 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,696 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:347)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,697 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,698 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,698 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,698 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,698 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,698 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,698 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:32,698 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:32,698 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:32,698 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.createFileStatus(FSDirStatAndListingOp.java:434)
2023-01-27 20:24:32,698 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:349)
2023-01-27 20:24:32,698 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:32,698 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:32,698 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,699 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.createFileStatus(FSDirStatAndListingOp.java:434)
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:349)
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,700 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,701 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,701 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,701 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,701 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,701 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,701 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,701 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,701 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,701 [IPC Server handler 3 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,701 [IPC Server handler 3 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/zone/success2	dst=null	perm=rizky:supergroup:rw-r--r--	proto=rpc
2023-01-27 20:24:32,707 [qtp1428842837-1169] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:32 +0000] "POST /kms/v1/keyversion/test_key%400/_eek?eek_op=decrypt HTTP/1.1" 200 90 "-" "Java/1.8.0_352"
2023-01-27 20:24:32,709 [IPC Server handler 4 on default port 44583] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(3229)) - DIR* completeFile: /zone/success2 is closed by DFSClient_NONMAPREDUCE_-1028944470_1162
2023-01-27 20:24:32,713 [IPC Server handler 5 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/zone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:32,714 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,715 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,715 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,715 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,715 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,715 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,715 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2776)
2023-01-27 20:24:32,715 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,715 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,715 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,715 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,715 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,715 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,716 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2776)
2023-01-27 20:24:32,717 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,717 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,717 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,717 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,717 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,717 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,717 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,717 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,717 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,717 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,717 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,717 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,717 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,717 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,718 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,718 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,718 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,718 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,718 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,718 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,718 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:564)
2023-01-27 20:24:32,718 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:32,718 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,719 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:564)
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,720 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,721 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,721 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,721 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,721 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,721 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,721 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,721 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,721 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,721 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,721 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,721 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,721 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,721 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1386)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1201)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:579)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,722 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,723 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,723 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,723 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,723 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,723 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,723 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,723 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,723 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1386)
2023-01-27 20:24:32,723 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1201)
2023-01-27 20:24:32,723 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:579)
2023-01-27 20:24:32,723 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:32,723 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,723 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,723 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,724 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,724 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,724 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,724 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,724 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,724 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,724 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,724 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,724 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,724 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,724 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,725 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,725 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,725 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,725 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,725 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.setNewINodeStoragePolicy(FSDirWriteFileOp.java:823)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:413)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,726 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.setNewINodeStoragePolicy(FSDirWriteFileOp.java:823)
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:413)
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,727 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,728 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,728 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,728 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,728 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,728 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,728 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,728 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,728 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,728 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,728 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,728 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,728 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,728 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:347)
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,729 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,730 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:347)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,731 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.createFileStatus(FSDirStatAndListingOp.java:434)
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:349)
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,732 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:32,733 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.createFileStatus(FSDirStatAndListingOp.java:434)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:349)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,734 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,735 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,735 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,735 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,735 [IPC Server handler 6 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,735 [IPC Server handler 6 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/zone/success3	dst=null	perm=rizky:supergroup:rw-r--r--	proto=rpc
2023-01-27 20:24:32,741 [qtp1428842837-1171] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:32 +0000] "POST /kms/v1/keyversion/test_key%400/_eek?eek_op=decrypt HTTP/1.1" 200 90 "-" "Java/1.8.0_352"
2023-01-27 20:24:32,754 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,754 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.validateAddBlock(FSDirWriteFileOp.java:202)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3053)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:931)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:601)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,755 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.validateAddBlock(FSDirWriteFileOp.java:202)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3053)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:931)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:601)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,756 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,757 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,757 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,760 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,760 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,760 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,760 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,760 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,760 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:1026)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:783)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:259)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3073)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:931)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:601)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,761 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:1026)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:783)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:259)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3073)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:931)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:601)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:32,762 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:32,763 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:32,763 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:32,763 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:32,763 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:32,763 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:32,763 [IPC Server handler 7 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:32,765 [IPC Server handler 7 on default port 44583] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(802)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:39785 for /zone/success3
2023-01-27 20:24:32,844 [DataXceiver for client DFSClient_NONMAPREDUCE_-1028944470_1162 at /127.0.0.1:45480 [Receiving block BP-788369989-127.0.1.1-1674825871009:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(751)) - Receiving BP-788369989-127.0.1.1-1674825871009:blk_1073741825_1001 src: /127.0.0.1:45480 dest: /127.0.0.1:39785
2023-01-27 20:24:32,894 [PacketResponder: BP-788369989-127.0.1.1-1674825871009:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1571)) - src: /127.0.0.1:45480, dest: /127.0.0.1:39785, volume: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1028944470_1162, offset: 0, srvID: 95b26f72-3dca-4769-862c-03bb0edbf375, blockid: BP-788369989-127.0.1.1-1674825871009:blk_1073741825_1001, duration(ns): 16874764
2023-01-27 20:24:32,895 [PacketResponder: BP-788369989-127.0.1.1-1674825871009:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1544)) - PacketResponder: BP-788369989-127.0.1.1-1674825871009:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2023-01-27 20:24:32,900 [IPC Server handler 9 on default port 44583] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(3276)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /zone/success3
2023-01-27 20:24:32,914 [Block report processor] INFO  BlockStateChange (BlockManager.java:addStoredBlock(3635)) - BLOCK* addStoredBlock: 127.0.0.1:39785 is added to blk_1073741825_1001 (size=4096)
2023-01-27 20:24:32,915 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:32,915 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:32,915 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:32,915 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,916 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,916 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,916 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:1026)
2023-01-27 20:24:32,916 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateSpaceConsumed(FSDirectory.java:983)
2023-01-27 20:24:32,916 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateSpaceForCompleteBlock(FSDirectory.java:1141)
2023-01-27 20:24:32,916 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.convertToCompleteBlock(BlockManager.java:1302)
2023-01-27 20:24:32,916 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.completeBlock(BlockManager.java:1274)
2023-01-27 20:24:32,916 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.addStoredBlock(BlockManager.java:3667)
2023-01-27 20:24:32,916 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processAndHandleReportedBlock(BlockManager.java:4389)
2023-01-27 20:24:32,916 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.addBlock(BlockManager.java:4344)
2023-01-27 20:24:32,916 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processIncrementalBlockReport(BlockManager.java:4461)
2023-01-27 20:24:32,917 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processIncrementalBlockReport(BlockManager.java:4428)
2023-01-27 20:24:32,917 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processIncrementalBlockReport(FSNamesystem.java:5286)
2023-01-27 20:24:32,917 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer$1.run(NameNodeRpcServer.java:1701)
2023-01-27 20:24:32,917 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.processQueue(BlockManager.java:5442)
2023-01-27 20:24:32,917 [Block report processor] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.run(BlockManager.java:5419)
2023-01-27 20:24:32,917 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:32,917 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:32,917 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:32,917 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:32,917 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:32,917 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:32,918 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:32,918 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:1026)
2023-01-27 20:24:32,918 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateSpaceConsumed(FSDirectory.java:983)
2023-01-27 20:24:32,918 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateSpaceForCompleteBlock(FSDirectory.java:1141)
2023-01-27 20:24:32,918 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.convertToCompleteBlock(BlockManager.java:1302)
2023-01-27 20:24:32,918 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.completeBlock(BlockManager.java:1274)
2023-01-27 20:24:32,918 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.addStoredBlock(BlockManager.java:3667)
2023-01-27 20:24:32,918 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processAndHandleReportedBlock(BlockManager.java:4389)
2023-01-27 20:24:32,918 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.addBlock(BlockManager.java:4344)
2023-01-27 20:24:32,918 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processIncrementalBlockReport(BlockManager.java:4461)
2023-01-27 20:24:32,918 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processIncrementalBlockReport(BlockManager.java:4428)
2023-01-27 20:24:32,918 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.processIncrementalBlockReport(FSNamesystem.java:5286)
2023-01-27 20:24:32,919 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer$1.run(NameNodeRpcServer.java:1701)
2023-01-27 20:24:32,919 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.processQueue(BlockManager.java:5442)
2023-01-27 20:24:32,919 [Block report processor] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.run(BlockManager.java:5419)
2023-01-27 20:24:33,303 [IPC Server handler 0 on default port 44583] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(3229)) - DIR* completeFile: /zone/success3 is closed by DFSClient_NONMAPREDUCE_-1028944470_1162
2023-01-27 20:24:33,309 [qtp1428842837-1169] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:33 +0000] "OPTIONS /kms/v1/keys/names HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:33,313 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:33,313 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:33,313 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:33,314 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:33,314 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:33,314 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:33,314 [qtp1428842837-1171] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:33,316 [qtp1428842837-1171] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:33 +0000] "OPTIONS /kms/v1/keys/names?user.name=rizky HTTP/1.1" 200 462 "-" "Java/1.8.0_352"
2023-01-27 20:24:33,320 [qtp1428842837-1165] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=GET_KEYS, user=rizky] 
2023-01-27 20:24:33,321 [qtp1428842837-1165] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:33 +0000] "GET /kms/v1/keys/names HTTP/1.1" 200 14 "-" "Java/1.8.0_352"
2023-01-27 20:24:33,519 [qtp1428842837-1171] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=GET_KEY_VERSIONS, key=test_key, user=rizky] 
2023-01-27 20:24:33,520 [qtp1428842837-1171] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:33 +0000] "GET /kms/v1/key/test_key/_versions HTTP/1.1" 200 102 "-" "Java/1.8.0_352"
2023-01-27 20:24:33,524 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:33,524 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:33,525 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:33,525 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:33,525 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.getXAttrByPrefixedName(FSDirXAttrOp.java:416)
2023-01-27 20:24:33,525 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkUnreadableBySuperuser(FSDirectory.java:1975)
2023-01-27 20:24:33,525 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:161)
2023-01-27 20:24:33,525 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2188)
2023-01-27 20:24:33,525 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:794)
2023-01-27 20:24:33,525 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:466)
2023-01-27 20:24:33,525 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:33,525 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:33,525 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:33,525 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:33,526 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:33,526 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:33,526 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:33,526 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:33,526 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:33,526 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:33,526 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:33,526 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:33,526 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:33,526 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:33,526 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:33,526 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:33,526 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.getXAttrByPrefixedName(FSDirXAttrOp.java:416)
2023-01-27 20:24:33,526 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkUnreadableBySuperuser(FSDirectory.java:1975)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:161)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2188)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:794)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:466)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:33,527 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:33,528 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:33,528 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:33,528 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:33,528 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:33,528 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:33,528 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:33,528 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:178)
2023-01-27 20:24:33,528 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2188)
2023-01-27 20:24:33,528 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:794)
2023-01-27 20:24:33,528 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:466)
2023-01-27 20:24:33,528 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:33,528 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:33,529 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:33,529 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:33,529 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:33,529 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:33,529 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:33,529 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:33,529 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:33,529 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:33,529 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:33,529 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:33,529 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:33,529 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:33,530 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:33,530 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:33,530 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:33,530 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:33,530 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:178)
2023-01-27 20:24:33,530 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2188)
2023-01-27 20:24:33,530 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:794)
2023-01-27 20:24:33,530 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:466)
2023-01-27 20:24:33,530 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:33,530 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:33,537 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:33,537 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:33,537 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:33,537 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:33,537 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:33,537 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:33,537 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:33,538 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:33,538 [IPC Server handler 1 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:33,539 [IPC Server handler 1 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/zone/success2	dst=null	perm=null	proto=rpc
2023-01-27 20:24:33,549 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:33,549 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:33,549 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:33,549 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:33,549 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.getXAttrByPrefixedName(FSDirXAttrOp.java:416)
2023-01-27 20:24:33,549 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkUnreadableBySuperuser(FSDirectory.java:1975)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:161)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2188)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:794)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:466)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:33,550 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.getXAttrByPrefixedName(FSDirXAttrOp.java:416)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkUnreadableBySuperuser(FSDirectory.java:1975)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:161)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2188)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:794)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:466)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:33,551 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:178)
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2188)
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:794)
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:466)
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:33,552 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:178)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2188)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:794)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:466)
2023-01-27 20:24:33,553 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:33,554 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:33,554 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:33,554 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:33,554 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:33,554 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:33,554 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:33,554 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:33,554 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:33,554 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:33,554 [IPC Server handler 2 on default port 44583] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:33,555 [IPC Server handler 2 on default port 44583] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/zone/success3	dst=null	perm=null	proto=rpc
2023-01-27 20:24:33,772 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2159)) - Shutting down the Mini HDFS Cluster
2023-01-27 20:24:33,773 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2208)) - Shutting down DataNode 0
2023-01-27 20:24:33,773 [Time-limited test] INFO  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(430)) - Shutdown has been called
2023-01-27 20:24:33,773 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@10d56cc1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(395)) - Closing all peers.
2023-01-27 20:24:33,774 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-4d1b6e72-cb5c-4c90-8eaa-50dc0d553316) exiting.
2023-01-27 20:24:33,774 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-ec83542b-b2b1-4b3a-abe1-3f9fee79e272) exiting.
2023-01-27 20:24:33,790 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@25635c38{datanode,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:33,790 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@3daf0472{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:33,790 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:33,791 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@577a281e{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:33,791 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2a1cada6{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:33,793 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2470)) - Waiting up to 30 seconds for transfer threads to complete
2023-01-27 20:24:33,793 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 35553
2023-01-27 20:24:33,794 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:33,794 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:33,796 [Command processor] ERROR datanode.DataNode (BPServiceActor.java:processQueue(1430)) - Command processor encountered interrupt and exit.
2023-01-27 20:24:33,796 [BP-788369989-127.0.1.1-1674825871009 heartbeating to localhost/127.0.0.1:44583] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:33,796 [BP-788369989-127.0.1.1-1674825871009 heartbeating to localhost/127.0.0.1:44583] WARN  datanode.DataNode (BPServiceActor.java:run(924)) - Ending block pool service for: Block pool BP-788369989-127.0.1.1-1674825871009 (Datanode Uuid 95b26f72-3dca-4769-862c-03bb0edbf375) service to localhost/127.0.0.1:44583
2023-01-27 20:24:33,796 [BP-788369989-127.0.1.1-1674825871009 heartbeating to localhost/127.0.0.1:44583] INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-788369989-127.0.1.1-1674825871009 (Datanode Uuid 95b26f72-3dca-4769-862c-03bb0edbf375)
2023-01-27 20:24:33,796 [BP-788369989-127.0.1.1-1674825871009 heartbeating to localhost/127.0.0.1:44583] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(3225)) - Removing block pool BP-788369989-127.0.1.1-1674825871009
2023-01-27 20:24:33,797 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-788369989-127.0.1.1-1674825871009] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:33,798 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-788369989-127.0.1.1-1674825871009] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:33,796 [Command processor] WARN  datanode.DataNode (BPServiceActor.java:run(1414)) - Ending command processor service for: Thread[Command processor,5,main]
2023-01-27 20:24:33,796 [ibr-executor-0] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:33,799 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(208)) - Shutting down all async disk service threads
2023-01-27 20:24:33,800 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(216)) - All async disk service threads have been shut down
2023-01-27 20:24:33,800 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(186)) - Shutting down all async lazy persist service threads
2023-01-27 20:24:33,800 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(193)) - All async lazy persist service threads have been shut down
2023-01-27 20:24:33,801 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2559)) - Shutdown complete.
2023-01-27 20:24:33,801 [Time-limited test] WARN  datanode.DataSetLockManager (DataSetLockManager.java:lockLeakCheck(260)) - not open lock leak check func
2023-01-27 20:24:33,801 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2241)) - Shutting down the namenode
2023-01-27 20:24:33,801 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:33,801 [Thread[Thread-717,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:33,802 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(576)) - EDEKCacheLoader interrupted before warming up.
2023-01-27 20:24:33,802 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@56369d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4561)) - NameNodeEditLogRoller was interrupted, exiting
2023-01-27 20:24:33,802 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1467)) - Ending log segment 1, 14
2023-01-27 20:24:33,802 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@11826a1c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4658)) - LazyPersistFileScrubber was interrupted, exiting
2023-01-27 20:24:33,804 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(801)) - Number of transactions: 15 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 1 Number of syncs: 15 SyncTimes(ms): 16 17 
2023-01-27 20:24:33,805 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000015
2023-01-27 20:24:33,805 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000015
2023-01-27 20:24:33,806 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(276)) - FSEditLogAsync was interrupted, exiting
2023-01-27 20:24:33,806 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(267)) - Re-encryption updater thread interrupted. Exiting.
2023-01-27 20:24:33,806 [CacheReplicationMonitor(2055187280)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2023-01-27 20:24:33,806 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(335)) - Re-encrypt handler interrupted. Exiting
2023-01-27 20:24:33,808 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 44583
2023-01-27 20:24:33,808 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:33,808 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:33,809 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5134)) - Stopping MarkedDeleteBlockScrubber.
2023-01-27 20:24:33,809 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(5160)) - Stopping RedundancyMonitor.
2023-01-27 20:24:33,817 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:33,818 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:33,818 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3e4fbb1c{hdfs,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:33,819 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@78b597c8{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:33,820 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:33,820 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@715672a0{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:33,820 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@c24fda9{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:33,826 [Thread[Thread-685,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:33,827 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextDestroyed(197)) - KMS Stopped
2023-01-27 20:24:33,827 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@665becac{kms,/,null,STOPPED}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:33,829 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6cfbf4b{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:33,829 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:33,829 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@591e1dc5{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-27 20:24:33,829 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2a1c9ded{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:33,830 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2023-01-27 20:24:33,831 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2023-01-27 20:24:33,831 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(612)) - DataNode metrics system shutdown complete.
2023-01-27 20:24:33,873 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:33,873 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context kms
2023-01-27 20:24:33,873 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:33,873 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:33,873 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:33,874 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 39979
2023-01-27 20:24:33,874 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:33,875 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:33,875 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:33,875 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:24:33,876 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2a01905a{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:33,876 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1f18a49f{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-27 20:24:33,901 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(94)) - -------------------------------------------------------------
2023-01-27 20:24:33,901 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(95)) -   Java runtime version : 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:33,901 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(97)) -   User: rizky
2023-01-27 20:24:33,901 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(98)) -   KMS Hadoop Version: 3.4.0-SNAPSHOT
2023-01-27 20:24:33,902 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(99)) - -------------------------------------------------------------
2023-01-27 20:24:33,902 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'CREATE' ACL '*'
2023-01-27 20:24:33,902 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DELETE' ACL '*'
2023-01-27 20:24:33,902 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'ROLLOVER' ACL '*'
2023-01-27 20:24:33,902 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET' ACL '*'
2023-01-27 20:24:33,903 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_KEYS' ACL '*'
2023-01-27 20:24:33,903 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_METADATA' ACL '*'
2023-01-27 20:24:33,903 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'SET_KEY_MATERIAL' ACL '*'
2023-01-27 20:24:33,903 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GENERATE_EEK' ACL '*'
2023-01-27 20:24:33,903 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DECRYPT_EEK' ACL '*'
2023-01-27 20:24:33,903 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2023-01-27 20:24:33,903 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2023-01-27 20:24:33,903 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2023-01-27 20:24:33,903 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2023-01-27 20:24:33,905 [Time-limited test] INFO  server.KMSAudit (KMSAudit.java:initializeAuditLoggers(157)) - Initializing audit logger class org.apache.hadoop.crypto.key.kms.server.SimpleKMSAuditLogger
2023-01-27 20:24:33,906 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(149)) - Initialized KeyProvider CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/a1279c08-4319-4205-8c0f-258d70d49cd4/kms.keystore
2023-01-27 20:24:33,907 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(163)) - Initialized KeyProviderCryptoExtension org.apache.hadoop.crypto.key.kms.server.KeyAuthorizationKeyProvider: EagerKeyGeneratorKeyProviderCryptoExtension: KeyProviderCryptoExtension: CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/a1279c08-4319-4205-8c0f-258d70d49cd4/kms.keystore
2023-01-27 20:24:33,907 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(168)) - Default key bitlength is 128
2023-01-27 20:24:33,907 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(169)) - KMS Started
2023-01-27 20:24:33,908 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:33,908 [Thread[Thread-799,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:33,910 [Time-limited test] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.crypto.key.kms.server
2023-01-27 20:24:33,911 [Thread[Thread-799,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:33,928 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMS
2023-01-27 20:24:33,928 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
  class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
2023-01-27 20:24:33,931 [Time-limited test] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:24:34,077 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@550c8370{kms,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/2/kms/webapp/,AVAILABLE}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:34,078 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@7086ae9a{HTTP/1.1, (http/1.1)}{localhost:39979}
2023-01-27 20:24:34,078 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @39100ms
2023-01-27 20:24:34,081 [Time-limited test] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(120)) - Loaded properties from hadoop-metrics2.properties
2023-01-27 20:24:34,082 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 0 second(s).
2023-01-27 20:24:34,082 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - KMS metrics system started
2023-01-27 20:24:34,095 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@63098a2a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:34,106 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(566)) - starting cluster: numNameNodes=1, numDataNodes=1
2023-01-27 20:24:34,108 [Time-limited test] INFO  namenode.NameNode (NameNode.java:format(1366)) - Formatting using clusterid: testClusterID
2023-01-27 20:24:34,108 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:34,119 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@141a7362
2023-01-27 20:24:34,120 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:34,120 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:34,120 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:34,120 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:34,120 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:34,120 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:34,120 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:34,121 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:34,122 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:34,122 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:34,122 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:34,122 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:34
2023-01-27 20:24:34,122 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:34,122 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:34,122 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:34,123 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:34,125 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:34,125 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:34,125 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:34,126 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:34,126 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:34,126 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:34,126 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:34,126 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:34,126 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:34,126 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:34,126 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:34,126 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:34,126 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:34,126 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:34,127 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:34,127 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:34,127 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:34,128 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:34,128 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:34,128 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:34,128 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:34,128 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:34,128 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:34,128 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:34,128 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:34,128 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:34,128 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:34,129 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:34,129 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:34,129 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:34,129 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:34,129 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:34,130 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:34,130 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:34,130 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:34,130 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:34,130 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:34,130 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:34,131 [Time-limited test] INFO  namenode.FSImage (FSImage.java:format(186)) - Allocated new BlockPoolId: BP-1038687131-127.0.1.1-1674825874131
2023-01-27 20:24:34,134 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 has been successfully formatted.
2023-01-27 20:24:34,136 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 has been successfully formatted.
2023-01-27 20:24:34,146 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:34,147 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:34,151 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 493 bytes saved in 0 seconds .
2023-01-27 20:24:34,152 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 493 bytes saved in 0 seconds .
2023-01-27 20:24:34,154 [Time-limited test] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(202)) - Going to retain 1 images with txid >= 0
2023-01-27 20:24:34,164 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:34,164 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:34,165 [Time-limited test] INFO  namenode.NameNode (NameNode.java:createNameNode(1824)) - createNameNode []
2023-01-27 20:24:34,165 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2023-01-27 20:24:34,165 [Time-limited test] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2023-01-27 20:24:34,180 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4a3f9114] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:34,181 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1736)) - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2023-01-27 20:24:34,181 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1758)) - Starting Web-server for hdfs at: http://localhost:0
2023-01-27 20:24:34,181 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:34,183 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:34,185 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:34,186 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:34,187 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-01-27 20:24:34,187 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:34,187 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:34,189 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2023-01-27 20:24:34,189 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2023-01-27 20:24:34,189 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2023-01-27 20:24:34,189 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:34,189 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(1018)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-01-27 20:24:34,190 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 36237
2023-01-27 20:24:34,190 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:34,200 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:34,200 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:34,201 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:34,202 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:34,204 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@68e0fff{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:34,205 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1ba65261{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:34,213 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@27c4ffc7{hdfs,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:34,219 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@70819afa{HTTP/1.1, (http/1.1)}{localhost:36237}
2023-01-27 20:24:34,219 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @39241ms
2023-01-27 20:24:34,221 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:34,232 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@451a8c30
2023-01-27 20:24:34,232 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:34,232 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:34,232 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:34,232 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:34,232 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:34,232 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:34,233 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:34,233 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:34,234 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:34,234 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:34,234 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:34,234 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:34
2023-01-27 20:24:34,234 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:34,234 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:34,235 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:34,235 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:34,236 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:34,237 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:34,237 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:34,237 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:34,237 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:34,237 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:34,237 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:34,237 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:34,238 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:34,238 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:34,238 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:34,238 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:34,238 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:34,238 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:34,238 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:34,239 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:34,240 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:34,241 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:34,241 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:34,241 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:34,241 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:34,241 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:34,242 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:34,242 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:34,242 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:34,242 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:34,242 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:34,243 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:34,243 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:34,243 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:34,243 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:34,244 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:34,244 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:34,244 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:34,244 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:34,244 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:34,244 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:34,244 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:34,247 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:34,250 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:34,251 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current
2023-01-27 20:24:34,251 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current
2023-01-27 20:24:34,252 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(734)) - No edit log streams selected.
2023-01-27 20:24:34,252 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(800)) - Planning to load image: FSImageFile(file=/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-01-27 20:24:34,253 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSectionHeader(411)) - Loading 1 INodes.
2023-01-27 20:24:34,254 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(369)) - Successfully loaded 1 inodes
2023-01-27 20:24:34,254 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:waitBlocksMapAndNameCacheUpdateFinished(342)) - Completed update blocks map and name cache, total waiting duration 0ms.
2023-01-27 20:24:34,255 [Time-limited test] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(255)) - Loaded FSImage in 0 seconds.
2023-01-27 20:24:34,255 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(980)) - Loaded image for txid 0 from /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000
2023-01-27 20:24:34,255 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1271)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-01-27 20:24:34,256 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1417)) - Starting log segment at 1
2023-01-27 20:24:34,269 [Time-limited test] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2023-01-27 20:24:34,269 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(836)) - Finished loading FSImage in 24 msecs
2023-01-27 20:24:34,270 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(451)) - RPC server is binding to localhost:0
2023-01-27 20:24:34,270 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(456)) - Enable NameNode state context:false
2023-01-27 20:24:34,271 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:34,271 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:34827
2023-01-27 20:24:34,271 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:34,277 [Time-limited test] INFO  namenode.NameNode (NameNode.java:initialize(893)) - Clients are to use localhost:34827 to access this namenode/service.
2023-01-27 20:24:34,277 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5607)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2023-01-27 20:24:34,288 [Time-limited test] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(166)) - Number of blocks under construction: 0
2023-01-27 20:24:34,290 [Time-limited test] INFO  blockmanagement.DatanodeAdminDefaultMonitor (DatanodeAdminDefaultMonitor.java:processConf(126)) - Initialized the Default Decommission and Maintenance monitor
2023-01-27 20:24:34,292 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(5310)) - initializing replication queues
2023-01-27 20:24:34,293 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(409)) - STATE* Leaving safe mode after 0 secs
2023-01-27 20:24:34,293 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(415)) - STATE* Network topology has 0 racks and 0 datanodes
2023-01-27 20:24:34,293 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(417)) - STATE* UnderReplicatedBlocks has 0 blocks
2023-01-27 20:24:34,293 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:34,296 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5102)) - Start MarkedDeleteBlockScrubber thread
2023-01-27 20:24:34,298 [Thread[Thread-831,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:34,302 [Thread[Thread-831,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:34,304 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:34,304 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:34,316 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3870)) - Total number of blocks            = 0
2023-01-27 20:24:34,316 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3871)) - Number of invalid blocks          = 0
2023-01-27 20:24:34,316 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3872)) - Number of under-replicated blocks = 0
2023-01-27 20:24:34,316 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3873)) - Number of  over-replicated blocks = 0
2023-01-27 20:24:34,316 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3875)) - Number of blocks being written    = 0
2023-01-27 20:24:34,316 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3878)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 20 msec
2023-01-27 20:24:34,329 [Time-limited test] INFO  namenode.NameNode (NameNode.java:startCommonServices(1010)) - NameNode RPC up at: localhost/127.0.0.1:34827
2023-01-27 20:24:34,329 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1383)) - Starting services required for active state
2023-01-27 20:24:34,329 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(857)) - Initializing quota with 12 thread(s)
2023-01-27 20:24:34,330 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(866)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2023-01-27 20:24:34,331 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(326)) - Starting up re-encrypt thread with interval=60000 millisecond.
2023-01-27 20:24:34,332 [CacheReplicationMonitor(1436284706)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-01-27 20:24:34,332 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2023-01-27 20:24:34,335 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1769)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1,[DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:34,336 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:34,336 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:34,347 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2023-01-27 20:24:34,347 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:34,348 [Time-limited test] INFO  datanode.BlockScanner (BlockScanner.java:<init>(201)) - Initialized block scanner with targetBytesPerSec 1048576
2023-01-27 20:24:34,348 [Time-limited test] INFO  datanode.DataNode (DataNode.java:<init>(571)) - Configured hostname is 127.0.0.1
2023-01-27 20:24:34,348 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:34,349 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1788)) - Starting DataNode with maxLockedMemory = 0
2023-01-27 20:24:34,349 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1551)) - Opened streaming server at /127.0.0.1:36159
2023-01-27 20:24:34,349 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(93)) - Balancing bandwidth is 104857600 bytes/s
2023-01-27 20:24:34,350 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(94)) - Number threads for balancing is 100
2023-01-27 20:24:34,350 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:34,352 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:34,354 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:34,356 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:34,356 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-01-27 20:24:34,357 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:34,357 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:34,357 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:34,358 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 37901
2023-01-27 20:24:34,358 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:34,359 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:34,359 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:34,359 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:24:34,360 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@d584dac{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:34,361 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@69a4a7db{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:34,365 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@43afec1d{datanode,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:34,366 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@36b0a4a9{HTTP/1.1, (http/1.1)}{localhost:37901}
2023-01-27 20:24:34,366 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @39388ms
2023-01-27 20:24:34,370 [Time-limited test] WARN  web.DatanodeHttpServer (RestCsrfPreventionFilterHandler.java:<init>(75)) - Got null for restCsrfPreventionFilter - will not do any filtering.
2023-01-27 20:24:34,372 [Time-limited test] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(306)) - Listening HTTP traffic on /127.0.0.1:34179
2023-01-27 20:24:34,372 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1816)) - dnUserName = rizky
2023-01-27 20:24:34,373 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1817)) - supergroup = supergroup
2023-01-27 20:24:34,373 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:34,374 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:41867
2023-01-27 20:24:34,372 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ed9f904] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:34,382 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:34,385 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initIpcServer(1438)) - Opened IPC server at /127.0.0.1:41867
2023-01-27 20:24:34,400 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(150)) - Refresh request received for nameservices: null
2023-01-27 20:24:34,400 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(211)) - Starting BPOfferServices for nameservices: <default>
2023-01-27 20:24:34,401 [Thread-864] INFO  datanode.DataNode (BPServiceActor.java:run(877)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34827 starting to offer service
2023-01-27 20:24:34,403 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:34,403 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:34,423 [Thread-864] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(382)) - Acknowledging ACTIVE Namenode during handshake Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34827
2023-01-27 20:24:34,427 [Thread-864] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(356)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2023-01-27 20:24:34,429 [Thread-864] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:34,429 [Thread-864] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 is not formatted for namespace 70301616. Formatting...
2023-01-27 20:24:34,430 [IPC Server handler 1 on default port 34827] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:34,430 [Thread-864] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c04c47bb-3476-4a81-b4af-9ed9c3ffd65d for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 
2023-01-27 20:24:34,431 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:34,432 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:34,434 [Thread-864] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:34,434 [Thread-864] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 is not formatted for namespace 70301616. Formatting...
2023-01-27 20:24:34,435 [Thread-864] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2f7a0c12-7820-4911-85da-691cff57eabd for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 
2023-01-27 20:24:34,456 [Thread-864] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-1038687131-127.0.1.1-1674825874131
2023-01-27 20:24:34,456 [Thread-864] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1038687131-127.0.1.1-1674825874131
2023-01-27 20:24:34,457 [Thread-864] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 and block pool id BP-1038687131-127.0.1.1-1674825874131 is not formatted. Formatting ...
2023-01-27 20:24:34,457 [Thread-864] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-1038687131-127.0.1.1-1674825874131 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1038687131-127.0.1.1-1674825874131/current
2023-01-27 20:24:34,476 [Thread-864] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-1038687131-127.0.1.1-1674825874131
2023-01-27 20:24:34,476 [Thread-864] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1038687131-127.0.1.1-1674825874131
2023-01-27 20:24:34,476 [Thread-864] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 and block pool id BP-1038687131-127.0.1.1-1674825874131 is not formatted. Formatting ...
2023-01-27 20:24:34,476 [Thread-864] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-1038687131-127.0.1.1-1674825874131 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1038687131-127.0.1.1-1674825874131/current
2023-01-27 20:24:34,479 [Thread-864] INFO  datanode.DataNode (DataNode.java:initStorage(2136)) - Setting up storage: nsid=70301616;bpid=BP-1038687131-127.0.1.1-1674825874131;lv=-57;nsInfo=lv=-67;cid=testClusterID;nsid=70301616;c=1674825874131;bpid=BP-1038687131-127.0.1.1-1674825874131;dnuuid=null
2023-01-27 20:24:34,482 [Thread-864] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1934)) - Generated and persisted new Datanode UUID 96f38763-dfcc-4d9d-a032-dfc3d3eee204
2023-01-27 20:24:34,482 [Thread-864] INFO  fsdataset.RoundRobinVolumeChoosingPolicy (RoundRobinVolumeChoosingPolicy.java:setConf(67)) - Round robin volume choosing policy initialized: dfs.datanode.round-robin-volume-choosing-policy.additional-available-space = 0
2023-01-27 20:24:34,484 [Thread-864] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-c04c47bb-3476-4a81-b4af-9ed9c3ffd65d
2023-01-27 20:24:34,484 [Thread-864] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, StorageType: DISK
2023-01-27 20:24:34,487 [Thread-864] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-2f7a0c12-7820-4911-85da-691cff57eabd
2023-01-27 20:24:34,487 [Thread-864] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, StorageType: DISK
2023-01-27 20:24:34,488 [Thread-864] INFO  impl.MemoryMappableBlockLoader (MemoryMappableBlockLoader.java:initialize(47)) - Initializing cache loader: MemoryMappableBlockLoader.
2023-01-27 20:24:34,488 [Thread-864] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2611)) - Registered FSDatasetState MBean
2023-01-27 20:24:34,489 [Thread-864] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(3188)) - Adding block pool BP-1038687131-127.0.1.1-1674825874131
2023-01-27 20:24:34,489 [Thread-881] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-1038687131-127.0.1.1-1674825874131 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:34,490 [Thread-881] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1038687131-127.0.1.1-1674825874131/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:34,490 [Thread-882] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-1038687131-127.0.1.1-1674825874131 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:34,490 [Thread-882] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1038687131-127.0.1.1-1674825874131/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:34,506 [Thread-881] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-1038687131-127.0.1.1-1674825874131 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 16ms
2023-01-27 20:24:34,509 [Thread-882] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-1038687131-127.0.1.1-1674825874131 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 18ms
2023-01-27 20:24:34,509 [Thread-864] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(538)) - Total time to scan all replicas for block pool BP-1038687131-127.0.1.1-1674825874131: 20ms
2023-01-27 20:24:34,509 [Thread-885] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-1038687131-127.0.1.1-1674825874131 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:34,509 [Thread-886] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-1038687131-127.0.1.1-1674825874131 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:34,509 [Thread-885] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1038687131-127.0.1.1-1674825874131/current/replicas doesn't exist 
2023-01-27 20:24:34,509 [Thread-886] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1038687131-127.0.1.1-1674825874131/current/replicas doesn't exist 
2023-01-27 20:24:34,510 [Thread-885] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-1038687131-127.0.1.1-1674825874131 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 0ms
2023-01-27 20:24:34,510 [Thread-886] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-1038687131-127.0.1.1-1674825874131 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 0ms
2023-01-27 20:24:34,510 [Thread-864] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(292)) - Total time to add all replicas to map for block pool BP-1038687131-127.0.1.1-1674825874131: 1ms
2023-01-27 20:24:34,510 [Thread-864] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:34,511 [Thread-864] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:34,511 [Thread-864] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:34,511 [Thread-864] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:34,512 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-1038687131-127.0.1.1-1674825874131 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:34,512 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-1038687131-127.0.1.1-1674825874131 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:34,512 [Thread-864] WARN  datanode.DirectoryScanner (DirectoryScanner.java:<init>(302)) - dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2023-01-27 20:24:34,512 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-2f7a0c12-7820-4911-85da-691cff57eabd): finished scanning block pool BP-1038687131-127.0.1.1-1674825874131
2023-01-27 20:24:34,512 [Thread-864] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(367)) - Periodic Directory Tree Verification scan starting in 5691053ms with interval of 21600000ms and throttle limit of -1ms/s
2023-01-27 20:24:34,512 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-c04c47bb-3476-4a81-b4af-9ed9c3ffd65d): finished scanning block pool BP-1038687131-127.0.1.1-1674825874131
2023-01-27 20:24:34,513 [BP-1038687131-127.0.1.1-1674825874131 heartbeating to localhost/127.0.0.1:34827] INFO  datanode.DataNode (BPServiceActor.java:register(819)) - Block pool BP-1038687131-127.0.1.1-1674825874131 (Datanode Uuid 96f38763-dfcc-4d9d-a032-dfc3d3eee204) service to localhost/127.0.0.1:34827 beginning handshake with NN: localhost/127.0.0.1:34827.
2023-01-27 20:24:34,513 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-2f7a0c12-7820-4911-85da-691cff57eabd): no suitable block pools found to scan.  Waiting 1814399999 ms.
2023-01-27 20:24:34,514 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-c04c47bb-3476-4a81-b4af-9ed9c3ffd65d): no suitable block pools found to scan.  Waiting 1814399998 ms.
2023-01-27 20:24:34,515 [IPC Server handler 2 on default port 34827] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1166)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36159, datanodeUuid=96f38763-dfcc-4d9d-a032-dfc3d3eee204, infoPort=34179, infoSecurePort=0, ipcPort=41867, storageInfo=lv=-57;cid=testClusterID;nsid=70301616;c=1674825874131) storage 96f38763-dfcc-4d9d-a032-dfc3d3eee204
2023-01-27 20:24:34,515 [IPC Server handler 2 on default port 34827] INFO  net.NetworkTopology (NetworkTopology.java:add(156)) - Adding a new node: /default-rack/127.0.0.1:36159
2023-01-27 20:24:34,515 [IPC Server handler 2 on default port 34827] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(200)) - Registered DN 96f38763-dfcc-4d9d-a032-dfc3d3eee204 (127.0.0.1:36159).
2023-01-27 20:24:34,517 [BP-1038687131-127.0.1.1-1674825874131 heartbeating to localhost/127.0.0.1:34827] INFO  datanode.DataNode (BPServiceActor.java:register(846)) - Block pool BP-1038687131-127.0.1.1-1674825874131 (Datanode Uuid 96f38763-dfcc-4d9d-a032-dfc3d3eee204) service to localhost/127.0.0.1:34827 successfully registered with NN: localhost/127.0.0.1:34827.
2023-01-27 20:24:34,517 [BP-1038687131-127.0.1.1-1674825874131 heartbeating to localhost/127.0.0.1:34827] INFO  datanode.DataNode (BPServiceActor.java:offerService(680)) - For namenode localhost/127.0.0.1:34827 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2023-01-27 20:24:34,517 [ibr-executor-0] INFO  datanode.DataNode (BPServiceActor.java:run(1145)) - Starting IBR Task Handler.
2023-01-27 20:24:34,519 [IPC Server handler 3 on default port 34827] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-c04c47bb-3476-4a81-b4af-9ed9c3ffd65d for DN 127.0.0.1:36159
2023-01-27 20:24:34,519 [IPC Server handler 3 on default port 34827] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-2f7a0c12-7820-4911-85da-691cff57eabd for DN 127.0.0.1:36159
2023-01-27 20:24:34,521 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0x9d58dfcc8881990f with lease ID 0x4ed03e1feb5ffe76: Processing first storage report for DS-2f7a0c12-7820-4911-85da-691cff57eabd from datanode DatanodeRegistration(127.0.0.1:36159, datanodeUuid=96f38763-dfcc-4d9d-a032-dfc3d3eee204, infoPort=34179, infoSecurePort=0, ipcPort=41867, storageInfo=lv=-57;cid=testClusterID;nsid=70301616;c=1674825874131)
2023-01-27 20:24:34,521 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0x9d58dfcc8881990f with lease ID 0x4ed03e1feb5ffe76: from storage DS-2f7a0c12-7820-4911-85da-691cff57eabd node DatanodeRegistration(127.0.0.1:36159, datanodeUuid=96f38763-dfcc-4d9d-a032-dfc3d3eee204, infoPort=34179, infoSecurePort=0, ipcPort=41867, storageInfo=lv=-57;cid=testClusterID;nsid=70301616;c=1674825874131), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:34,521 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0x9d58dfcc8881990f with lease ID 0x4ed03e1feb5ffe76: Processing first storage report for DS-c04c47bb-3476-4a81-b4af-9ed9c3ffd65d from datanode DatanodeRegistration(127.0.0.1:36159, datanodeUuid=96f38763-dfcc-4d9d-a032-dfc3d3eee204, infoPort=34179, infoSecurePort=0, ipcPort=41867, storageInfo=lv=-57;cid=testClusterID;nsid=70301616;c=1674825874131)
2023-01-27 20:24:34,521 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0x9d58dfcc8881990f with lease ID 0x4ed03e1feb5ffe76: from storage DS-c04c47bb-3476-4a81-b4af-9ed9c3ffd65d node DatanodeRegistration(127.0.0.1:36159, datanodeUuid=96f38763-dfcc-4d9d-a032-dfc3d3eee204, infoPort=34179, infoSecurePort=0, ipcPort=41867, storageInfo=lv=-57;cid=testClusterID;nsid=70301616;c=1674825874131), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:34,522 [BP-1038687131-127.0.1.1-1674825874131 heartbeating to localhost/127.0.0.1:34827] INFO  datanode.DataNode (BPServiceActor.java:blockReport(464)) - Successfully sent block report 0x9d58dfcc8881990f with lease ID 0x4ed03e1feb5ffe76 to namenode: localhost/127.0.0.1:34827,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msecs to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-01-27 20:24:34,523 [Command processor] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(763)) - Got finalize command for block pool BP-1038687131-127.0.1.1-1674825874131
2023-01-27 20:24:34,533 [IPC Server handler 4 on default port 34827] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:34,534 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:34,538 [IPC Server handler 6 on default port 34827] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:34,539 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:34,543 [qtp2078442172-1362] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:34 +0000] "OPTIONS /kms/v1/keys HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:34,553 [qtp2078442172-1356] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:34,554 [qtp2078442172-1356] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:34,554 [qtp2078442172-1356] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:34,554 [qtp2078442172-1356] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:34,554 [qtp2078442172-1356] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:34,555 [qtp2078442172-1356] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:34,555 [qtp2078442172-1356] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:34,555 [qtp2078442172-1356] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:34,557 [qtp2078442172-1356] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:34 +0000] "OPTIONS /kms/v1/keys?user.name=rizky HTTP/1.1" 200 520 "-" "Java/1.8.0_352"
2023-01-27 20:24:34,958 [qtp2078442172-1357] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=CREATE_KEY, key=test_key, user=rizky] UserProvidedMaterial:false Description:test_key
2023-01-27 20:24:34,959 [qtp2078442172-1357] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:34 +0000] "POST /kms/v1/keys HTTP/1.1" 201 98 "-" "Java/1.8.0_352"
2023-01-27 20:24:34,962 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2159)) - Shutting down the Mini HDFS Cluster
2023-01-27 20:24:34,962 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2208)) - Shutting down DataNode 0
2023-01-27 20:24:34,962 [Time-limited test] INFO  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(430)) - Shutdown has been called
2023-01-27 20:24:34,962 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@16c83f2d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(395)) - Closing all peers.
2023-01-27 20:24:34,963 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-2f7a0c12-7820-4911-85da-691cff57eabd) exiting.
2023-01-27 20:24:34,964 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-c04c47bb-3476-4a81-b4af-9ed9c3ffd65d) exiting.
2023-01-27 20:24:34,967 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@43afec1d{datanode,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:34,968 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@36b0a4a9{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:34,968 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:34,969 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@69a4a7db{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:34,969 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@d584dac{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:34,970 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2470)) - Waiting up to 30 seconds for transfer threads to complete
2023-01-27 20:24:34,970 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 41867
2023-01-27 20:24:34,973 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:34,974 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:34,974 [BP-1038687131-127.0.1.1-1674825874131 heartbeating to localhost/127.0.0.1:34827] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:34,974 [Command processor] ERROR datanode.DataNode (BPServiceActor.java:processQueue(1430)) - Command processor encountered interrupt and exit.
2023-01-27 20:24:34,974 [BP-1038687131-127.0.1.1-1674825874131 heartbeating to localhost/127.0.0.1:34827] WARN  datanode.DataNode (BPServiceActor.java:run(924)) - Ending block pool service for: Block pool BP-1038687131-127.0.1.1-1674825874131 (Datanode Uuid 96f38763-dfcc-4d9d-a032-dfc3d3eee204) service to localhost/127.0.0.1:34827
2023-01-27 20:24:34,974 [ibr-executor-0] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:34,975 [BP-1038687131-127.0.1.1-1674825874131 heartbeating to localhost/127.0.0.1:34827] INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-1038687131-127.0.1.1-1674825874131 (Datanode Uuid 96f38763-dfcc-4d9d-a032-dfc3d3eee204)
2023-01-27 20:24:34,974 [Command processor] WARN  datanode.DataNode (BPServiceActor.java:run(1414)) - Ending command processor service for: Thread[Command processor,5,main]
2023-01-27 20:24:34,975 [BP-1038687131-127.0.1.1-1674825874131 heartbeating to localhost/127.0.0.1:34827] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(3225)) - Removing block pool BP-1038687131-127.0.1.1-1674825874131
2023-01-27 20:24:34,976 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1038687131-127.0.1.1-1674825874131] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:34,977 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1038687131-127.0.1.1-1674825874131] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:34,978 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(208)) - Shutting down all async disk service threads
2023-01-27 20:24:34,978 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(216)) - All async disk service threads have been shut down
2023-01-27 20:24:34,979 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(186)) - Shutting down all async lazy persist service threads
2023-01-27 20:24:34,979 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(193)) - All async lazy persist service threads have been shut down
2023-01-27 20:24:34,980 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2559)) - Shutdown complete.
2023-01-27 20:24:34,980 [Time-limited test] WARN  datanode.DataSetLockManager (DataSetLockManager.java:lockLeakCheck(260)) - not open lock leak check func
2023-01-27 20:24:34,980 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2241)) - Shutting down the namenode
2023-01-27 20:24:34,980 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:34,980 [Thread[Thread-831,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:34,980 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1467)) - Ending log segment 1, 3
2023-01-27 20:24:34,980 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@f420d62] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4658)) - LazyPersistFileScrubber was interrupted, exiting
2023-01-27 20:24:34,980 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4482b6cb] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4561)) - NameNodeEditLogRoller was interrupted, exiting
2023-01-27 20:24:34,980 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(576)) - EDEKCacheLoader interrupted before warming up.
2023-01-27 20:24:34,983 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(801)) - Number of transactions: 4 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 9 4 
2023-01-27 20:24:34,983 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000004
2023-01-27 20:24:34,984 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000004
2023-01-27 20:24:34,984 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(276)) - FSEditLogAsync was interrupted, exiting
2023-01-27 20:24:34,984 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(267)) - Re-encryption updater thread interrupted. Exiting.
2023-01-27 20:24:34,984 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(335)) - Re-encrypt handler interrupted. Exiting
2023-01-27 20:24:34,984 [CacheReplicationMonitor(1436284706)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2023-01-27 20:24:34,986 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 34827
2023-01-27 20:24:34,987 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:34,988 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:34,988 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(5160)) - Stopping RedundancyMonitor.
2023-01-27 20:24:34,988 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5134)) - Stopping MarkedDeleteBlockScrubber.
2023-01-27 20:24:34,997 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:34,998 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:34,999 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@27c4ffc7{hdfs,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:35,000 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@70819afa{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:35,000 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:35,000 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1ba65261{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:35,000 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@68e0fff{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:35,008 [Thread[Thread-799,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:35,008 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextDestroyed(197)) - KMS Stopped
2023-01-27 20:24:35,009 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@550c8370{kms,/,null,STOPPED}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:35,010 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@7086ae9a{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:35,010 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:35,011 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1f18a49f{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-27 20:24:35,011 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2a01905a{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:35,012 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2023-01-27 20:24:35,013 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2023-01-27 20:24:35,013 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(612)) - DataNode metrics system shutdown complete.
2023-01-27 20:24:35,163 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:35,163 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context kms
2023-01-27 20:24:35,163 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:35,163 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:35,163 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:35,164 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 37105
2023-01-27 20:24:35,164 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:35,165 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:35,166 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:35,166 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:35,167 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@ea0c97a{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:35,167 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5d1d31a3{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-27 20:24:35,221 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(94)) - -------------------------------------------------------------
2023-01-27 20:24:35,221 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(95)) -   Java runtime version : 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:35,222 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(97)) -   User: rizky
2023-01-27 20:24:35,222 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(98)) -   KMS Hadoop Version: 3.4.0-SNAPSHOT
2023-01-27 20:24:35,222 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(99)) - -------------------------------------------------------------
2023-01-27 20:24:35,222 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'CREATE' ACL '*'
2023-01-27 20:24:35,223 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DELETE' ACL '*'
2023-01-27 20:24:35,223 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'ROLLOVER' ACL '*'
2023-01-27 20:24:35,223 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET' ACL '*'
2023-01-27 20:24:35,223 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_KEYS' ACL '*'
2023-01-27 20:24:35,223 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_METADATA' ACL '*'
2023-01-27 20:24:35,223 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'SET_KEY_MATERIAL' ACL '*'
2023-01-27 20:24:35,224 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GENERATE_EEK' ACL '*'
2023-01-27 20:24:35,224 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DECRYPT_EEK' ACL '*'
2023-01-27 20:24:35,224 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2023-01-27 20:24:35,224 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2023-01-27 20:24:35,224 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2023-01-27 20:24:35,225 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2023-01-27 20:24:35,227 [Time-limited test] INFO  server.KMSAudit (KMSAudit.java:initializeAuditLoggers(157)) - Initializing audit logger class org.apache.hadoop.crypto.key.kms.server.SimpleKMSAuditLogger
2023-01-27 20:24:35,228 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(149)) - Initialized KeyProvider CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/34c264d2-f8c1-4a60-b69a-530fbc9ad974/kms.keystore
2023-01-27 20:24:35,229 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(163)) - Initialized KeyProviderCryptoExtension org.apache.hadoop.crypto.key.kms.server.KeyAuthorizationKeyProvider: EagerKeyGeneratorKeyProviderCryptoExtension: KeyProviderCryptoExtension: CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/34c264d2-f8c1-4a60-b69a-530fbc9ad974/kms.keystore
2023-01-27 20:24:35,229 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(168)) - Default key bitlength is 128
2023-01-27 20:24:35,229 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(169)) - KMS Started
2023-01-27 20:24:35,230 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:35,231 [Thread[Thread-902,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:35,231 [Thread[Thread-902,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:35,233 [Time-limited test] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.crypto.key.kms.server
2023-01-27 20:24:35,266 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMS
2023-01-27 20:24:35,267 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
  class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
2023-01-27 20:24:35,271 [Time-limited test] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:24:35,435 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@4976004c{kms,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/2/kms/webapp/,AVAILABLE}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:35,436 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@692251e4{HTTP/1.1, (http/1.1)}{localhost:37105}
2023-01-27 20:24:35,436 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @40458ms
2023-01-27 20:24:35,438 [Time-limited test] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(120)) - Loaded properties from hadoop-metrics2.properties
2023-01-27 20:24:35,446 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 0 second(s).
2023-01-27 20:24:35,447 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - KMS metrics system started
2023-01-27 20:24:35,461 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2f17c89d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:35,475 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(566)) - starting cluster: numNameNodes=1, numDataNodes=1
2023-01-27 20:24:35,477 [Time-limited test] INFO  namenode.NameNode (NameNode.java:format(1366)) - Formatting using clusterid: testClusterID
2023-01-27 20:24:35,478 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:35,493 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@7d68c383
2023-01-27 20:24:35,494 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:35,494 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:35,494 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:35,494 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:35,494 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:35,494 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:35,494 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:35,495 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:35,495 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:35,495 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:35,496 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:35,496 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:35
2023-01-27 20:24:35,496 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:35,496 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:35,496 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:35,497 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:35,498 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:35,499 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:35,499 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:35,499 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:35,499 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:35,499 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:35,499 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:35,500 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:35,500 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:35,500 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:35,500 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:35,500 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:35,500 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:35,500 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:35,501 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:35,501 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:35,501 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:35,502 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:35,502 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:35,502 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:35,502 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:35,503 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:35,503 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:35,503 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:35,503 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:35,503 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:35,503 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:35,504 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:35,504 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:35,504 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:35,504 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:35,504 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:35,505 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:35,505 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:35,505 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:35,505 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:35,506 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:35,506 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:35,507 [Time-limited test] INFO  namenode.FSImage (FSImage.java:format(186)) - Allocated new BlockPoolId: BP-636111183-127.0.1.1-1674825875507
2023-01-27 20:24:35,510 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 has been successfully formatted.
2023-01-27 20:24:35,513 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 has been successfully formatted.
2023-01-27 20:24:35,528 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:35,535 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 496 bytes saved in 0 seconds .
2023-01-27 20:24:35,535 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:35,543 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 496 bytes saved in 0 seconds .
2023-01-27 20:24:35,545 [Time-limited test] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(202)) - Going to retain 1 images with txid >= 0
2023-01-27 20:24:35,556 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:35,556 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:35,557 [Time-limited test] INFO  namenode.NameNode (NameNode.java:createNameNode(1824)) - createNameNode []
2023-01-27 20:24:35,557 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2023-01-27 20:24:35,558 [Time-limited test] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2023-01-27 20:24:35,574 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@54a20f5f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:35,574 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1736)) - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2023-01-27 20:24:35,575 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1758)) - Starting Web-server for hdfs at: http://localhost:0
2023-01-27 20:24:35,575 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:35,577 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:35,579 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:35,581 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:35,582 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-01-27 20:24:35,582 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:35,582 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:35,584 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2023-01-27 20:24:35,584 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2023-01-27 20:24:35,584 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2023-01-27 20:24:35,584 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:35,585 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(1018)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-01-27 20:24:35,585 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 40787
2023-01-27 20:24:35,585 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:35,608 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:35,608 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:35,608 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:35,610 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:35,610 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5d98eec9{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:35,611 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1a99aa4d{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:35,615 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@145c34ab{hdfs,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:35,617 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@12312384{HTTP/1.1, (http/1.1)}{localhost:40787}
2023-01-27 20:24:35,617 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @40640ms
2023-01-27 20:24:35,619 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:35,638 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@125cc413
2023-01-27 20:24:35,639 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:35,639 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:35,639 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:35,639 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:35,639 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:35,639 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:35,640 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:35,640 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:35,640 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:35,641 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:35,641 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:35,641 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:35
2023-01-27 20:24:35,641 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:35,641 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:35,642 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:35,642 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:35,643 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:35,644 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:35,644 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:35,644 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:35,644 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:35,644 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:35,644 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:35,644 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:35,645 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:35,645 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:35,645 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:35,645 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:35,645 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:35,645 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:35,646 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:35,646 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:35,646 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:35,647 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:35,647 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:35,647 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:35,647 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:35,648 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:35,648 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:35,648 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:35,648 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:35,648 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:35,648 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:35,649 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:35,649 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:35,649 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:35,649 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:35,649 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:35,650 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:35,650 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:35,650 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:35,650 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:35,650 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:35,650 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:35,662 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:35,672 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:35,673 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current
2023-01-27 20:24:35,674 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current
2023-01-27 20:24:35,674 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(734)) - No edit log streams selected.
2023-01-27 20:24:35,674 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(800)) - Planning to load image: FSImageFile(file=/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-01-27 20:24:35,684 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSectionHeader(411)) - Loading 1 INodes.
2023-01-27 20:24:35,684 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(369)) - Successfully loaded 1 inodes
2023-01-27 20:24:35,685 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:waitBlocksMapAndNameCacheUpdateFinished(342)) - Completed update blocks map and name cache, total waiting duration 0ms.
2023-01-27 20:24:35,686 [Time-limited test] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(255)) - Loaded FSImage in 0 seconds.
2023-01-27 20:24:35,686 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(980)) - Loaded image for txid 0 from /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000
2023-01-27 20:24:35,686 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1271)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-01-27 20:24:35,687 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1417)) - Starting log segment at 1
2023-01-27 20:24:35,730 [Time-limited test] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2023-01-27 20:24:35,730 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(836)) - Finished loading FSImage in 79 msecs
2023-01-27 20:24:35,731 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(451)) - RPC server is binding to localhost:0
2023-01-27 20:24:35,731 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(456)) - Enable NameNode state context:false
2023-01-27 20:24:35,731 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:35,732 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:46811
2023-01-27 20:24:35,732 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:35,736 [Time-limited test] INFO  namenode.NameNode (NameNode.java:initialize(893)) - Clients are to use localhost:46811 to access this namenode/service.
2023-01-27 20:24:35,736 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5607)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2023-01-27 20:24:35,763 [Time-limited test] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(166)) - Number of blocks under construction: 0
2023-01-27 20:24:35,764 [Time-limited test] INFO  blockmanagement.DatanodeAdminDefaultMonitor (DatanodeAdminDefaultMonitor.java:processConf(126)) - Initialized the Default Decommission and Maintenance monitor
2023-01-27 20:24:35,783 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5102)) - Start MarkedDeleteBlockScrubber thread
2023-01-27 20:24:35,783 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(5310)) - initializing replication queues
2023-01-27 20:24:35,784 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(409)) - STATE* Leaving safe mode after 0 secs
2023-01-27 20:24:35,784 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(415)) - STATE* Network topology has 0 racks and 0 datanodes
2023-01-27 20:24:35,784 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(417)) - STATE* UnderReplicatedBlocks has 0 blocks
2023-01-27 20:24:35,785 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:35,815 [Thread[Thread-934,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:35,816 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3870)) - Total number of blocks            = 0
2023-01-27 20:24:35,816 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3871)) - Number of invalid blocks          = 0
2023-01-27 20:24:35,816 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3872)) - Number of under-replicated blocks = 0
2023-01-27 20:24:35,816 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3873)) - Number of  over-replicated blocks = 0
2023-01-27 20:24:35,816 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3875)) - Number of blocks being written    = 0
2023-01-27 20:24:35,816 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3878)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 29 msec
2023-01-27 20:24:35,818 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:35,845 [Thread[Thread-934,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:35,847 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:35,886 [Time-limited test] INFO  namenode.NameNode (NameNode.java:startCommonServices(1010)) - NameNode RPC up at: localhost/127.0.0.1:46811
2023-01-27 20:24:35,898 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1383)) - Starting services required for active state
2023-01-27 20:24:35,898 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(857)) - Initializing quota with 12 thread(s)
2023-01-27 20:24:35,899 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(866)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2023-01-27 20:24:35,904 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(326)) - Starting up re-encrypt thread with interval=60000 millisecond.
2023-01-27 20:24:35,910 [CacheReplicationMonitor(155972635)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-01-27 20:24:35,910 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2023-01-27 20:24:35,913 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1769)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1,[DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:35,914 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:35,924 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:35,965 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2023-01-27 20:24:35,965 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:35,965 [Time-limited test] INFO  datanode.BlockScanner (BlockScanner.java:<init>(201)) - Initialized block scanner with targetBytesPerSec 1048576
2023-01-27 20:24:35,966 [Time-limited test] INFO  datanode.DataNode (DataNode.java:<init>(571)) - Configured hostname is 127.0.0.1
2023-01-27 20:24:35,966 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:35,966 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1788)) - Starting DataNode with maxLockedMemory = 0
2023-01-27 20:24:35,967 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1551)) - Opened streaming server at /127.0.0.1:42273
2023-01-27 20:24:35,967 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(93)) - Balancing bandwidth is 104857600 bytes/s
2023-01-27 20:24:35,967 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(94)) - Number threads for balancing is 100
2023-01-27 20:24:35,968 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:35,969 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:35,971 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:35,973 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:35,973 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-01-27 20:24:35,973 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:35,973 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:35,973 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:35,974 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 40605
2023-01-27 20:24:35,974 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:35,975 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:35,975 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:35,975 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:24:35,976 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@23fe8db8{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:35,976 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7b9ca72f{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:35,979 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@9a90a4e{datanode,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:35,979 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@39dad963{HTTP/1.1, (http/1.1)}{localhost:40605}
2023-01-27 20:24:35,980 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @41002ms
2023-01-27 20:24:35,982 [Time-limited test] WARN  web.DatanodeHttpServer (RestCsrfPreventionFilterHandler.java:<init>(75)) - Got null for restCsrfPreventionFilter - will not do any filtering.
2023-01-27 20:24:35,983 [Time-limited test] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(306)) - Listening HTTP traffic on /127.0.0.1:34527
2023-01-27 20:24:35,984 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1816)) - dnUserName = rizky
2023-01-27 20:24:35,984 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2f015af5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:35,984 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1817)) - supergroup = supergroup
2023-01-27 20:24:35,985 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:35,985 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:35339
2023-01-27 20:24:35,985 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:35,988 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initIpcServer(1438)) - Opened IPC server at /127.0.0.1:35339
2023-01-27 20:24:36,001 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(150)) - Refresh request received for nameservices: null
2023-01-27 20:24:36,001 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(211)) - Starting BPOfferServices for nameservices: <default>
2023-01-27 20:24:36,002 [Thread-967] INFO  datanode.DataNode (BPServiceActor.java:run(877)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46811 starting to offer service
2023-01-27 20:24:36,008 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:36,008 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:36,039 [Thread-967] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(382)) - Acknowledging ACTIVE Namenode during handshake Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46811
2023-01-27 20:24:36,041 [Thread-967] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(356)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2023-01-27 20:24:36,043 [Thread-967] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:36,043 [Thread-967] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 is not formatted for namespace 764967838. Formatting...
2023-01-27 20:24:36,044 [Thread-967] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-44a7dca2-3c19-4989-92df-2a30a54c1635 for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 
2023-01-27 20:24:36,048 [IPC Server handler 1 on default port 46811] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:36,049 [Thread-967] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:36,049 [Thread-967] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 is not formatted for namespace 764967838. Formatting...
2023-01-27 20:24:36,049 [Thread-967] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3211f305-2045-4346-be52-5062b8c4d03b for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 
2023-01-27 20:24:36,049 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:36,050 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:36,079 [Thread-967] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-636111183-127.0.1.1-1674825875507
2023-01-27 20:24:36,079 [Thread-967] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-636111183-127.0.1.1-1674825875507
2023-01-27 20:24:36,079 [Thread-967] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 and block pool id BP-636111183-127.0.1.1-1674825875507 is not formatted. Formatting ...
2023-01-27 20:24:36,080 [Thread-967] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-636111183-127.0.1.1-1674825875507 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-636111183-127.0.1.1-1674825875507/current
2023-01-27 20:24:36,097 [Thread-967] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-636111183-127.0.1.1-1674825875507
2023-01-27 20:24:36,097 [Thread-967] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-636111183-127.0.1.1-1674825875507
2023-01-27 20:24:36,098 [Thread-967] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 and block pool id BP-636111183-127.0.1.1-1674825875507 is not formatted. Formatting ...
2023-01-27 20:24:36,098 [Thread-967] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-636111183-127.0.1.1-1674825875507 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-636111183-127.0.1.1-1674825875507/current
2023-01-27 20:24:36,100 [Thread-967] INFO  datanode.DataNode (DataNode.java:initStorage(2136)) - Setting up storage: nsid=764967838;bpid=BP-636111183-127.0.1.1-1674825875507;lv=-57;nsInfo=lv=-67;cid=testClusterID;nsid=764967838;c=1674825875507;bpid=BP-636111183-127.0.1.1-1674825875507;dnuuid=null
2023-01-27 20:24:36,106 [Thread-967] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1934)) - Generated and persisted new Datanode UUID 0af554cc-136c-4ab9-b467-a017132eb0c8
2023-01-27 20:24:36,106 [Thread-967] INFO  fsdataset.RoundRobinVolumeChoosingPolicy (RoundRobinVolumeChoosingPolicy.java:setConf(67)) - Round robin volume choosing policy initialized: dfs.datanode.round-robin-volume-choosing-policy.additional-available-space = 0
2023-01-27 20:24:36,108 [Thread-967] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-44a7dca2-3c19-4989-92df-2a30a54c1635
2023-01-27 20:24:36,108 [Thread-967] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, StorageType: DISK
2023-01-27 20:24:36,113 [Thread-967] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-3211f305-2045-4346-be52-5062b8c4d03b
2023-01-27 20:24:36,113 [Thread-967] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, StorageType: DISK
2023-01-27 20:24:36,113 [Thread-967] INFO  impl.MemoryMappableBlockLoader (MemoryMappableBlockLoader.java:initialize(47)) - Initializing cache loader: MemoryMappableBlockLoader.
2023-01-27 20:24:36,114 [Thread-967] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2611)) - Registered FSDatasetState MBean
2023-01-27 20:24:36,115 [Thread-967] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(3188)) - Adding block pool BP-636111183-127.0.1.1-1674825875507
2023-01-27 20:24:36,116 [Thread-984] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-636111183-127.0.1.1-1674825875507 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:36,117 [Thread-984] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-636111183-127.0.1.1-1674825875507/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:36,118 [Thread-985] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-636111183-127.0.1.1-1674825875507 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:36,118 [Thread-985] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-636111183-127.0.1.1-1674825875507/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:36,138 [Thread-984] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-636111183-127.0.1.1-1674825875507 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 22ms
2023-01-27 20:24:36,138 [Thread-985] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-636111183-127.0.1.1-1674825875507 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 20ms
2023-01-27 20:24:36,139 [Thread-967] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(538)) - Total time to scan all replicas for block pool BP-636111183-127.0.1.1-1674825875507: 24ms
2023-01-27 20:24:36,139 [Thread-988] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-636111183-127.0.1.1-1674825875507 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:36,139 [Thread-989] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-636111183-127.0.1.1-1674825875507 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:36,140 [Thread-988] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-636111183-127.0.1.1-1674825875507/current/replicas doesn't exist 
2023-01-27 20:24:36,140 [Thread-989] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-636111183-127.0.1.1-1674825875507/current/replicas doesn't exist 
2023-01-27 20:24:36,140 [Thread-988] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-636111183-127.0.1.1-1674825875507 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 1ms
2023-01-27 20:24:36,140 [Thread-989] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-636111183-127.0.1.1-1674825875507 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 1ms
2023-01-27 20:24:36,140 [Thread-967] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(292)) - Total time to add all replicas to map for block pool BP-636111183-127.0.1.1-1674825875507: 1ms
2023-01-27 20:24:36,140 [Thread-967] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:36,141 [Thread-967] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:36,141 [Thread-967] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:36,141 [Thread-967] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:36,142 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-636111183-127.0.1.1-1674825875507 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:36,142 [Thread-967] WARN  datanode.DirectoryScanner (DirectoryScanner.java:<init>(302)) - dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2023-01-27 20:24:36,142 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-636111183-127.0.1.1-1674825875507 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:36,143 [Thread-967] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(367)) - Periodic Directory Tree Verification scan starting in 3586994ms with interval of 21600000ms and throttle limit of -1ms/s
2023-01-27 20:24:36,143 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-3211f305-2045-4346-be52-5062b8c4d03b): finished scanning block pool BP-636111183-127.0.1.1-1674825875507
2023-01-27 20:24:36,143 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-44a7dca2-3c19-4989-92df-2a30a54c1635): finished scanning block pool BP-636111183-127.0.1.1-1674825875507
2023-01-27 20:24:36,143 [BP-636111183-127.0.1.1-1674825875507 heartbeating to localhost/127.0.0.1:46811] INFO  datanode.DataNode (BPServiceActor.java:register(819)) - Block pool BP-636111183-127.0.1.1-1674825875507 (Datanode Uuid 0af554cc-136c-4ab9-b467-a017132eb0c8) service to localhost/127.0.0.1:46811 beginning handshake with NN: localhost/127.0.0.1:46811.
2023-01-27 20:24:36,144 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-44a7dca2-3c19-4989-92df-2a30a54c1635): no suitable block pools found to scan.  Waiting 1814399998 ms.
2023-01-27 20:24:36,145 [IPC Server handler 2 on default port 46811] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1166)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42273, datanodeUuid=0af554cc-136c-4ab9-b467-a017132eb0c8, infoPort=34527, infoSecurePort=0, ipcPort=35339, storageInfo=lv=-57;cid=testClusterID;nsid=764967838;c=1674825875507) storage 0af554cc-136c-4ab9-b467-a017132eb0c8
2023-01-27 20:24:36,145 [IPC Server handler 2 on default port 46811] INFO  net.NetworkTopology (NetworkTopology.java:add(156)) - Adding a new node: /default-rack/127.0.0.1:42273
2023-01-27 20:24:36,145 [IPC Server handler 2 on default port 46811] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(200)) - Registered DN 0af554cc-136c-4ab9-b467-a017132eb0c8 (127.0.0.1:42273).
2023-01-27 20:24:36,146 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-3211f305-2045-4346-be52-5062b8c4d03b): no suitable block pools found to scan.  Waiting 1814399996 ms.
2023-01-27 20:24:36,149 [BP-636111183-127.0.1.1-1674825875507 heartbeating to localhost/127.0.0.1:46811] INFO  datanode.DataNode (BPServiceActor.java:register(846)) - Block pool BP-636111183-127.0.1.1-1674825875507 (Datanode Uuid 0af554cc-136c-4ab9-b467-a017132eb0c8) service to localhost/127.0.0.1:46811 successfully registered with NN: localhost/127.0.0.1:46811.
2023-01-27 20:24:36,149 [BP-636111183-127.0.1.1-1674825875507 heartbeating to localhost/127.0.0.1:46811] INFO  datanode.DataNode (BPServiceActor.java:offerService(680)) - For namenode localhost/127.0.0.1:46811 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2023-01-27 20:24:36,149 [ibr-executor-0] INFO  datanode.DataNode (BPServiceActor.java:run(1145)) - Starting IBR Task Handler.
2023-01-27 20:24:36,152 [IPC Server handler 3 on default port 46811] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-44a7dca2-3c19-4989-92df-2a30a54c1635 for DN 127.0.0.1:42273
2023-01-27 20:24:36,152 [IPC Server handler 3 on default port 46811] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-3211f305-2045-4346-be52-5062b8c4d03b for DN 127.0.0.1:42273
2023-01-27 20:24:36,152 [IPC Server handler 6 on default port 46811] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:36,154 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2922)) - No heartbeat from DataNode: 127.0.0.1:42273
2023-01-27 20:24:36,154 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:36,154 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0x924cd5ce6cf1c490 with lease ID 0x7ebce6a420c27e38: Processing first storage report for DS-3211f305-2045-4346-be52-5062b8c4d03b from datanode DatanodeRegistration(127.0.0.1:42273, datanodeUuid=0af554cc-136c-4ab9-b467-a017132eb0c8, infoPort=34527, infoSecurePort=0, ipcPort=35339, storageInfo=lv=-57;cid=testClusterID;nsid=764967838;c=1674825875507)
2023-01-27 20:24:36,155 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0x924cd5ce6cf1c490 with lease ID 0x7ebce6a420c27e38: from storage DS-3211f305-2045-4346-be52-5062b8c4d03b node DatanodeRegistration(127.0.0.1:42273, datanodeUuid=0af554cc-136c-4ab9-b467-a017132eb0c8, infoPort=34527, infoSecurePort=0, ipcPort=35339, storageInfo=lv=-57;cid=testClusterID;nsid=764967838;c=1674825875507), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:36,155 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0x924cd5ce6cf1c490 with lease ID 0x7ebce6a420c27e38: Processing first storage report for DS-44a7dca2-3c19-4989-92df-2a30a54c1635 from datanode DatanodeRegistration(127.0.0.1:42273, datanodeUuid=0af554cc-136c-4ab9-b467-a017132eb0c8, infoPort=34527, infoSecurePort=0, ipcPort=35339, storageInfo=lv=-57;cid=testClusterID;nsid=764967838;c=1674825875507)
2023-01-27 20:24:36,155 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0x924cd5ce6cf1c490 with lease ID 0x7ebce6a420c27e38: from storage DS-44a7dca2-3c19-4989-92df-2a30a54c1635 node DatanodeRegistration(127.0.0.1:42273, datanodeUuid=0af554cc-136c-4ab9-b467-a017132eb0c8, infoPort=34527, infoSecurePort=0, ipcPort=35339, storageInfo=lv=-57;cid=testClusterID;nsid=764967838;c=1674825875507), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:36,155 [BP-636111183-127.0.1.1-1674825875507 heartbeating to localhost/127.0.0.1:46811] INFO  datanode.DataNode (BPServiceActor.java:blockReport(464)) - Successfully sent block report 0x924cd5ce6cf1c490 with lease ID 0x7ebce6a420c27e38 to namenode: localhost/127.0.0.1:46811,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msecs to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-01-27 20:24:36,156 [Command processor] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(763)) - Got finalize command for block pool BP-636111183-127.0.1.1-1674825875507
2023-01-27 20:24:36,255 [IPC Server handler 4 on default port 46811] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:36,256 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:36,259 [IPC Server handler 8 on default port 46811] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:36,260 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:36,265 [qtp5768233-1535] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:36 +0000] "OPTIONS /kms/v1/keys HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:36,281 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:36,282 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:36,282 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:36,282 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:36,282 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:36,283 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:36,283 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:36,283 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:36,285 [qtp5768233-1529] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:36 +0000] "OPTIONS /kms/v1/keys?user.name=rizky HTTP/1.1" 200 520 "-" "Java/1.8.0_352"
2023-01-27 20:24:36,708 [qtp5768233-1530] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=CREATE_KEY, key=test_key, user=rizky] UserProvidedMaterial:false Description:test_key
2023-01-27 20:24:36,712 [qtp5768233-1530] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:36 +0000] "POST /kms/v1/keys HTTP/1.1" 201 98 "-" "Java/1.8.0_352"
2023-01-27 20:24:36,713 [IPC Server handler 7 on default port 46811] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2023-01-27 20:24:36,715 [IPC Server handler 9 on default port 46811] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/TestEncryptionZone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:36,724 [qtp5768233-1534] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=GET_METADATA, key=test_key, user=rizky] 
2023-01-27 20:24:36,730 [qtp5768233-1534] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:36 +0000] "GET /kms/v1/key/test_key/_metadata HTTP/1.1" 200 210 "-" "Java/1.8.0_352"
2023-01-27 20:24:36,929 [qtp5768233-1529] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditEvent(59)) - OK[op=GENERATE_EEK, key=test_key, user=rizky, accessCount=1, interval=0ms] 
2023-01-27 20:24:36,932 [qtp5768233-1529] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:36 +0000] "GET /kms/v1/key/test_key/_eek?num_keys=150&eek_op=generate HTTP/1.1" 200 29702 "-" "Java/1.8.0_352"
2023-01-27 20:24:36,935 [IPC Server handler 0 on default port 46811] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=createEncryptionZone	src=/TestEncryptionZone	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:24:36,938 [IPC Server handler 1 on default port 46811] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/TestEncryptionZone/foo	dst=null	perm=null	proto=rpc
2023-01-27 20:24:36,940 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:36,940 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:36,940 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:36,941 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:36,941 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:36,941 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:36,941 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2776)
2023-01-27 20:24:36,941 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:36,941 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:36,941 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:36,941 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:36,941 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:36,941 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:36,941 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:36,941 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:36,942 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:36,942 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:36,942 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:36,942 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:36,942 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:36,942 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:36,942 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:36,942 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:36,942 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:36,942 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:36,942 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:36,942 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:36,943 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:36,943 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2776)
2023-01-27 20:24:36,943 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:36,943 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:36,943 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:36,943 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:36,943 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:36,943 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:36,943 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:36,943 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:36,943 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:36,943 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:36,944 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:36,944 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:36,944 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:36,944 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:36,947 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:36,947 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:36,948 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:36,948 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:36,948 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:36,948 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:36,948 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:564)
2023-01-27 20:24:36,948 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:36,948 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:36,948 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:36,948 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:36,948 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:36,948 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:36,948 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:36,949 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:36,949 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:36,949 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:36,949 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:36,949 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:36,949 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:36,949 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:36,949 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:36,950 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:36,950 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:36,950 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:36,950 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:36,950 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:36,950 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicyForPath(FSDirErasureCodingOp.java:472)
2023-01-27 20:24:36,950 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(FSDirErasureCodingOp.java:421)
2023-01-27 20:24:36,950 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.getErasureCodingPolicy(FSDirErasureCodingOp.java:402)
2023-01-27 20:24:36,951 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:564)
2023-01-27 20:24:36,951 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:36,951 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:36,951 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:36,951 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:36,951 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:36,951 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:36,951 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:36,951 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:36,951 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:36,951 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:36,951 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:36,952 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:36,952 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:36,952 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:36,952 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:36,952 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:36,952 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:36,952 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:36,952 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:36,952 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:36,952 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:36,953 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1386)
2023-01-27 20:24:36,953 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1201)
2023-01-27 20:24:36,953 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:579)
2023-01-27 20:24:36,953 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:36,953 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:36,953 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:36,953 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:36,953 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:36,953 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:36,953 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:36,953 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:36,953 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:36,954 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:36,954 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:36,954 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:36,954 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:36,954 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:36,954 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:36,954 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:36,954 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:36,954 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:36,954 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:36,954 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:36,955 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:36,955 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:36,955 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1386)
2023-01-27 20:24:36,955 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1201)
2023-01-27 20:24:36,955 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:579)
2023-01-27 20:24:36,955 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)
2023-01-27 20:24:36,955 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:36,956 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:36,956 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:36,956 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:36,956 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:36,956 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:36,956 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:36,956 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:36,956 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:36,956 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:36,956 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:36,956 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:36,956 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:36,957 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:36,957 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:36,964 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:36,964 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:36,964 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:36,964 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:36,964 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:36,964 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:36,964 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.setNewINodeStoragePolicy(FSDirWriteFileOp.java:823)
2023-01-27 20:24:36,964 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:413)
2023-01-27 20:24:36,964 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:36,965 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:36,965 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:36,965 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:36,965 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:36,965 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:36,965 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:36,965 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:36,965 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:36,965 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:36,965 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:36,966 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:36,966 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:36,966 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:36,966 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:36,966 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:36,966 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:36,966 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:36,967 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:36,967 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:36,967 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:36,967 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:36,967 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.setNewINodeStoragePolicy(FSDirWriteFileOp.java:823)
2023-01-27 20:24:36,971 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:413)
2023-01-27 20:24:36,971 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:36,972 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:36,972 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:36,972 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:36,972 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:36,972 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:36,972 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:36,972 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:36,972 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:36,972 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:36,972 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:36,972 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:36,974 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:36,974 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:36,974 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:36,975 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:36,975 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:36,975 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:36,975 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:36,975 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:36,976 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:36,976 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:347)
2023-01-27 20:24:36,976 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:36,976 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:36,976 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:36,976 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:36,976 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:36,976 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:36,976 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:36,976 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:36,977 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:36,977 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:36,977 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:36,977 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:36,977 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:36,977 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:36,977 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:36,977 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:36,977 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:36,977 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:36,977 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:36,978 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:36,978 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:36,978 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:36,978 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:36,978 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:36,978 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:347)
2023-01-27 20:24:36,978 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:36,978 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:36,978 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:36,978 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:36,979 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:36,979 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:36,979 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:36,979 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:36,979 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:36,979 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:36,979 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:36,979 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:36,979 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:36,979 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:36,979 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:36,980 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:36,980 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:36,980 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:36,980 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:36,980 [qtp5768233-1534] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:36 +0000] "GET /kms/v1/key/test_key/_eek?num_keys=351&eek_op=generate HTTP/1.1" 200 69500 "-" "Java/1.8.0_352"
2023-01-27 20:24:36,980 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:36,980 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:36,980 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:36,981 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:36,981 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.createFileStatus(FSDirStatAndListingOp.java:434)
2023-01-27 20:24:36,981 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:349)
2023-01-27 20:24:36,981 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:36,981 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:36,981 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:36,981 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:36,981 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:36,981 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:36,981 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:36,981 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:36,982 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:36,982 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:36,982 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:36,982 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:36,982 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:36,982 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:36,982 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:36,982 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:36,982 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:36,982 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:36,983 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:36,983 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:36,983 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:36,983 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:36,983 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:36,983 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:36,983 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.createFileStatus(FSDirStatAndListingOp.java:434)
2023-01-27 20:24:36,983 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:349)
2023-01-27 20:24:36,983 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:36,984 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:419)
2023-01-27 20:24:36,984 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2809)
2023-01-27 20:24:36,984 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2703)
2023-01-27 20:24:36,984 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:829)
2023-01-27 20:24:36,984 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:502)
2023-01-27 20:24:36,984 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:36,984 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:36,984 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:36,984 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:36,984 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:36,984 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:36,985 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:36,985 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:36,985 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:36,985 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:36,985 [IPC Server handler 2 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:36,985 [IPC Server handler 2 on default port 46811] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestEncryptionZone/foo	dst=null	perm=rizky:supergroup:rw-r--r--	proto=rpc
2023-01-27 20:24:36,997 [qtp5768233-1529] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:36 +0000] "OPTIONS /kms/v1/keyversion/test_key%400/_eek?eek_op=decrypt HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:37,003 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:37,004 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:37,004 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:37,004 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:37,004 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:37,005 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:37,005 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:37,005 [qtp5768233-1529] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:37,007 [qtp5768233-1529] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:36 +0000] "OPTIONS /kms/v1/keyversion/test_key%400/_eek?eek_op=decrypt&user.name=rizky HTTP/1.1" 200 639 "-" "Java/1.8.0_352"
2023-01-27 20:24:37,199 [qtp5768233-1531] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditEvent(59)) - OK[op=DECRYPT_EEK, key=test_key, user=rizky, accessCount=1, interval=0ms] 
2023-01-27 20:24:37,200 [qtp5768233-1531] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:37 +0000] "POST /kms/v1/keyversion/test_key%400/_eek?eek_op=decrypt HTTP/1.1" 200 90 "-" "Java/1.8.0_352"
2023-01-27 20:24:37,203 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:37,203 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.validateAddBlock(FSDirWriteFileOp.java:202)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3053)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:931)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:601)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:37,204 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.validateAddBlock(FSDirWriteFileOp.java:202)
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3053)
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:931)
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:601)
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:37,205 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:37,206 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:37,206 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:37,206 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:37,206 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:37,206 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:37,206 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:37,206 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:37,206 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:37,206 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:37,207 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:37,207 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:37,207 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:37,207 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:37,207 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:1026)
2023-01-27 20:24:37,207 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
2023-01-27 20:24:37,207 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:783)
2023-01-27 20:24:37,207 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:259)
2023-01-27 20:24:37,207 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3073)
2023-01-27 20:24:37,207 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:931)
2023-01-27 20:24:37,207 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:601)
2023-01-27 20:24:37,207 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:37,207 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:37,207 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:37,208 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:1026)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addBlock(FSDirWriteFileOp.java:513)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.saveAllocatedBlock(FSDirWriteFileOp.java:783)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.storeAllocatedBlock(FSDirWriteFileOp.java:259)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3073)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:931)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:601)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:37,209 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:37,210 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:37,210 [IPC Server handler 4 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:37,210 [IPC Server handler 4 on default port 46811] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(802)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:42273 for /TestEncryptionZone/foo
2023-01-27 20:24:37,213 [DataXceiver for client DFSClient_NONMAPREDUCE_1578715187_1526 at /127.0.0.1:56488 [Receiving block BP-636111183-127.0.1.1-1674825875507:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(751)) - Receiving BP-636111183-127.0.1.1-1674825875507:blk_1073741825_1001 src: /127.0.0.1:56488 dest: /127.0.0.1:42273
2023-01-27 20:24:37,219 [PacketResponder: BP-636111183-127.0.1.1-1674825875507:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1571)) - src: /127.0.0.1:56488, dest: /127.0.0.1:42273, volume: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, bytes: 11, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1578715187_1526, offset: 0, srvID: 0af554cc-136c-4ab9-b467-a017132eb0c8, blockid: BP-636111183-127.0.1.1-1674825875507:blk_1073741825_1001, duration(ns): 2950404
2023-01-27 20:24:37,219 [PacketResponder: BP-636111183-127.0.1.1-1674825875507:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1544)) - PacketResponder: BP-636111183-127.0.1.1-1674825875507:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2023-01-27 20:24:37,221 [Block report processor] INFO  BlockStateChange (BlockManager.java:addStoredBlock(3635)) - BLOCK* addStoredBlock: 127.0.0.1:42273 is added to blk_1073741825_1001 (size=11)
2023-01-27 20:24:37,222 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:37,222 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:37,223 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:37,223 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:37,223 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:37,223 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:37,223 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:1026)
2023-01-27 20:24:37,223 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateSpaceConsumed(FSDirectory.java:983)
2023-01-27 20:24:37,223 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateSpaceForCompleteBlock(FSDirectory.java:1141)
2023-01-27 20:24:37,223 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.convertToCompleteBlock(BlockManager.java:1302)
2023-01-27 20:24:37,223 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.completeBlock(BlockManager.java:1274)
2023-01-27 20:24:37,224 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.commitOrCompleteLastBlock(BlockManager.java:1207)
2023-01-27 20:24:37,224 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.commitOrCompleteLastBlock(FSNamesystem.java:3862)
2023-01-27 20:24:37,224 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.completeFileInternal(FSDirWriteFileOp.java:732)
2023-01-27 20:24:37,224 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.completeFile(FSDirWriteFileOp.java:690)
2023-01-27 20:24:37,224 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3222)
2023-01-27 20:24:37,224 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:982)
2023-01-27 20:24:37,224 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:647)
2023-01-27 20:24:37,224 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:37,224 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:37,224 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:37,225 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:37,225 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:37,225 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:37,225 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:37,225 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:37,225 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:37,225 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:37,225 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:37,225 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:37,225 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:37,226 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:37,226 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:37,226 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:37,226 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:37,226 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:37,226 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount(FSDirectory.java:1026)
2023-01-27 20:24:37,226 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateSpaceConsumed(FSDirectory.java:983)
2023-01-27 20:24:37,226 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateSpaceForCompleteBlock(FSDirectory.java:1141)
2023-01-27 20:24:37,226 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.convertToCompleteBlock(BlockManager.java:1302)
2023-01-27 20:24:37,226 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.completeBlock(BlockManager.java:1274)
2023-01-27 20:24:37,227 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.commitOrCompleteLastBlock(BlockManager.java:1207)
2023-01-27 20:24:37,227 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.commitOrCompleteLastBlock(FSNamesystem.java:3862)
2023-01-27 20:24:37,227 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.completeFileInternal(FSDirWriteFileOp.java:732)
2023-01-27 20:24:37,227 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.completeFile(FSDirWriteFileOp.java:690)
2023-01-27 20:24:37,227 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3222)
2023-01-27 20:24:37,227 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:982)
2023-01-27 20:24:37,227 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:647)
2023-01-27 20:24:37,227 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:37,227 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:37,227 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:37,228 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:37,228 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:37,228 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:37,228 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:37,228 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:37,228 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:37,228 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:37,228 [IPC Server handler 7 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:37,229 [IPC Server handler 7 on default port 46811] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(3229)) - DIR* completeFile: /TestEncryptionZone/foo is closed by DFSClient_NONMAPREDUCE_1578715187_1526
2023-01-27 20:24:37,234 [qtp968267706-1561] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.namenode.web.resources
  org.apache.hadoop.hdfs.web.resources
2023-01-27 20:24:37,463 [qtp968267706-1561] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods
2023-01-27 20:24:37,464 [qtp968267706-1561] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
  class org.apache.hadoop.hdfs.web.resources.UserProvider
2023-01-27 20:24:37,466 [qtp968267706-1561] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:24:37,599 [qtp968267706-1561] WARN  inject.Errors (Errors.java:processErrorMessages(173)) - The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam,org.apache.hadoop.hdfs.web.resources.NameSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageTypeParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.SnapshotDiffStartPathParam,org.apache.hadoop.hdfs.web.resources.SnapshotDiffIndexParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2023-01-27 20:24:37,604 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:37,604 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:37,604 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:37,604 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:37,604 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:37,604 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:37,604 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:347)
2023-01-27 20:24:37,604 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:115)
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3462)
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1228)
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.redirectURI(NamenodeWebHdfsMethods.java:414)
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1182)
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1133)
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1130)
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:78)
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:30)
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:37,605 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getLocalStoragePolicyID(INodeDirectory.java:125)
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getStoragePolicyID(INodeDirectory.java:135)
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.getStoragePolicyID(INodeFile.java:594)
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:347)
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:115)
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3462)
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1228)
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.redirectURI(NamenodeWebHdfsMethods.java:414)
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1182)
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1133)
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1130)
2023-01-27 20:24:37,606 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:78)
2023-01-27 20:24:37,607 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:30)
2023-01-27 20:24:37,607 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:37,607 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:37,607 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:37,607 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:37,607 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:37,607 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:37,607 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:37,607 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:37,607 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:37,607 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:37,607 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.createFileStatus(FSDirStatAndListingOp.java:434)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:349)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:115)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3462)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1228)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.redirectURI(NamenodeWebHdfsMethods.java:414)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1182)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1133)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1130)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:78)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:30)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:37,608 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:37,609 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:37,609 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:37,609 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:37,609 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:37,609 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:37,609 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.createFileStatus(FSDirStatAndListingOp.java:434)
2023-01-27 20:24:37,609 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:349)
2023-01-27 20:24:37,609 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:368)
2023-01-27 20:24:37,609 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:115)
2023-01-27 20:24:37,609 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3462)
2023-01-27 20:24:37,609 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1228)
2023-01-27 20:24:37,609 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.redirectURI(NamenodeWebHdfsMethods.java:414)
2023-01-27 20:24:37,609 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1182)
2023-01-27 20:24:37,610 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1133)
2023-01-27 20:24:37,610 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1130)
2023-01-27 20:24:37,610 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:78)
2023-01-27 20:24:37,610 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:30)
2023-01-27 20:24:37,610 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:37,610 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:37,611 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:37,611 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:37,612 [IPC Server handler 9 on default port 46811] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=dr.who (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/TestEncryptionZone/foo	dst=null	perm=null	proto=webhdfs
2023-01-27 20:24:37,613 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:37,613 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:37,613 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:37,613 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:37,613 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:37,613 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:37,613 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:178)
2023-01-27 20:24:37,613 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2188)
2023-01-27 20:24:37,613 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:794)
2023-01-27 20:24:37,613 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.chooseDatanode(NamenodeWebHdfsMethods.java:337)
2023-01-27 20:24:37,613 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.redirectURI(NamenodeWebHdfsMethods.java:416)
2023-01-27 20:24:37,613 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1182)
2023-01-27 20:24:37,613 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1133)
2023-01-27 20:24:37,613 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1130)
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:78)
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:30)
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:178)
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2188)
2023-01-27 20:24:37,614 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:794)
2023-01-27 20:24:37,615 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.chooseDatanode(NamenodeWebHdfsMethods.java:337)
2023-01-27 20:24:37,615 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.redirectURI(NamenodeWebHdfsMethods.java:416)
2023-01-27 20:24:37,615 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1182)
2023-01-27 20:24:37,615 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1133)
2023-01-27 20:24:37,615 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1130)
2023-01-27 20:24:37,615 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:78)
2023-01-27 20:24:37,615 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:30)
2023-01-27 20:24:37,615 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:37,615 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:37,615 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:37,615 [IPC Server handler 9 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:37,616 [IPC Server handler 9 on default port 46811] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=dr.who (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/TestEncryptionZone/foo	dst=null	perm=null	proto=webhdfs
2023-01-27 20:24:37,620 [qtp968267706-1561] INFO  requests.namenode (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:37 +0000] "GET /webhdfs/v1/TestEncryptionZone/foo?op=OPEN HTTP/1.1" 307 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:37,818 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(113)) - [wasabi] XAttrFeature 110
2023-01-27 20:24:37,818 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(114)) - Printing stack trace:
2023-01-27 20:24:37,818 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:115)
2023-01-27 20:24:37,818 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:37,818 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:37,819 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:37,819 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:178)
2023-01-27 20:24:37,819 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2188)
2023-01-27 20:24:37,819 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:794)
2023-01-27 20:24:37,819 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:466)
2023-01-27 20:24:37,819 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:37,819 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:37,819 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:37,819 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:37,819 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:37,819 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:37,819 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:37,819 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:37,820 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:37,820 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:37,820 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFeature (XAttrFeature.java:getXAttr(118)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:37,820 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(138)) - [wasabi] XAttrFormat 136
2023-01-27 20:24:37,820 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(139)) - Printing stack trace:
2023-01-27 20:24:37,820 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFormat.getXAttr(XAttrFormat.java:140)
2023-01-27 20:24:37,820 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrFeature.getXAttr(XAttrFeature.java:120)
2023-01-27 20:24:37,820 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.XAttrStorage.readINodeXAttrByPrefixedName(XAttrStorage.java:46)
2023-01-27 20:24:37,820 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedGetXAttrByPrefixedName(FSDirXAttrOp.java:426)
2023-01-27 20:24:37,820 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.getFileEncryptionInfo(FSDirEncryptionZoneOp.java:460)
2023-01-27 20:24:37,820 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:178)
2023-01-27 20:24:37,820 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2188)
2023-01-27 20:24:37,821 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:794)
2023-01-27 20:24:37,821 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:466)
2023-01-27 20:24:37,821 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:-1)
2023-01-27 20:24:37,821 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
2023-01-27 20:24:37,823 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
2023-01-27 20:24:37,823 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
2023-01-27 20:24:37,823 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
2023-01-27 20:24:37,823 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
2023-01-27 20:24:37,823 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
2023-01-27 20:24:37,823 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at java.security.AccessController.doPrivileged(AccessController.java:-2)
2023-01-27 20:24:37,823 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at javax.security.auth.Subject.doAs(Subject.java:422)
2023-01-27 20:24:37,824 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
2023-01-27 20:24:37,824 [IPC Server handler 0 on default port 46811] INFO  namenode.XAttrFormat (XAttrFormat.java:getXAttr(143)) - 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)
2023-01-27 20:24:37,825 [IPC Server handler 0 on default port 46811] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=dr.who (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/TestEncryptionZone/foo	dst=null	perm=null	proto=rpc
2023-01-27 20:24:37,852 [qtp5768233-1529] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:37 +0000] "POST /kms/v1/keyversion/test_key%400/_eek?eek_op=decrypt HTTP/1.1" 200 90 "-" "Java/1.8.0_352"
2023-01-27 20:24:37,937 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2159)) - Shutting down the Mini HDFS Cluster
2023-01-27 20:24:37,937 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2208)) - Shutting down DataNode 0
2023-01-27 20:24:37,937 [Time-limited test] INFO  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(430)) - Shutdown has been called
2023-01-27 20:24:37,937 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@34d0654e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(395)) - Closing all peers.
2023-01-27 20:24:37,938 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-3211f305-2045-4346-be52-5062b8c4d03b) exiting.
2023-01-27 20:24:37,938 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-44a7dca2-3c19-4989-92df-2a30a54c1635) exiting.
2023-01-27 20:24:37,938 [nioEventLoopGroup-19-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/TestEncryptionZone/foo?op=OPEN&namenoderpcaddress=localhost:46811&offset=0 200
2023-01-27 20:24:37,942 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@9a90a4e{datanode,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:37,942 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@39dad963{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:37,942 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:37,943 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7b9ca72f{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:37,943 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@23fe8db8{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:37,944 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2470)) - Waiting up to 30 seconds for transfer threads to complete
2023-01-27 20:24:37,944 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 35339
2023-01-27 20:24:37,945 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:37,945 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:37,945 [Command processor] ERROR datanode.DataNode (BPServiceActor.java:processQueue(1430)) - Command processor encountered interrupt and exit.
2023-01-27 20:24:37,945 [ibr-executor-0] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:37,945 [Command processor] WARN  datanode.DataNode (BPServiceActor.java:run(1414)) - Ending command processor service for: Thread[Command processor,5,main]
2023-01-27 20:24:37,946 [BP-636111183-127.0.1.1-1674825875507 heartbeating to localhost/127.0.0.1:46811] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:37,947 [BP-636111183-127.0.1.1-1674825875507 heartbeating to localhost/127.0.0.1:46811] WARN  datanode.DataNode (BPServiceActor.java:run(924)) - Ending block pool service for: Block pool BP-636111183-127.0.1.1-1674825875507 (Datanode Uuid 0af554cc-136c-4ab9-b467-a017132eb0c8) service to localhost/127.0.0.1:46811
2023-01-27 20:24:37,947 [BP-636111183-127.0.1.1-1674825875507 heartbeating to localhost/127.0.0.1:46811] INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-636111183-127.0.1.1-1674825875507 (Datanode Uuid 0af554cc-136c-4ab9-b467-a017132eb0c8)
2023-01-27 20:24:37,947 [BP-636111183-127.0.1.1-1674825875507 heartbeating to localhost/127.0.0.1:46811] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(3225)) - Removing block pool BP-636111183-127.0.1.1-1674825875507
2023-01-27 20:24:37,948 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-636111183-127.0.1.1-1674825875507] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:37,948 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-636111183-127.0.1.1-1674825875507] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:37,949 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(208)) - Shutting down all async disk service threads
2023-01-27 20:24:37,949 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(216)) - All async disk service threads have been shut down
2023-01-27 20:24:37,950 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(186)) - Shutting down all async lazy persist service threads
2023-01-27 20:24:37,950 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(193)) - All async lazy persist service threads have been shut down
2023-01-27 20:24:37,951 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2559)) - Shutdown complete.
2023-01-27 20:24:37,951 [Time-limited test] WARN  datanode.DataSetLockManager (DataSetLockManager.java:lockLeakCheck(260)) - not open lock leak check func
2023-01-27 20:24:37,951 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2241)) - Shutting down the namenode
2023-01-27 20:24:37,951 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:37,951 [Thread[Thread-934,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:37,951 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(576)) - EDEKCacheLoader interrupted before warming up.
2023-01-27 20:24:37,951 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1467)) - Ending log segment 1, 10
2023-01-27 20:24:37,951 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3de701ee] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4658)) - LazyPersistFileScrubber was interrupted, exiting
2023-01-27 20:24:37,951 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7bab46c7] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4561)) - NameNodeEditLogRoller was interrupted, exiting
2023-01-27 20:24:37,954 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(801)) - Number of transactions: 11 Total time for transactions(ms): 38 Number of transactions batched in Syncs: 1 Number of syncs: 11 SyncTimes(ms): 73 14 
2023-01-27 20:24:37,955 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000011
2023-01-27 20:24:37,955 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000011
2023-01-27 20:24:37,956 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(276)) - FSEditLogAsync was interrupted, exiting
2023-01-27 20:24:37,956 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(267)) - Re-encryption updater thread interrupted. Exiting.
2023-01-27 20:24:37,956 [CacheReplicationMonitor(155972635)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2023-01-27 20:24:37,956 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(335)) - Re-encrypt handler interrupted. Exiting
2023-01-27 20:24:37,959 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 46811
2023-01-27 20:24:37,959 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:37,959 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:37,960 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(5160)) - Stopping RedundancyMonitor.
2023-01-27 20:24:37,961 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5134)) - Stopping MarkedDeleteBlockScrubber.
2023-01-27 20:24:37,970 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:37,970 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:37,971 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@145c34ab{hdfs,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:37,972 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@12312384{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:37,972 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:37,972 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1a99aa4d{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:37,973 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5d98eec9{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:37,978 [Thread[Thread-902,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:37,978 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextDestroyed(197)) - KMS Stopped
2023-01-27 20:24:37,979 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@4976004c{kms,/,null,STOPPED}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:37,980 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@692251e4{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:37,980 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:37,980 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5d1d31a3{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-27 20:24:37,980 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@ea0c97a{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:37,982 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2023-01-27 20:24:37,983 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2023-01-27 20:24:37,983 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(612)) - DataNode metrics system shutdown complete.
2023-01-27 20:24:38,029 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:38,029 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context kms
2023-01-27 20:24:38,029 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:38,029 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:38,030 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:38,030 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 42161
2023-01-27 20:24:38,030 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:38,040 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:38,040 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:38,041 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:38,041 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@e5031d0{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:38,042 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@371376ba{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-27 20:24:38,076 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(94)) - -------------------------------------------------------------
2023-01-27 20:24:38,077 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(95)) -   Java runtime version : 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:38,077 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(97)) -   User: rizky
2023-01-27 20:24:38,077 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(98)) -   KMS Hadoop Version: 3.4.0-SNAPSHOT
2023-01-27 20:24:38,077 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(99)) - -------------------------------------------------------------
2023-01-27 20:24:38,078 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'CREATE' ACL '*'
2023-01-27 20:24:38,078 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DELETE' ACL '*'
2023-01-27 20:24:38,078 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'ROLLOVER' ACL '*'
2023-01-27 20:24:38,078 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET' ACL '*'
2023-01-27 20:24:38,078 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_KEYS' ACL '*'
2023-01-27 20:24:38,078 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_METADATA' ACL '*'
2023-01-27 20:24:38,079 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'SET_KEY_MATERIAL' ACL '*'
2023-01-27 20:24:38,079 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GENERATE_EEK' ACL '*'
2023-01-27 20:24:38,079 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DECRYPT_EEK' ACL '*'
2023-01-27 20:24:38,079 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2023-01-27 20:24:38,079 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2023-01-27 20:24:38,079 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2023-01-27 20:24:38,079 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2023-01-27 20:24:38,082 [Time-limited test] INFO  server.KMSAudit (KMSAudit.java:initializeAuditLoggers(157)) - Initializing audit logger class org.apache.hadoop.crypto.key.kms.server.SimpleKMSAuditLogger
2023-01-27 20:24:38,084 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(149)) - Initialized KeyProvider CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/6c7e4093-cb2b-4d04-aa89-7ac83c9c2aed/kms.keystore
2023-01-27 20:24:38,085 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(163)) - Initialized KeyProviderCryptoExtension org.apache.hadoop.crypto.key.kms.server.KeyAuthorizationKeyProvider: EagerKeyGeneratorKeyProviderCryptoExtension: KeyProviderCryptoExtension: CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/6c7e4093-cb2b-4d04-aa89-7ac83c9c2aed/kms.keystore
2023-01-27 20:24:38,085 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(168)) - Default key bitlength is 128
2023-01-27 20:24:38,085 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(169)) - KMS Started
2023-01-27 20:24:38,086 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:38,087 [Thread[Thread-1013,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:38,087 [Thread[Thread-1013,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:38,089 [Time-limited test] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.crypto.key.kms.server
2023-01-27 20:24:38,105 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMS
2023-01-27 20:24:38,105 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
  class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
2023-01-27 20:24:38,108 [Time-limited test] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:24:38,238 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@5b052e2b{kms,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/2/kms/webapp/,AVAILABLE}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:38,239 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@55faf7ed{HTTP/1.1, (http/1.1)}{localhost:42161}
2023-01-27 20:24:38,240 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @43262ms
2023-01-27 20:24:38,242 [Time-limited test] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(120)) - Loaded properties from hadoop-metrics2.properties
2023-01-27 20:24:38,243 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 0 second(s).
2023-01-27 20:24:38,243 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - KMS metrics system started
2023-01-27 20:24:38,255 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@44417185] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:38,265 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(566)) - starting cluster: numNameNodes=1, numDataNodes=1
2023-01-27 20:24:38,266 [Time-limited test] INFO  namenode.NameNode (NameNode.java:format(1366)) - Formatting using clusterid: testClusterID
2023-01-27 20:24:38,267 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:38,278 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@2dfff28
2023-01-27 20:24:38,278 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:38,278 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:38,278 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:38,278 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:38,278 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:38,278 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:38,278 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:38,278 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:38,279 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:38,279 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:38,279 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:38,279 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:38
2023-01-27 20:24:38,279 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:38,279 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:38,280 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:38,280 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:38,281 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:38,281 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:38,281 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:38,281 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:38,281 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:38,282 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:38,282 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:38,282 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:38,282 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:38,282 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:38,282 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:38,282 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:38,282 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:38,282 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:38,283 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:38,283 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:38,283 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:38,284 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:38,284 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:38,284 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:38,284 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:38,284 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:38,285 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:38,285 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:38,285 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:38,285 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:38,285 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:38,285 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:38,285 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:38,286 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:38,286 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:38,286 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:38,287 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:38,287 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:38,287 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:38,287 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:38,287 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:38,287 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:38,289 [Time-limited test] INFO  namenode.FSImage (FSImage.java:format(186)) - Allocated new BlockPoolId: BP-410830630-127.0.1.1-1674825878289
2023-01-27 20:24:38,293 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 has been successfully formatted.
2023-01-27 20:24:38,298 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 has been successfully formatted.
2023-01-27 20:24:38,310 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:38,311 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:38,315 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 493 bytes saved in 0 seconds .
2023-01-27 20:24:38,318 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 493 bytes saved in 0 seconds .
2023-01-27 20:24:38,321 [Time-limited test] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(202)) - Going to retain 1 images with txid >= 0
2023-01-27 20:24:38,337 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:38,337 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:38,338 [Time-limited test] INFO  namenode.NameNode (NameNode.java:createNameNode(1824)) - createNameNode []
2023-01-27 20:24:38,338 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2023-01-27 20:24:38,339 [Time-limited test] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2023-01-27 20:24:38,354 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4b365003] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:38,354 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1736)) - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2023-01-27 20:24:38,355 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1758)) - Starting Web-server for hdfs at: http://localhost:0
2023-01-27 20:24:38,355 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:38,356 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:38,358 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:38,359 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:38,360 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-01-27 20:24:38,360 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:38,360 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:38,361 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2023-01-27 20:24:38,361 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2023-01-27 20:24:38,361 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2023-01-27 20:24:38,361 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:38,362 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(1018)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-01-27 20:24:38,362 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 43817
2023-01-27 20:24:38,362 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:38,363 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:38,364 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:38,364 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:38,365 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:38,366 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@204d325e{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:38,366 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7e50969d{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:38,371 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7beb92eb{hdfs,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:38,372 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@1cc6e840{HTTP/1.1, (http/1.1)}{localhost:43817}
2023-01-27 20:24:38,372 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @43394ms
2023-01-27 20:24:38,374 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:38,383 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@745ab0bd
2023-01-27 20:24:38,384 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:38,384 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:38,384 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:38,384 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:38,384 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:38,384 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:38,384 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:38,384 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:38,385 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:38,385 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:38,385 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:38,385 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:38
2023-01-27 20:24:38,385 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:38,385 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:38,385 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:38,385 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:38,387 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:38,387 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:38,387 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:38,388 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:38,388 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:38,388 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:38,388 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:38,388 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:38,388 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:38,388 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:38,388 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:38,388 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:38,389 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:38,389 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:38,389 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:38,389 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:38,389 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:38,390 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:38,390 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:38,390 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:38,391 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:38,391 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:38,391 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:38,391 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:38,391 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:38,391 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:38,391 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:38,392 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:38,392 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:38,392 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:38,392 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:38,392 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:38,392 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:38,392 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:38,392 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:38,393 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:38,393 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:38,393 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:38,395 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:38,396 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:38,397 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current
2023-01-27 20:24:38,398 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current
2023-01-27 20:24:38,398 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(734)) - No edit log streams selected.
2023-01-27 20:24:38,398 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(800)) - Planning to load image: FSImageFile(file=/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-01-27 20:24:38,400 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSectionHeader(411)) - Loading 1 INodes.
2023-01-27 20:24:38,400 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(369)) - Successfully loaded 1 inodes
2023-01-27 20:24:38,400 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:waitBlocksMapAndNameCacheUpdateFinished(342)) - Completed update blocks map and name cache, total waiting duration 0ms.
2023-01-27 20:24:38,401 [Time-limited test] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(255)) - Loaded FSImage in 0 seconds.
2023-01-27 20:24:38,401 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(980)) - Loaded image for txid 0 from /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000
2023-01-27 20:24:38,401 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1271)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-01-27 20:24:38,401 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1417)) - Starting log segment at 1
2023-01-27 20:24:38,417 [Time-limited test] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2023-01-27 20:24:38,417 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(836)) - Finished loading FSImage in 24 msecs
2023-01-27 20:24:38,417 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(451)) - RPC server is binding to localhost:0
2023-01-27 20:24:38,417 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(456)) - Enable NameNode state context:false
2023-01-27 20:24:38,418 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:38,418 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:36343
2023-01-27 20:24:38,418 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:38,422 [Time-limited test] INFO  namenode.NameNode (NameNode.java:initialize(893)) - Clients are to use localhost:36343 to access this namenode/service.
2023-01-27 20:24:38,423 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5607)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2023-01-27 20:24:38,456 [Time-limited test] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(166)) - Number of blocks under construction: 0
2023-01-27 20:24:38,457 [Time-limited test] INFO  blockmanagement.DatanodeAdminDefaultMonitor (DatanodeAdminDefaultMonitor.java:processConf(126)) - Initialized the Default Decommission and Maintenance monitor
2023-01-27 20:24:38,457 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5102)) - Start MarkedDeleteBlockScrubber thread
2023-01-27 20:24:38,457 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(5310)) - initializing replication queues
2023-01-27 20:24:38,458 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(409)) - STATE* Leaving safe mode after 0 secs
2023-01-27 20:24:38,458 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(415)) - STATE* Network topology has 0 racks and 0 datanodes
2023-01-27 20:24:38,458 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(417)) - STATE* UnderReplicatedBlocks has 0 blocks
2023-01-27 20:24:38,463 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:38,466 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3870)) - Total number of blocks            = 0
2023-01-27 20:24:38,466 [Thread[Thread-1045,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:38,466 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3871)) - Number of invalid blocks          = 0
2023-01-27 20:24:38,466 [Thread[Thread-1045,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:38,466 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3872)) - Number of under-replicated blocks = 0
2023-01-27 20:24:38,467 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3873)) - Number of  over-replicated blocks = 0
2023-01-27 20:24:38,467 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3875)) - Number of blocks being written    = 0
2023-01-27 20:24:38,467 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3878)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2023-01-27 20:24:38,469 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:38,469 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:38,471 [Time-limited test] INFO  namenode.NameNode (NameNode.java:startCommonServices(1010)) - NameNode RPC up at: localhost/127.0.0.1:36343
2023-01-27 20:24:38,472 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1383)) - Starting services required for active state
2023-01-27 20:24:38,472 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(857)) - Initializing quota with 12 thread(s)
2023-01-27 20:24:38,473 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(866)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2023-01-27 20:24:38,473 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(326)) - Starting up re-encrypt thread with interval=60000 millisecond.
2023-01-27 20:24:38,474 [CacheReplicationMonitor(291595287)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-01-27 20:24:38,475 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2023-01-27 20:24:38,480 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1769)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1,[DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:38,481 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:38,482 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:38,499 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2023-01-27 20:24:38,499 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:38,499 [Time-limited test] INFO  datanode.BlockScanner (BlockScanner.java:<init>(201)) - Initialized block scanner with targetBytesPerSec 1048576
2023-01-27 20:24:38,500 [Time-limited test] INFO  datanode.DataNode (DataNode.java:<init>(571)) - Configured hostname is 127.0.0.1
2023-01-27 20:24:38,500 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:38,500 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1788)) - Starting DataNode with maxLockedMemory = 0
2023-01-27 20:24:38,500 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1551)) - Opened streaming server at /127.0.0.1:35293
2023-01-27 20:24:38,501 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(93)) - Balancing bandwidth is 104857600 bytes/s
2023-01-27 20:24:38,501 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(94)) - Number threads for balancing is 100
2023-01-27 20:24:38,502 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:38,503 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:38,505 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:38,506 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:38,506 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-01-27 20:24:38,506 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:38,506 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:38,506 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:38,507 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 35091
2023-01-27 20:24:38,507 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:38,508 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:38,508 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:38,508 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:38,509 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@379b4bf1{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:38,509 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3f32090c{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:38,512 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@2a16f9d7{datanode,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:38,513 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@27390b18{HTTP/1.1, (http/1.1)}{localhost:35091}
2023-01-27 20:24:38,514 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @43536ms
2023-01-27 20:24:38,516 [Time-limited test] WARN  web.DatanodeHttpServer (RestCsrfPreventionFilterHandler.java:<init>(75)) - Got null for restCsrfPreventionFilter - will not do any filtering.
2023-01-27 20:24:38,518 [Time-limited test] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(306)) - Listening HTTP traffic on /127.0.0.1:41441
2023-01-27 20:24:38,518 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1816)) - dnUserName = rizky
2023-01-27 20:24:38,518 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@340f4386] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:38,518 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1817)) - supergroup = supergroup
2023-01-27 20:24:38,519 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:38,519 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:41209
2023-01-27 20:24:38,520 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:38,521 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initIpcServer(1438)) - Opened IPC server at /127.0.0.1:41209
2023-01-27 20:24:38,535 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(150)) - Refresh request received for nameservices: null
2023-01-27 20:24:38,535 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(211)) - Starting BPOfferServices for nameservices: <default>
2023-01-27 20:24:38,536 [Thread-1078] INFO  datanode.DataNode (BPServiceActor.java:run(877)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36343 starting to offer service
2023-01-27 20:24:38,537 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:38,539 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:38,547 [Thread-1078] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(382)) - Acknowledging ACTIVE Namenode during handshake Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36343
2023-01-27 20:24:38,547 [Thread-1078] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(356)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2023-01-27 20:24:38,549 [Thread-1078] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:38,549 [Thread-1078] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 is not formatted for namespace 69521373. Formatting...
2023-01-27 20:24:38,550 [Thread-1078] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6b604483-4465-4dda-a9dc-c025ce5ea4e2 for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 
2023-01-27 20:24:38,552 [IPC Server handler 1 on default port 36343] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:38,553 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:38,553 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:38,554 [Thread-1078] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:38,554 [Thread-1078] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 is not formatted for namespace 69521373. Formatting...
2023-01-27 20:24:38,554 [Thread-1078] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c5b1743e-1c9b-4b47-a85b-4dd6a4255fce for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 
2023-01-27 20:24:38,779 [IPC Server handler 2 on default port 36343] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:38,785 [Thread-1078] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-410830630-127.0.1.1-1674825878289
2023-01-27 20:24:38,785 [Thread-1078] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-410830630-127.0.1.1-1674825878289
2023-01-27 20:24:38,785 [Thread-1078] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 and block pool id BP-410830630-127.0.1.1-1674825878289 is not formatted. Formatting ...
2023-01-27 20:24:38,785 [Thread-1078] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-410830630-127.0.1.1-1674825878289 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-410830630-127.0.1.1-1674825878289/current
2023-01-27 20:24:38,791 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:38,791 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:38,812 [Thread-1078] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-410830630-127.0.1.1-1674825878289
2023-01-27 20:24:38,812 [Thread-1078] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-410830630-127.0.1.1-1674825878289
2023-01-27 20:24:38,812 [Thread-1078] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 and block pool id BP-410830630-127.0.1.1-1674825878289 is not formatted. Formatting ...
2023-01-27 20:24:38,812 [Thread-1078] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-410830630-127.0.1.1-1674825878289 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-410830630-127.0.1.1-1674825878289/current
2023-01-27 20:24:38,815 [Thread-1078] INFO  datanode.DataNode (DataNode.java:initStorage(2136)) - Setting up storage: nsid=69521373;bpid=BP-410830630-127.0.1.1-1674825878289;lv=-57;nsInfo=lv=-67;cid=testClusterID;nsid=69521373;c=1674825878289;bpid=BP-410830630-127.0.1.1-1674825878289;dnuuid=null
2023-01-27 20:24:38,818 [Thread-1078] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1934)) - Generated and persisted new Datanode UUID 6ed905d9-787d-4c08-98a1-0f01d6de883a
2023-01-27 20:24:38,820 [Thread-1078] INFO  fsdataset.RoundRobinVolumeChoosingPolicy (RoundRobinVolumeChoosingPolicy.java:setConf(67)) - Round robin volume choosing policy initialized: dfs.datanode.round-robin-volume-choosing-policy.additional-available-space = 0
2023-01-27 20:24:38,822 [Thread-1078] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-6b604483-4465-4dda-a9dc-c025ce5ea4e2
2023-01-27 20:24:38,822 [Thread-1078] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, StorageType: DISK
2023-01-27 20:24:38,823 [Thread-1078] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-c5b1743e-1c9b-4b47-a85b-4dd6a4255fce
2023-01-27 20:24:38,823 [Thread-1078] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, StorageType: DISK
2023-01-27 20:24:38,824 [Thread-1078] INFO  impl.MemoryMappableBlockLoader (MemoryMappableBlockLoader.java:initialize(47)) - Initializing cache loader: MemoryMappableBlockLoader.
2023-01-27 20:24:38,825 [Thread-1078] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2611)) - Registered FSDatasetState MBean
2023-01-27 20:24:38,828 [Thread-1078] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(3188)) - Adding block pool BP-410830630-127.0.1.1-1674825878289
2023-01-27 20:24:38,829 [Thread-1096] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-410830630-127.0.1.1-1674825878289 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:38,829 [Thread-1095] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-410830630-127.0.1.1-1674825878289 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:38,830 [Thread-1096] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-410830630-127.0.1.1-1674825878289/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:38,830 [Thread-1095] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-410830630-127.0.1.1-1674825878289/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:38,853 [Thread-1096] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-410830630-127.0.1.1-1674825878289 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 25ms
2023-01-27 20:24:38,856 [Thread-1095] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-410830630-127.0.1.1-1674825878289 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 27ms
2023-01-27 20:24:38,865 [Thread-1078] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(538)) - Total time to scan all replicas for block pool BP-410830630-127.0.1.1-1674825878289: 37ms
2023-01-27 20:24:38,866 [Thread-1099] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-410830630-127.0.1.1-1674825878289 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:38,866 [Thread-1099] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-410830630-127.0.1.1-1674825878289/current/replicas doesn't exist 
2023-01-27 20:24:38,867 [Thread-1100] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-410830630-127.0.1.1-1674825878289 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:38,867 [Thread-1100] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-410830630-127.0.1.1-1674825878289/current/replicas doesn't exist 
2023-01-27 20:24:38,867 [Thread-1099] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-410830630-127.0.1.1-1674825878289 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 0ms
2023-01-27 20:24:38,871 [Thread-1100] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-410830630-127.0.1.1-1674825878289 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 5ms
2023-01-27 20:24:38,871 [Thread-1078] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(292)) - Total time to add all replicas to map for block pool BP-410830630-127.0.1.1-1674825878289: 6ms
2023-01-27 20:24:38,871 [Thread-1078] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:38,875 [Thread-1078] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:38,875 [Thread-1078] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:38,880 [Thread-1078] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:38,881 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-410830630-127.0.1.1-1674825878289 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:38,881 [Thread-1078] WARN  datanode.DirectoryScanner (DirectoryScanner.java:<init>(302)) - dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2023-01-27 20:24:38,881 [Thread-1078] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(367)) - Periodic Directory Tree Verification scan starting in 20136777ms with interval of 21600000ms and throttle limit of -1ms/s
2023-01-27 20:24:38,881 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-410830630-127.0.1.1-1674825878289 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:38,882 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-c5b1743e-1c9b-4b47-a85b-4dd6a4255fce): finished scanning block pool BP-410830630-127.0.1.1-1674825878289
2023-01-27 20:24:38,882 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-c5b1743e-1c9b-4b47-a85b-4dd6a4255fce): no suitable block pools found to scan.  Waiting 1814399999 ms.
2023-01-27 20:24:38,881 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-6b604483-4465-4dda-a9dc-c025ce5ea4e2): finished scanning block pool BP-410830630-127.0.1.1-1674825878289
2023-01-27 20:24:38,883 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-6b604483-4465-4dda-a9dc-c025ce5ea4e2): no suitable block pools found to scan.  Waiting 1814399998 ms.
2023-01-27 20:24:38,884 [BP-410830630-127.0.1.1-1674825878289 heartbeating to localhost/127.0.0.1:36343] INFO  datanode.DataNode (BPServiceActor.java:register(819)) - Block pool BP-410830630-127.0.1.1-1674825878289 (Datanode Uuid 6ed905d9-787d-4c08-98a1-0f01d6de883a) service to localhost/127.0.0.1:36343 beginning handshake with NN: localhost/127.0.0.1:36343.
2023-01-27 20:24:38,896 [IPC Server handler 3 on default port 36343] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1166)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35293, datanodeUuid=6ed905d9-787d-4c08-98a1-0f01d6de883a, infoPort=41441, infoSecurePort=0, ipcPort=41209, storageInfo=lv=-57;cid=testClusterID;nsid=69521373;c=1674825878289) storage 6ed905d9-787d-4c08-98a1-0f01d6de883a
2023-01-27 20:24:38,896 [IPC Server handler 3 on default port 36343] INFO  net.NetworkTopology (NetworkTopology.java:add(156)) - Adding a new node: /default-rack/127.0.0.1:35293
2023-01-27 20:24:38,896 [IPC Server handler 3 on default port 36343] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(200)) - Registered DN 6ed905d9-787d-4c08-98a1-0f01d6de883a (127.0.0.1:35293).
2023-01-27 20:24:38,898 [IPC Server handler 4 on default port 36343] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:38,898 [BP-410830630-127.0.1.1-1674825878289 heartbeating to localhost/127.0.0.1:36343] INFO  datanode.DataNode (BPServiceActor.java:register(846)) - Block pool BP-410830630-127.0.1.1-1674825878289 (Datanode Uuid 6ed905d9-787d-4c08-98a1-0f01d6de883a) service to localhost/127.0.0.1:36343 successfully registered with NN: localhost/127.0.0.1:36343.
2023-01-27 20:24:38,899 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2922)) - No heartbeat from DataNode: 127.0.0.1:35293
2023-01-27 20:24:38,899 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:38,899 [BP-410830630-127.0.1.1-1674825878289 heartbeating to localhost/127.0.0.1:36343] INFO  datanode.DataNode (BPServiceActor.java:offerService(680)) - For namenode localhost/127.0.0.1:36343 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2023-01-27 20:24:38,899 [ibr-executor-0] INFO  datanode.DataNode (BPServiceActor.java:run(1145)) - Starting IBR Task Handler.
2023-01-27 20:24:38,901 [IPC Server handler 5 on default port 36343] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-6b604483-4465-4dda-a9dc-c025ce5ea4e2 for DN 127.0.0.1:35293
2023-01-27 20:24:38,901 [IPC Server handler 5 on default port 36343] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-c5b1743e-1c9b-4b47-a85b-4dd6a4255fce for DN 127.0.0.1:35293
2023-01-27 20:24:38,905 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0x73ed5e99da2e8134 with lease ID 0x3d03949635ba8838: Processing first storage report for DS-6b604483-4465-4dda-a9dc-c025ce5ea4e2 from datanode DatanodeRegistration(127.0.0.1:35293, datanodeUuid=6ed905d9-787d-4c08-98a1-0f01d6de883a, infoPort=41441, infoSecurePort=0, ipcPort=41209, storageInfo=lv=-57;cid=testClusterID;nsid=69521373;c=1674825878289)
2023-01-27 20:24:38,905 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0x73ed5e99da2e8134 with lease ID 0x3d03949635ba8838: from storage DS-6b604483-4465-4dda-a9dc-c025ce5ea4e2 node DatanodeRegistration(127.0.0.1:35293, datanodeUuid=6ed905d9-787d-4c08-98a1-0f01d6de883a, infoPort=41441, infoSecurePort=0, ipcPort=41209, storageInfo=lv=-57;cid=testClusterID;nsid=69521373;c=1674825878289), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:38,905 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0x73ed5e99da2e8134 with lease ID 0x3d03949635ba8838: Processing first storage report for DS-c5b1743e-1c9b-4b47-a85b-4dd6a4255fce from datanode DatanodeRegistration(127.0.0.1:35293, datanodeUuid=6ed905d9-787d-4c08-98a1-0f01d6de883a, infoPort=41441, infoSecurePort=0, ipcPort=41209, storageInfo=lv=-57;cid=testClusterID;nsid=69521373;c=1674825878289)
2023-01-27 20:24:38,905 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0x73ed5e99da2e8134 with lease ID 0x3d03949635ba8838: from storage DS-c5b1743e-1c9b-4b47-a85b-4dd6a4255fce node DatanodeRegistration(127.0.0.1:35293, datanodeUuid=6ed905d9-787d-4c08-98a1-0f01d6de883a, infoPort=41441, infoSecurePort=0, ipcPort=41209, storageInfo=lv=-57;cid=testClusterID;nsid=69521373;c=1674825878289), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:38,906 [BP-410830630-127.0.1.1-1674825878289 heartbeating to localhost/127.0.0.1:36343] INFO  datanode.DataNode (BPServiceActor.java:blockReport(464)) - Successfully sent block report 0x73ed5e99da2e8134 with lease ID 0x3d03949635ba8838 to namenode: localhost/127.0.0.1:36343,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msecs to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-01-27 20:24:38,907 [Command processor] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(763)) - Got finalize command for block pool BP-410830630-127.0.1.1-1674825878289
2023-01-27 20:24:39,000 [IPC Server handler 7 on default port 36343] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:39,001 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:39,004 [IPC Server handler 8 on default port 36343] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:39,005 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:39,009 [qtp200898865-1726] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:39 +0000] "OPTIONS /kms/v1/keys HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:39,022 [qtp200898865-1722] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:39,023 [qtp200898865-1722] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:39,023 [qtp200898865-1722] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:39,023 [qtp200898865-1722] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:39,024 [qtp200898865-1722] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:39,024 [qtp200898865-1722] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:39,024 [qtp200898865-1722] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:39,025 [qtp200898865-1722] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:39,027 [qtp200898865-1722] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:39 +0000] "OPTIONS /kms/v1/keys?user.name=rizky HTTP/1.1" 200 520 "-" "Java/1.8.0_352"
2023-01-27 20:24:39,426 [qtp200898865-1723] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=CREATE_KEY, key=test_key, user=rizky] UserProvidedMaterial:false Description:test_key
2023-01-27 20:24:39,428 [qtp200898865-1723] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:39 +0000] "POST /kms/v1/keys HTTP/1.1" 201 98 "-" "Java/1.8.0_352"
2023-01-27 20:24:39,429 [IPC Server handler 9 on default port 36343] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=false	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=createEncryptionZone	src=/zone1	dst=null	perm=null	proto=rpc
2023-01-27 20:24:39,430 [IPC Server handler 9 on default port 36343] INFO  ipc.Server (Server.java:logException(3206)) - IPC Server handler 9 on default port 36343, call Call#136 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.createEncryptionZone from 127.0.0.1:53068
org.apache.hadoop.security.authorize.AuthorizationException: User [root] is not authorized to perform [READ] on key with ACL name [key2]!!
2023-01-27 20:24:39,431 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2159)) - Shutting down the Mini HDFS Cluster
2023-01-27 20:24:39,431 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2208)) - Shutting down DataNode 0
2023-01-27 20:24:39,431 [Time-limited test] INFO  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(430)) - Shutdown has been called
2023-01-27 20:24:39,431 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@57735b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(395)) - Closing all peers.
2023-01-27 20:24:39,432 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-c5b1743e-1c9b-4b47-a85b-4dd6a4255fce) exiting.
2023-01-27 20:24:39,432 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-6b604483-4465-4dda-a9dc-c025ce5ea4e2) exiting.
2023-01-27 20:24:39,455 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2a16f9d7{datanode,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:39,459 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@27390b18{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:39,460 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:39,460 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3f32090c{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:39,460 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@379b4bf1{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:39,465 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2470)) - Waiting up to 30 seconds for transfer threads to complete
2023-01-27 20:24:39,465 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 41209
2023-01-27 20:24:39,466 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:39,466 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:39,467 [BP-410830630-127.0.1.1-1674825878289 heartbeating to localhost/127.0.0.1:36343] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:39,467 [BP-410830630-127.0.1.1-1674825878289 heartbeating to localhost/127.0.0.1:36343] WARN  datanode.DataNode (BPServiceActor.java:run(924)) - Ending block pool service for: Block pool BP-410830630-127.0.1.1-1674825878289 (Datanode Uuid 6ed905d9-787d-4c08-98a1-0f01d6de883a) service to localhost/127.0.0.1:36343
2023-01-27 20:24:39,468 [BP-410830630-127.0.1.1-1674825878289 heartbeating to localhost/127.0.0.1:36343] INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-410830630-127.0.1.1-1674825878289 (Datanode Uuid 6ed905d9-787d-4c08-98a1-0f01d6de883a)
2023-01-27 20:24:39,468 [BP-410830630-127.0.1.1-1674825878289 heartbeating to localhost/127.0.0.1:36343] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(3225)) - Removing block pool BP-410830630-127.0.1.1-1674825878289
2023-01-27 20:24:39,468 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-410830630-127.0.1.1-1674825878289] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:39,468 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-410830630-127.0.1.1-1674825878289] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:24:39,468 [ibr-executor-0] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2023-01-27 20:24:39,469 [Command processor] ERROR datanode.DataNode (BPServiceActor.java:processQueue(1430)) - Command processor encountered interrupt and exit.
2023-01-27 20:24:39,469 [Command processor] WARN  datanode.DataNode (BPServiceActor.java:run(1414)) - Ending command processor service for: Thread[Command processor,5,main]
2023-01-27 20:24:39,471 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(208)) - Shutting down all async disk service threads
2023-01-27 20:24:39,471 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(216)) - All async disk service threads have been shut down
2023-01-27 20:24:39,471 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(186)) - Shutting down all async lazy persist service threads
2023-01-27 20:24:39,471 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(193)) - All async lazy persist service threads have been shut down
2023-01-27 20:24:39,472 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2559)) - Shutdown complete.
2023-01-27 20:24:39,472 [Time-limited test] WARN  datanode.DataSetLockManager (DataSetLockManager.java:lockLeakCheck(260)) - not open lock leak check func
2023-01-27 20:24:39,472 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2241)) - Shutting down the namenode
2023-01-27 20:24:39,472 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:39,473 [Thread[Thread-1045,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:39,473 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(576)) - EDEKCacheLoader interrupted before warming up.
2023-01-27 20:24:39,473 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1467)) - Ending log segment 1, 3
2023-01-27 20:24:39,473 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7fa06597] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4561)) - NameNodeEditLogRoller was interrupted, exiting
2023-01-27 20:24:39,473 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6dc72e59] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4658)) - LazyPersistFileScrubber was interrupted, exiting
2023-01-27 20:24:39,486 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(801)) - Number of transactions: 4 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 18 10 
2023-01-27 20:24:39,486 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000004
2023-01-27 20:24:39,487 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000004
2023-01-27 20:24:39,488 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(276)) - FSEditLogAsync was interrupted, exiting
2023-01-27 20:24:39,488 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(267)) - Re-encryption updater thread interrupted. Exiting.
2023-01-27 20:24:39,488 [CacheReplicationMonitor(291595287)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2023-01-27 20:24:39,488 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(335)) - Re-encrypt handler interrupted. Exiting
2023-01-27 20:24:39,489 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 36343
2023-01-27 20:24:39,491 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:24:39,492 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:24:39,503 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5134)) - Stopping MarkedDeleteBlockScrubber.
2023-01-27 20:24:39,503 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(5160)) - Stopping RedundancyMonitor.
2023-01-27 20:24:39,519 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:39,519 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:39,520 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@7beb92eb{hdfs,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:39,521 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@1cc6e840{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:39,522 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:39,522 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7e50969d{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:24:39,522 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@204d325e{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:39,532 [Thread[Thread-1013,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:24:39,533 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextDestroyed(197)) - KMS Stopped
2023-01-27 20:24:39,533 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@5b052e2b{kms,/,null,STOPPED}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:39,535 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@55faf7ed{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:24:39,535 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:24:39,535 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@371376ba{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-27 20:24:39,535 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@e5031d0{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:24:39,536 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2023-01-27 20:24:39,539 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2023-01-27 20:24:39,539 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(612)) - DataNode metrics system shutdown complete.
2023-01-27 20:24:39,581 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:39,582 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context kms
2023-01-27 20:24:39,582 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:39,582 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:39,582 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:39,583 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 41783
2023-01-27 20:24:39,583 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:39,594 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:39,595 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:39,595 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:24:39,596 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6480b952{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:39,597 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4c4be33c{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-27 20:24:39,636 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(94)) - -------------------------------------------------------------
2023-01-27 20:24:39,636 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(95)) -   Java runtime version : 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:39,637 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(97)) -   User: rizky
2023-01-27 20:24:39,637 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(98)) -   KMS Hadoop Version: 3.4.0-SNAPSHOT
2023-01-27 20:24:39,637 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(99)) - -------------------------------------------------------------
2023-01-27 20:24:39,638 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'CREATE' ACL '*'
2023-01-27 20:24:39,638 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DELETE' ACL '*'
2023-01-27 20:24:39,638 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'ROLLOVER' ACL '*'
2023-01-27 20:24:39,638 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET' ACL '*'
2023-01-27 20:24:39,638 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_KEYS' ACL '*'
2023-01-27 20:24:39,639 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_METADATA' ACL '*'
2023-01-27 20:24:39,639 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'SET_KEY_MATERIAL' ACL '*'
2023-01-27 20:24:39,639 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GENERATE_EEK' ACL '*'
2023-01-27 20:24:39,639 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DECRYPT_EEK' ACL '*'
2023-01-27 20:24:39,639 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2023-01-27 20:24:39,639 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2023-01-27 20:24:39,640 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2023-01-27 20:24:39,640 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2023-01-27 20:24:39,643 [Time-limited test] INFO  server.KMSAudit (KMSAudit.java:initializeAuditLoggers(157)) - Initializing audit logger class org.apache.hadoop.crypto.key.kms.server.SimpleKMSAuditLogger
2023-01-27 20:24:39,645 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(149)) - Initialized KeyProvider CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/c4204874-55d3-469c-8374-bbdfde3d67b6/kms.keystore
2023-01-27 20:24:39,646 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(163)) - Initialized KeyProviderCryptoExtension org.apache.hadoop.crypto.key.kms.server.KeyAuthorizationKeyProvider: EagerKeyGeneratorKeyProviderCryptoExtension: KeyProviderCryptoExtension: CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/c4204874-55d3-469c-8374-bbdfde3d67b6/kms.keystore
2023-01-27 20:24:39,646 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(168)) - Default key bitlength is 128
2023-01-27 20:24:39,646 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(169)) - KMS Started
2023-01-27 20:24:39,648 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:39,649 [Thread[Thread-1116,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:39,649 [Thread[Thread-1116,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:39,659 [Time-limited test] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.crypto.key.kms.server
2023-01-27 20:24:39,678 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMS
2023-01-27 20:24:39,678 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
  class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
2023-01-27 20:24:39,683 [Time-limited test] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:24:39,813 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7cd0ee94{kms,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/2/kms/webapp/,AVAILABLE}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:24:39,815 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4ed0bb3d{HTTP/1.1, (http/1.1)}{localhost:41783}
2023-01-27 20:24:39,815 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @44837ms
2023-01-27 20:24:39,817 [Time-limited test] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(120)) - Loaded properties from hadoop-metrics2.properties
2023-01-27 20:24:39,822 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 0 second(s).
2023-01-27 20:24:39,822 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - KMS metrics system started
2023-01-27 20:24:39,843 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@180a6ddc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:39,854 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(566)) - starting cluster: numNameNodes=1, numDataNodes=1
2023-01-27 20:24:39,857 [Time-limited test] INFO  namenode.NameNode (NameNode.java:format(1366)) - Formatting using clusterid: testClusterID
2023-01-27 20:24:39,857 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:39,871 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@4a177fc5
2023-01-27 20:24:39,872 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:39,872 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:39,872 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:39,872 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:39,872 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:39,872 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:39,873 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:39,873 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:39,873 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:39,873 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:39,874 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:39,874 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:39
2023-01-27 20:24:39,874 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:39,874 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:39,874 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:39,875 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:39,876 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:39,876 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:39,877 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:39,877 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:39,877 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:39,877 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:39,877 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:39,877 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:39,877 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:39,878 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:39,878 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:39,878 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:39,878 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:39,878 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:39,878 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:39,878 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:39,879 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:39,879 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:39,880 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:39,880 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:39,880 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:39,880 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:39,880 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:39,880 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:39,880 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:39,881 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:39,881 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:39,881 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:39,881 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:39,882 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:39,882 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:39,882 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:39,882 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:39,882 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:39,883 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:39,883 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:39,883 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:39,883 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:39,884 [Time-limited test] INFO  namenode.FSImage (FSImage.java:format(186)) - Allocated new BlockPoolId: BP-1865570562-127.0.1.1-1674825879884
2023-01-27 20:24:39,893 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 has been successfully formatted.
2023-01-27 20:24:39,897 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 has been successfully formatted.
2023-01-27 20:24:39,911 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:39,916 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:24:39,918 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 496 bytes saved in 0 seconds .
2023-01-27 20:24:39,925 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 496 bytes saved in 0 seconds .
2023-01-27 20:24:39,928 [Time-limited test] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(202)) - Going to retain 1 images with txid >= 0
2023-01-27 20:24:39,938 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:24:39,938 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:24:39,938 [Time-limited test] INFO  namenode.NameNode (NameNode.java:createNameNode(1824)) - createNameNode []
2023-01-27 20:24:39,939 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2023-01-27 20:24:39,939 [Time-limited test] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2023-01-27 20:24:39,951 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@d7ba49d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:39,951 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1736)) - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2023-01-27 20:24:39,951 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1758)) - Starting Web-server for hdfs at: http://localhost:0
2023-01-27 20:24:39,951 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:39,953 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:39,955 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:39,957 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:39,957 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-01-27 20:24:39,957 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:39,957 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:39,959 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2023-01-27 20:24:39,959 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2023-01-27 20:24:39,959 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2023-01-27 20:24:39,959 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:39,960 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(1018)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-01-27 20:24:39,960 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 46737
2023-01-27 20:24:39,960 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:39,962 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:39,962 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:39,962 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-27 20:24:39,963 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:39,963 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@273d2650{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:39,964 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@694e4f95{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:39,967 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@652c83cf{hdfs,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:24:39,969 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4d4906cb{HTTP/1.1, (http/1.1)}{localhost:46737}
2023-01-27 20:24:39,969 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @44991ms
2023-01-27 20:24:39,970 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:24:39,985 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@23ce45e3
2023-01-27 20:24:39,985 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:24:39,985 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:24:39,985 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:24:39,985 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:24:39,985 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:24:39,985 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:24:39,986 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:24:39,986 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:39,986 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:24:39,986 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:24:39,986 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:24:39,987 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:24:39
2023-01-27 20:24:39,987 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:24:39,987 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:39,987 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:24:39,987 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:24:39,989 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:24:39,989 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:24:39,989 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:24:39,989 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:24:39,989 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:24:39,989 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:24:39,989 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:24:39,989 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:24:39,989 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:24:39,990 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:24:39,990 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:24:39,990 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:24:39,990 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:24:39,990 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:24:39,990 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:39,990 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:24:39,990 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:24:39,991 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:24:39,991 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:24:39,991 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:24:39,991 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:24:39,992 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:24:39,992 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:24:39,992 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:24:39,992 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:24:39,992 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:24:39,992 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:39,992 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:24:39,993 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:24:39,993 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:24:39,993 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:24:39,993 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:24:39,993 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:24:39,993 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:24:39,993 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:24:39,993 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:24:39,994 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:24:39,994 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:24:39,996 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:39,997 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:39,999 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current
2023-01-27 20:24:39,999 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current
2023-01-27 20:24:39,999 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(734)) - No edit log streams selected.
2023-01-27 20:24:39,999 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(800)) - Planning to load image: FSImageFile(file=/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-01-27 20:24:40,001 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSectionHeader(411)) - Loading 1 INodes.
2023-01-27 20:24:40,002 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(369)) - Successfully loaded 1 inodes
2023-01-27 20:24:40,002 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:waitBlocksMapAndNameCacheUpdateFinished(342)) - Completed update blocks map and name cache, total waiting duration 0ms.
2023-01-27 20:24:40,002 [Time-limited test] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(255)) - Loaded FSImage in 0 seconds.
2023-01-27 20:24:40,002 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(980)) - Loaded image for txid 0 from /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000
2023-01-27 20:24:40,003 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1271)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-01-27 20:24:40,003 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1417)) - Starting log segment at 1
2023-01-27 20:24:40,020 [Time-limited test] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2023-01-27 20:24:40,021 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(836)) - Finished loading FSImage in 26 msecs
2023-01-27 20:24:40,021 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(451)) - RPC server is binding to localhost:0
2023-01-27 20:24:40,021 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(456)) - Enable NameNode state context:false
2023-01-27 20:24:40,021 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:40,022 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:34939
2023-01-27 20:24:40,022 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:40,025 [Time-limited test] INFO  namenode.NameNode (NameNode.java:initialize(893)) - Clients are to use localhost:34939 to access this namenode/service.
2023-01-27 20:24:40,026 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5607)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2023-01-27 20:24:40,093 [Time-limited test] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(166)) - Number of blocks under construction: 0
2023-01-27 20:24:40,094 [Time-limited test] INFO  blockmanagement.DatanodeAdminDefaultMonitor (DatanodeAdminDefaultMonitor.java:processConf(126)) - Initialized the Default Decommission and Maintenance monitor
2023-01-27 20:24:40,095 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(5310)) - initializing replication queues
2023-01-27 20:24:40,095 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(409)) - STATE* Leaving safe mode after 0 secs
2023-01-27 20:24:40,095 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5102)) - Start MarkedDeleteBlockScrubber thread
2023-01-27 20:24:40,096 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(415)) - STATE* Network topology has 0 racks and 0 datanodes
2023-01-27 20:24:40,097 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(417)) - STATE* UnderReplicatedBlocks has 0 blocks
2023-01-27 20:24:40,097 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:40,102 [Thread[Thread-1148,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:24:40,104 [Thread[Thread-1148,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:24:40,104 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3870)) - Total number of blocks            = 0
2023-01-27 20:24:40,104 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:40,104 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3871)) - Number of invalid blocks          = 0
2023-01-27 20:24:40,113 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3872)) - Number of under-replicated blocks = 0
2023-01-27 20:24:40,113 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3873)) - Number of  over-replicated blocks = 0
2023-01-27 20:24:40,113 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:40,115 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3875)) - Number of blocks being written    = 0
2023-01-27 20:24:40,122 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3878)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 26 msec
2023-01-27 20:24:40,128 [Time-limited test] INFO  namenode.NameNode (NameNode.java:startCommonServices(1010)) - NameNode RPC up at: localhost/127.0.0.1:34939
2023-01-27 20:24:40,144 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1383)) - Starting services required for active state
2023-01-27 20:24:40,144 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(857)) - Initializing quota with 12 thread(s)
2023-01-27 20:24:40,145 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(866)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2023-01-27 20:24:40,147 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(326)) - Starting up re-encrypt thread with interval=60000 millisecond.
2023-01-27 20:24:40,148 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2023-01-27 20:24:40,150 [CacheReplicationMonitor(97871013)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-01-27 20:24:40,152 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1769)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1,[DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:40,153 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:40,154 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:40,195 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2023-01-27 20:24:40,195 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:40,196 [Time-limited test] INFO  datanode.BlockScanner (BlockScanner.java:<init>(201)) - Initialized block scanner with targetBytesPerSec 1048576
2023-01-27 20:24:40,196 [Time-limited test] INFO  datanode.DataNode (DataNode.java:<init>(571)) - Configured hostname is 127.0.0.1
2023-01-27 20:24:40,196 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:24:40,196 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1788)) - Starting DataNode with maxLockedMemory = 0
2023-01-27 20:24:40,197 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1551)) - Opened streaming server at /127.0.0.1:41343
2023-01-27 20:24:40,197 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(93)) - Balancing bandwidth is 104857600 bytes/s
2023-01-27 20:24:40,197 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(94)) - Number threads for balancing is 100
2023-01-27 20:24:40,198 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:40,201 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:24:40,203 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:24:40,205 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:24:40,205 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-01-27 20:24:40,206 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:24:40,206 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:24:40,206 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:24:40,206 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 44557
2023-01-27 20:24:40,206 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:24:40,207 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:24:40,207 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:24:40,208 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:24:40,208 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6622c77d{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:24:40,209 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@44d20a96{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:24:40,213 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@a63be64{datanode,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:24:40,214 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@1c1e6074{HTTP/1.1, (http/1.1)}{localhost:44557}
2023-01-27 20:24:40,214 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @45236ms
2023-01-27 20:24:40,227 [Time-limited test] WARN  web.DatanodeHttpServer (RestCsrfPreventionFilterHandler.java:<init>(75)) - Got null for restCsrfPreventionFilter - will not do any filtering.
2023-01-27 20:24:40,229 [Time-limited test] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(306)) - Listening HTTP traffic on /127.0.0.1:45081
2023-01-27 20:24:40,230 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1816)) - dnUserName = rizky
2023-01-27 20:24:40,230 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1817)) - supergroup = supergroup
2023-01-27 20:24:40,230 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:24:40,231 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:39793
2023-01-27 20:24:40,230 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@8bc417e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:24:40,231 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:24:40,237 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initIpcServer(1438)) - Opened IPC server at /127.0.0.1:39793
2023-01-27 20:24:40,252 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(150)) - Refresh request received for nameservices: null
2023-01-27 20:24:40,253 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(211)) - Starting BPOfferServices for nameservices: <default>
2023-01-27 20:24:40,254 [Thread-1181] INFO  datanode.DataNode (BPServiceActor.java:run(877)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34939 starting to offer service
2023-01-27 20:24:40,264 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:24:40,266 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:24:40,289 [Thread-1181] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(382)) - Acknowledging ACTIVE Namenode during handshake Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34939
2023-01-27 20:24:40,290 [Thread-1181] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(356)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2023-01-27 20:24:40,291 [IPC Server handler 2 on default port 34939] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:40,291 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:40,291 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:40,295 [Thread-1181] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:40,295 [Thread-1181] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 is not formatted for namespace 313681503. Formatting...
2023-01-27 20:24:40,296 [Thread-1181] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4e2d2b65-79a0-460a-8124-8cfd89ebb7fe for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 
2023-01-27 20:24:40,328 [Thread-1181] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:24:40,328 [Thread-1181] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 is not formatted for namespace 313681503. Formatting...
2023-01-27 20:24:40,329 [Thread-1181] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7ebaab66-cfeb-4338-96dd-bb696310bdc0 for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 
2023-01-27 20:24:40,363 [Thread-1181] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-1865570562-127.0.1.1-1674825879884
2023-01-27 20:24:40,363 [Thread-1181] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1865570562-127.0.1.1-1674825879884
2023-01-27 20:24:40,364 [Thread-1181] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 and block pool id BP-1865570562-127.0.1.1-1674825879884 is not formatted. Formatting ...
2023-01-27 20:24:40,364 [Thread-1181] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-1865570562-127.0.1.1-1674825879884 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1865570562-127.0.1.1-1674825879884/current
2023-01-27 20:24:40,393 [IPC Server handler 1 on default port 34939] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:40,394 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:40,394 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:40,444 [Thread-1181] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-1865570562-127.0.1.1-1674825879884
2023-01-27 20:24:40,445 [Thread-1181] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1865570562-127.0.1.1-1674825879884
2023-01-27 20:24:40,445 [Thread-1181] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 and block pool id BP-1865570562-127.0.1.1-1674825879884 is not formatted. Formatting ...
2023-01-27 20:24:40,445 [Thread-1181] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-1865570562-127.0.1.1-1674825879884 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1865570562-127.0.1.1-1674825879884/current
2023-01-27 20:24:40,476 [Thread-1181] INFO  datanode.DataNode (DataNode.java:initStorage(2136)) - Setting up storage: nsid=313681503;bpid=BP-1865570562-127.0.1.1-1674825879884;lv=-57;nsInfo=lv=-67;cid=testClusterID;nsid=313681503;c=1674825879884;bpid=BP-1865570562-127.0.1.1-1674825879884;dnuuid=null
2023-01-27 20:24:40,480 [Thread-1181] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1934)) - Generated and persisted new Datanode UUID efa066dc-4257-4c13-bf43-f3ebdaa798e8
2023-01-27 20:24:40,481 [Thread-1181] INFO  fsdataset.RoundRobinVolumeChoosingPolicy (RoundRobinVolumeChoosingPolicy.java:setConf(67)) - Round robin volume choosing policy initialized: dfs.datanode.round-robin-volume-choosing-policy.additional-available-space = 0
2023-01-27 20:24:40,483 [Thread-1181] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-4e2d2b65-79a0-460a-8124-8cfd89ebb7fe
2023-01-27 20:24:40,483 [Thread-1181] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, StorageType: DISK
2023-01-27 20:24:40,484 [Thread-1181] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-7ebaab66-cfeb-4338-96dd-bb696310bdc0
2023-01-27 20:24:40,485 [Thread-1181] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, StorageType: DISK
2023-01-27 20:24:40,485 [Thread-1181] INFO  impl.MemoryMappableBlockLoader (MemoryMappableBlockLoader.java:initialize(47)) - Initializing cache loader: MemoryMappableBlockLoader.
2023-01-27 20:24:40,486 [Thread-1181] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2611)) - Registered FSDatasetState MBean
2023-01-27 20:24:40,486 [Thread-1181] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(3188)) - Adding block pool BP-1865570562-127.0.1.1-1674825879884
2023-01-27 20:24:40,487 [Thread-1198] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-1865570562-127.0.1.1-1674825879884 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:40,487 [Thread-1199] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-1865570562-127.0.1.1-1674825879884 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:40,487 [Thread-1199] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1865570562-127.0.1.1-1674825879884/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:40,492 [Thread-1198] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1865570562-127.0.1.1-1674825879884/current, will proceed with Du for space computation calculation, 
2023-01-27 20:24:40,495 [IPC Server handler 4 on default port 34939] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:40,496 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:24:40,496 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:24:40,525 [Thread-1198] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-1865570562-127.0.1.1-1674825879884 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 39ms
2023-01-27 20:24:40,525 [Thread-1199] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-1865570562-127.0.1.1-1674825879884 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 39ms
2023-01-27 20:24:40,526 [Thread-1181] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(538)) - Total time to scan all replicas for block pool BP-1865570562-127.0.1.1-1674825879884: 40ms
2023-01-27 20:24:40,527 [Thread-1202] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-1865570562-127.0.1.1-1674825879884 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:24:40,527 [Thread-1203] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-1865570562-127.0.1.1-1674825879884 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:24:40,527 [Thread-1202] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1865570562-127.0.1.1-1674825879884/current/replicas doesn't exist 
2023-01-27 20:24:40,527 [Thread-1203] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1865570562-127.0.1.1-1674825879884/current/replicas doesn't exist 
2023-01-27 20:24:40,527 [Thread-1202] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-1865570562-127.0.1.1-1674825879884 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 1ms
2023-01-27 20:24:40,527 [Thread-1203] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-1865570562-127.0.1.1-1674825879884 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 1ms
2023-01-27 20:24:40,527 [Thread-1181] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(292)) - Total time to add all replicas to map for block pool BP-1865570562-127.0.1.1-1674825879884: 1ms
2023-01-27 20:24:40,527 [Thread-1181] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:40,528 [Thread-1181] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:40,528 [Thread-1181] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:40,528 [Thread-1181] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:40,537 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-1865570562-127.0.1.1-1674825879884 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:24:40,538 [Thread-1181] WARN  datanode.DirectoryScanner (DirectoryScanner.java:<init>(302)) - dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2023-01-27 20:24:40,538 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-4e2d2b65-79a0-460a-8124-8cfd89ebb7fe): finished scanning block pool BP-1865570562-127.0.1.1-1674825879884
2023-01-27 20:24:40,539 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-4e2d2b65-79a0-460a-8124-8cfd89ebb7fe): no suitable block pools found to scan.  Waiting 1814399998 ms.
2023-01-27 20:24:40,538 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-1865570562-127.0.1.1-1674825879884 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:24:40,540 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-7ebaab66-cfeb-4338-96dd-bb696310bdc0): finished scanning block pool BP-1865570562-127.0.1.1-1674825879884
2023-01-27 20:24:40,541 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-7ebaab66-cfeb-4338-96dd-bb696310bdc0): no suitable block pools found to scan.  Waiting 1814399996 ms.
2023-01-27 20:24:40,538 [Thread-1181] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(367)) - Periodic Directory Tree Verification scan starting in 8138891ms with interval of 21600000ms and throttle limit of -1ms/s
2023-01-27 20:24:40,549 [BP-1865570562-127.0.1.1-1674825879884 heartbeating to localhost/127.0.0.1:34939] INFO  datanode.DataNode (BPServiceActor.java:register(819)) - Block pool BP-1865570562-127.0.1.1-1674825879884 (Datanode Uuid efa066dc-4257-4c13-bf43-f3ebdaa798e8) service to localhost/127.0.0.1:34939 beginning handshake with NN: localhost/127.0.0.1:34939.
2023-01-27 20:24:40,551 [IPC Server handler 3 on default port 34939] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1166)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41343, datanodeUuid=efa066dc-4257-4c13-bf43-f3ebdaa798e8, infoPort=45081, infoSecurePort=0, ipcPort=39793, storageInfo=lv=-57;cid=testClusterID;nsid=313681503;c=1674825879884) storage efa066dc-4257-4c13-bf43-f3ebdaa798e8
2023-01-27 20:24:40,552 [IPC Server handler 3 on default port 34939] INFO  net.NetworkTopology (NetworkTopology.java:add(156)) - Adding a new node: /default-rack/127.0.0.1:41343
2023-01-27 20:24:40,552 [IPC Server handler 3 on default port 34939] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(200)) - Registered DN efa066dc-4257-4c13-bf43-f3ebdaa798e8 (127.0.0.1:41343).
2023-01-27 20:24:40,554 [BP-1865570562-127.0.1.1-1674825879884 heartbeating to localhost/127.0.0.1:34939] INFO  datanode.DataNode (BPServiceActor.java:register(846)) - Block pool BP-1865570562-127.0.1.1-1674825879884 (Datanode Uuid efa066dc-4257-4c13-bf43-f3ebdaa798e8) service to localhost/127.0.0.1:34939 successfully registered with NN: localhost/127.0.0.1:34939.
2023-01-27 20:24:40,556 [BP-1865570562-127.0.1.1-1674825879884 heartbeating to localhost/127.0.0.1:34939] INFO  datanode.DataNode (BPServiceActor.java:offerService(680)) - For namenode localhost/127.0.0.1:34939 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2023-01-27 20:24:40,569 [IPC Server handler 5 on default port 34939] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-4e2d2b65-79a0-460a-8124-8cfd89ebb7fe for DN 127.0.0.1:41343
2023-01-27 20:24:40,569 [ibr-executor-0] INFO  datanode.DataNode (BPServiceActor.java:run(1145)) - Starting IBR Task Handler.
2023-01-27 20:24:40,569 [IPC Server handler 5 on default port 34939] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-7ebaab66-cfeb-4338-96dd-bb696310bdc0 for DN 127.0.0.1:41343
2023-01-27 20:24:40,577 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0xa5ceb4066337a7f3 with lease ID 0x9e8a54e0c87f85e2: Processing first storage report for DS-4e2d2b65-79a0-460a-8124-8cfd89ebb7fe from datanode DatanodeRegistration(127.0.0.1:41343, datanodeUuid=efa066dc-4257-4c13-bf43-f3ebdaa798e8, infoPort=45081, infoSecurePort=0, ipcPort=39793, storageInfo=lv=-57;cid=testClusterID;nsid=313681503;c=1674825879884)
2023-01-27 20:24:40,578 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0xa5ceb4066337a7f3 with lease ID 0x9e8a54e0c87f85e2: from storage DS-4e2d2b65-79a0-460a-8124-8cfd89ebb7fe node DatanodeRegistration(127.0.0.1:41343, datanodeUuid=efa066dc-4257-4c13-bf43-f3ebdaa798e8, infoPort=45081, infoSecurePort=0, ipcPort=39793, storageInfo=lv=-57;cid=testClusterID;nsid=313681503;c=1674825879884), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:40,578 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0xa5ceb4066337a7f3 with lease ID 0x9e8a54e0c87f85e2: Processing first storage report for DS-7ebaab66-cfeb-4338-96dd-bb696310bdc0 from datanode DatanodeRegistration(127.0.0.1:41343, datanodeUuid=efa066dc-4257-4c13-bf43-f3ebdaa798e8, infoPort=45081, infoSecurePort=0, ipcPort=39793, storageInfo=lv=-57;cid=testClusterID;nsid=313681503;c=1674825879884)
2023-01-27 20:24:40,578 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0xa5ceb4066337a7f3 with lease ID 0x9e8a54e0c87f85e2: from storage DS-7ebaab66-cfeb-4338-96dd-bb696310bdc0 node DatanodeRegistration(127.0.0.1:41343, datanodeUuid=efa066dc-4257-4c13-bf43-f3ebdaa798e8, infoPort=45081, infoSecurePort=0, ipcPort=39793, storageInfo=lv=-57;cid=testClusterID;nsid=313681503;c=1674825879884), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:24:40,578 [BP-1865570562-127.0.1.1-1674825879884 heartbeating to localhost/127.0.0.1:34939] INFO  datanode.DataNode (BPServiceActor.java:blockReport(464)) - Successfully sent block report 0xa5ceb4066337a7f3 with lease ID 0x9e8a54e0c87f85e2 to namenode: localhost/127.0.0.1:34939,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msecs to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-01-27 20:24:40,579 [Command processor] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(763)) - Got finalize command for block pool BP-1865570562-127.0.1.1-1674825879884
2023-01-27 20:24:40,607 [IPC Server handler 7 on default port 34939] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:40,608 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:40,611 [IPC Server handler 8 on default port 34939] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:24:40,612 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:24:40,620 [qtp1459605637-1901] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:40 +0000] "OPTIONS /kms/v1/keys HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:24:40,655 [qtp1459605637-1895] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:40,656 [qtp1459605637-1895] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:40,656 [qtp1459605637-1895] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:40,656 [qtp1459605637-1895] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:40,657 [qtp1459605637-1895] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:40,657 [qtp1459605637-1895] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:24:40,657 [qtp1459605637-1895] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:40,658 [qtp1459605637-1895] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:24:40,667 [qtp1459605637-1895] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:40 +0000] "OPTIONS /kms/v1/keys?user.name=rizky HTTP/1.1" 200 520 "-" "Java/1.8.0_352"
2023-01-27 20:24:44,011 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(589)) - Successfully warmed up 0 EDEKs.
2023-01-27 20:24:44,043 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@180a6ddc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(202)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1232ms
No GCs detected
2023-01-27 20:24:44,043 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@d7ba49d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(202)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1253ms
No GCs detected
2023-01-27 20:24:44,067 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@8bc417e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(202)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1284ms
No GCs detected
2023-01-27 20:24:50,999 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@d7ba49d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(202)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1330ms
No GCs detected
2023-01-27 20:24:50,999 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@8bc417e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(202)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1329ms
No GCs detected
2023-01-27 20:24:51,000 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@180a6ddc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(202)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1206ms
No GCs detected
2023-01-27 20:25:04,958 [qtp1459605637-1896] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=CREATE_KEY, key=test_key, user=rizky] UserProvidedMaterial:false Description:test_key
2023-01-27 20:26:06,657 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@d7ba49d] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:run(198)) - Detected pause in JVM or host machine (eg GC): pause of approximately 53210ms
No GCs detected
2023-01-27 20:26:07,115 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@180a6ddc] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:run(198)) - Detected pause in JVM or host machine (eg GC): pause of approximately 53266ms
No GCs detected
2023-01-27 20:26:07,050 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@8bc417e] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:run(198)) - Detected pause in JVM or host machine (eg GC): pause of approximately 53097ms
No GCs detected
2023-01-27 20:28:45,088 [qtp1459605637-1896] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:24:40 +0000] "POST /kms/v1/keys HTTP/1.1" 201 98 "-" "Java/1.8.0_352"
2023-01-27 20:28:45,390 [CacheReplicationMonitor(97871013)] INFO  namenode.FSNamesystem (FSNamesystemLock.java:writeUnlock(339)) - 	Number of suppressed write-lock reports: 0
	Longest write-lock held at 2023-01-27 20:26:06,890+0700 for 56702ms by cacheReplicationMonitorRescan via java.lang.Thread.getStackTrace(Thread.java:1564)
org.apache.hadoop.util.StringUtils.getStackTrace(StringUtils.java:1099)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:319)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:265)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.writeUnlock(FSNamesystem.java:1822)
org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.rescan(CacheReplicationMonitor.java:305)
org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.run(CacheReplicationMonitor.java:189)

	Total suppressed write-lock held time: 0.0
2023-01-27 20:28:45,765 [Time-limited test] WARN  kms.LoadBalancingKMSClientProvider (LoadBalancingKMSClientProvider.java:doOp(184)) - KMS provider at [http://localhost:41783/kms/v1/] threw an IOException: 
java.net.SocketTimeoutException: Read timed out
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
	at java.net.SocketInputStream.read(SocketInputStream.java:171)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:743)
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1595)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1500)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:564)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:540)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.createKeyInternal(KMSClientProvider.java:716)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.createKey(KMSClientProvider.java:724)
	at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:486)
	at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:482)
	at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.doOp(LoadBalancingKMSClientProvider.java:176)
	at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.createKey(LoadBalancingKMSClientProvider.java:482)
	at org.apache.hadoop.crypto.key.KeyProviderExtension.createKey(KeyProviderExtension.java:74)
	at org.apache.hadoop.hdfs.DFSTestUtil.createKey(DFSTestUtil.java:1874)
	at org.apache.hadoop.hdfs.DFSTestUtil.createKey(DFSTestUtil.java:1855)
	at org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:212)
	at org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.setup(TestEncryptionZonesWithKMS.java:64)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:750)
2023-01-27 20:28:46,449 [Time-limited test] ERROR kms.LoadBalancingKMSClientProvider (LoadBalancingKMSClientProvider.java:doOp(208)) - Aborting since the Request has failed with all KMS providers(depending on hadoop.security.kms.client.failover.max.retries=1 setting and numProviders=1) in the group OR the exception is not recoverable
2023-01-27 20:28:46,772 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2159)) - Shutting down the Mini HDFS Cluster
2023-01-27 20:28:46,791 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2208)) - Shutting down DataNode 0
2023-01-27 20:28:46,791 [Time-limited test] INFO  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(430)) - Shutdown has been called
2023-01-27 20:28:46,808 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7a24381d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(395)) - Closing all peers.
2023-01-27 20:28:46,848 [Time-limited test] ERROR datanode.DirectoryScanner (DirectoryScanner.java:shutdown(444)) - interrupted while waiting for masterThread to terminate
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2067)
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1475)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.shutdown(DirectoryScanner.java:442)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdownDirectoryScanner(DataNode.java:1504)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdownPeriodicScanners(DataNode.java:1474)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2441)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2210)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2200)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2179)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2152)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2145)
	at org.apache.hadoop.hdfs.TestEncryptionZones.teardown(TestEncryptionZones.java:225)
	at org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.teardown(TestEncryptionZonesWithKMS.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:750)
2023-01-27 20:28:47,676 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-7ebaab66-cfeb-4338-96dd-bb696310bdc0) exiting.
2023-01-27 20:28:47,676 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(672)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-4e2d2b65-79a0-460a-8124-8cfd89ebb7fe) exiting.
2023-01-27 20:28:48,334 [BP-1865570562-127.0.1.1-1674825879884 heartbeating to localhost/127.0.0.1:34939] WARN  datanode.DataNode (BPServiceActor.java:run(924)) - Ending block pool service for: Block pool BP-1865570562-127.0.1.1-1674825879884 (Datanode Uuid efa066dc-4257-4c13-bf43-f3ebdaa798e8) service to localhost/127.0.0.1:34939
2023-01-27 20:28:48,618 [BP-1865570562-127.0.1.1-1674825879884 heartbeating to localhost/127.0.0.1:34939] INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-1865570562-127.0.1.1-1674825879884 (Datanode Uuid efa066dc-4257-4c13-bf43-f3ebdaa798e8)
2023-01-27 20:28:48,845 [BP-1865570562-127.0.1.1-1674825879884 heartbeating to localhost/127.0.0.1:34939] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(3225)) - Removing block pool BP-1865570562-127.0.1.1-1674825879884
2023-01-27 20:28:49,204 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-1865570562-127.0.1.1-1674825879884] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:28:49,273 [refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-1865570562-127.0.1.1-1674825879884] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(231)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2023-01-27 20:28:52,254 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@a63be64{datanode,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:28:52,494 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@1c1e6074{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:28:52,534 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:28:52,670 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@44d20a96{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:28:52,851 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@6622c77d{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:28:53,486 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2470)) - Waiting up to 30 seconds for transfer threads to complete
2023-01-27 20:28:53,553 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 39793
2023-01-27 20:28:53,625 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:28:53,630 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
2023-01-27 20:28:54,061 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(208)) - Shutting down all async disk service threads
2023-01-27 20:28:54,101 [Time-limited test] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(216)) - All async disk service threads have been shut down
2023-01-27 20:28:54,541 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(186)) - Shutting down all async lazy persist service threads
2023-01-27 20:28:54,596 [Time-limited test] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(193)) - All async lazy persist service threads have been shut down
2023-01-27 20:28:55,071 [Time-limited test] INFO  datanode.DataNode (DataNode.java:shutdown(2559)) - Shutdown complete.
2023-01-27 20:28:55,180 [Time-limited test] WARN  datanode.DataSetLockManager (DataSetLockManager.java:lockLeakCheck(260)) - not open lock leak check func
2023-01-27 20:28:55,196 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2241)) - Shutting down the namenode
2023-01-27 20:28:55,197 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:28:55,360 [Thread[Thread-1148,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:28:55,433 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1467)) - Ending log segment 1, 3
2023-01-27 20:28:55,433 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@106ffcde] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4658)) - LazyPersistFileScrubber was interrupted, exiting
2023-01-27 20:28:55,437 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4ab7a084] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4561)) - NameNodeEditLogRoller was interrupted, exiting
2023-01-27 20:28:55,438 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(801)) - Number of transactions: 4 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 24 9 
2023-01-27 20:28:55,509 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(801)) - Number of transactions: 4 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 51 29 
2023-01-27 20:28:55,652 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000004
2023-01-27 20:28:55,798 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000004
2023-01-27 20:28:56,016 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(276)) - FSEditLogAsync was interrupted, exiting
2023-01-27 20:28:56,135 [CacheReplicationMonitor(97871013)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2023-01-27 20:28:56,307 [Time-limited test] INFO  ipc.Server (Server.java:stop(3639)) - Stopping server on 34939
2023-01-27 20:28:56,297 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(335)) - Re-encrypt handler interrupted. Exiting
2023-01-27 20:28:56,155 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(267)) - Re-encryption updater thread interrupted. Exiting.
2023-01-27 20:28:56,329 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1551)) - Stopping IPC Server listener on 0
2023-01-27 20:28:56,330 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1684)) - Stopping IPC Server Responder
====> TEST TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2023-01-27 08:28:55,433

"qtp1459605637-1900" daemon prio=5 tid=1900 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"IPC Server listener on 0" daemon prio=5 tid=1940 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1525)
"Block report processor" daemon prio=5 tid=1936 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.processQueue(BlockManager.java:5432)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.run(BlockManager.java:5419)
"org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner" daemon prio=5 tid=28 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:4143)
        at java.lang.Thread.run(Thread.java:750)
"pool-348-thread-1"  prio=5 tid=1929 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.hdfs.PeerCache@15779044" daemon prio=10 tid=1687 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.PeerCache.run(PeerCache.java:253)
        at org.apache.hadoop.hdfs.PeerCache.access$000(PeerCache.java:46)
        at org.apache.hadoop.hdfs.PeerCache$1.run(PeerCache.java:124)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 34939" daemon prio=5 tid=1954 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"AsyncAppender-Dispatcher-Thread-57" daemon prio=5 tid=86 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
        at java.lang.Thread.run(Thread.java:750)
"Timer for 'KMS' metrics system" daemon prio=5 tid=1907 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 4 on default port 34939" daemon prio=5 tid=1956 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1672 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 34939" daemon prio=5 tid=1960 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"SSL Certificates Store Monitor" daemon prio=5 tid=591 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"Socket Reader #1 for port 0" daemon prio=5 tid=1941 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1463)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1442)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"qtp1459605637-1898" daemon prio=5 tid=1898 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 34939" daemon prio=5 tid=1942 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 3 on default port 34939" daemon prio=5 tid=1955 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"MarkedDeleteBlockScrubberThread" daemon prio=5 tid=1933 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$MarkedDeleteBlockScrubber.run(BlockManager.java:5132)
        at java.lang.Thread.run(Thread.java:750)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=11 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:284)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
        at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
        at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
        at java.io.InputStreamReader.read(InputStreamReader.java:184)
        at java.io.Reader.read(Reader.java:100)
        at java.util.Scanner.readInput(Scanner.java:804)
        at java.util.Scanner.findWithinHorizon(Scanner.java:1685)
        at java.util.Scanner.hasNextLine(Scanner.java:1500)
        at org.apache.maven.surefire.booter.PpidChecker$ProcessInfoConsumer.execute(PpidChecker.java:354)
        at org.apache.maven.surefire.booter.PpidChecker.unix(PpidChecker.java:190)
        at org.apache.maven.surefire.booter.PpidChecker.isProcessAlive(PpidChecker.java:123)
        at org.apache.maven.surefire.booter.ForkedBooter$2.run(ForkedBooter.java:214)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 34939" daemon prio=5 tid=1958 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1744 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=44 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"pool-355-thread-1"  prio=5 tid=1962 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=34 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1459605637-1899" daemon prio=5 tid=1899 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=295 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"qtp1459605637-1894" daemon prio=5 tid=1894 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Thread[Thread-1116,5,main]" daemon prio=5 tid=1906 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$ExpiredTokenRemover.run(AbstractDelegationTokenSecretManager.java:797)
        at java.lang.Thread.run(Thread.java:750)
"main"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1615)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:87)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:73)
        at org.apache.hadoop.test.TimedOutTestsListener.testFailure(TimedOutTestsListener.java:62)
        at org.junit.runner.notification.SynchronizedRunListener.testFailure(SynchronizedRunListener.java:94)
        at org.junit.runner.notification.RunNotifier$6.notifyListener(RunNotifier.java:177)
        at org.junit.runner.notification.RunNotifier$SafeNotifier.run(RunNotifier.java:72)
        at org.junit.runner.notification.RunNotifier.fireTestFailures(RunNotifier.java:173)
        at org.junit.runner.notification.RunNotifier.fireTestFailure(RunNotifier.java:167)
        at org.apache.maven.surefire.common.junit4.Notifier.fireTestFailure(Notifier.java:114)
        at org.junit.internal.runners.model.EachTestNotifier.addFailure(EachTestNotifier.java:23)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:370)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
        at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
        at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1306 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@d7ba49d" daemon prio=5 tid=1917 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:189)
        at java.lang.Thread.run(Thread.java:750)
"reencryptionUpdaterThread #0" daemon prio=5 tid=1965 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ExecutorCompletionService.take(ExecutorCompletionService.java:193)
        at org.apache.hadoop.hdfs.server.namenode.ReencryptionUpdater.takeAndProcessTasks(ReencryptionUpdater.java:425)
        at org.apache.hadoop.hdfs.server.namenode.ReencryptionUpdater.run(ReencryptionUpdater.java:265)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1379 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1127 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@180a6ddc" daemon prio=5 tid=1908 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:189)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1009 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"qtp626555619-1927" daemon prio=5 tid=1927 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=772 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor" daemon prio=5 tid=1996 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor$CommandProcessingThread.processQueue(BPServiceActor.java:1425)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor$CommandProcessingThread.run(BPServiceActor.java:1409)
"SSL Certificates Store Monitor" daemon prio=5 tid=950 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"Session-HouseKeeper-3dab963-1"  prio=5 tid=1928 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp626555619-1920" daemon prio=5 tid=1920 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Time-limited test" daemon prio=5 tid=1892 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync$SyncEdit.logSyncWait(FSEditLogAsync.java:340)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.logSyncAll(FSEditLogAsync.java:162)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.endCurrentLogSegment(FSEditLog.java:1477)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.close(FSEditLog.java:409)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.close(FSEditLogAsync.java:122)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.stopActiveServices(FSNamesystem.java:1528)
        at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.stopActiveServices(NameNode.java:2159)
        at org.apache.hadoop.hdfs.server.namenode.ha.ActiveState.exitState(ActiveState.java:70)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.stop(NameNode.java:1203)
        at org.apache.hadoop.hdfs.MiniDFSCluster.stopAndJoinNameNode(MiniDFSCluster.java:2242)
        at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2182)
        at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2152)
        at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2145)
        at org.apache.hadoop.hdfs.TestEncryptionZones.teardown(TestEncryptionZones.java:225)
        at org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.teardown(TestEncryptionZonesWithKMS.java:69)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
        at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
        at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)
        at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=172 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DatanodeAdminMonitor-0" daemon prio=5 tid=1948 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp626555619-1921" daemon prio=5 tid=1921 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1459605637-1901" daemon prio=5 tid=1901 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1459605637-1897-acceptor-0@776930db-ServerConnector@4ed0bb3d{HTTP/1.1, (http/1.1)}{localhost:41783}" daemon prio=3 tid=1897 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=1944 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 34939" daemon prio=5 tid=1952 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=173 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"kms-audit_thread" daemon prio=5 tid=1904 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1126 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1459605637-1895" daemon prio=5 tid=1895 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1671 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"AsyncAppender-Dispatcher-Thread-80" daemon prio=5 tid=123 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
        at java.lang.Thread.run(Thread.java:750)
"qtp626555619-1925" daemon prio=5 tid=1925 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"RedundancyMonitor" daemon prio=5 tid=1932 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:5157)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=1943 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1699)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1682)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"pool-341-thread-1"  prio=5 tid=1903 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=832 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1305 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"reencryptionHandlerThread #0" daemon prio=5 tid=1964 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler.run(ReencryptionHandler.java:331)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp626555619-1924-acceptor-0@5ef30f1b-ServerConnector@4d4906cb{HTTP/1.1, (http/1.1)}{localhost:46737}" daemon prio=3 tid=1924 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"process reaper" daemon prio=10 tid=147 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.UNIXProcess.waitForProcessExit(Native Method)
        at java.lang.UNIXProcess.lambda$initStreams$3(UNIXProcess.java:289)
        at java.lang.UNIXProcess$$Lambda$7/296289559.run(Unknown Source)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-77ea7569-1"  prio=5 tid=1902 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Connector-Scheduler-4ed0bb3d-1"  prio=5 tid=2032 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 34939" daemon prio=5 tid=1959 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"qtp626555619-1926" daemon prio=5 tid=1926 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FSEditLogAsync" daemon prio=5 tid=1939 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileOutputStream.2023-01-27 20:28:56,364 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5134)) - Stopping MarkedDeleteBlockScrubber.
2023-01-27 20:28:56,364 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(5160)) - Stopping RedundancyMonitor.
2023-01-27 20:28:56,407 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:28:56,500 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:28:57,171 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@652c83cf{hdfs,/,null,STOPPED}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:29:02,238 [pool-341-thread-1] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'CREATE' ACL '*'
2023-01-27 20:29:07,144 [pool-341-thread-1] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DELETE' ACL '*'
2023-01-27 20:29:40,738 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@180a6ddc] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:run(198)) - Detected pause in JVM or host machine (eg GC): pause of approximately 32899ms
No GCs detected
2023-01-27 20:30:12,145 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4d4906cb{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:31:53,446 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:30:11,207 [pool-341-thread-1] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'ROLLOVER' ACL '*'
2023-01-27 20:31:53,596 [pool-341-thread-1] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET' ACL '*'
2023-01-27 20:31:53,597 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@694e4f95{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,STOPPED}
2023-01-27 20:31:53,438 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@180a6ddc] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:run(198)) - Detected pause in JVM or host machine (eg GC): pause of approximately 53293ms
No GCs detected
2023-01-27 20:31:53,597 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@273d2650{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:31:53,597 [pool-341-thread-1] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_KEYS' ACL '*'
2023-01-27 20:31:53,613 [pool-341-thread-1] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_METADATA' ACL '*'
2023-01-27 20:31:53,613 [pool-341-thread-1] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'SET_KEY_MATERIAL' ACL '*'
2023-01-27 20:31:53,613 [pool-341-thread-1] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GENERATE_EEK' ACL '*'
2023-01-27 20:31:53,613 [pool-341-thread-1] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DECRYPT_EEK' ACL '*'
writeBytes(Native Method)
        at java.io.FileOutputStream.write(FileOutputStream.java:326)
        at java.io.ByteArrayOutputStream.writeTo(ByteArrayOutputStream.java:167)
        at org.apache.hadoop.io.DataOutputBuffer.writeTo(DataOutputBuffer.java:142)
        at org.apache.hadoop.hdfs.server.namenode.EditsDoubleBuffer.flushTo(EditsDoubleBuffer.java:95)
        at org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream.flushAndSync(EditLogFileOutputStream.java:211)
        at org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream.flush(EditLogOutputStream.java:126)
        at org.apache.hadoop.hdfs.server.namenode.EditLogOutputStream.flush(EditLogOutputStream.java:120)
        at org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalSetOutputStream$8.apply(JournalSet.java:547)
        at org.apache.hadoop.hdfs.server.namenode.JournalSet.mapJournalsAndReportErrors(JournalSet.java:393)
        at org.apache.hadoop.hdfs.server.namenode.JournalSet.access$200(JournalSet.java:56)
        at org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalSetOutputStream.flush(JournalSet.java:543)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLog.logSync(FSEditLog.java:737)
        at org.apache.hadoop.hdfs.server.namenode.FSEditLogAsync.run(FSEditLogAsync.java:266)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=771 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@58928ef3" daemon prio=5 tid=1947 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:267)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=474 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"IPC Server handler 9 on default port 34939" daemon prio=5 tid=1961 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"qtp1459605637-1896" daemon prio=5 tid=1896 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ForkJoinPool-2-worker-2" daemon prio=5 tid=155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)
"qtp626555619-1923" daemon prio=5 tid=1923 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1918 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"CacheReplicationMonitor(97871013)" daemon prio=5 tid=1970 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.run(CacheReplicationMonitor.java:181)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=10 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readInt(DataInputStream.java:387)
        at org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:115)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:390)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 34939" daemon prio=5 tid=1957 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:188)
"org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@2b3c6d63" daemon prio=5 tid=1934 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor.run(HeartbeatManager.java:558)
        at java.lang.Thread.run(Thread.java:750)
"qtp626555619-1922" daemon prio=5 tid=1922 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"pool-340-thread-1"  prio=5 tid=1893 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=652 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"IPC Server handler 1 on default port 34939" daemon prio=5 tid=1953 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"pool-347-thread-1"  prio=5 tid=1919 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

====> TEST TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2023-01-27 08:31:53,597

"qtp1459605637-1900" daemon prio=5 tid=1900 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner" daemon prio=5 tid=28 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:4143)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.hdfs.PeerCache@15779044" daemon prio=10 tid=1687 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.PeerCache.run(PeerCache.java:253)
        at org.apache.hadoop.hdfs.PeerCache.access$000(PeerCache.java:46)
        at org.apache.hadoop.hdfs.PeerCache$1.run(PeerCache.java:124)
        at java.lang.Thread.run(Thread.java:750)
"AsyncAppender-Dispatcher-Thread-57" daemon prio=5 tid=86 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
        at java.lang.Thread.run(Thread.java:750)
"Timer for 'KMS' metrics system" daemon prio=5 tid=1907 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1672 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=591 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"qtp1459605637-1898" daemon prio=5 tid=1898 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=11 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:284)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
        at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
        at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
        at java.io.InputStreamReader.read(InputStreamReader.java:184)
        at java.io.Reader.read(Reader.java:100)
        at java.util.Scanner.readInput(Scanner.java:804)
        at java.util.Scanner.findWithinHorizon(Scanner.java:1685)
        at java.util.Scanner.hasNextLine(Scanner.java:1500)
        at org.apache.maven.surefire.booter.PpidChecker$ProcessInfoConsumer.execute(PpidChecker.java:354)
        at org.apache.maven.surefire.booter.PpidChecker.unix(PpidChecker.java:190)
        at org.apache.maven.surefire.booter.PpidChecker.isProcessAlive(PpidChecker.java:123)
        at org.apache.maven.surefire.booter.ForkedBooter$2.run(ForkedBooter.java:214)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1744 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=44 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"SSL Certificates Store Monitor" daemon prio=5 tid=34 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1459605637-1899" daemon prio=5 tid=1899 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=295 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"qtp1459605637-1894" daemon prio=5 tid=1894 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Thread[Thread-1116,5,main]" daemon prio=5 tid=1906 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$ExpiredTokenRemover.run(AbstractDelegationTokenSecretManager.java:797)
        at java.lang.Thread.run(Thread.java:750)
"main"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1615)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:87)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:73)
        at org.apache.hadoop.test.TimedOutTestsListener.testFailure(TimedOutTestsListener.java:62)
        at org.junit.runner.notification.SynchronizedRunListener.testFailure(SynchronizedRunListener.java:94)
        at org.junit.runner.notification.RunNotifier$6.notifyListener(RunNotifier.java:177)
        at org.junit.runner.notification.RunNotifier$SafeNotifier.run(RunNotifier.java:72)
        at org.junit.runner.notification.RunNotifier.fireTestFailures(RunNotifier.java:173)
        at org.junit.runner.notification.RunNotifier.fireTestFailure(RunNotifier.java:167)
        at org.apache.maven.surefire.common.junit4.Notifier.fireTestFailure(Notifier.java:114)
        at org.junit.internal.runners.model.EachTestNotifier.addFailure(EachTestNotifier.java:23)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:370)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
        at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
        at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1306 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1379 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1127 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@180a6ddc" daemon prio=5 tid=1908 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:189)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1009 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"qtp626555619-1927" daemon prio=5 tid=1927 terminated
java.lang.Thread.State: TERMINATED
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=772 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor" daemon prio=5 tid=1996 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor$CommandProcessingThread.processQueue(BPServiceActor.java:1425)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor$CommandProcessingThread.run(BPServiceActor.java:1409)
"SSL Certificates Store Monitor" daemon prio=5 tid=950 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"Session-HouseKeeper-3dab963-1"  prio=5 tid=1928 terminated
java.lang.Thread.State: TERMINATED
"qtp626555619-1920" daemon prio=5 tid=1920 terminated
java.lang.Thread.State: TERMINATED
"Time-limited test" daemon prio=5 tid=1892 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Object.wait(Native Method)
        at java.lang.Thread.join(Thread.java:1265)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.joinThreads(QueuedThreadPool.java:320)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.doStop(QueuedThreadPool.java:244)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:94)
        at org.eclipse.jetty.util.component.ContainerLifeCycle.stop(ContainerLifeCycle.java:180)
        at org.eclipse.jetty.util.component.ContainerLifeCycle.doStop(ContainerLifeCycle.java:201)
        at org.eclipse.jetty.server.handler.AbstractHandler.doStop(AbstractHandler.java:108)
        at org.eclipse.jetty.server.Server.doStop(Server.java:470)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:94)
        at org.apache.hadoop.http.HttpServer2.stop(HttpServer2.java:1577)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.stop(NameNodeHttpServer.java:197)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.stopHttpServer(NameNode.java:1075)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.stopCommonServices(NameNode.java:1030)
        at org.apache.hadoop.hdfs.server.namenode.NameNode.stop(NameNode.java:1209)
        at org.apache.hadoop.hdfs.MiniDFSCluster.stopAndJoinNameNode(MiniDFSCluster.java:2242)
        at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2182)
        at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2152)
        at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2145)
        at org.apache.hadoop.hdfs.TestEncryptionZones.teardown(TestEncryptionZones.java:225)
        at org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.teardown(TestEncryptionZonesWithKMS.java:69)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
        at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
        at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)
        at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=172 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp626555619-1921" daemon prio=5 tid=1921 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1459605637-1901" daemon prio=5 tid=1901 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1459605637-1897-acceptor-0@776930db-ServerConnector@4ed0bb3d{HTTP/1.1, (http/1.1)}{localhost:41783}" daemon prio=3 tid=1897 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"Time-limited test" daemon prio=5 tid=2074 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.UnixFileSystem.getBooleanAttributes0(Native Method)
        at java.io.UnixFileSystem.getBooleanAttributes(UnixFileSystem.java:247)
        at java.io.File.exists(File.java:830)
        at sun.misc.URLClassPath$FileLoader.getResource(URLClassPath.java:1391)
        at sun.misc.URLClassPath$FileLoader.findResource(URLClassPath.java:1358)
        at sun.misc.URLClassPath.findResource(URLClassPath.java:226)
        at java.net.URLClassLoader$2.run(URLClassLoader.java:577)
        at java.net.URLClassLoader$2.run(URLClassLoader.java:575)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findResource(URLClassLoader.java:574)
        at java.lang.ClassLoader.getResource(ClassLoader.java:1089)
        at org.apache.hadoop.conf.Configuration.getResource(Configuration.java:2861)
        at org.apache.hadoop.conf.Configuration.getStreamReader(Configuration.java:3135)
        at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3094)
        at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:3067)
        at org.apache.hadoop.conf.Configuration.loadProps(Configuration.java:2945)
        at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2927)
        at org.apache.hadoop.conf.Configuration.handleDeprecation(Configuration.java:779)
        at org.apache.hadoop.conf.Configuration.asXmlDocument(Configuration.java:3643)
        at org.apache.hadoop.conf.Configuration.writeXml(Configuration.java:3603)
        at org.apache.hadoop.conf.Configuration.writeXml(Configuration.java:3622)
        at org.apache.hadoop.conf.Configuration.writeXml(Configuration.java:3572)
        at org.apache.hadoop.crypto.key.kms.server.MiniKMS.start(MiniKMS.java:124)
        at org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.setup(TestEncryptionZonesWithKMS.java:63)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
        at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)
        at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=173 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"kms-audit_thread" daemon prio=5 tid=1904 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1126 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1459605637-1895" daemon prio=5 tid=1895 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1671 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        a2023-01-27 20:31:53,679 [pool-341-thread-1] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2023-01-27 20:31:53,730 [pool-341-thread-1] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2023-01-27 20:31:53,730 [pool-341-thread-1] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2023-01-27 20:31:53,730 [pool-341-thread-1] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2023-01-27 20:31:54,005 [Thread[Thread-1116,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(799)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2023-01-27 20:31:54,018 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextDestroyed(197)) - KMS Stopped
2023-01-27 20:31:54,035 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@7cd0ee94{kms,/,null,STOPPED}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:31:54,036 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4ed0bb3d{HTTP/1.1, (http/1.1)}{localhost:0}
2023-01-27 20:31:54,036 [Time-limited test] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-27 20:31:54,037 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4c4be33c{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-27 20:31:54,037 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@6480b952{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,STOPPED}
2023-01-27 20:31:54,059 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2023-01-27 20:31:54,064 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2023-01-27 20:31:54,064 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(612)) - DataNode metrics system shutdown complete.
2023-01-27 20:31:54,157 [Time-limited test] ERROR conf.Configuration (Configuration.java:loadResource(3122)) - error parsing conf file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/c57319b9-93d4-4dfc-b06f-45b711f31e0c/core-site.xml
com.ctc.wstx.exc.WstxEOFException: Unexpected EOF in prolog
 at [row,col,system-id]: [1,0,"file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/c57319b9-93d4-4dfc-b06f-45b711f31e0c/core-site.xml"]
	at com.ctc.wstx.sr.StreamScanner.throwUnexpectedEOF(StreamScanner.java:701)
	at com.ctc.wstx.sr.BasicStreamReader.handleEOF(BasicStreamReader.java:2217)
	at com.ctc.wstx.sr.BasicStreamReader.nextFromProlog(BasicStreamReader.java:2123)
	at com.ctc.wstx.sr.BasicStreamReader.next(BasicStreamReader.java:1179)
	at org.apache.hadoop.conf.Configuration$Parser.parseNext(Configuration.java:3427)
	at org.apache.hadoop.conf.Configuration$Parser.parse(Configuration.java:3213)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3106)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:3072)
	at org.apache.hadoop.conf.Configuration.loadProps(Configuration.java:2945)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2927)
	at org.apache.hadoop.conf.Configuration.set(Configuration.java:1431)
	at org.apache.hadoop.conf.Configuration.set(Configuration.java:1403)
	at org.apache.hadoop.crypto.key.kms.server.MiniKMS.start(MiniKMS.java:140)
	at org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.setup(TestEncryptionZonesWithKMS.java:63)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:750)
2023-01-27 20:31:54,400 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:31:54,400 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context kms
2023-01-27 20:31:54,400 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:31:54,400 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:31:54,400 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:31:54,497 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 36139
2023-01-27 20:31:54,499 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:31:54,514 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:31:54,515 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:31:54,515 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:31:54,525 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@538cbbd3{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:31:54,526 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@50642978{static,/static,jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-27 20:31:54,811 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(94)) - -------------------------------------------------------------
2023-01-27 20:31:54,811 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(95)) -   Java runtime version : 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:31:54,811 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(97)) -   User: rizky
2023-01-27 20:31:54,811 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(98)) -   KMS Hadoop Version: 3.4.0-SNAPSHOT
2023-01-27 20:31:54,811 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(99)) - -------------------------------------------------------------
2023-01-27 20:31:54,817 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'CREATE' ACL '*'
2023-01-27 20:31:54,818 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DELETE' ACL '*'
2023-01-27 20:31:54,818 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'ROLLOVER' ACL '*'
2023-01-27 20:31:54,818 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET' ACL '*'
2023-01-27 20:31:54,818 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_KEYS' ACL '*'
2023-01-27 20:31:54,818 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GET_METADATA' ACL '*'
2023-01-27 20:31:54,818 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'SET_KEY_MATERIAL' ACL '*'
2023-01-27 20:31:54,818 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'GENERATE_EEK' ACL '*'
2023-01-27 20:31:54,818 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(112)) - 'DECRYPT_EEK' ACL '*'
2023-01-27 20:31:54,819 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2023-01-27 20:31:54,819 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2023-01-27 20:31:54,819 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2023-01-27 20:31:54,819 [Time-limited test] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(190)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2023-01-27 20:31:54,844 [Time-limited test] INFO  server.KMSAudit (KMSAudit.java:initializeAuditLoggers(157)) - Initializing audit logger class org.apache.hadoop.crypto.key.kms.server.SimpleKMSAuditLogger
2023-01-27 20:31:54,846 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(149)) - Initialized KeyProvider CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/c57319b9-93d4-4dfc-b06f-45b711f31e0c/kms.keystore
2023-01-27 20:31:54,847 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(163)) - Initialized KeyProviderCryptoExtension org.apache.hadoop.crypto.key.kms.server.KeyAuthorizationKeyProvider: EagerKeyGeneratorKeyProviderCryptoExtension: KeyProviderCryptoExtension: CachingKeyProvider: jceks://file@/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/c57319b9-93d4-4dfc-b06f-45b711f31e0c/kms.keystore
2023-01-27 20:31:54,848 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(168)) - Default key bitlength is 128
2023-01-27 20:31:54,848 [Time-limited test] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(169)) - KMS Started
2023-01-27 20:31:54,856 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:31:54,857 [Thread[Thread-1219,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:31:54,858 [Time-limited test] INFO  core.PackagesResourceConfig (PackagesResourceConfig.java:init(101)) - Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.crypto.key.kms.server
2023-01-27 20:31:54,870 [Thread[Thread-1219,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:31:54,899 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Root resource classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMS
2023-01-27 20:31:54,899 [Time-limited test] INFO  core.ScanningResourceConfig (ScanningResourceConfig.java:logClasses(153)) - Provider classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
  class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
2023-01-27 20:31:54,926 [Time-limited test] INFO  application.WebApplicationImpl (WebApplicationImpl.java:_initiate(815)) - Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
2023-01-27 20:31:55,114 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@5060d527{kms,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/2/kms/webapp/,AVAILABLE}{jar:file:/home/rizky/.m2/repository/org/apache/hadoop/hadoop-kms/3.4.0-SNAPSHOT/hadoop-kms-3.4.0-SNAPSHOT.jar!/webapps/kms}
2023-01-27 20:31:55,128 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@43f7749{HTTP/1.1, (http/1.1)}{localhost:36139}
2023-01-27 20:31:55,128 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @480150ms
2023-01-27 20:31:55,160 [Time-limited test] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(120)) - Loaded properties from hadoop-metrics2.properties
2023-01-27 20:31:55,172 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 0 second(s).
2023-01-27 20:31:55,172 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - KMS metrics system started
2023-01-27 20:31:55,220 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@66220d5c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:31:55,234 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(566)) - starting cluster: numNameNodes=1, numDataNodes=1
2023-01-27 20:31:55,240 [Time-limited test] INFO  namenode.NameNode (NameNode.java:format(1366)) - Formatting using clusterid: testClusterID
2023-01-27 20:31:55,241 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:31:55,250 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@6f559d6
2023-01-27 20:31:55,251 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:31:55,251 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:31:55,251 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:31:55,251 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:31:55,251 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:31:55,251 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:31:55,251 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:31:55,252 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:31:55,252 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:31:55,252 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:31:55,252 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:31:55,253 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:31:55
2023-01-27 20:31:55,253 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:31:55,253 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:31:55,253 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:31:55,253 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:31:55,254 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:31:55,255 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:31:55,255 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:31:55,255 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:31:55,255 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:31:55,255 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:31:55,256 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:31:55,256 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:31:55,256 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:31:55,256 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:31:55,256 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:31:55,256 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:31:55,256 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:31:55,257 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:31:55,257 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:31:55,257 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:31:55,257 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:31:55,258 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:31:55,258 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:31:55,258 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:31:55,258 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:31:55,258 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:31:55,259 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:31:55,259 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:31:55,259 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:31:55,259 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:31:55,259 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:31:55,259 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:31:55,260 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:31:55,260 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:31:55,260 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:31:55,260 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:31:55,261 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:31:55,261 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:31:55,261 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:31:55,261 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:31:55,261 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:31:55,261 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:31:55,262 [Time-limited test] INFO  namenode.FSImage (FSImage.java:format(186)) - Allocated new BlockPoolId: BP-13373003-127.0.1.1-1674826315262
2023-01-27 20:31:55,270 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 has been successfully formatted.
2023-01-27 20:31:55,278 [Time-limited test] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 has been successfully formatted.
2023-01-27 20:31:55,291 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:31:55,296 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(732)) - Saving image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2023-01-27 20:31:55,297 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 496 bytes saved in 0 seconds .
2023-01-27 20:31:55,300 [FSImageSaver for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(736)) - Image file /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 496 bytes saved in 0 seconds .
2023-01-27 20:31:55,305 [Time-limited test] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(202)) - Going to retain 1 images with txid >= 0
2023-01-27 20:31:55,314 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1500)) - Stopping services started for active state
2023-01-27 20:31:55,315 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1604)) - Stopping services started for standby state
2023-01-27 20:31:55,315 [Time-limited test] INFO  namenode.NameNode (NameNode.java:createNameNode(1824)) - createNameNode []
2023-01-27 20:31:55,316 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2023-01-27 20:31:55,316 [Time-limited test] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2023-01-27 20:31:55,326 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@178dfb78] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:31:55,326 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1736)) - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2023-01-27 20:31:55,327 [Time-limited test] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1758)) - Starting Web-server for hdfs at: http://localhost:0
2023-01-27 20:31:55,331 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:31:55,333 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:31:55,335 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:31:55,336 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:31:55,336 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2023-01-27 20:31:55,336 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:31:55,336 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:31:55,337 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2023-01-27 20:31:55,337 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2023-01-27 20:31:55,337 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2023-01-27 20:31:55,337 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:31:55,338 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(1018)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2023-01-27 20:31:55,338 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 34381
2023-01-27 20:31:55,338 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:31:55,344 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:31:55,345 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:31:55,345 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:31:55,348 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:31:55,349 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@222a5cb1{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:31:55,350 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1b346ad3{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:31:55,354 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@fa93e0{hdfs,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs}
2023-01-27 20:31:55,355 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@12c89cd7{HTTP/1.1, (http/1.1)}{localhost:34381}
2023-01-27 20:31:55,355 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @480377ms
2023-01-27 20:31:55,356 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(238)) - Edit logging is async:true
2023-01-27 20:31:55,369 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(864)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@5f6e61b
2023-01-27 20:31:55,369 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(142)) - fsLock is fair: true
2023-01-27 20:31:55,369 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(160)) - Detailed lock hold time metrics enabled: false
2023-01-27 20:31:55,370 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(903)) - fsOwner                = rizky (auth:SIMPLE)
2023-01-27 20:31:55,370 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(904)) - supergroup             = supergroup
2023-01-27 20:31:55,370 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(905)) - isPermissionEnabled    = true
2023-01-27 20:31:55,370 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(906)) - isStoragePolicyEnabled = true
2023-01-27 20:31:55,370 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(917)) - HA Enabled: false
2023-01-27 20:31:55,370 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:31:55,370 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:setBlockInvalidateLimit(2146)) - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2023-01-27 20:31:55,370 [Time-limited test] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(323)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2023-01-27 20:31:55,370 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(77)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2023-01-27 20:31:55,371 [Time-limited test] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(83)) - The block deletion will start around 2023 Jan 27 20:31:55
2023-01-27 20:31:55,371 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map BlocksMap
2023-01-27 20:31:55,371 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:31:55,371 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 2.0% max memory 1.8 GB = 36.4 MB
2023-01-27 20:31:55,371 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^22 = 4194304 entries
2023-01-27 20:31:55,372 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5583)) - Storage policy satisfier is disabled
2023-01-27 20:31:55,372 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(676)) - dfs.block.access.token.enable = false
2023-01-27 20:31:55,372 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(656)) - Using 1000 as SafeModeMonitor Interval
2023-01-27 20:31:55,372 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.999
2023-01-27 20:31:55,373 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2023-01-27 20:31:55,373 [Time-limited test] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2023-01-27 20:31:55,373 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(662)) - defaultReplication         = 1
2023-01-27 20:31:55,373 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(663)) - maxReplication             = 512
2023-01-27 20:31:55,373 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(664)) - minReplication             = 1
2023-01-27 20:31:55,373 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(665)) - maxReplicationStreams      = 2
2023-01-27 20:31:55,373 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(666)) - redundancyRecheckInterval  = 3000ms
2023-01-27 20:31:55,373 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(667)) - encryptDataTransfer        = false
2023-01-27 20:31:55,373 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:printInitialConfigs(668)) - maxNumBlocksToLog          = 1000
2023-01-27 20:31:55,373 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map INodeMap
2023-01-27 20:31:55,373 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:31:55,373 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 1.0% max memory 1.8 GB = 18.2 MB
2023-01-27 20:31:55,373 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^21 = 2097152 entries
2023-01-27 20:31:55,374 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(339)) - ACLs enabled? true
2023-01-27 20:31:55,374 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(343)) - POSIX ACL inheritance enabled? true
2023-01-27 20:31:55,375 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:<init>(347)) - XAttrs enabled? true
2023-01-27 20:31:55,375 [Time-limited test] INFO  namenode.NameNode (FSDirectory.java:<init>(414)) - Caching file names occurring more than 10 times
2023-01-27 20:31:55,375 [Time-limited test] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2023-01-27 20:31:55,375 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(163)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotFSLimit: 65536, maxSnapshotLimit: 65536
2023-01-27 20:31:55,375 [Time-limited test] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(176)) - dfs.namenode.snapshot.deletion.ordered = false
2023-01-27 20:31:55,375 [Time-limited test] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2023-01-27 20:31:55,375 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map cachedBlocks
2023-01-27 20:31:55,376 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:31:55,376 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.25% max memory 1.8 GB = 4.6 MB
2023-01-27 20:31:55,376 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^19 = 524288 entries
2023-01-27 20:31:55,376 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2023-01-27 20:31:55,376 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2023-01-27 20:31:55,377 [Time-limited test] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2023-01-27 20:31:55,377 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1149)) - Retry cache on namenode is enabled
2023-01-27 20:31:55,377 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1157)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2023-01-27 20:31:55,377 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(408)) - Computing capacity for map NameNodeRetryCache
2023-01-27 20:31:55,377 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(409)) - VM type       = 64-bit
2023-01-27 20:31:55,377 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(410)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2023-01-27 20:31:55,377 [Time-limited test] INFO  util.GSet (LightWeightGSet.java:computeCapacity(415)) - capacity      = 2^16 = 65536 entries
2023-01-27 20:31:55,393 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:31:55,412 [Time-limited test] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:31:55,413 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current
2023-01-27 20:31:55,414 [Time-limited test] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-2/current
2023-01-27 20:31:55,414 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(734)) - No edit log streams selected.
2023-01-27 20:31:55,414 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(800)) - Planning to load image: FSImageFile(file=/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2023-01-27 20:31:55,416 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSectionHeader(411)) - Loading 1 INodes.
2023-01-27 20:31:55,417 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(369)) - Successfully loaded 1 inodes
2023-01-27 20:31:55,418 [Time-limited test] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:waitBlocksMapAndNameCacheUpdateFinished(342)) - Completed update blocks map and name cache, total waiting duration 0ms.
2023-01-27 20:31:55,418 [Time-limited test] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(255)) - Loaded FSImage in 0 seconds.
2023-01-27 20:31:55,419 [Time-limited test] INFO  namenode.FSImage (FSImage.java:loadFSImage(980)) - Loaded image for txid 0 from /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/name-0-1/current/fsimage_0000000000000000000
2023-01-27 20:31:55,419 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1271)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2023-01-27 20:31:55,420 [Time-limited test] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1417)) - Starting log segment at 1
2023-01-27 20:31:55,474 [Time-limited test] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2023-01-27 20:31:55,475 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(836)) - Finished loading FSImage in 97 msecs
2023-01-27 20:31:55,475 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(451)) - RPC server is binding to localhost:0
2023-01-27 20:31:55,475 [Time-limited test] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(456)) - Enable NameNode state context:false
2023-01-27 20:31:55,475 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:31:55,476 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:36799
2023-01-27 20:31:55,476 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:31:55,478 [Time-limited test] INFO  namenode.NameNode (NameNode.java:initialize(893)) - Clients are to use localhost:36799 to access this namenode/service.
2023-01-27 20:31:55,479 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5607)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2023-01-27 20:31:55,524 [Time-limited test] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(166)) - Number of blocks under construction: 0
2023-01-27 20:31:55,525 [Time-limited test] INFO  blockmanagement.DatanodeAdminDefaultMonitor (DatanodeAdminDefaultMonitor.java:processConf(126)) - Initialized the Default Decommission and Maintenance monitor
2023-01-27 20:31:55,526 [MarkedDeleteBlockScrubberThread] INFO  blockmanagement.BlockManager (BlockManager.java:run(5102)) - Start MarkedDeleteBlockScrubber thread
2023-01-27 20:31:55,527 [Time-limited test] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(5310)) - initializing replication queues
2023-01-27 20:31:55,527 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(409)) - STATE* Leaving safe mode after 0 secs
2023-01-27 20:31:55,528 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(415)) - STATE* Network topology has 0 racks and 0 datanodes
2023-01-27 20:31:55,528 [Time-limited test] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(417)) - STATE* UnderReplicatedBlocks has 0 blocks
2023-01-27 20:31:55,533 [Time-limited test] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:31:55,543 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3870)) - Total number of blocks            = 0
2023-01-27 20:31:55,543 [Thread[Thread-1251,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(778)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2023-01-27 20:31:55,543 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3871)) - Number of invalid blocks          = 0
2023-01-27 20:31:55,544 [Thread[Thread-1251,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(424)) - Updating the current master key for generating delegation tokens
2023-01-27 20:31:55,544 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3872)) - Number of under-replicated blocks = 0
2023-01-27 20:31:55,544 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3873)) - Number of  over-replicated blocks = 0
2023-01-27 20:31:55,544 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3875)) - Number of blocks being written    = 0
2023-01-27 20:31:55,544 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3878)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 17 msec
2023-01-27 20:31:55,547 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:31:55,550 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:31:55,560 [Time-limited test] INFO  namenode.NameNode (NameNode.java:startCommonServices(1010)) - NameNode RPC up at: localhost/127.0.0.1:36799
2023-01-27 20:31:55,562 [Time-limited test] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1383)) - Starting services required for active state
2023-01-27 20:31:55,562 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(857)) - Initializing quota with 12 thread(s)
2023-01-27 20:31:55,563 [Time-limited test] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(866)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0, NVDIMM=0
2023-01-27 20:31:55,564 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(326)) - Starting up re-encrypt thread with interval=60000 millisecond.
2023-01-27 20:31:55,569 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2023-01-27 20:31:55,570 [CacheReplicationMonitor(1471652259)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2023-01-27 20:31:55,578 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1769)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1,[DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:31:55,579 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:31:55,579 [Time-limited test] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:31:55,599 [Time-limited test] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2023-01-27 20:31:55,599 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:31:55,599 [Time-limited test] INFO  datanode.BlockScanner (BlockScanner.java:<init>(201)) - Initialized block scanner with targetBytesPerSec 1048576
2023-01-27 20:31:55,599 [Time-limited test] INFO  datanode.DataNode (DataNode.java:<init>(571)) - Configured hostname is 127.0.0.1
2023-01-27 20:31:55,599 [Time-limited test] INFO  common.Util (Util.java:isDiskStatsEnabled(428)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-01-27 20:31:55,599 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1788)) - Starting DataNode with maxLockedMemory = 0
2023-01-27 20:31:55,600 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1551)) - Opened streaming server at /127.0.0.1:44269
2023-01-27 20:31:55,600 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(93)) - Balancing bandwidth is 104857600 bytes/s
2023-01-27 20:31:55,600 [Time-limited test] INFO  datanode.DataNode (DataXceiverServer.java:<init>(94)) - Number threads for balancing is 100
2023-01-27 20:31:55,601 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:31:55,603 [Time-limited test] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/rizky/hadoop-http-auth-signature-secret
2023-01-27 20:31:55,605 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1279)) - Web server is in development mode. Resources will be read from the source tree.
2023-01-27 20:31:55,606 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1191)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-01-27 20:31:55,607 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1164)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-01-27 20:31:55,607 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-27 20:31:55,607 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1174)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-27 20:31:55,607 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:addAsyncProfilerServlet(804)) - ASYNC_PROFILER_HOME environment variable and async.profiler.home system property not specified. Disabling /prof endpoint.
2023-01-27 20:31:55,608 [Time-limited test] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1434)) - Jetty bound to port 41651
2023-01-27 20:31:55,608 [Time-limited test] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_352-8u352-ga-1~22.04-b08
2023-01-27 20:31:55,609 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-27 20:31:55,609 [Time-limited test] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-27 20:31:55,609 [Time-limited test] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-27 20:31:55,610 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4a40648d{logs,/logs,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2023-01-27 20:31:55,610 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@688455b8{static,/static,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2023-01-27 20:31:55,617 [Time-limited test] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3bc03338{datanode,/,file:///home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode}
2023-01-27 20:31:55,619 [Time-limited test] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@a7214cb{HTTP/1.1, (http/1.1)}{localhost:41651}
2023-01-27 20:31:55,619 [Time-limited test] INFO  server.Server (Server.java:doStart(415)) - Started @480641ms
2023-01-27 20:31:55,622 [Time-limited test] WARN  web.DatanodeHttpServer (RestCsrfPreventionFilterHandler.java:<init>(75)) - Got null for restCsrfPreventionFilter - will not do any filtering.
2023-01-27 20:31:55,624 [Time-limited test] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(306)) - Listening HTTP traffic on /127.0.0.1:42921
2023-01-27 20:31:55,625 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1816)) - dnUserName = rizky
2023-01-27 20:31:55,625 [Time-limited test] INFO  datanode.DataNode (DataNode.java:startDataNode(1817)) - supergroup = supergroup
2023-01-27 20:31:55,626 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1c3541c2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(185)) - Starting JVM pause monitor
2023-01-27 20:31:55,626 [Time-limited test] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(93)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-27 20:31:55,626 [Time-limited test] INFO  ipc.Server (Server.java:<init>(1404)) - Listener at localhost:37555
2023-01-27 20:31:55,631 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1440)) - Starting Socket Reader #1 for port 0
2023-01-27 20:31:55,636 [Time-limited test] INFO  datanode.DataNode (DataNode.java:initIpcServer(1438)) - Opened IPC server at /127.0.0.1:37555
2023-01-27 20:31:55,685 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(150)) - Refresh request received for nameservices: null
2023-01-27 20:31:55,685 [Time-limited test] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(211)) - Starting BPOfferServices for nameservices: <default>
2023-01-27 20:31:55,686 [Thread-1284] INFO  datanode.DataNode (BPServiceActor.java:run(877)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36799 starting to offer service
2023-01-27 20:31:55,686 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1679)) - IPC Server Responder: starting
2023-01-27 20:31:55,687 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1519)) - IPC Server listener on 0: starting
2023-01-27 20:31:55,707 [Thread-1284] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(382)) - Acknowledging ACTIVE Namenode during handshake Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36799
2023-01-27 20:31:55,708 [Thread-1284] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(356)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2023-01-27 20:31:55,713 [Thread-1284] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:31:55,713 [Thread-1284] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 is not formatted for namespace 1228212439. Formatting...
2023-01-27 20:31:55,713 [Thread-1284] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8bcde1a9-9980-4912-9328-f9120c4d6810 for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 
2023-01-27 20:31:55,721 [Thread-1284] INFO  common.Storage (Storage.java:tryLock(948)) - Lock on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/in_use.lock acquired by nodename 59625@rizky
2023-01-27 20:31:55,721 [Thread-1284] INFO  common.Storage (DataStorage.java:loadStorageDirectory(284)) - Storage directory with location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 is not formatted for namespace 1228212439. Formatting...
2023-01-27 20:31:55,721 [Thread-1284] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-246f1175-fbd0-41db-a77b-867619854a1b for directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 
2023-01-27 20:31:55,743 [Thread-1284] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-13373003-127.0.1.1-1674826315262
2023-01-27 20:31:55,744 [Thread-1284] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-13373003-127.0.1.1-1674826315262
2023-01-27 20:31:55,744 [Thread-1284] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1 and block pool id BP-13373003-127.0.1.1-1674826315262 is not formatted. Formatting ...
2023-01-27 20:31:55,744 [Thread-1284] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-13373003-127.0.1.1-1674826315262 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-13373003-127.0.1.1-1674826315262/current
2023-01-27 20:31:55,770 [Thread-1284] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(255)) - Analyzing storage directories for bpid BP-13373003-127.0.1.1-1674826315262
2023-01-27 20:31:55,770 [Thread-1284] INFO  common.Storage (Storage.java:lock(907)) - Locking is disabled for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-13373003-127.0.1.1-1674826315262
2023-01-27 20:31:55,770 [Thread-1284] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2 and block pool id BP-13373003-127.0.1.1-1674826315262 is not formatted. Formatting ...
2023-01-27 20:31:55,770 [Thread-1284] INFO  common.Storage (BlockPoolSliceStorage.java:format(284)) - Formatting block pool BP-13373003-127.0.1.1-1674826315262 directory /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-13373003-127.0.1.1-1674826315262/current
2023-01-27 20:31:55,785 [IPC Server handler 1 on default port 36799] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:31:55,786 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:31:55,786 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:31:55,789 [Thread-1284] INFO  datanode.DataNode (DataNode.java:initStorage(2136)) - Setting up storage: nsid=1228212439;bpid=BP-13373003-127.0.1.1-1674826315262;lv=-57;nsInfo=lv=-67;cid=testClusterID;nsid=1228212439;c=1674826315262;bpid=BP-13373003-127.0.1.1-1674826315262;dnuuid=null
2023-01-27 20:31:55,804 [Thread-1284] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1934)) - Generated and persisted new Datanode UUID 9392b37a-e805-4c9a-af9d-4e01244b521e
2023-01-27 20:31:55,805 [Thread-1284] INFO  fsdataset.RoundRobinVolumeChoosingPolicy (RoundRobinVolumeChoosingPolicy.java:setConf(67)) - Round robin volume choosing policy initialized: dfs.datanode.round-robin-volume-choosing-policy.additional-available-space = 0
2023-01-27 20:31:55,817 [Thread-1284] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-8bcde1a9-9980-4912-9328-f9120c4d6810
2023-01-27 20:31:55,817 [Thread-1284] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, StorageType: DISK
2023-01-27 20:31:55,819 [Thread-1284] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(400)) - Added new volume: DS-246f1175-fbd0-41db-a77b-867619854a1b
2023-01-27 20:31:55,819 [Thread-1284] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(482)) - Added volume - [DISK]file:/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, StorageType: DISK
2023-01-27 20:31:55,819 [Thread-1284] INFO  impl.MemoryMappableBlockLoader (MemoryMappableBlockLoader.java:initialize(47)) - Initializing cache loader: MemoryMappableBlockLoader.
2023-01-27 20:31:55,819 [Thread-1284] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2611)) - Registered FSDatasetState MBean
2023-01-27 20:31:55,820 [Thread-1284] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(3188)) - Adding block pool BP-13373003-127.0.1.1-1674826315262
2023-01-27 20:31:55,821 [Thread-1302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-13373003-127.0.1.1-1674826315262 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:31:55,821 [Thread-1302] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-13373003-127.0.1.1-1674826315262/current, will proceed with Du for space computation calculation, 
2023-01-27 20:31:55,822 [Thread-1303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(513)) - Scanning block pool BP-13373003-127.0.1.1-1674826315262 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:31:55,823 [Thread-1303] WARN  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(347)) - dfsUsed file missing in /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-13373003-127.0.1.1-1674826315262/current, will proceed with Du for space computation calculation, 
2023-01-27 20:31:55,853 [Thread-1302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-13373003-127.0.1.1-1674826315262 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 33ms
2023-01-27 20:31:55,863 [Thread-1303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(518)) - Time taken to scan block pool BP-13373003-127.0.1.1-1674826315262 on /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 42ms
2023-01-27 20:31:55,864 [Thread-1284] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(538)) - Total time to scan all replicas for block pool BP-13373003-127.0.1.1-1674826315262: 43ms
2023-01-27 20:31:55,864 [Thread-1306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-13373003-127.0.1.1-1674826315262 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1...
2023-01-27 20:31:55,864 [Thread-1307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(266)) - Adding replicas to map for block pool BP-13373003-127.0.1.1-1674826315262 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2...
2023-01-27 20:31:55,864 [Thread-1306] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-13373003-127.0.1.1-1674826315262/current/replicas doesn't exist 
2023-01-27 20:31:55,864 [Thread-1307] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(963)) - Replica Cache file: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-13373003-127.0.1.1-1674826315262/current/replicas doesn't exist 
2023-01-27 20:31:55,865 [Thread-1307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-13373003-127.0.1.1-1674826315262 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2: 0ms
2023-01-27 20:31:55,874 [Thread-1306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(271)) - Time to add replicas to map for block pool BP-13373003-127.0.1.1-1674826315262 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1: 10ms
2023-01-27 20:31:55,877 [Thread-1284] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(292)) - Total time to add all replicas to map for block pool BP-13373003-127.0.1.1-1674826315262: 14ms
2023-01-27 20:31:55,877 [Thread-1284] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:31:55,879 [Thread-1284] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:31:55,879 [Thread-1284] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:31:55,879 [Thread-1284] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(223)) - Scheduled health check for volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:31:55,880 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-13373003-127.0.1.1-1674826315262 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2
2023-01-27 20:31:55,880 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(385)) - Now scanning bpid BP-13373003-127.0.1.1-1674826315262 on volume /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1
2023-01-27 20:31:55,880 [Thread-1284] WARN  datanode.DirectoryScanner (DirectoryScanner.java:<init>(302)) - dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2023-01-27 20:31:55,881 [Thread-1284] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(367)) - Periodic Directory Tree Verification scan starting in 4626631ms with interval of 21600000ms and throttle limit of -1ms/s
2023-01-27 20:31:55,881 [BP-13373003-127.0.1.1-1674826315262 heartbeating to localhost/127.0.0.1:36799] INFO  datanode.DataNode (BPServiceActor.java:register(819)) - Block pool BP-13373003-127.0.1.1-1674826315262 (Datanode Uuid 9392b37a-e805-4c9a-af9d-4e01244b521e) service to localhost/127.0.0.1:36799 beginning handshake with NN: localhost/127.0.0.1:36799.
2023-01-27 20:31:55,881 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-246f1175-fbd0-41db-a77b-867619854a1b): finished scanning block pool BP-13373003-127.0.1.1-1674826315262
2023-01-27 20:31:55,881 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:getNextBlockToScan(505)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-8bcde1a9-9980-4912-9328-f9120c4d6810): finished scanning block pool BP-13373003-127.0.1.1-1674826315262
2023-01-27 20:31:55,885 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2, DS-246f1175-fbd0-41db-a77b-867619854a1b): no suitable block pools found to scan.  Waiting 1814399995 ms.
2023-01-27 20:31:55,885 [VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(402)) - VolumeScanner(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, DS-8bcde1a9-9980-4912-9328-f9120c4d6810): no suitable block pools found to scan.  Waiting 1814399995 ms.
2023-01-27 20:31:55,891 [IPC Server handler 2 on default port 36799] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:31:55,893 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2906)) - dnInfo.length != numDataNodes
2023-01-27 20:31:55,893 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2830)) - Waiting for cluster to become active
2023-01-27 20:31:55,896 [IPC Server handler 4 on default port 36799] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1166)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44269, datanodeUuid=9392b37a-e805-4c9a-af9d-4e01244b521e, infoPort=42921, infoSecurePort=0, ipcPort=37555, storageInfo=lv=-57;cid=testClusterID;nsid=1228212439;c=1674826315262) storage 9392b37a-e805-4c9a-af9d-4e01244b521e
2023-01-27 20:31:55,896 [IPC Server handler 4 on default port 36799] INFO  net.NetworkTopology (NetworkTopology.java:add(156)) - Adding a new node: /default-rack/127.0.0.1:44269
2023-01-27 20:31:55,896 [IPC Server handler 4 on default port 36799] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(200)) - Registered DN 9392b37a-e805-4c9a-af9d-4e01244b521e (127.0.0.1:44269).
2023-01-27 20:31:55,898 [BP-13373003-127.0.1.1-1674826315262 heartbeating to localhost/127.0.0.1:36799] INFO  datanode.DataNode (BPServiceActor.java:register(846)) - Block pool BP-13373003-127.0.1.1-1674826315262 (Datanode Uuid 9392b37a-e805-4c9a-af9d-4e01244b521e) service to localhost/127.0.0.1:36799 successfully registered with NN: localhost/127.0.0.1:36799.
2023-01-27 20:31:55,898 [BP-13373003-127.0.1.1-1674826315262 heartbeating to localhost/127.0.0.1:36799] INFO  datanode.DataNode (BPServiceActor.java:offerService(680)) - For namenode localhost/127.0.0.1:36799 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2023-01-27 20:31:55,898 [ibr-executor-0] INFO  datanode.DataNode (BPServiceActor.java:run(1145)) - Starting IBR Task Handler.
2023-01-27 20:31:55,900 [IPC Server handler 3 on default port 36799] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-8bcde1a9-9980-4912-9328-f9120c4d6810 for DN 127.0.0.1:44269
2023-01-27 20:31:55,900 [IPC Server handler 3 on default port 36799] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(1050)) - Adding new storage ID DS-246f1175-fbd0-41db-a77b-867619854a1b for DN 127.0.0.1:44269
2023-01-27 20:31:55,902 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0xa648a8880ff1b021 with lease ID 0x29e040b2894bd056: Processing first storage report for DS-8bcde1a9-9980-4912-9328-f9120c4d6810 from datanode DatanodeRegistration(127.0.0.1:44269, datanodeUuid=9392b37a-e805-4c9a-af9d-4e01244b521e, infoPort=42921, infoSecurePort=0, ipcPort=37555, storageInfo=lv=-57;cid=testClusterID;nsid=1228212439;c=1674826315262)
2023-01-27 20:31:55,902 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0xa648a8880ff1b021 with lease ID 0x29e040b2894bd056: from storage DS-8bcde1a9-9980-4912-9328-f9120c4d6810 node DatanodeRegistration(127.0.0.1:44269, datanodeUuid=9392b37a-e805-4c9a-af9d-4e01244b521e, infoPort=42921, infoSecurePort=0, ipcPort=37555, storageInfo=lv=-57;cid=testClusterID;nsid=1228212439;c=1674826315262), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:31:55,903 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2912)) - BLOCK* processReport 0xa648a8880ff1b021 with lease ID 0x29e040b2894bd056: Processing first storage report for DS-246f1175-fbd0-41db-a77b-867619854a1b from datanode DatanodeRegistration(127.0.0.1:44269, datanodeUuid=9392b37a-e805-4c9a-af9d-4e01244b521e, infoPort=42921, infoSecurePort=0, ipcPort=37555, storageInfo=lv=-57;cid=testClusterID;nsid=1228212439;c=1674826315262)
2023-01-27 20:31:55,903 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2944)) - BLOCK* processReport 0xa648a8880ff1b021 with lease ID 0x29e040b2894bd056: from storage DS-246f1175-fbd0-41db-a77b-867619854a1b node DatanodeRegistration(127.0.0.1:44269, datanodeUuid=9392b37a-e805-4c9a-af9d-4e01244b521e, infoPort=42921, infoSecurePort=0, ipcPort=37555, storageInfo=lv=-57;cid=testClusterID;nsid=1228212439;c=1674826315262), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2023-01-27 20:31:55,903 [BP-13373003-127.0.1.1-1674826315262 heartbeating to localhost/127.0.0.1:36799] INFO  datanode.DataNode (BPServiceActor.java:blockReport(464)) - Successfully sent block report 0xa648a8880ff1b021 with lease ID 0x29e040b2894bd056 to namenode: localhost/127.0.0.1:36799,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msecs to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2023-01-27 20:31:55,910 [Command processor] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(763)) - Got finalize command for block pool BP-13373003-127.0.1.1-1674826315262
2023-01-27 20:31:55,994 [IPC Server handler 6 on default port 36799] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:31:55,995 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:31:55,997 [IPC Server handler 7 on default port 36799] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2023-01-27 20:31:55,998 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2882)) - Cluster is active
2023-01-27 20:31:56,008 [qtp283400364-2084] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:31:56 +0000] "OPTIONS /kms/v1/keys HTTP/1.1" 401 0 "-" "Java/1.8.0_352"
2023-01-27 20:31:56,025 [qtp283400364-2078] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:31:56,025 [qtp283400364-2078] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:31:56,025 [qtp283400364-2078] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:31:56,026 [qtp283400364-2078] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:31:56,026 [qtp283400364-2078] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:31:56,026 [qtp283400364-2078] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class javax.ws.rs.core.Response
2023-01-27 20:31:56,026 [qtp283400364-2078] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:31:56,027 [qtp283400364-2078] INFO  generators.AbstractWadlGeneratorGrammarGenerator (AbstractWadlGeneratorGrammarGenerator.java:attachTypes(479)) - Couldn't find grammar element for class java.util.Map
2023-01-27 20:31:56,028 [qtp283400364-2078] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:31:56 +0000] "OPTIONS /kms/v1/keys?user.name=rizky HTTP/1.1" 200 520 "-" "Java/1.8.0_352"
2023-01-27 20:31:56,573 [qtp283400364-2079] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=CREATE_KEY, key=test_key, user=rizky] UserProvidedMaterial:false Description:test_key
2023-01-27 20:31:56,575 [qtp283400364-2079] INFO  requests.kms (Slf4jRequestLogWriter.java:write(62)) - 127.0.0.1 - - [27/Jan/2023:13:31:56 +0000] "POST /kms/v1/keys HTTP/1.1" 201 98 "-" "Java/1.8.0_352"
2023-01-27 20:31:56,582 [IPC Server handler 0 on default port 36799] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=rizky:supergroup:rwxr-xr-x	proto=rpc
2023-01-27 20:31:56,595 [IPC Server handler 1 on default port 36799] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8856)) - allowed=true	ugi=rizky (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/base	dst=null	perm=rizky:supergroup:rw-r--r--	proto=rpc
2023-01-27 20:31:56,637 [IPC Server handler 2 on default port 36799] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(802)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:44269 for /base
2023-01-27 20:31:56,652 [DataXceiver for client DFSClient_NONMAPREDUCE_-1984679839_2075 at /127.0.0.1:35514 [Receiving block BP-13373003-127.0.1.1-1674826315262:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(751)) - Receiving BP-13373003-127.0.1.1-1674826315262:blk_1073741825_1001 src: /127.0.0.1:35514 dest: /127.0.0.1:44269
2023-01-27 20:31:56,674 [PacketResponder: BP-13373003-127.0.1.1-1674826315262:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1571)) - src: /127.0.0.1:35514, dest: /127.0.0.1:44269, volume: /home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1984679839_2075, offset: 0, srvID: 9392b37a-e805-4c9a-af9d-4e01244b521e, blockid: BP-13373003-127.0.1.1-1674826315262:blk_1073741825_1001, duration(ns): 6977472
2023-01-27 20:31:56,674 [PacketResponder: BP-13373003-127.0.1.1-1674826315262:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1544)) - PacketResponder: BP-13373003-127.0.1.1-1674826315262:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2023-01-27 20:31:56,687 [IPC Server handler 5 on default port 36799] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(3276)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /base
2023-01-27 20:31:56,688 [Block report processor] INFO  BlockStateChange (BlockManager.java:addStoredBlock(3635)) - BLOCK* addStoredBlock: 127.0.0.1:44269 is added to blk_1073741825_1001 (size=8192)
2023-01-27 20:31:58,628 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(589)) - Successfully warmed up 0 EDEKs.
2023-01-27 20:33:11,526 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@178dfb78] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:run(198)) - Detected pause in JVM or host machine (eg GC): pause of approximately 68969ms
No GCs detected
2023-01-27 20:33:11,524 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1c3541c2] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:run(198)) - Detected pause in JVM or host machine (eg GC): pause of approximately 69213ms
No GCs detected
2023-01-27 20:33:11,524 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@66220d5c] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:run(198)) - Detected pause in JVM or host machine (eg GC): pause of approximately 69237ms
No GCs detected
2023-01-27 20:34:12,112 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(801)) - Number of transactions: 8 Total time for transactions(ms): 241 Number of transactions batched in Syncs: 2 Number of syncs: 6 SyncTimes(ms): 73 30 
2023-01-27 20:34:22,779 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@66220d5c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(202)) - Detected pause in JVM or host machine (eg GC): pause of approximately 2519ms
No GCs detected
2023-01-27 20:34:22,756 [IPC Server handler 2 on default port 36799] INFO  namenode.FSNamesystem (FSNamesystemLock.java:writeUnlock(339)) - 	Number of suppressed write-lock reports: 0
	Longest write-lock held at 2023-01-27 20:34:14,260+0700 for 7026ms by completeFile via java.lang.Thread.getStackTrace(Thread.java:1564)
org.apache.hadoop.util.StringUtils.getStackTrace(StringUtils.java:1099)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:319)
org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:265)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.writeUnlock(FSNamesystem.java:1822)
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3225)
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:982)
org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:647)
org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:621)
org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:589)
org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1213)
org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1213)
org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1136)
java.security.AccessController.doPrivileged(Native Method)
javax.security.auth.Subject.doAs(Subject.java:422)
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
org.apache.hadoop.ipc.Server$Handler.run(Server.java:3144)

	Total suppressed write-lock held time: 0.0
2023-01-27 20:34:22,781 [IPC Server handler 2 on default port 36799] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(3229)) - DIR* completeFile: /base is closed by DFSClient_NONMAPREDUCE_-1984679839_2075
2023-01-27 20:34:19,183 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1c3541c2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(202)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1528ms
No GCs detected
2023-01-27 20:34:19,186 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@178dfb78] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(202)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1528ms
No GCs detected
2023-01-27 20:37:35,312 [Time-limited test] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2159)) - Shutting down the Mini HDFS Cluster
2023-01-27 20:37:34,679 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1c3541c2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(202)) - Detected pause in JVM or host machine (eg GC): pause of approximately 8528ms
No GCs detected
t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"AsyncAppender-Dispatcher-Thread-80" daemon prio=5 tid=123 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
        at java.lang.Thread.run(Thread.java:750)
"qtp626555619-1925" daemon prio=5 tid=1925 terminated
java.lang.Thread.State: TERMINATED
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"pool-341-thread-1"  prio=5 tid=1903 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Throwable.getStackTraceElement(Native Method)
        at java.lang.Throwable.getOurStackTrace(Throwable.java:828)
        at java.lang.Throwable.getStackTrace(Throwable.java:817)
        at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.log4j.spi.LocationInfo.<init>(LocationInfo.java:139)
        at org.apache.log4j.spi.LoggingEvent.getLocationInformation(LoggingEvent.java:253)
        at org.apache.log4j.helpers.PatternParser$LocationPatternConverter.convert(PatternParser.java:500)
        at org.apache.log4j.helpers.PatternConverter.format(PatternConverter.java:65)
        at org.apache.log4j.PatternLayout.format(PatternLayout.java:506)
        at org.apache.log4j.WriterAppender.subAppend(WriterAppender.java:310)
        at org.apache.log4j.WriterAppender.append(WriterAppender.java:162)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.log(Category.java:856)
        at org.slf4j.impl.Log4jLoggerAdapter.info(Log4jLoggerAdapter.java:347)
        at org.apache.hadoop.crypto.key.kms.server.KMSACLs.setKMSACLs(KMSACLs.java:112)
        at org.apache.hadoop.crypto.key.kms.server.KMSACLs.run(KMSACLs.java:201)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=832 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1305 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp626555619-1924" daemon prio=5 tid=1924 terminated
java.lang.Thread.State: TERMINATED
"process reaper" daemon prio=10 tid=147 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.UNIXProcess.waitForProcessExit(Native Method)
        at java.lang.UNIXProcess.lambda$initStreams$3(UNIXProcess.java:289)
        at java.lang.UNIXProcess$$Lambda$7/296289559.run(Unknown Source)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-77ea7569-1"  prio=5 tid=1902 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Connector-Scheduler-4ed0bb3d-1"  prio=5 tid=2032 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1081)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp626555619-1926" daemon prio=5 tid=1926 terminated
java.lang.Thread.State: TERMINATED
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=771 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=474 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"qtp1459605637-1896" daemon prio=5 tid=1896 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp626555619-1923" daemon prio=5 tid=1923 terminated
java.lang.Thread.State: TERMINATED
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1918 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=10 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readInt(DataInputStream.java:387)
        at org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:115)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:390)
        at java.lang.Thread.run(Thread.java:750)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:188)
"qtp626555619-1922" daemon prio=5 tid=1922 terminated
java.lang.Thread.State: TERMINATED
"pool-340-thread-1"  prio=5 tid=1893 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=652 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)

====> TEST TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2023-01-27 08:34:22,781

"qtp283400364-2077" daemon prio=5 tid=2077 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"kms-audit_thread" daemon prio=5 tid=2087 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner" daemon prio=5 tid=28 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:4143)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-1a60b50c-1"  prio=5 tid=2085 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1/current/BP-13373003-127.0.1.1-1674826315262" daemon prio=5 tid=2205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:225)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 36799" daemon prio=5 tid=2133 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"org.apache.hadoop.hdfs.PeerCache@15779044" daemon prio=10 tid=1687 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.PeerCache.run(PeerCache.java:253)
        at org.apache.hadoop.hdfs.PeerCache.access$000(PeerCache.java:46)
        at org.apache.hadoop.hdfs.PeerCache$1.run(PeerCache.java:124)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (104984469) connection to localhost/127.0.0.1:36799 from rizky" daemon prio=5 tid=2193 terminated
java.lang.Thread.State: TERMINATED
        at sun.reflect.Reflection.getClassAccessFlags(Native Method)
        at sun.reflect.Reflection.quickCheckMemberAccess(Reflection.java:84)
        at java.lang.Class.newInstance(Class.java:433)
        at org.apache.hadoop.ipc.RpcWritable$Buffer.newInstance(RpcWritable.java:221)
        at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1210)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1096)
"BP-13373003-127.0.1.1-1674826315262 heartbeating to localhost/127.0.0.1:36799" daemon prio=5 tid=2179 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.util.concurrent.AsyncGet$Util.wait(AsyncGet.java:65)
        at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1566)
        at org.apache.hadoop.ipc.Client.call(Client.java:1524)
        at org.apache.hadoop.ipc.Client.call(Client.java:1421)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:258)
        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:139)
        at com.sun.proxy.$Proxy72.sendHeartbeat(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:570)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:712)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:913)
        at java.lang.Thread.run(Thread.java:750)
"pool-395-thread-1"  prio=5 tid=2163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=2125 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ForkJoinPool-2-worker-2" daemon prio=5 tid=2210 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)
"IPC Server handler 6 on default port 37555" daemon prio=5 tid=2189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"CacheReplicationMonitor(1471652259)" daemon prio=5 tid=2151 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.run(CacheReplicationMonitor.java:181)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor@66fd3c74" daemon prio=5 tid=2148 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor.run(FSNamesystem.java:4517)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=2174 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1699)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1682)
"qtp283400364-2084" daemon prio=5 tid=2084 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@178dfb78" daemon prio=5 tid=2100 blocked
java.lang.Thread.State: BLOCKED
        at org.apache.log4j.Category.callAppenders(Category.java:204)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.log(Category.java:856)
        at org.slf4j.impl.Log4jLoggerAdapter.info(Log4jLoggerAdapter.java:305)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:202)
        at java.lang.Thread.run(Thread.java:750)
"ForkJoinPool-2-worker-1" daemon prio=5 tid=2209 terminated
java.lang.Thread.State: TERMINATED
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1824)
        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1693)
        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)
"qtp283400364-2079" daemon prio=5 tid=2079 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=2175 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1744 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"qtp46025291-2104" daemon prio=5 tid=2104 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 36799" daemon prio=5 tid=2141 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"pool-372-thread-1"  prio=5 tid=2076 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=34 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=295 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"IPC Server idle connection scanner for port 36799" daemon prio=5 tid=2123 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"LeaseRenewer:rizky@localhost:36799" daemon prio=5 tid=2228 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.UnixFileSystem.getBooleanAttributes0(Native Method)
        at java.io.UnixFileSystem.getBooleanAttributes(UnixFileSystem.java:247)
        at java.io.File.exists(File.java:830)
        at sun.misc.URLClassPath$FileLoader.getResource(URLClassPath.java:1391)
        at sun.misc.URLClassPath.getResource(URLClassPath.java:250)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto.toBuilder(ClientNamenodeProtocolProtos.java:43104)
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$RenewLeaseRequestProto.newBuilder(ClientNamenodeProtocolProtos.java:43097)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:750)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:437)
        at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:170)
        at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:162)
        at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:100)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:366)
        at com.sun.proxy.$Proxy74.renewLease(Unknown Source)
        at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:619)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.renew(LeaseRenewer.java:425)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.run(LeaseRenewer.java:445)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer.access$800(LeaseRenewer.java:77)
        at org.apache.hadoop.hdfs.client.impl.LeaseRenewer$1.run(LeaseRenewer.java:336)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1379 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1127 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 36799" daemon prio=5 tid=2136 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1009 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"qtp1637806877-2164" daemon prio=5 tid=2164 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp46025291-2106" daemon prio=5 tid=2106 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=2124 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1699)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1682)
"Thread[Thread-1251,5,main]" daemon prio=5 tid=2132 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$ExpiredTokenRemover.run(AbstractDelegationTokenSecretManager.java:797)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=772 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@1c3541c2" daemon prio=5 tid=2170 blocked
java.lang.Thread.State: BLOCKED
        at java.lang.StringBuffer.capacity(StringBuffer.java:174)
        at org.apache.log4j.PatternLayout.format(PatternLayout.java:497)
        at org.apache.log4j.WriterAppender.subAppend(WriterAppender.java:310)
        at org.apache.log4j.WriterAppender.append(WriterAppender.java:162)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.log(Category.java:856)
        at org.slf4j.impl.Log4jLoggerAdapter.info(Log4jLoggerAdapter.java:305)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:202)
        at java.lang.Thread.run(Thread.java:750)
"qtp46025291-2109" daemon prio=5 tid=2109 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"java.util.concurrent.ThreadPoolExecutor$Worker@750ea074[State = -1, empty queue]" daemon prio=5 tid=2218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=172 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1e5dc21" daemon prio=5 tid=2149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller.run(FSNamesystem.java:4559)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 37555" daemon prio=5 tid=2182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@551a8961" daemon prio=5 tid=2150 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber.run(FSNamesystem.java:4656)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 36799" daemon prio=5 tid=2138 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"qtp1637806877-2166" daemon prio=5 tid=2166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"reencryptionHandlerThread #0" daemon prio=5 tid=2145 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler.run(ReencryptionHandler.java:331)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1671 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"refreshUsed-/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data2/current/BP-13373003-127.0.1.1-1674826315262" daemon prio=5 tid=2204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:225)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 37555" daemon prio=5 tid=2183 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=832 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1305 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@5ce7816a" daemon prio=5 tid=2115 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor.run(HeartbeatManager.java:558)
        at java.lang.Thread.run(Thread.java:750)
"process reaper" daemon prio=10 tid=147 terminated
java.lang.Thread.State: TERMINATED
        at java.lang.UNIXProcess.waitForProcessExit(Native Method)
        at java.lang.UNIXProcess.lambda$initStreams$3(UNIXProcess.java:289)
        at java.lang.UNIXProcess$$Lambda$7/296289559.run(Unknown Source)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 37555" daemon prio=5 tid=2190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"nioEventLoopGroup-24-1"  prio=10 tid=2169 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 36799" daemon prio=5 tid=2134 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"IPC Server handler 5 on default port 37555" daemon prio=5 tid=2186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"pool-380-thread-1"  prio=5 tid=2112 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=1918 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=10 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readInt(DataInputStream.java:387)
        at org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:115)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:390)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 37555" daemon prio=5 tid=2192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"IPC Parameter Sending Thread for localhost/127.0.0.1:36799" daemon prio=5 tid=2233 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1129)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=652 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"IPC Server handler 9 on default port 36799" daemon prio=5 tid=2142 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"qtp1637806877-2165-acceptor-0@6f023dd6-ServerConnector@a7214cb{HTTP/1.1, (http/1.1)}{localhost:41651}" daemon prio=3 tid=2165 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ibr-executor-0" daemon prio=5 tid=2219 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor$IBRTaskHandler.run(BPServiceActor.java:1146)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-392-thread-1" daemon prio=5 tid=2215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp46025291-2105" daemon prio=5 tid=2105 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"VolumeScannerThread(/home/rizky/hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/2/dfs/data/data1)" daemon prio=5 tid=2198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:656)
"qtp283400364-2080" daemon prio=5 tid=2080 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 37555" daemon prio=5 tid=2191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"pool-379-thread-1"  prio=5 tid=2102 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"AsyncAppender-Dispatcher-Thread-57" daemon prio=5 tid=86 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:548)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-310ea5de-1"  prio=5 tid=2168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1672 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=2101 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"SSL Certificates Store Monitor" daemon prio=5 tid=591 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 0 on default port 37555" daemon prio=5 tid=2181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:321)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3111)
"qtp46025291-2103" daemon prio=5 tid=2103 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$70/1899621770.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=11 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:284)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
        at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
        at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
        at java.io.InputStreamReader.read(InputStreamReader.java:184)
        at java.io.Reader.read(Reader.java:100)
        at java.util.Scanner.readInput(Scanner.java:804)
        at java.util.Scanner.findWithinHorizon(Scanner.java:1685)
        at java.util.Scanner.hasNextLine(Scanner.java:1500)
        at org.apache.maven.surefire.booter.PpidChecker$ProcessInfoConsumer.execute(PpidChecker.java:354)
        at org.apache.maven.surefire.booter.PpidChecker.unix(PpidChecker.java:190)
        at org.apache.maven.surefire.booter.PpidChecker.isProcessAlive(PpidChecker.java:123)
        at org.apache.maven.surefire.booter.ForkedBooter$2.run(ForkedBooter.java:214)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-373-thread-1"  prio=5 tid=2086 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.crypto.key.kms.server.KMSConfiguration.isACLsFileNewer(KMSConfiguration.java:148)
        at org.apache.hadoop.crypto.key.kms.server.KMSACLs.run(KMSACLs.java:200)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@2f8b4bbd" daemon prio=5 tid=2147 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:537)
        at java.lang.Thread.run(Thread.java:750)
"GcTimeMonitor obsWindow = 60000, sleepInterval = 5000, maxGcTimePerc = 100" daemon prio=5 tid=44 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.GcTimeMonitor.run(GcTimeMonitor.java:161)
"org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@748512db" daemon prio=5 tid=2162 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:113)
        at org.apache.hadoop.hdfs.net.TcpPeerServer.accept(TcpPeerServer.java:85)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:228)
        at java.lang.Thread.run(Thread.java:750)
"qtp1637806877-2167" daemon prio=5 tid=2167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=2121 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1525)
"main"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1615)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:87)
        at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:73)
        at org.apache.hadoop.test.TimedOutTestsListener.testFailure(TimedOutTestsListener.java:62)
        at org.junit.runner.notification.SynchronizedRunListener.testFailure(SynchronizedRunListener.java:94)
        at org.junit.runner.notification.RunNotifier$6.notifyListener(RunNotifier.java:177)
        at org.junit.runner.notification.RunNotifier$SafeNotifier.run(RunNotifier.java:72)
        at org.junit.runner.notification.RunNotifier.fireTestFailures(RunNotifier.java:173)
        at org.junit.runner.notification.RunNotifier.fireTestFailure(RunNotifier.java:167)
        at org.apache.maven.surefire.common.junit4.Notifier.fireTestFailure(Notifier.java:114)
        at org.junit.internal.runners.model.EachTestNotifier.addFailure(EachTestNotifier.java:23)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:370)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
        at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
        at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
"org.apache.hadoop.crypto.key.kms.ValueQueue_thread" daemon prio=5 tid=1306 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:169)
        at org.apache.hadoop.crypto.key.kms.ValueQueue$UniqueKeyBlockingQueue.take(ValueQueue.java:153)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp46025291-2108" daemon prio=5 tid=2108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp283400364-2082" daemon prio=5 tid=2082 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"reencryptionUpdaterThread #0" daemon prio=5 tid=2146 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ExecutorCompletionService.take(ExecutorCompletionService.java:193)
        at org.apache.hadoop.hdfs.server.namenode.ReencryptionUpdater.takeAndProcessTasks(ReencryptionUpdater.java:425)
        at org.apache.hadoop.hdfs.server.namenode.ReencryptionUpdater.run(ReencryptionUpdater.java:265)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Warm Up EDEK Cache Thread #0" daemon prio=5 tid=2152 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0" daemon prio=5 tid=2172 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1463)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1442)
"org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@3698efe2" daemon prio=5 tid=2128 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:267)
        at java.lang.Thread.run(Thread.java:750)
"pool-387-thread-1"  prio=5 tid=2143 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"MarkedDeleteBlockScrubberThread" daemon prio=5 tid=2114 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$MarkedDeleteBlockScrubber.run(BlockManager.java:5132)
        at java.lang.Thread.run(Thread.java:750)
"RedundancyMonitor" daemon prio=5 tid=2113 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:5157)
        at java.lang.Thread.run(Thread.java:750)
"Command processor" daemon prio=5 tid=1996 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor$CommandProcessingThread.processQueue(BPServiceActor.java:1425)
        at org.apache.hadoop.hdfs.server.datanode.BPServiceActor$CommandProcessingThread.run(BPServiceActor.java:1409)
"SSL Certificates Store Monitor" daemon prio=5 tid=950 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"Thread[Thread-1219,5,main]" daemon prio=5 tid=2089 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$ExpiredTokenRemover.run(AbstractDelegationTokenSecretManager.java:797)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 37555" daemon prio=5 tid=2185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.A