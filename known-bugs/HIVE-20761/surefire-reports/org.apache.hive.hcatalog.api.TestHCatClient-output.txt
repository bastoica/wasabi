DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.hcatalog.api.TestHCatClient
DEBUG StatusLogger Took 0.043920 seconds to load 267 plugins from sun.misc.Launcher$AppClassLoader@677327b6
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Converter' found 48 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=677327b6, org.apache.logging.log4j.core.LoggerContext@1ebd319f]...
DEBUG StatusLogger Reconfiguration started for context[name=677327b6] at URI null (org.apache.logging.log4j.core.LoggerContext@1ebd319f) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@50caa560
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Apache Log4j Core 2.18.0 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@503d687a
INFO StatusLogger Scanning for classes in '/home/rizky/hive/common/target/hive-common-4.0.0-SNAPSHOT.jar' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/rizky/hive/ql/target/hive-exec-4.0.0-SNAPSHOT.jar' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/rizky/hive/ql/target/hive-exec-4.0.0-SNAPSHOT-tests.jar' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0.022326 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 142 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="${sys:test.tmp.dir}/log", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/rizky/hive/hcatalog/webhcat/java-client/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="ERROR", levelAndRefs="null", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="ERROR", levelAndRefs="null", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="ERROR", levelAndRefs="null", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="ERROR", levelAndRefs="null", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="DEBUG", levelAndRefs="null", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.logging.log4j.core.filter.MarkerFilter].
ERROR StatusLogger MarkerFilter contains an invalid element or attribute "onMismatch"
DEBUG StatusLogger createFilter(marker="FULL_PLAN", onMatch="DENY", onMismatch="NEUTRAL")
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="OFF", levelAndRefs="null", name="org.apache.hadoop.hive.ql.optimizer.calcite.RuleEventLogger", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), MarkerFilter(FULL_PLAN))
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger LoggerConfig$RootLogger$Builder(additivity="null", level="DEBUG", levelAndRefs="null", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, org.apache.hadoop.hive.ql.optimizer.calcite.RuleEventLogger, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 48 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/rizky/hive/hcatalog/webhcat/java-client/target/tmp/log/hive.log", filePattern="/home/rizky/hive/hcatalog/webhcat/java-client/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/rizky/hive/hcatalog/webhcat/java-client/target/tmp/log/hive.log seek to 0
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/rizky/hive/hcatalog/webhcat/java-client/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2023-02-15T14:44:20.856-0800
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2023/02/16-00:00:00.000, nextFileTime=2023/02/15-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2023/02/15-14:44:20.860, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2023/02/16-00:00:00.000, nextFileTime=2023/02/15-00:00:00.000, prevFileTime=2023/02/15-00:00:00.000, current=2023/02/15-14:44:20.860, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@503d687a initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@503d687a
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@503d687a OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@5dda768f...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@5dda768f OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@183ec003
TRACE StatusLogger Reregistering context (1/1): '677327b6' org.apache.logging.log4j.core.LoggerContext@1ebd319f
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.calcite.RuleEventLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=677327b6] at URI /home/rizky/hive/hcatalog/webhcat/java-client/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@1ebd319f) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=677327b6, org.apache.logging.log4j.core.LoggerContext@1ebd319f] started OK.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.conf.Configuration
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.conf.Configuration
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.conf.HiveConf
2023-02-15T14:44:20,901  INFO [main] conf.HiveConf: Found configuration file file:/home/rizky/hive/hcatalog/webhcat/java-client/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.conf.SystemVariables
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.conf.valcoersion.JavaIOTmpdirVariableCoercion
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.FileSystem
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.FileUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.common.HiveCompat
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.JobConf
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.lib.output.FileOutputFormat
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.Credentials
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.UserGroupInformation
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.impl.MetricsSystemImpl
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.lib.Interns
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.lib.MetricsSourceBuilder
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.lib.MutableMetricsFactory
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.conf.HiveConfUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.Shell
2023-02-15T14:44:21,076  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:21,076  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:21,076  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:21,076  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:21,076  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:21,076  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:21,077  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:21,077  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:21,077  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:21,078  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:21,078  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:21,078  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.conf.MetastoreConf
2023-02-15T14:44:21,094  INFO [main] conf.MetastoreConf: Found configuration file: file:/home/rizky/hive/hcatalog/webhcat/java-client/target/testconf/hive-site.xml
2023-02-15T14:44:21,094  INFO [main] conf.MetastoreConf: Found configuration file: file:/home/rizky/hive/hcatalog/webhcat/java-client/target/testconf/hivemetastore-site.xml
2023-02-15T14:44:21,094  INFO [main] conf.MetastoreConf: Unable to find config file: metastore-site.xml
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.MetaStoreTestUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.TestTxnDbUtil
2023-02-15T14:44:21,106  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.calcite.avatica.remote.Driver
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.DatabaseProduct
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.MetaStoreSchemaInfoFactory
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.MetastoreVersionInfo
2023-02-15T14:44:21,460  INFO [main] utils.TestTxnDbUtil: Reinitializing the metastore db with hive-schema-4.0.0.derby.sql on the database jdbc:derby:memory:/home/rizky/hive/hcatalog/webhcat/java-client/target/tmp/junit_metastore_db_42647;create=true
2023-02-15T14:44:21,778  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveMetaStore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HMSHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HMSHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.AuthFactory
2023-02-15T14:44:21,807  INFO [MetaStoreThread-42647] metastore.AuthFactory: Using authentication NOSASL with kerberos authentication disabled
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.RetryingHMSHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.MetaStoreInit
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.metrics.PerfLogger
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.metrics.Metrics
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.Deadline
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.JavaUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveAlterHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.Warehouse
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.ReplChangeManager
2023-02-15T14:44:21,926  INFO [MetaStoreThread-42647] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.ObjectStore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.PersistenceManagerProvider
2023-02-15T14:44:21,945  INFO [MetaStoreThread-42647] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T14:44:21,946  INFO [MetaStoreThread-42647] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.datasource.HikariCPDataSourceProvider
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.datasource.DbCPDataSourceProvider
2023-02-15T14:44:21,952  INFO [MetaStoreThread-42647] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: objectstore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.HikariConfig
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.HikariDataSource
2023-02-15T14:44:21,956  WARN [MetaStoreThread-42647] hikari.HikariConfig: objectstore - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:44:21,958  INFO [MetaStoreThread-42647] hikari.HikariDataSource: objectstore - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.util.DriverDataSource
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.util.ConcurrentBag
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolEntry
2023-02-15T14:44:21,966  INFO [MetaStoreThread-42647] pool.PoolBase: objectstore - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:44:21,967  INFO [MetaStoreThread-42647] hikari.HikariDataSource: objectstore - Start completed.
2023-02-15T14:44:21,967  INFO [MetaStoreThread-42647] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 2, name: objectstore-secondary
2023-02-15T14:44:21,967  WARN [MetaStoreThread-42647] hikari.HikariConfig: objectstore-secondary - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:44:21,968  INFO [MetaStoreThread-42647] hikari.HikariDataSource: objectstore-secondary - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:44:21,969  INFO [MetaStoreThread-42647] pool.PoolBase: objectstore-secondary - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:44:21,970  INFO [MetaStoreThread-42647] hikari.HikariDataSource: objectstore-secondary - Start completed.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.ProxyLeakTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.ProxyConnection
2023-02-15T14:44:22,152  INFO [MetaStoreThread-42647] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2023-02-15T14:44:22,153  INFO [MetaStoreThread-42647] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ec9cb54, with PersistenceManager: null will be shutdown
2023-02-15T14:44:22,165  INFO [MetaStoreThread-42647] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ec9cb54, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@469a8182 created in the thread with id: 25
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.MetaStoreDirectSql
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.tools.SQLGenerator
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.PartFilterExprUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.DirectSqlUpdateStat
2023-02-15T14:44:22,782  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.MetastoreDirectSqlUtils
2023-02-15T14:44:23,182  INFO [MetaStoreThread-42647] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4ec9cb54
2023-02-15T14:44:23,188  INFO [MetaStoreThread-42647] metastore.HMSHandler: Setting location of default catalog, as it hasn't been done after upgrade
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.SecurityUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.authentication.util.KerberosName
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.HadoopKerberosName
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.Groups
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.NativeCodeLoader
2023-02-15T14:44:23,202  WARN [MetaStoreThread-42647] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.PerformanceAdvisory
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.ShellBasedUnixGroupsMapping
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.HarFileSystem
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hdfs.DistributedFileSystem
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hdfs.web.WebHdfsFileSystem
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.shims.ShimLoader
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.VersionInfo
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.ThreadUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.io.IOUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.shims.HadoopShimsSecure
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.ShutdownHookManager
2023-02-15T14:44:23,339  INFO [MetaStoreThread-42647] metastore.HMSHandler: Started creating a default database with name: default
2023-02-15T14:44:23,361  INFO [MetaStoreThread-42647] metastore.HMSHandler: Successfully created a default database with name: default
2023-02-15T14:44:23,370  INFO [MetaStoreThread-42647] metastore.HMSHandler: Added admin role in metastore
2023-02-15T14:44:23,371  INFO [MetaStoreThread-42647] metastore.HMSHandler: Added public role in metastore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.MetaStoreUtils
2023-02-15T14:44:23,400  INFO [MetaStoreThread-42647] metastore.HMSHandler: Added hive_admin_user to admin role
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.TransactionalValidationListener
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.hcatalog.listener.DbNotificationListener
2023-02-15T14:44:23,405  INFO [MetaStoreThread-42647] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T14:44:23,406  INFO [MetaStoreThread-42647] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47f71223, with PersistenceManager: null will be shutdown
2023-02-15T14:44:23,406  INFO [MetaStoreThread-42647] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@47f71223, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@30202454 created in the thread with id: 25
2023-02-15T14:44:23,409  INFO [DB-Notification-Cleaner] listener.DbNotificationListener: Wait interval is 86400000
2023-02-15T14:44:23,409  INFO [DB-Notification-Cleaner] listener.DbNotificationListener: Cleaner Thread Restarted and metastore.event.db.listener.clean.startup.wait.interval or hive.metastore.event.db.listener.clean.startup.wait.interval is configured. So cleaner thread will startup post waiting 86400000 ms
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.messaging.MessageFactory
2023-02-15T14:44:23,409  INFO [MetaStoreThread-42647] conf.MetastoreConf: Found configuration file: file:/home/rizky/hive/hcatalog/webhcat/java-client/target/testconf/hivemetastore-site.xml
2023-02-15T14:44:23,410  INFO [MetaStoreThread-42647] conf.MetastoreConf: Unable to find config file: metastore-site.xml
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.FileMetadataManager
2023-02-15T14:44:23,480  INFO [MetaStoreThread-42647] metastore.HMSHandler: HMS server filtering is disabled by configuration
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.dataconnector.DataConnectorProviderFactory
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.facebook.fb303.FacebookService$Processor
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.TUGIBasedProcessor
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.thrift.ProcessFunction
2023-02-15T14:44:23,569  INFO [MetaStoreThread-42647] metastore.HiveMetaStore: Starting DB backed MetaStore Server with SetUGI enabled
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.SecurityUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.thrift.transport.TServerSocket
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.thrift.server.TThreadPoolServer
2023-02-15T14:44:23,572  INFO [MetaStoreThread-42647] metastore.HiveMetaStore: Direct SQL optimization = true
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.thrift.transport.TIOStreamTransport
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.thrift.transport.TSocket
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.permission.FsPermission
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.io.nativeio.NativeIO
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.FileUtil
2023-02-15T14:44:23,810  INFO [Metastore-Handler-Pool: Thread-39] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T14:44:23,813  INFO [main] metastore.MetaStoreTestUtils: MetaStore warehouse root dir (pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647) is created
2023-02-15T14:44:23,813  INFO [main] metastore.MetaStoreTestUtils: MetaStore Thrift Server started on port: 42647 with warehouse dir: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647 with jdbcUrl: jdbc:derby:memory:/home/rizky/hive/hcatalog/webhcat/java-client/target/tmp/junit_metastore_db_42647;create=true
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.exec.Utilities
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.exec.Utilities
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.exec.Utilities
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.io.HiveFileFormatUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.session.SessionState
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.JavaUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.hcatalog.api.HCatClientHMSImpl
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.hcatalog.common.HCatUtil
2023-02-15T14:44:23,879  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:23,879  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:23,879  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:23,879  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:23,879  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:23,879  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:23,879  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:23,879  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:23,879  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:23,879  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:23,879  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:23,880  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:23,880  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:23,880  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.hcatalog.common.HiveClientCache
2023-02-15T14:44:23,885  INFO [main] common.HiveClientCache: Initializing cache: eviction-timeout=120 initial-capacity=50 maximum-capacity=50
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.common.util.ShutdownHookManager
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.shims.Utils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.RetryingMetaStoreClient
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveMetaStoreClient
2023-02-15T14:44:23,918  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T14:44:23,918  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:42647]
2023-02-15T14:44:23,918  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:42647) in binary transport mode
2023-02-15T14:44:23,925  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:42647) current connections: 1
2023-02-15T14:44:23,937  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
2023-02-15T14:44:23,952  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:23,952  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T14:44:23,953  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29f8fbfa, with PersistenceManager: null will be shutdown
2023-02-15T14:44:23,953  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29f8fbfa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d125920 created in the thread with id: 44
2023-02-15T14:44:23,955  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29f8fbfa
2023-02-15T14:44:23,967  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2023-02-15T14:44:23,971  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:myDb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2023-02-15T14:44:23,973  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Creating database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.FileUtils
2023-02-15T14:44:23,975  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:44:23,976  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Created database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.messaging.MessageBuilder
2023-02-15T14:44:23,991  INFO [Metastore-Handler-Pool: Thread-44] conf.MetastoreConf: Found configuration file: file:/home/rizky/hive/hcatalog/webhcat/java-client/target/testconf/hivemetastore-site.xml
2023-02-15T14:44:23,992  INFO [Metastore-Handler-Pool: Thread-44] conf.MetastoreConf: Unable to find config file: metastore-site.xml
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.ObjectStore$RetryingExecutor
2023-02-15T14:44:24,026  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,026  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.hcatalog.api.HCatTable
2023-02-15T14:44:24,042  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:44:24,058  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:24,058  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:24,058  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:24,058  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:24,058  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:24,058  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:24,058  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:24,058  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:24,058  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:24,058  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:24,058  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:24,058  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:24,063  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:myTable, dbName:myDb, owner:rizky, createTime:1676501064, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:int, comment:), FieldSchema(name:bar, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:dt, type:string, comment:), FieldSchema(name:grid, type:string, comment:)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:44:24,076  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.txn.TxnUtils
2023-02-15T14:44:24,121  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,121  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:24,145  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:44:24,171  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.serde2.typeinfo.TypeInfoUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.type.TimestampTZUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.hcatalog.api.HCatPartition
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.hcatalog.api.HCatAddPartitionDesc
2023-02-15T14:44:24,190  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,196  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:24,201  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,209  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable/dt=2011_12_31/grid=AB
2023-02-15T14:44:24,227  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,227  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:24,230  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,234  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:24,235  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,238  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable/dt=2012_01_01/grid=AB
2023-02-15T14:44:24,243  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,243  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:24,247  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,251  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:24,252  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,256  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable/dt=2012_01_01/grid=OB
2023-02-15T14:44:24,259  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,259  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:24,262  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,266  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:24,267  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,270  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable/dt=2012_01_01/grid=XB
2023-02-15T14:44:24,274  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,274  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:24,276  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:44:24,280  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:24,283  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_filter : tbl=hive.mydb.mytable	
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.Batchable
2023-02-15T14:44:24,324  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2023-02-15T14:44:24,328  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:44:24,329  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:44:24,334  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2023-02-15T14:44:24,340  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2023-02-15T14:44:24,355  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: myDb	
2023-02-15T14:44:24,356  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2023-02-15T14:44:24,356  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2023-02-15T14:44:24,364  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2023-02-15T14:44:24,371  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2023-02-15T14:44:24,391  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:44:24,436  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,515  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,515  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:24,518  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore: Dropping database hive.myDb along with all tables
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.txn.TxnHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler
2023-02-15T14:44:24,545  INFO [Metastore-Handler-Pool: Thread-44] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: txnhandler
2023-02-15T14:44:24,546  WARN [Metastore-Handler-Pool: Thread-44] hikari.HikariConfig: txnhandler - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:44:24,546  INFO [Metastore-Handler-Pool: Thread-44] hikari.HikariDataSource: txnhandler - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:44:24,547  INFO [Metastore-Handler-Pool: Thread-44] pool.PoolBase: txnhandler - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:44:24,548  INFO [Metastore-Handler-Pool: Thread-44] hikari.HikariDataSource: txnhandler - Start completed.
2023-02-15T14:44:24,548  INFO [Metastore-Handler-Pool: Thread-44] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: mutex
2023-02-15T14:44:24,548  WARN [Metastore-Handler-Pool: Thread-44] hikari.HikariConfig: mutex - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:44:24,549  INFO [Metastore-Handler-Pool: Thread-44] hikari.HikariDataSource: mutex - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:44:24,550  INFO [Metastore-Handler-Pool: Thread-44] pool.PoolBase: mutex - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:44:24,550  INFO [Metastore-Handler-Pool: Thread-44] hikari.HikariDataSource: mutex - Start completed.
2023-02-15T14:44:24,551  INFO [Metastore-Handler-Pool: Thread-44] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 5, name: compactor
2023-02-15T14:44:24,552  WARN [Metastore-Handler-Pool: Thread-44] hikari.HikariConfig: compactor - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:44:24,552  INFO [Metastore-Handler-Pool: Thread-44] hikari.HikariDataSource: compactor - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:44:24,553  INFO [Metastore-Handler-Pool: Thread-44] pool.PoolBase: compactor - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:44:24,553  INFO [Metastore-Handler-Pool: Thread-44] hikari.HikariDataSource: compactor - Start completed.
2023-02-15T14:44:24,563  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,563  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.Trash
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.TrashPolicyDefault
2023-02-15T14:44:24,571  WARN [Metastore-Handler-Pool: Thread-44] utils.FileUtils: File file:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db does not exist; Force to delete it.
2023-02-15T14:44:24,571 ERROR [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Failed to delete pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:44:24,584  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:24,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:24,584  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:24,584  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:24,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:24,584  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:24,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:24,584  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:24,584  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:24,584  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:24,584  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:24,584  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:24,584  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:24,585  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:24,586  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2023-02-15T14:44:24,586  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:24,588  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: locationDB	
2023-02-15T14:44:24,589  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:locationDB, description:null, locationUri:/tmp/locationDB, parameters:null, catalogName:hive)	
2023-02-15T14:44:24,591  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Creating database path in external directory file:/tmp/locationDB
2023-02-15T14:44:24,591  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: file:/tmp/locationDB
2023-02-15T14:44:24,593  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Created database path in external directory file:/tmp/locationDB
2023-02-15T14:44:24,594  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,594  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:24,596  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: locationDB	
2023-02-15T14:44:24,597  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=1 expired=false
2023-02-15T14:44:24,621  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:24,621  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:24,621  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:24,621  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:24,621  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:24,621  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:24,621  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:24,621  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:24,621  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:24,621  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:24,621  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:24,621  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:24,621  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:24,621  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:24,622  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2023-02-15T14:44:24,622  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:24,624  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2023-02-15T14:44:24,626  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:myDb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2023-02-15T14:44:24,627  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Creating database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:44:24,627  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:44:24,629  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Created database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:44:24,630  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,630  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:24,631  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:44:24,649  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:24,649  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:24,649  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:24,649  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:24,649  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:24,649  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:24,649  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:24,649  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:24,649  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:24,649  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:24,649  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:24,649  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:24,650  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:myTable, dbName:myDb, owner:rizky, createTime:1676501064, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:int, comment:), FieldSchema(name:bar, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:dt, type:string, comment:), FieldSchema(name:grid, type:string, comment:)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:44:24,655  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable
2023-02-15T14:44:24,666  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,666  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:24,677  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:44:24,689  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:24,689  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,693  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:24,693  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,698  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable/dt=2011_12_31/grid=AB
2023-02-15T14:44:24,706  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,706  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:24,708  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,711  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:24,712  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,715  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable/dt=2012_01_01/grid=AB
2023-02-15T14:44:24,719  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,719  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:24,721  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,724  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:24,725  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,728  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable/dt=2012_01_01/grid=OB
2023-02-15T14:44:24,731  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,731  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:24,733  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,736  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:24,737  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2023-02-15T14:44:24,739  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable/dt=2012_01_01/grid=XB
2023-02-15T14:44:24,742  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:24,742  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:24,744  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=myDb,table=myTable, partitionSpec: [{dt=2012_01_01}]).
2023-02-15T14:44:24,745  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:44:24,747  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:24,748  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableHiveVarcharObjectInspector
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.plan.ExprNodeGenericFuncDesc
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.exec.FunctionRegistry
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.exec.Registry
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.UDFPI
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.UDFE
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFRegExp
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.serde2.io.HiveIntervalYearMonthWritable
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.serde2.io.HiveIntervalDayTimeWritable
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFRestrictInformationSchema
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFCurrentAuthorizer
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.common.util.HiveVersionInfo
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFToString
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFToVarchar
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFToChar
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMax
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMin
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFSum
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFAverage
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFVariance
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFHistogramNumeric
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFPercentileApprox
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFnGrams
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFContextNGrams
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFComputeStats
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFExceptionInVertex
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.calcite.util.trace.CalciteTrace
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.calcite.util.trace.CalciteTrace
2023-02-15T14:44:25,084  WARN [main] exec.FunctionRegistry: UDF Class org.apache.hive.org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2023-02-15T14:44:25,087  WARN [main] exec.FunctionRegistry: UDF Class org.apache.hive.org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2023-02-15T14:44:25,088  WARN [main] exec.FunctionRegistry: UDF Class org.apache.hive.org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2023-02-15T14:44:25,088  WARN [main] exec.FunctionRegistry: UDF Class org.apache.hive.org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2023-02-15T14:44:25,088  WARN [main] exec.FunctionRegistry: UDF Class org.apache.hive.org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2023-02-15T14:44:25,089  WARN [main] exec.FunctionRegistry: UDF Class org.apache.hive.org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2023-02-15T14:44:25,089  WARN [main] exec.FunctionRegistry: UDF Class org.apache.hive.org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFReflect
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFExceptionInVertex
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFFromUtcTimestamp
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFCastFormat
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDTFJSONTuple
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDTFParseUrlTuple
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDTFGetSplits
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDTFGetSplits2
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDTFGetSQLSchema
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFRowNumber
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFRank
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFPercentRank
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFNTile
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFFirstValue
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFLastValue
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFLeadLag
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFLead
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFLag
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.BaseMaskUDF
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.MaskHashTransformer
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Length
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_LineString
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Point
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_AsText
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Aggr_ConvexHull
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Aggr_Union
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Area
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_AsBinary
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_AsGeoJson
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_AsJson
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_AsShape
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Boundary
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Buffer
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Centroid
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_ConvexHull
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_CoordDim
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Difference
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Dimension
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Distance
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_EndPoint
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Envelope
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_EnvIntersects
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_ExteriorRing
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeodesicLengthWGS84
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeomCollection
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeometryN
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeomFromGeoJson
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeomFromShape
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeomFromText
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeomFromWKB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeometryType
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_InteriorRingN
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Intersection
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Is3D
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_IsClosed
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_IsEmpty
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_IsMeasured
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_IsRing
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_IsSimple
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_LineFromWKB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_M
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MaxM
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MaxX
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MaxY
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MaxZ
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MinM
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MinX
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MinY
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MinZ
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MLineFromWKB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MPointFromWKB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MPolyFromWKB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MultiLineString
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MultiPoint
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MultiPolygon
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_NumGeometries
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_NumInteriorRing
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_NumPoints
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_PointFromWKB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_PointN
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_PolyFromWKB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Polygon
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Relate
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_SetSRID
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_SRID
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_StartPoint
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_SymmetricDiff
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Union
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_X
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Y
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Z
2023-02-15T14:44:25,154  WARN [main] exec.FunctionRegistry: iceberg_bucket function could not be registered
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.exec.SerializationUtilities
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.plan.ExprNodeDescUtils
2023-02-15T14:44:25,255  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,255  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,258  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:25,265  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:44:25,268  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,273  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions : tbl=hive.myDb.myTable	
2023-02-15T14:44:25,286  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2023-02-15T14:44:25,287  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:44:25,287  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:44:25,289  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2023-02-15T14:44:25,291  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2023-02-15T14:44:25,300  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: myDb	
2023-02-15T14:44:25,301  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2023-02-15T14:44:25,301  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2023-02-15T14:44:25,303  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2023-02-15T14:44:25,305  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2023-02-15T14:44:25,306  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:44:25,328  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.mydb.mytable	
2023-02-15T14:44:25,367  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,367  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,369  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2023-02-15T14:44:25,381  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,381  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,385  WARN [Metastore-Handler-Pool: Thread-44] utils.FileUtils: File file:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db does not exist; Force to delete it.
2023-02-15T14:44:25,385 ERROR [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Failed to delete pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:44:25,397  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:25,397  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:25,397  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:25,397  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:25,397  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:25,397  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:25,397  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:25,397  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:25,397  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:25,397  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:25,397  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:25,397  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:25,397  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:25,397  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:25,398  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2023-02-15T14:44:25,398  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:25,400  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testdb	
2023-02-15T14:44:25,401  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:testdb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2023-02-15T14:44:25,402  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Creating database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testdb.db
2023-02-15T14:44:25,403  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testdb.db
2023-02-15T14:44:25,404  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Created database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testdb.db
2023-02-15T14:44:25,405  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,405  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,407  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#*	
2023-02-15T14:44:25,408  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testdb	
2023-02-15T14:44:25,410  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:44:25,425  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:25,425  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:25,425  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:25,425  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:25,425  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:25,425  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:25,425  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:25,425  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:25,425  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:25,425  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:25,425  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:25,425  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:25,425  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testTable1, dbName:testdb, owner:rizky, createTime:1676501065, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id comment), FieldSchema(name:value, type:string, comment:value comment)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:44:25,427  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testdb.db/testtable1
2023-02-15T14:44:25,438  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,438  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,446  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testdb.testTable1	
2023-02-15T14:44:25,454  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,454  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testTable1, dbName:testdb, owner:rizky, createTime:1676501065, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id comment), FieldSchema(name:value, type:string, comment:value comment)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:44:25,458  WARN [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: create_table_req got 
org.apache.hadoop.hive.metastore.api.AlreadyExistsException: Table hive.testdb.testTable1 already exists
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_core(HMSHandler.java:2275) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_req(HMSHandler.java:2540) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at com.sun.proxy.$Proxy32.create_table_req(Unknown Source) ~[?:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:19435) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:19414) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_352]
	at javax.security.auth.Subject.doAs(Subject.java:422) ~[?:1.8.0_352]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) ~[hadoop-common-3.3.1.jar:?]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
2023-02-15T14:44:25,462 ERROR [Metastore-Handler-Pool: Thread-44] metastore.RetryingHMSHandler: AlreadyExistsException(message:Table hive.testdb.testTable1 already exists)
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_core(HMSHandler.java:2275)
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_req(HMSHandler.java:2540)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.create_table_req(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:19435)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:19414)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:25,463  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testdb.testTable1	
2023-02-15T14:44:25,465  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,468  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.testdb.testTable1	
2023-02-15T14:44:25,477  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,477  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,481  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:44:25,497  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:25,497  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:25,497  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:25,497  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:25,497  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:25,497  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:25,497  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:25,497  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:25,497  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:25,497  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:25,497  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:25,497  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:25,498  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testTable2, dbName:testdb, owner:rizky, createTime:1676501065, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id comment), FieldSchema(name:value, type:string, comment:value comment)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{escape.delim=, line.delim=, field.delim=, mapkey.delim=, serialization.format=1, collection.delim=, serialization.null.format=}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:44:25,499  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testdb.db/testtable2
2023-02-15T14:44:25,503  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,503  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,505  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testdb.testTable2	
2023-02-15T14:44:25,508  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,510  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:44:25,526  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:25,526  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:25,526  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:25,526  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:25,526  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:25,526  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:25,526  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:25,526  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:25,526  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:25,526  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:25,526  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:25,526  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:25,526  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testTable3, dbName:testdb, owner:rizky, createTime:1676501065, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id comment), FieldSchema(name:value, type:string, comment:value comment)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:44:25,528  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testdb.db/testtable3
2023-02-15T14:44:25,531  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,531  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,534  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testdb.testTable3	
2023-02-15T14:44:25,536  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,537  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=2 expired=false
2023-02-15T14:44:25,547  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:25,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:25,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:25,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:25,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:25,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:25,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:25,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:25,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:25,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:25,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:25,547  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:25,547  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:25,548  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:25,548  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2023-02-15T14:44:25,548  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:25,549  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:44:25,564  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:25,564  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:25,564  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:25,564  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:25,564  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:25,564  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:25,564  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:25,564  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:25,564  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:25,564  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:25,564  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:25,564  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:25,565  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:Temptable11110101101000110110010111001100011110110100010111100000100010110110011111111000101011101000010000010101000001100010101101101110000010010000001101000001110011101000010111000010111100111100101101101011011110001010010010111000000110001101110001100000111010010100, dbName:default, owner:rizky, createTime:1676501065, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id columns), FieldSchema(name:value, type:string, comment:id columns)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:44:25,566  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/temptable11110101101000110110010111001100011110110100010111100000100010110110011111111000101011101000010000010101000001100010101101101110000010010000001101000001110011101000010111000010111100111100101101101011011110001010010010111000000110001101110001100000111010010100
2023-02-15T14:44:25,567  WARN [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: create_table_req got 
org.apache.hadoop.hive.metastore.api.MetaException: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/temptable11110101101000110110010111001100011110110100010111100000100010110110011111111000101011101000010000010101000001100010101101101110000010010000001101000001110011101000010111000010111100111100101101101011011110001010010010111000000110001101110001100000111010010100 is not a directory or unable to create one
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_core(HMSHandler.java:2358) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_req(HMSHandler.java:2540) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at com.sun.proxy.$Proxy32.create_table_req(Unknown Source) ~[?:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:19435) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:19414) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_352]
	at javax.security.auth.Subject.doAs(Subject.java:422) ~[?:1.8.0_352]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) ~[hadoop-common-3.3.1.jar:?]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
2023-02-15T14:44:25,568 ERROR [Metastore-Handler-Pool: Thread-44] metastore.RetryingHMSHandler: MetaException(message:pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/temptable11110101101000110110010111001100011110110100010111100000100010110110011111111000101011101000010000010101000001100010101101101110000010010000001101000001110011101000010111000010111100111100101101101011011110001010010010111000000110001101110001100000111010010100 is not a directory or unable to create one)
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_core(HMSHandler.java:2358)
	at org.apache.hadoop.hive.metastore.HMSHandler.create_table_req(HMSHandler.java:2540)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.create_table_req(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:19435)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_table_req.getResult(ThriftHiveMetastore.java:19414)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:25,578  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:25,579  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:25,579  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:25,579  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:25,579  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:25,579  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:25,579  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:25,579  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:25,579  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 4 HCatClient: thread: 1 users=4 expired=false closed=false
2023-02-15T14:44:25,579  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:25,580  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.goodTable	
2023-02-15T14:44:25,581  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:44:25,596  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:25,596  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:25,596  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:25,596  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:25,596  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:25,596  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:25,596  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:25,596  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:25,596  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:25,596  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:25,596  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:25,596  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:25,597  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:goodTable, dbName:default, owner:rizky, createTime:1676501065, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id columns), FieldSchema(name:value, type:string, comment:id columns)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:44:25,598  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/goodtable
2023-02-15T14:44:25,601  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,601  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,604  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.goodTable	
2023-02-15T14:44:25,606  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,607  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=3 expired=false
2023-02-15T14:44:25,617  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:25,617  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:25,617  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:25,617  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:25,617  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:25,617  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:25,617  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:25,617  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:25,617  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:25,617  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:25,617  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:25,617  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:25,617  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:25,618  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:25,618  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 4 HCatClient: thread: 1 users=4 expired=false closed=false
2023-02-15T14:44:25,618  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:25,619  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.temptable	
2023-02-15T14:44:25,620  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.mytable	
2023-02-15T14:44:25,620  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:44:25,641  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:25,641  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:25,641  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:25,641  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:25,641  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:25,641  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:25,641  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:25,641  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:25,641  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:25,641  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:25,641  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:25,641  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:25,642  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:temptable, dbName:default, owner:rizky, createTime:1676501065, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id columns), FieldSchema(name:value, type:string, comment:id columns)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:44:25,643  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/temptable
2023-02-15T14:44:25,646  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,646  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,649  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.temptable	
2023-02-15T14:44:25,651  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,655  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: hive.default.temptable newtbl=mytable	
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.DefaultIncompatibleTableChangeHandler
2023-02-15T14:44:25,665  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Renaming pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/temptable to pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mytable
2023-02-15T14:44:25,672  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,672  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,675  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.temptable	
2023-02-15T14:44:25,676  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.mytable	
2023-02-15T14:44:25,680  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,680  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=3 expired=false
2023-02-15T14:44:25,691  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:25,691  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:25,691  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:25,691  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:25,691  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:25,691  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:25,691  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:25,691  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:25,692  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:25,692  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:25,692  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:25,692  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:25,692  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:25,692  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:25,692  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 4 HCatClient: thread: 1 users=4 expired=false closed=false
2023-02-15T14:44:25,692  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:25,693  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.tableToBeDropped	
2023-02-15T14:44:25,694  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.tableToBeDropped	
2023-02-15T14:44:25,695  INFO [main] api.TestHCatClient: Drop Table Exception: NoSuchObjectException(message:hive.default.tableToBeDropped table not found)
2023-02-15T14:44:25,695  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=3 expired=false
2023-02-15T14:44:25,723  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:25,723  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:25,723  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:25,723  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:25,723  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:25,723  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:25,723  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:25,723  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:25,723  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:25,723  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:25,723  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:25,723  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:25,724  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:25,724  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:25,724  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 4 HCatClient: thread: 1 users=4 expired=false closed=false
2023-02-15T14:44:25,725  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:25,731  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testReplicationTaskIter	
2023-02-15T14:44:25,732  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:testReplicationTaskIter, description:null, locationUri:null, parameters:null, catalogName:hive)	
2023-02-15T14:44:25,733  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Creating database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db
2023-02-15T14:44:25,733  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db
2023-02-15T14:44:25,734  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Created database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db
2023-02-15T14:44:25,734  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,734  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,737  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:44:25,755  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:25,755  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:25,755  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:25,755  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:25,755  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:25,755  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:25,755  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:25,755  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:25,755  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:25,755  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:25,755  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:25,755  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:25,756  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:T1, dbName:testReplicationTaskIter, owner:rizky, createTime:1676501065, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null), FieldSchema(name:b, type:string, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:44:25,757  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t1
2023-02-15T14:44:25,760  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,760  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,762  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:44:25,776  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:25,776  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:25,776  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:25,776  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:25,776  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:25,776  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:25,776  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:25,776  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:25,776  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:25,776  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:25,776  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:25,776  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:25,777  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:T2, dbName:testReplicationTaskIter, owner:rizky, createTime:1676501065, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:int, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:b, type:string, comment:null)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:44:25,778  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2
2023-02-15T14:44:25,782  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,782  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,784  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:25,787  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,788  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:25,791  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,791  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:25,796  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=test1
2023-02-15T14:44:25,802  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,802  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,804  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:25,806  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,807  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:25,809  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul0
2023-02-15T14:44:25,812  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,812  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,814  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul0}]).
2023-02-15T14:44:25,814  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:25,817  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,817  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:25,849  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,849  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,851  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:25,854  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:25,857  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,858  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:25,860  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul1
2023-02-15T14:44:25,863  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,863  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,864  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul1}]).
2023-02-15T14:44:25,864  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:25,867  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,867  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:25,948  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,948  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,950  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:25,952  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:25,955  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,956  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:25,958  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul2
2023-02-15T14:44:25,962  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,962  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,964  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul2}]).
2023-02-15T14:44:25,964  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:25,968  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:25,968  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:25,998  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:25,998  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:25,999  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,001  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,005  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,006  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,008  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul3
2023-02-15T14:44:26,011  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,011  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,012  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul3}]).
2023-02-15T14:44:26,013  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,015  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,015  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,040  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,040  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,042  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,044  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,046  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,047  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,049  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul4
2023-02-15T14:44:26,052  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,052  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,054  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul4}]).
2023-02-15T14:44:26,054  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,056  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,057  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,080  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,080  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,082  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,084  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,089  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,089  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,093  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul5
2023-02-15T14:44:26,096  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,096  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,100  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul5}]).
2023-02-15T14:44:26,101  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,103  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,103  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,126  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,126  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,128  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,130  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,132  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,133  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,135  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul6
2023-02-15T14:44:26,138  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,138  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,139  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul6}]).
2023-02-15T14:44:26,139  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,142  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,142  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,166  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,166  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,168  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,170  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,174  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,175  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,176  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul7
2023-02-15T14:44:26,179  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,179  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,181  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul7}]).
2023-02-15T14:44:26,181  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,183  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,183  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,207  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,207  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,208  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,210  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,212  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,213  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,215  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul8
2023-02-15T14:44:26,217  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,217  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,218  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul8}]).
2023-02-15T14:44:26,219  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,221  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,221  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,243  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,243  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,245  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,247  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,249  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,250  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,251  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul9
2023-02-15T14:44:26,254  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,254  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,255  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul9}]).
2023-02-15T14:44:26,255  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,257  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,258  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,278  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,278  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,280  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,282  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,285  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,286  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,288  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul10
2023-02-15T14:44:26,291  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,291  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,297  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul10}]).
2023-02-15T14:44:26,297  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,301  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,301  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,325  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,325  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,327  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,329  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,331  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,331  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,333  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul11
2023-02-15T14:44:26,336  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,336  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,337  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul11}]).
2023-02-15T14:44:26,338  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,340  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,340  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,362  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,362  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,363  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,365  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,367  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,368  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,369  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul12
2023-02-15T14:44:26,372  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,372  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,374  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul12}]).
2023-02-15T14:44:26,374  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,376  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,376  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,397  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,397  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,398  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,400  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,402  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,403  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,404  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul13
2023-02-15T14:44:26,406  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,406  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,407  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul13}]).
2023-02-15T14:44:26,408  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,409  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,410  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,430  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,430  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,431  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,433  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,435  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,435  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,437  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul14
2023-02-15T14:44:26,439  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,439  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,441  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul14}]).
2023-02-15T14:44:26,441  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,442  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,443  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,462  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,462  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,463  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,465  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,467  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,467  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,469  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul15
2023-02-15T14:44:26,471  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,471  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,474  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul15}]).
2023-02-15T14:44:26,474  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,476  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,476  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,497  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,497  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,499  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,500  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,502  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,503  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,504  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul16
2023-02-15T14:44:26,507  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,507  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,508  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul16}]).
2023-02-15T14:44:26,508  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,510  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,510  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,529  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,529  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,531  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,533  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,535  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,535  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,537  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul17
2023-02-15T14:44:26,539  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,539  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,540  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul17}]).
2023-02-15T14:44:26,540  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,545  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,545  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,565  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,565  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,566  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,568  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,570  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,571  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,572  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul18
2023-02-15T14:44:26,575  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,575  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,576  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul18}]).
2023-02-15T14:44:26,576  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,578  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,578  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,601  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,601  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,602  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,604  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,606  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,606  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.testreplicationtaskiter.t2	
2023-02-15T14:44:26,608  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testreplicationtaskiter.db/t2/b=testmul19
2023-02-15T14:44:26,610  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,610  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,611  INFO [main] api.HCatClientHMSImpl: HCatClient dropPartitions(db=testReplicationTaskIter,table=T2, partitionSpec: [{b=testmul19}]).
2023-02-15T14:44:26,611  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,613  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,614  INFO [main] api.HCatClientHMSImpl: HCatClient: Dropping partitions using partition-predicate Expressions.
2023-02-15T14:44:26,633  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,633  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,634  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: dropPartition() will move partition-directories to trash-directory.
2023-02-15T14:44:26,636  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T1	
2023-02-15T14:44:26,638  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,639  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.testReplicationTaskIter.T1	
2023-02-15T14:44:26,674  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,675  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,679  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,681  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,681  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.testReplicationTaskIter.T2	
2023-02-15T14:44:26,698  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,698  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:1:1676501064,t:CREATE_DATABASE,o:myDb.null
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:2:1676501064,t:CREATE_TABLE,o:myDb.myTable
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:3:1676501064,t:ADD_PARTITION,o:mydb.mytable
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:4:1676501064,t:ADD_PARTITION,o:mydb.mytable
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:5:1676501064,t:ADD_PARTITION,o:mydb.mytable
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:6:1676501064,t:ADD_PARTITION,o:mydb.mytable
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:7:1676501064,t:DROP_TABLE,o:mydb.mytable
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:8:1676501064,t:DROP_DATABASE,o:mydb.null
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:9:1676501064,t:CREATE_DATABASE,o:locationDB.null
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:10:1676501064,t:CREATE_DATABASE,o:myDb.null
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:11:1676501064,t:CREATE_TABLE,o:myDb.myTable
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:12:1676501064,t:ADD_PARTITION,o:mydb.mytable
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:13:1676501064,t:ADD_PARTITION,o:mydb.mytable
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:14:1676501064,t:ADD_PARTITION,o:mydb.mytable
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:15:1676501064,t:ADD_PARTITION,o:mydb.mytable
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:16:1676501065,t:DROP_PARTITION,o:mydb.mytable
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:17:1676501065,t:DROP_TABLE,o:mydb.mytable
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:18:1676501065,t:DROP_DATABASE,o:mydb.null
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:19:1676501065,t:CREATE_DATABASE,o:testdb.null
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:20:1676501065,t:CREATE_TABLE,o:testdb.testTable1
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:21:1676501065,t:DROP_TABLE,o:testdb.testtable1
2023-02-15T14:44:26,712  INFO [main] api.TestHCatClient: notif from dblistener:22:1676501065,t:CREATE_TABLE,o:testdb.testTable2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:23:1676501065,t:CREATE_TABLE,o:testdb.testTable3
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:24:1676501065,t:CREATE_TABLE,o:default.goodTable
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:25:1676501065,t:CREATE_TABLE,o:default.temptable
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:26:1676501065,t:ALTER_TABLE,o:default.mytable
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:27:1676501065,t:CREATE_DATABASE,o:testReplicationTaskIter.null
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:28:1676501065,t:CREATE_TABLE,o:testReplicationTaskIter.T1
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:29:1676501065,t:CREATE_TABLE,o:testReplicationTaskIter.T2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:30:1676501065,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:31:1676501065,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:32:1676501065,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:33:1676501065,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:34:1676501065,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:35:1676501065,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:36:1676501065,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:37:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:38:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:39:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:40:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:41:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:42:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:43:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:44:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:45:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:46:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:47:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:48:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:49:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:50:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:51:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:52:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:53:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:54:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:55:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:56:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:57:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:58:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:59:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:60:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:61:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:62:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:63:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:64:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:65:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:66:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:67:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:68:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:69:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:70:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:71:1676501066,t:DROP_TABLE,o:testreplicationtaskiter.t1
2023-02-15T14:44:26,713  INFO [main] api.TestHCatClient: notif from dblistener:72:1676501066,t:DROP_TABLE,o:testreplicationtaskiter.t2
2023-02-15T14:44:26,732  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:26,732  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:26,732  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:26,732  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:26,732  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:26,732  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:26,732  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:26,732  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:26,732  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:26,732  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:26,732  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:26,732  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.hcatalog.messaging.json.JSONMessageFactory
2023-02-15T14:44:26,804  INFO [main] api.TestHCatClient: notif from tasks:27:1676501065,t:CREATE_DATABASE,o:testReplicationTaskIter.null,s:DB
2023-02-15T14:44:26,804  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.CreateDatabaseReplicationTask
2023-02-15T14:44:26,804  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,804  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,808  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPGw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[27]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,808  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,808  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPGw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[27]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,837  INFO [main] api.TestHCatClient: notif from tasks:28:1676501065,t:CREATE_TABLE,o:testReplicationTaskIter.T1,s:TABLE
2023-02-15T14:44:26,837  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.CreateTableReplicationTask
2023-02-15T14:44:26,837  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,837  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,837  INFO [main] api.TestHCatClient: getStagingDirectory(28.testreplicationtaskiter.t1.null.1755218969) called!
2023-02-15T14:44:26,837  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdFJlcGxpY2F0aW9uVGFza0l0ZXI3AAAAAlQxATcAAAAyL3RtcC8yOC50ZXN0cmVwbGljYXRpb250YXNraXRlci50MS5udWxsLjE3NTUyMTg5NjkFAA8c
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[28]
CMD:EXPORT TABLE testReplicationTaskIter.T1 TO '/tmp/28.testreplicationtaskiter.t1.null.1755218969' FOR REPLICATION('28')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/28.testreplicationtaskiter.t1.null.1755218969
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/28.testreplicationtaskiter.t1.null.1755218969

2023-02-15T14:44:26,837  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,838  INFO [main] api.TestHCatClient: getStagingDirectory(28.testreplicationtaskiter.t1.null.1755218969) called!
2023-02-15T14:44:26,838  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdFJlcGxpY2F0aW9uVGFza0l0ZXI3AAAAAlQxATcAAAAyL3RtcC8yOC50ZXN0cmVwbGljYXRpb250YXNraXRlci50MS5udWxsLjE3NTUyMTg5NjkFAA8c
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[28]
CMD:IMPORT TABLE testReplicationTaskIter.T1 FROM '/tmp/28.testreplicationtaskiter.t1.null.1755218969'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/28.testreplicationtaskiter.t1.null.1755218969

2023-02-15T14:44:26,838  INFO [main] api.TestHCatClient: notif from tasks:29:1676501065,t:CREATE_TABLE,o:testReplicationTaskIter.T2,s:TABLE
2023-02-15T14:44:26,838  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.CreateTableReplicationTask
2023-02-15T14:44:26,838  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,838  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,838  INFO [main] api.TestHCatClient: getStagingDirectory(29.testreplicationtaskiter.t2.null.1755219000) called!
2023-02-15T14:44:26,838  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdFJlcGxpY2F0aW9uVGFza0l0ZXI3AAAAAlQyATcAAAAyL3RtcC8yOS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5udWxsLjE3NTUyMTkwMDAFAA8d
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[29]
CMD:EXPORT TABLE testReplicationTaskIter.T2 TO '/tmp/29.testreplicationtaskiter.t2.null.1755219000' FOR REPLICATION('29')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/29.testreplicationtaskiter.t2.null.1755219000
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/29.testreplicationtaskiter.t2.null.1755219000

2023-02-15T14:44:26,838  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,838  INFO [main] api.TestHCatClient: getStagingDirectory(29.testreplicationtaskiter.t2.null.1755219000) called!
2023-02-15T14:44:26,838  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdFJlcGxpY2F0aW9uVGFza0l0ZXI3AAAAAlQyATcAAAAyL3RtcC8yOS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5udWxsLjE3NTUyMTkwMDAFAA8d
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[29]
CMD:IMPORT TABLE testReplicationTaskIter.T2 FROM '/tmp/29.testreplicationtaskiter.t2.null.1755219000'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/29.testreplicationtaskiter.t2.null.1755219000

2023-02-15T14:44:26,841  INFO [main] api.TestHCatClient: notif from tasks:30:1676501065,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,842  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,842  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,842  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,842  INFO [main] api.TestHCatClient: getStagingDirectory(30.testreplicationtaskiter.t2.b=test1.-1038536203) called!
2023-02-15T14:44:26,842  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAABXRlc3QxNwAAADYvdG1wLzMwLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdDEuLTEwMzg1MzYyMDMFAA8e
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[30]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="test1") TO '/tmp/30.testreplicationtaskiter.t2.b=test1.-1038536203' FOR REPLICATION('30')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/30.testreplicationtaskiter.t2.b=test1.-1038536203
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/30.testreplicationtaskiter.t2.b=test1.-1038536203

2023-02-15T14:44:26,842  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,842  INFO [main] api.TestHCatClient: getStagingDirectory(30.testreplicationtaskiter.t2.b=test1.-1038536203) called!
2023-02-15T14:44:26,842  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAABXRlc3QxNwAAADYvdG1wLzMwLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdDEuLTEwMzg1MzYyMDMFAA8e
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[30]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="test1") FROM '/tmp/30.testreplicationtaskiter.t2.b=test1.-1038536203'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/30.testreplicationtaskiter.t2.b=test1.-1038536203

2023-02-15T14:44:26,843  INFO [main] api.TestHCatClient: notif from tasks:31:1676501065,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,843  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,843  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,843  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,843  INFO [main] api.TestHCatClient: getStagingDirectory(31.testreplicationtaskiter.t2.b=testmul0.2000150612) called!
2023-02-15T14:44:26,843  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwwNwAAADgvdG1wLzMxLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDAuMjAwMDE1MDYxMgUADx8=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[31]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul0") TO '/tmp/31.testreplicationtaskiter.t2.b=testmul0.2000150612' FOR REPLICATION('31')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/31.testreplicationtaskiter.t2.b=testmul0.2000150612
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/31.testreplicationtaskiter.t2.b=testmul0.2000150612

2023-02-15T14:44:26,843  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,843  INFO [main] api.TestHCatClient: getStagingDirectory(31.testreplicationtaskiter.t2.b=testmul0.2000150612) called!
2023-02-15T14:44:26,843  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwwNwAAADgvdG1wLzMxLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDAuMjAwMDE1MDYxMgUADx8=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[31]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul0") FROM '/tmp/31.testreplicationtaskiter.t2.b=testmul0.2000150612'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/31.testreplicationtaskiter.t2.b=testmul0.2000150612

2023-02-15T14:44:26,844  INFO [main] api.TestHCatClient: notif from tasks:32:1676501065,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,844  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,844  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,844  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPIA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[32]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsMAUBDyA=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[32]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul0") FOR REPLICATION('32')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: notif from tasks:33:1676501065,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: getStagingDirectory(33.testreplicationtaskiter.t2.b=testmul1.2000150613) called!
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwxNwAAADgvdG1wLzMzLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDEuMjAwMDE1MDYxMwUADyE=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[33]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul1") TO '/tmp/33.testreplicationtaskiter.t2.b=testmul1.2000150613' FOR REPLICATION('33')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/33.testreplicationtaskiter.t2.b=testmul1.2000150613
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/33.testreplicationtaskiter.t2.b=testmul1.2000150613

2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: getStagingDirectory(33.testreplicationtaskiter.t2.b=testmul1.2000150613) called!
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwxNwAAADgvdG1wLzMzLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDEuMjAwMDE1MDYxMwUADyE=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[33]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul1") FROM '/tmp/33.testreplicationtaskiter.t2.b=testmul1.2000150613'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/33.testreplicationtaskiter.t2.b=testmul1.2000150613

2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: notif from tasks:34:1676501065,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPIg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[34]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,845  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsMQUBDyI=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[34]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul1") FOR REPLICATION('34')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: notif from tasks:35:1676501065,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: getStagingDirectory(35.testreplicationtaskiter.t2.b=testmul2.2000150810) called!
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwyNwAAADgvdG1wLzM1LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDIuMjAwMDE1MDgxMAUADyM=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[35]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul2") TO '/tmp/35.testreplicationtaskiter.t2.b=testmul2.2000150810' FOR REPLICATION('35')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/35.testreplicationtaskiter.t2.b=testmul2.2000150810
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/35.testreplicationtaskiter.t2.b=testmul2.2000150810

2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: getStagingDirectory(35.testreplicationtaskiter.t2.b=testmul2.2000150810) called!
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwyNwAAADgvdG1wLzM1LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDIuMjAwMDE1MDgxMAUADyM=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[35]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul2") FROM '/tmp/35.testreplicationtaskiter.t2.b=testmul2.2000150810'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/35.testreplicationtaskiter.t2.b=testmul2.2000150810

2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: notif from tasks:36:1676501065,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPJA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[36]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsMgUBDyQ=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[36]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul2") FOR REPLICATION('36')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: notif from tasks:37:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: getStagingDirectory(37.testreplicationtaskiter.t2.b=testmul3.2000150811) called!
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwzNwAAADgvdG1wLzM3LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDMuMjAwMDE1MDgxMQUADyU=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[37]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul3") TO '/tmp/37.testreplicationtaskiter.t2.b=testmul3.2000150811' FOR REPLICATION('37')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/37.testreplicationtaskiter.t2.b=testmul3.2000150811
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/37.testreplicationtaskiter.t2.b=testmul3.2000150811

2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: getStagingDirectory(37.testreplicationtaskiter.t2.b=testmul3.2000150811) called!
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWwzNwAAADgvdG1wLzM3LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDMuMjAwMDE1MDgxMQUADyU=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[37]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul3") FROM '/tmp/37.testreplicationtaskiter.t2.b=testmul3.2000150811'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/37.testreplicationtaskiter.t2.b=testmul3.2000150811

2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: notif from tasks:38:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPJg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[38]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,846  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsMwUBDyY=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[38]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul3") FOR REPLICATION('38')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: notif from tasks:39:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: getStagingDirectory(39.testreplicationtaskiter.t2.b=testmul4.2000150808) called!
2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw0NwAAADgvdG1wLzM5LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDQuMjAwMDE1MDgwOAUADyc=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[39]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul4") TO '/tmp/39.testreplicationtaskiter.t2.b=testmul4.2000150808' FOR REPLICATION('39')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/39.testreplicationtaskiter.t2.b=testmul4.2000150808
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/39.testreplicationtaskiter.t2.b=testmul4.2000150808

2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: getStagingDirectory(39.testreplicationtaskiter.t2.b=testmul4.2000150808) called!
2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw0NwAAADgvdG1wLzM5LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDQuMjAwMDE1MDgwOAUADyc=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[39]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul4") FROM '/tmp/39.testreplicationtaskiter.t2.b=testmul4.2000150808'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/39.testreplicationtaskiter.t2.b=testmul4.2000150808

2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: notif from tasks:40:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPKA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[40]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,847  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsNAUBDyg=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[40]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul4") FOR REPLICATION('40')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: notif from tasks:41:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: getStagingDirectory(41.testreplicationtaskiter.t2.b=testmul5.2000150809) called!
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw1NwAAADgvdG1wLzQxLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDUuMjAwMDE1MDgwOQUADyk=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[41]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul5") TO '/tmp/41.testreplicationtaskiter.t2.b=testmul5.2000150809' FOR REPLICATION('41')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/41.testreplicationtaskiter.t2.b=testmul5.2000150809
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/41.testreplicationtaskiter.t2.b=testmul5.2000150809

2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: getStagingDirectory(41.testreplicationtaskiter.t2.b=testmul5.2000150809) called!
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw1NwAAADgvdG1wLzQxLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDUuMjAwMDE1MDgwOQUADyk=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[41]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul5") FROM '/tmp/41.testreplicationtaskiter.t2.b=testmul5.2000150809'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/41.testreplicationtaskiter.t2.b=testmul5.2000150809

2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: notif from tasks:42:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPKg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[42]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsNQUBDyo=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[42]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul5") FOR REPLICATION('42')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: notif from tasks:43:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: getStagingDirectory(43.testreplicationtaskiter.t2.b=testmul6.2000150814) called!
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw2NwAAADgvdG1wLzQzLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDYuMjAwMDE1MDgxNAUADys=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[43]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul6") TO '/tmp/43.testreplicationtaskiter.t2.b=testmul6.2000150814' FOR REPLICATION('43')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/43.testreplicationtaskiter.t2.b=testmul6.2000150814
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/43.testreplicationtaskiter.t2.b=testmul6.2000150814

2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: getStagingDirectory(43.testreplicationtaskiter.t2.b=testmul6.2000150814) called!
2023-02-15T14:44:26,848  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw2NwAAADgvdG1wLzQzLnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDYuMjAwMDE1MDgxNAUADys=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[43]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul6") FROM '/tmp/43.testreplicationtaskiter.t2.b=testmul6.2000150814'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/43.testreplicationtaskiter.t2.b=testmul6.2000150814

2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: notif from tasks:44:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPLA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[44]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsNgUBDyw=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[44]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul6") FOR REPLICATION('44')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: notif from tasks:45:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: getStagingDirectory(45.testreplicationtaskiter.t2.b=testmul7.2000150815) called!
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw3NwAAADgvdG1wLzQ1LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDcuMjAwMDE1MDgxNQUADy0=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[45]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul7") TO '/tmp/45.testreplicationtaskiter.t2.b=testmul7.2000150815' FOR REPLICATION('45')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/45.testreplicationtaskiter.t2.b=testmul7.2000150815
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/45.testreplicationtaskiter.t2.b=testmul7.2000150815

2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: getStagingDirectory(45.testreplicationtaskiter.t2.b=testmul7.2000150815) called!
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw3NwAAADgvdG1wLzQ1LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDcuMjAwMDE1MDgxNQUADy0=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[45]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul7") FROM '/tmp/45.testreplicationtaskiter.t2.b=testmul7.2000150815'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/45.testreplicationtaskiter.t2.b=testmul7.2000150815

2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: notif from tasks:46:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPLg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[46]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsNwUBDy4=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[46]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul7") FOR REPLICATION('46')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: notif from tasks:47:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: getStagingDirectory(47.testreplicationtaskiter.t2.b=testmul8.2000150812) called!
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw4NwAAADgvdG1wLzQ3LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDguMjAwMDE1MDgxMgUADy8=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[47]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul8") TO '/tmp/47.testreplicationtaskiter.t2.b=testmul8.2000150812' FOR REPLICATION('47')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/47.testreplicationtaskiter.t2.b=testmul8.2000150812
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/47.testreplicationtaskiter.t2.b=testmul8.2000150812

2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: getStagingDirectory(47.testreplicationtaskiter.t2.b=testmul8.2000150812) called!
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw4NwAAADgvdG1wLzQ3LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDguMjAwMDE1MDgxMgUADy8=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[47]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul8") FROM '/tmp/47.testreplicationtaskiter.t2.b=testmul8.2000150812'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/47.testreplicationtaskiter.t2.b=testmul8.2000150812

2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: notif from tasks:48:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPMA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[48]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsOAUBDzA=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[48]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul8") FOR REPLICATION('48')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: notif from tasks:49:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,849  INFO [main] api.TestHCatClient: getStagingDirectory(49.testreplicationtaskiter.t2.b=testmul9.2000150813) called!
2023-02-15T14:44:26,850  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw5NwAAADgvdG1wLzQ5LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDkuMjAwMDE1MDgxMwUADzE=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[49]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul9") TO '/tmp/49.testreplicationtaskiter.t2.b=testmul9.2000150813' FOR REPLICATION('49')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/49.testreplicationtaskiter.t2.b=testmul9.2000150813
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/49.testreplicationtaskiter.t2.b=testmul9.2000150813

2023-02-15T14:44:26,850  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,850  INFO [main] api.TestHCatClient: getStagingDirectory(49.testreplicationtaskiter.t2.b=testmul9.2000150813) called!
2023-02-15T14:44:26,850  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACHRlc3RtdWw5NwAAADgvdG1wLzQ5LnRlc3RyZXBsaWNhdGlvbnRhc2tpdGVyLnQyLmI9dGVzdG11bDkuMjAwMDE1MDgxMwUADzE=
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[49]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul9") FROM '/tmp/49.testreplicationtaskiter.t2.b=testmul9.2000150813'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/49.testreplicationtaskiter.t2.b=testmul9.2000150813

2023-02-15T14:44:26,850  INFO [main] api.TestHCatClient: notif from tasks:50:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,850  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,850  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,850  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,850  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPMg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[50]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,850  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,850  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAh0ZXN0bXVsOQUBDzI=
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[50]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul9") FOR REPLICATION('50')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: notif from tasks:51:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: getStagingDirectory(51.testreplicationtaskiter.t2.b=testmul10.1979021355) called!
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMDcAAAA5L3RtcC81MS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMC4xOTc5MDIxMzU1BQAPMw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[51]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul10") TO '/tmp/51.testreplicationtaskiter.t2.b=testmul10.1979021355' FOR REPLICATION('51')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/51.testreplicationtaskiter.t2.b=testmul10.1979021355
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/51.testreplicationtaskiter.t2.b=testmul10.1979021355

2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: getStagingDirectory(51.testreplicationtaskiter.t2.b=testmul10.1979021355) called!
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMDcAAAA5L3RtcC81MS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMC4xOTc5MDIxMzU1BQAPMw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[51]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul10") FROM '/tmp/51.testreplicationtaskiter.t2.b=testmul10.1979021355'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/51.testreplicationtaskiter.t2.b=testmul10.1979021355

2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: notif from tasks:52:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPNA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[52]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTAFAQ80
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[52]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul10") FOR REPLICATION('52')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: notif from tasks:53:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: getStagingDirectory(53.testreplicationtaskiter.t2.b=testmul11.1979021352) called!
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMTcAAAA5L3RtcC81My50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMS4xOTc5MDIxMzUyBQAPNQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[53]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul11") TO '/tmp/53.testreplicationtaskiter.t2.b=testmul11.1979021352' FOR REPLICATION('53')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/53.testreplicationtaskiter.t2.b=testmul11.1979021352
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/53.testreplicationtaskiter.t2.b=testmul11.1979021352

2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: getStagingDirectory(53.testreplicationtaskiter.t2.b=testmul11.1979021352) called!
2023-02-15T14:44:26,851  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMTcAAAA5L3RtcC81My50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMS4xOTc5MDIxMzUyBQAPNQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[53]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul11") FROM '/tmp/53.testreplicationtaskiter.t2.b=testmul11.1979021352'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/53.testreplicationtaskiter.t2.b=testmul11.1979021352

2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: notif from tasks:54:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPNg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[54]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTEFAQ82
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[54]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul11") FOR REPLICATION('54')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: notif from tasks:55:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: getStagingDirectory(55.testreplicationtaskiter.t2.b=testmul12.1979021353) called!
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMjcAAAA5L3RtcC81NS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMi4xOTc5MDIxMzUzBQAPNw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[55]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul12") TO '/tmp/55.testreplicationtaskiter.t2.b=testmul12.1979021353' FOR REPLICATION('55')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/55.testreplicationtaskiter.t2.b=testmul12.1979021353
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/55.testreplicationtaskiter.t2.b=testmul12.1979021353

2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: getStagingDirectory(55.testreplicationtaskiter.t2.b=testmul12.1979021353) called!
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMjcAAAA5L3RtcC81NS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMi4xOTc5MDIxMzUzBQAPNw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[55]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul12") FROM '/tmp/55.testreplicationtaskiter.t2.b=testmul12.1979021353'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/55.testreplicationtaskiter.t2.b=testmul12.1979021353

2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: notif from tasks:56:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPOA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[56]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTIFAQ84
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[56]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul12") FOR REPLICATION('56')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: notif from tasks:57:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: getStagingDirectory(57.testreplicationtaskiter.t2.b=testmul13.1979021358) called!
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMzcAAAA5L3RtcC81Ny50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMy4xOTc5MDIxMzU4BQAPOQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[57]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul13") TO '/tmp/57.testreplicationtaskiter.t2.b=testmul13.1979021358' FOR REPLICATION('57')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/57.testreplicationtaskiter.t2.b=testmul13.1979021358
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/57.testreplicationtaskiter.t2.b=testmul13.1979021358

2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: getStagingDirectory(57.testreplicationtaskiter.t2.b=testmul13.1979021358) called!
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxMzcAAAA5L3RtcC81Ny50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxMy4xOTc5MDIxMzU4BQAPOQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[57]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul13") FROM '/tmp/57.testreplicationtaskiter.t2.b=testmul13.1979021358'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/57.testreplicationtaskiter.t2.b=testmul13.1979021358

2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: notif from tasks:58:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,852  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPOg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[58]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTMFAQ86
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[58]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul13") FOR REPLICATION('58')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: notif from tasks:59:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: getStagingDirectory(59.testreplicationtaskiter.t2.b=testmul14.1979021359) called!
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNDcAAAA5L3RtcC81OS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNC4xOTc5MDIxMzU5BQAPOw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[59]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul14") TO '/tmp/59.testreplicationtaskiter.t2.b=testmul14.1979021359' FOR REPLICATION('59')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/59.testreplicationtaskiter.t2.b=testmul14.1979021359
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/59.testreplicationtaskiter.t2.b=testmul14.1979021359

2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: getStagingDirectory(59.testreplicationtaskiter.t2.b=testmul14.1979021359) called!
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNDcAAAA5L3RtcC81OS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNC4xOTc5MDIxMzU5BQAPOw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[59]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul14") FROM '/tmp/59.testreplicationtaskiter.t2.b=testmul14.1979021359'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/59.testreplicationtaskiter.t2.b=testmul14.1979021359

2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: notif from tasks:60:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPPA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[60]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,853  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTQFAQ88
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[60]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul14") FOR REPLICATION('60')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: notif from tasks:61:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: getStagingDirectory(61.testreplicationtaskiter.t2.b=testmul15.1979021356) called!
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNTcAAAA5L3RtcC82MS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNS4xOTc5MDIxMzU2BQAPPQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[61]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul15") TO '/tmp/61.testreplicationtaskiter.t2.b=testmul15.1979021356' FOR REPLICATION('61')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/61.testreplicationtaskiter.t2.b=testmul15.1979021356
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/61.testreplicationtaskiter.t2.b=testmul15.1979021356

2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: getStagingDirectory(61.testreplicationtaskiter.t2.b=testmul15.1979021356) called!
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNTcAAAA5L3RtcC82MS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNS4xOTc5MDIxMzU2BQAPPQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[61]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul15") FROM '/tmp/61.testreplicationtaskiter.t2.b=testmul15.1979021356'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/61.testreplicationtaskiter.t2.b=testmul15.1979021356

2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: notif from tasks:62:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPPg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[62]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTUFAQ8-
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[62]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul15") FOR REPLICATION('62')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: notif from tasks:63:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: getStagingDirectory(63.testreplicationtaskiter.t2.b=testmul16.1979021357) called!
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNjcAAAA5L3RtcC82My50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNi4xOTc5MDIxMzU3BQAPPw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[63]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul16") TO '/tmp/63.testreplicationtaskiter.t2.b=testmul16.1979021357' FOR REPLICATION('63')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/63.testreplicationtaskiter.t2.b=testmul16.1979021357
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/63.testreplicationtaskiter.t2.b=testmul16.1979021357

2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: getStagingDirectory(63.testreplicationtaskiter.t2.b=testmul16.1979021357) called!
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNjcAAAA5L3RtcC82My50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNi4xOTc5MDIxMzU3BQAPPw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[63]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul16") FROM '/tmp/63.testreplicationtaskiter.t2.b=testmul16.1979021357'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/63.testreplicationtaskiter.t2.b=testmul16.1979021357

2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: notif from tasks:64:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPQA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[64]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,854  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTYFAQ9A
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[64]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul16") FOR REPLICATION('64')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: notif from tasks:65:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: getStagingDirectory(65.testreplicationtaskiter.t2.b=testmul17.1979021362) called!
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNzcAAAA5L3RtcC82NS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNy4xOTc5MDIxMzYyBQAPQQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[65]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul17") TO '/tmp/65.testreplicationtaskiter.t2.b=testmul17.1979021362' FOR REPLICATION('65')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/65.testreplicationtaskiter.t2.b=testmul17.1979021362
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/65.testreplicationtaskiter.t2.b=testmul17.1979021362

2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: getStagingDirectory(65.testreplicationtaskiter.t2.b=testmul17.1979021362) called!
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxNzcAAAA5L3RtcC82NS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxNy4xOTc5MDIxMzYyBQAPQQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[65]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul17") FROM '/tmp/65.testreplicationtaskiter.t2.b=testmul17.1979021362'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/65.testreplicationtaskiter.t2.b=testmul17.1979021362

2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: notif from tasks:66:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPQg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[66]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTcFAQ9C
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[66]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul17") FOR REPLICATION('66')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: notif from tasks:67:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: getStagingDirectory(67.testreplicationtaskiter.t2.b=testmul18.1979021363) called!
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxODcAAAA5L3RtcC82Ny50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxOC4xOTc5MDIxMzYzBQAPQw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[67]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul18") TO '/tmp/67.testreplicationtaskiter.t2.b=testmul18.1979021363' FOR REPLICATION('67')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/67.testreplicationtaskiter.t2.b=testmul18.1979021363
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/67.testreplicationtaskiter.t2.b=testmul18.1979021363

2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: getStagingDirectory(67.testreplicationtaskiter.t2.b=testmul18.1979021363) called!
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxODcAAAA5L3RtcC82Ny50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxOC4xOTc5MDIxMzYzBQAPQw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[67]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul18") FROM '/tmp/67.testreplicationtaskiter.t2.b=testmul18.1979021363'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/67.testreplicationtaskiter.t2.b=testmul18.1979021363

2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: notif from tasks:68:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPRA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[68]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTgFAQ9E
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[68]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul18") FOR REPLICATION('68')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: notif from tasks:69:1676501066,t:ADD_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.AddPartitionReplicationTask
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: getStagingDirectory(69.testreplicationtaskiter.t2.b=testmul19.1979021360) called!
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRXhwb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxOTcAAAA5L3RtcC82OS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxOS4xOTc5MDIxMzYwBQAPRQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ExportCommand]
EVENTID:[69]
CMD:EXPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul19") TO '/tmp/69.testreplicationtaskiter.t2.b=testmul19.1979021360' FOR REPLICATION('69')
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :1RETRY_CLEANUP:/tmp/69.testreplicationtaskiter.t2.b=testmul19.1979021360
cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/69.testreplicationtaskiter.t2.b=testmul19.1979021360

2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: getStagingDirectory(69.testreplicationtaskiter.t2.b=testmul19.1979021360) called!
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADhvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuSW1wb3J0Q29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyZAAAAAE3AAAAAWI3AAAACXRlc3RtdWwxOTcAAAA5L3RtcC82OS50ZXN0cmVwbGljYXRpb250YXNraXRlci50Mi5iPXRlc3RtdWwxOS4xOTc5MDIxMzYwBQAPRQ==
CMD:[org.apache.hive.hcatalog.api.repl.commands.ImportCommand]
EVENTID:[69]
CMD:IMPORT TABLE testreplicationtaskiter.t2 PARTITION (b="testmul19") FROM '/tmp/69.testreplicationtaskiter.t2.b=testmul19.1979021360'
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :1AFTER_EVENT_CLEANUP:/tmp/69.testreplicationtaskiter.t2.b=testmul19.1979021360

2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: notif from tasks:70:1676501066,t:DROP_PARTITION,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropPartitionReplicationTask
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPRg==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[70]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,855  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,856  INFO [main] api.TestHCatClient: SERIALIZED:NwAAAD9vcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFBhcnRpdGlvbkNvbW1hbmQ3AAAAF3Rlc3RyZXBsaWNhdGlvbnRhc2tpdGVyNwAAAAJ0MmQAAAABNwAAAAFiNwAAAAl0ZXN0bXVsMTkFAQ9G
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropPartitionCommand]
EVENTID:[70]
CMD:ALTER TABLE testreplicationtaskiter.t2 DROP IF EXISTS PARTITION (b="testmul19") FOR REPLICATION('70')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,857  INFO [main] api.TestHCatClient: notif from tasks:71:1676501066,t:DROP_TABLE,o:testreplicationtaskiter.t1,s:TABLE
2023-02-15T14:44:26,857  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropTableReplicationTask
2023-02-15T14:44:26,857  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,857  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,857  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPRw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[71]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,857  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,858  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADtvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFRhYmxlQ29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQxBQEPRw==
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropTableCommand]
EVENTID:[71]
CMD:DROP TABLE IF EXISTS testreplicationtaskiter.t1 FOR REPLICATION('71')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,858  INFO [main] api.TestHCatClient: notif from tasks:72:1676501066,t:DROP_TABLE,o:testreplicationtaskiter.t2,s:TABLE
2023-02-15T14:44:26,858  INFO [main] api.TestHCatClient: task :org.apache.hive.hcatalog.api.repl.exim.DropTableReplicationTask
2023-02-15T14:44:26,858  INFO [main] api.TestHCatClient: task was actionable!
2023-02-15T14:44:26,858  INFO [main] api.TestHCatClient: On src:
2023-02-15T14:44:26,858  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADZvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuTm9vcENvbW1hbmQPSA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.NoopCommand]
EVENTID:[72]
Retriable:true
Undoable:true
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,858  INFO [main] api.TestHCatClient: On dest:
2023-02-15T14:44:26,858  INFO [main] api.TestHCatClient: SERIALIZED:NwAAADtvcmcuYXBhY2hlLmhpdmUuaGNhdGFsb2cuYXBpLnJlcGwuY29tbWFuZHMuRHJvcFRhYmxlQ29tbWFuZDcAAAAXdGVzdHJlcGxpY2F0aW9udGFza2l0ZXI3AAAAAnQyBQEPSA==
CMD:[org.apache.hive.hcatalog.api.repl.commands.DropTableCommand]
EVENTID:[72]
CMD:DROP TABLE IF EXISTS testreplicationtaskiter.t2 FOR REPLICATION('72')
Retriable:true
Undoable:false
cleanupLocationsPerRetry entries :0cleanupLocationsAfterEvent entries :0
2023-02-15T14:44:26,869  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:26,869  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:26,869  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:26,869  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:26,869  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:26,869  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:26,869  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:26,869  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:26,869  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:26,869  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:26,869  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:26,869  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:26,869  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:26,869  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:26,870  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 5 HCatClient: thread: 1 users=5 expired=false closed=false
2023-02-15T14:44:26,870  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:26,872  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testObjectNotFoundException_DBName	
2023-02-15T14:44:26,872  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testObjectNotFoundException_DBName	
2023-02-15T14:44:26,873  INFO [main] api.TestHCatClient: Got exception: 
org.apache.hive.hcatalog.api.ObjectNotFoundException: org.apache.hive.hcatalog.common.HCatException : 9001 : Exception occurred while processing HCat request : NoSuchObjectException while fetching database. Cause : NoSuchObjectException(message:database hive.testObjectNotFoundException_DBName)
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getDatabase(HCatClientHMSImpl.java:116) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testObjectNotFoundException(TestHCatClient.java:575) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.hadoop.hive.metastore.api.NoSuchObjectException: database hive.testObjectNotFoundException_DBName
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_database_req_result$get_database_req_resultStandardScheme.read(ThriftHiveMetastore.java:55047) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_database_req_result$get_database_req_resultStandardScheme.read(ThriftHiveMetastore.java:55024) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_database_req_result.read(ThriftHiveMetastore.java:54955) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_database_req(ThriftHiveMetastore.java:1420) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_database_req(ThriftHiveMetastore.java:1407) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getDatabaseInternal(HiveMetaStoreClient.java:2444) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getDatabase(HiveMetaStoreClient.java:2431) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getDatabase(HiveMetaStoreClient.java:2412) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at com.sun.proxy.$Proxy33.getDatabase(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getDatabase(HCatClientHMSImpl.java:111) ~[classes/:?]
	... 31 more
2023-02-15T14:44:26,873  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:testObjectNotFoundException_DBName, description:null, locationUri:null, parameters:null, catalogName:hive)	
2023-02-15T14:44:26,875  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Creating database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testobjectnotfoundexception_dbname.db
2023-02-15T14:44:26,875  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testobjectnotfoundexception_dbname.db
2023-02-15T14:44:26,877  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Created database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testobjectnotfoundexception_dbname.db
2023-02-15T14:44:26,878  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,878  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,880  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testObjectNotFoundException_DBName.testObjectNotFoundException_TableName	
2023-02-15T14:44:26,881  INFO [main] api.TestHCatClient: Got exception: 
org.apache.hive.hcatalog.api.ObjectNotFoundException: org.apache.hive.hcatalog.common.HCatException : 9001 : Exception occurred while processing HCat request : NoSuchObjectException while fetching table.. Cause : NoSuchObjectException(message:hive.testObjectNotFoundException_DBName.testObjectNotFoundException_TableName table not found)
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getTable(HCatClientHMSImpl.java:200) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testObjectNotFoundException(TestHCatClient.java:586) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.hadoop.hive.metastore.api.NoSuchObjectException: hive.testObjectNotFoundException_DBName.testObjectNotFoundException_TableName table not found
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_table_req_result$get_table_req_resultStandardScheme.read(ThriftHiveMetastore.java) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_table_req_result$get_table_req_resultStandardScheme.read(ThriftHiveMetastore.java) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_table_req_result.read(ThriftHiveMetastore.java) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:88) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_table_req(ThriftHiveMetastore.java:2742) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_table_req(ThriftHiveMetastore.java:2729) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTableInternal(HiveMetaStoreClient.java:2632) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:2690) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getTable(HiveMetaStoreClient.java:2568) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at sun.reflect.GeneratedMethodAccessor75.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at com.sun.proxy.$Proxy33.getTable(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getTable(HCatClientHMSImpl.java:193) ~[classes/:?]
	... 31 more
2023-02-15T14:44:26,882  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:44:26,898  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:26,898  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:26,898  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:26,898  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:26,898  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:26,898  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:26,898  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:26,898  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:26,898  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:26,898  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:26,898  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:26,898  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:26,899  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testObjectNotFoundException_TableName, dbName:testObjectNotFoundException_DBName, owner:rizky, createTime:1676501066, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:col, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:part, type:string, comment:)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:44:26,900  INFO [Metastore-Handler-Pool: Thread-44] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testobjectnotfoundexception_dbname.db/testobjectnotfoundexception_tablename
2023-02-15T14:44:26,909  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:26,909  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:26,911  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testObjectNotFoundException_DBName.testObjectNotFoundException_TableName	
2023-02-15T14:44:26,913  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,913  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testObjectNotFoundException_DBName.testObjectNotFoundException_TableName	
2023-02-15T14:44:26,914  INFO [Metastore-Handler-Pool: Thread-44] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:26,918  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2023-02-15T14:44:26,918  INFO [Metastore-Handler-Pool: Thread-44] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@29f8fbfa, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d125920 will be shutdown
2023-02-15T14:44:26,918  INFO [Metastore-Handler-Pool: Thread-44] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Exception in thread "Metastore-Handler-Pool: Thread-44" java.lang.NoSuchMethodError: org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_partition_args.access$6(Lorg/apache/hadoop/hive/metastore/api/ThriftHiveMetastore$get_partition_args;)Ljava/lang/String;
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:20846)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:1)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-15T14:44:26,918  WARN [main] metastore.RetryingMetaStoreClient: MetaStoreClient lost connection. Attempting to reconnect (1 of 1) after 1s. getPartition
org.apache.thrift.transport.TTransportException: Socket is closed by peer.
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:184) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:109) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:464) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:362) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:245) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_partition(ThriftHiveMetastore.java:3477) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_partition(ThriftHiveMetastore.java:3462) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2468) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2450) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at com.sun.proxy.$Proxy33.getPartition(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getPartition(HCatClientHMSImpl.java:455) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testObjectNotFoundException(TestHCatClient.java:607) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T14:44:27,919  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient trying reconnect as rizky (auth:SIMPLE)
2023-02-15T14:44:27,920  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=4 expired=false
2023-02-15T14:44:27,921  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:42647) in binary transport mode
2023-02-15T14:44:27,921  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:42647) current connections: 2
2023-02-15T14:44:27,925  INFO [Metastore-Handler-Pool: Thread-143] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Exception in thread "Metastore-Handler-Pool: Thread-143" java.lang.NoSuchMethodError: org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_partition_args.access$6(Lorg/apache/hadoop/hive/metastore/api/ThriftHiveMetastore$get_partition_args;)Ljava/lang/String;
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:20846)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:1)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-15T14:44:27,926  INFO [main] api.TestHCatClient: Got exception: 
org.apache.hive.hcatalog.api.ConnectionFailureException: org.apache.hive.hcatalog.common.HCatException : 9001 : Exception occurred while processing HCat request : TException while retrieving partition.. Cause : org.apache.thrift.transport.TTransportException: Socket is closed by peer.
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getPartition(HCatClientHMSImpl.java:467) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testObjectNotFoundException(TestHCatClient.java:607) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.thrift.transport.TTransportException: Socket is closed by peer.
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:184) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:109) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:464) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:362) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:245) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_partition(ThriftHiveMetastore.java:3477) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_partition(ThriftHiveMetastore.java:3462) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2468) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2450) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at com.sun.proxy.$Proxy33.getPartition(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getPartition(HCatClientHMSImpl.java:455) ~[classes/:?]
	... 31 more
2023-02-15T14:44:27,928 ERROR [main] api.TestHCatClient: Unexpected exception!
java.lang.AssertionError: Expected ObjectNotFoundException. Got:class org.apache.hive.hcatalog.api.ConnectionFailureException
	at org.junit.Assert.fail(Assert.java:89) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.Assert.assertTrue(Assert.java:42) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.hive.hcatalog.api.TestHCatClient.testObjectNotFoundException(TestHCatClient.java:611) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T14:44:27,955  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:27,955  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:27,955  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:27,955  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:27,955  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:27,955  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:27,956  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:27,956  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:27,956  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:27,956  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:27,956  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:27,956  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:27,956  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T14:44:27,980  INFO [main] utils.TestTxnDbUtil: Reinitializing the metastore db with hive-schema-4.0.0.derby.sql on the database jdbc:derby:memory:/home/rizky/hive/hcatalog/webhcat/java-client/target/tmp/junit_metastore_db_37795;create=true
2023-02-15T14:44:28,111  INFO [MetaStoreThread-37795] metastore.AuthFactory: Using authentication NOSASL with kerberos authentication disabled
2023-02-15T14:44:28,111  INFO [main] metastore.MetaStoreTestUtils: Waiting the HMS to start.
2023-02-15T14:44:28,112  INFO [MetaStoreThread-37795] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T14:44:28,112  INFO [MetaStoreThread-37795] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T14:44:28,112  INFO [MetaStoreThread-37795] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2023-02-15T14:44:28,115  INFO [MetaStoreThread-37795] hikari.HikariDataSource: objectstore - Shutdown initiated...
2023-02-15T14:44:28,116  INFO [MetaStoreThread-37795] hikari.HikariDataSource: objectstore - Shutdown completed.
2023-02-15T14:44:28,116  INFO [MetaStoreThread-37795] hikari.HikariDataSource: objectstore-secondary - Shutdown initiated...
2023-02-15T14:44:28,116  INFO [MetaStoreThread-37795] hikari.HikariDataSource: objectstore-secondary - Shutdown completed.
2023-02-15T14:44:28,116  INFO [MetaStoreThread-37795] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: objectstore
2023-02-15T14:44:28,116  WARN [MetaStoreThread-37795] hikari.HikariConfig: objectstore - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:44:28,117  INFO [MetaStoreThread-37795] hikari.HikariDataSource: objectstore - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:44:28,118  INFO [MetaStoreThread-37795] pool.PoolBase: objectstore - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:44:28,118  INFO [MetaStoreThread-37795] hikari.HikariDataSource: objectstore - Start completed.
2023-02-15T14:44:28,118  INFO [MetaStoreThread-37795] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 2, name: objectstore-secondary
2023-02-15T14:44:28,118  WARN [MetaStoreThread-37795] hikari.HikariConfig: objectstore-secondary - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:44:28,118  INFO [MetaStoreThread-37795] hikari.HikariDataSource: objectstore-secondary - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:44:28,119  INFO [MetaStoreThread-37795] pool.PoolBase: objectstore-secondary - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:44:28,119  INFO [MetaStoreThread-37795] hikari.HikariDataSource: objectstore-secondary - Start completed.
2023-02-15T14:44:28,442  INFO [MetaStoreThread-37795] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2023-02-15T14:44:28,443  INFO [MetaStoreThread-37795] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d5befd9, with PersistenceManager: null will be shutdown
2023-02-15T14:44:28,443  INFO [MetaStoreThread-37795] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d5befd9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6710c203 created in the thread with id: 147
2023-02-15T14:44:28,686  INFO [MetaStoreThread-37795] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d5befd9
2023-02-15T14:44:28,689  INFO [MetaStoreThread-37795] metastore.HMSHandler: Setting location of default catalog, as it hasn't been done after upgrade
2023-02-15T14:44:28,691  INFO [MetaStoreThread-37795] metastore.HMSHandler: Started creating a default database with name: default
2023-02-15T14:44:28,695  INFO [MetaStoreThread-37795] metastore.HMSHandler: Successfully created a default database with name: default
2023-02-15T14:44:28,699  INFO [MetaStoreThread-37795] metastore.HMSHandler: Added admin role in metastore
2023-02-15T14:44:28,700  INFO [MetaStoreThread-37795] metastore.HMSHandler: Added public role in metastore
2023-02-15T14:44:28,709  INFO [MetaStoreThread-37795] metastore.HMSHandler: Added hive_admin_user to admin role
2023-02-15T14:44:28,709  INFO [MetaStoreThread-37795] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T14:44:28,709  INFO [MetaStoreThread-37795] metastore.HiveMetaStore: Starting DB backed MetaStore Server with SetUGI enabled
2023-02-15T14:44:28,709  INFO [MetaStoreThread-37795] metastore.HiveMetaStore: Direct SQL optimization = true
2023-02-15T14:44:29,127  INFO [Metastore-Handler-Pool: Thread-160] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T14:44:29,132  INFO [main] metastore.MetaStoreTestUtils: MetaStore warehouse root dir (pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/37795) is created
2023-02-15T14:44:29,132  INFO [main] metastore.MetaStoreTestUtils: MetaStore Thrift Server started on port: 37795 with warehouse dir: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/37795 with jdbcUrl: jdbc:derby:memory:/home/rizky/hive/hcatalog/webhcat/java-client/target/tmp/junit_metastore_db_37795;create=true
2023-02-15T14:44:29,153  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:29,153  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:29,153  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:29,153  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:29,153  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:29,153  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:29,153  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:29,153  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:29,153  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:29,153  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:29,153  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:29,153  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:29,153  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:29,154  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:29,154  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 5 HCatClient: thread: 1 users=5 expired=false closed=false
2023-02-15T14:44:29,156  WARN [main] metastore.HiveMetaStoreClient: Evicted client has non-zero user count: 5
2023-02-15T14:44:29,156  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=5 expired=true
2023-02-15T14:44:29,156  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=4 expired=true
2023-02-15T14:44:29,156  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T14:44:29,156  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:42647]
2023-02-15T14:44:29,156  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:42647) in binary transport mode
2023-02-15T14:44:29,156  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:42647) current connections: 3
2023-02-15T14:44:29,157  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
2023-02-15T14:44:29,157  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2023-02-15T14:44:29,157  INFO [Metastore-Handler-Pool: Thread-163] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T14:44:29,157  INFO [Metastore-Handler-Pool: Thread-163] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2023-02-15T14:44:29,158  INFO [Metastore-Handler-Pool: Thread-163] hikari.HikariDataSource: objectstore - Shutdown initiated...
2023-02-15T14:44:29,159  INFO [Metastore-Handler-Pool: Thread-163] hikari.HikariDataSource: objectstore - Shutdown completed.
2023-02-15T14:44:29,159  INFO [Metastore-Handler-Pool: Thread-163] hikari.HikariDataSource: objectstore-secondary - Shutdown initiated...
2023-02-15T14:44:29,159  INFO [Metastore-Handler-Pool: Thread-163] hikari.HikariDataSource: objectstore-secondary - Shutdown completed.
2023-02-15T14:44:29,159  INFO [Metastore-Handler-Pool: Thread-163] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: objectstore
2023-02-15T14:44:29,159  WARN [Metastore-Handler-Pool: Thread-163] hikari.HikariConfig: objectstore - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:44:29,159  INFO [Metastore-Handler-Pool: Thread-163] hikari.HikariDataSource: objectstore - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:44:29,160  INFO [Metastore-Handler-Pool: Thread-163] pool.PoolBase: objectstore - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:44:29,160  INFO [Metastore-Handler-Pool: Thread-163] hikari.HikariDataSource: objectstore - Start completed.
2023-02-15T14:44:29,160  INFO [Metastore-Handler-Pool: Thread-163] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 2, name: objectstore-secondary
2023-02-15T14:44:29,160  WARN [Metastore-Handler-Pool: Thread-163] hikari.HikariConfig: objectstore-secondary - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:44:29,161  INFO [Metastore-Handler-Pool: Thread-163] hikari.HikariDataSource: objectstore-secondary - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:44:29,161  INFO [Metastore-Handler-Pool: Thread-163] pool.PoolBase: objectstore-secondary - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:44:29,162  INFO [Metastore-Handler-Pool: Thread-163] hikari.HikariDataSource: objectstore-secondary - Start completed.
2023-02-15T14:44:29,451  INFO [Metastore-Handler-Pool: Thread-163] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2023-02-15T14:44:29,451  INFO [Metastore-Handler-Pool: Thread-163] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@70c49209, with PersistenceManager: null will be shutdown
2023-02-15T14:44:29,451  INFO [Metastore-Handler-Pool: Thread-163] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@70c49209, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@477151c5 created in the thread with id: 163
2023-02-15T14:44:29,645  INFO [Metastore-Handler-Pool: Thread-163] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@70c49209
2023-02-15T14:44:29,656  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:29,656  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:29,656  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:29,656  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:29,656  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:29,656  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:29,656  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:29,656  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:29,656  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:29,656  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:29,656  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:29,656  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:29,656  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:29,657  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:29,657  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2023-02-15T14:44:29,657  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:29,659  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:myDb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2023-02-15T14:44:29,662  INFO [Metastore-Handler-Pool: Thread-163] metastore.HMSHandler: Creating database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:44:29,662  INFO [Metastore-Handler-Pool: Thread-163] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:44:29,663  INFO [Metastore-Handler-Pool: Thread-163] metastore.HMSHandler: Created database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:44:29,665  INFO [Metastore-Handler-Pool: Thread-163] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:29,665  INFO [Metastore-Handler-Pool: Thread-163] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:29,677  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:29,677  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:29,677  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:29,677  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:29,677  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:29,677  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:29,677  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:29,677  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:29,677  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:29,677  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:29,677  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:29,677  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:29,677  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:29,678  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:29,678  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2023-02-15T14:44:29,678  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:29,679  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:44:29,693  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:29,693  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:29,693  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:29,693  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:29,693  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:29,693  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:29,693  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:29,693  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:29,693  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:29,693  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:29,693  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:29,693  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:29,694  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:myTable, dbName:myDb, owner:rizky, createTime:1676501069, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:int, comment:), FieldSchema(name:bar, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:dt, type:string, comment:), FieldSchema(name:grid, type:string, comment:)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:44:29,697  INFO [Metastore-Handler-Pool: Thread-163] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable
2023-02-15T14:44:29,705  INFO [Metastore-Handler-Pool: Thread-163] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:29,705  INFO [Metastore-Handler-Pool: Thread-163] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:29,717  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:29,717  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:29,717  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:29,717  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:29,717  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:29,717  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:29,717  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:29,717  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:29,717  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:29,717  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:29,717  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:29,717  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:29,717  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:29,717  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:29,718  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 4 HCatClient: thread: 1 users=4 expired=false closed=false
2023-02-15T14:44:29,718  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:29,719  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:44:29,728  INFO [Metastore-Handler-Pool: Thread-163] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:29,739  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:29,739  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:29,739  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:29,739  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:29,739  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:29,739  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:29,739  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:29,739  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:29,739  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:29,739  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:29,739  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:29,739  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:29,739  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:29,739  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:29,739  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 5 HCatClient: thread: 1 users=5 expired=false closed=false
2023-02-15T14:44:29,740  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.hcatalog.api.MetadataJSONSerializer
2023-02-15T14:44:29,750  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:29,750  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:29,750  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:29,750  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:29,750  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:29,750  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:29,750  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:29,750  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:29,750  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:29,750  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:29,750  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:29,750  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:29,751  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:29,751  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:29,751  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T14:44:29,751  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:37795]
2023-02-15T14:44:29,751  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:37795) in binary transport mode
2023-02-15T14:44:29,752  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:37795) current connections: 4
2023-02-15T14:44:29,752  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
2023-02-15T14:44:29,753  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:29,753  INFO [Metastore-Handler-Pool: Thread-178] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T14:44:29,753  INFO [Metastore-Handler-Pool: Thread-178] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T14:44:29,753  INFO [Metastore-Handler-Pool: Thread-178] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2023-02-15T14:44:29,753  INFO [Metastore-Handler-Pool: Thread-178] hikari.HikariDataSource: objectstore - Shutdown initiated...
2023-02-15T14:44:29,754  INFO [Metastore-Handler-Pool: Thread-178] hikari.HikariDataSource: objectstore - Shutdown completed.
2023-02-15T14:44:29,754  INFO [Metastore-Handler-Pool: Thread-178] hikari.HikariDataSource: objectstore-secondary - Shutdown initiated...
2023-02-15T14:44:29,754  INFO [Metastore-Handler-Pool: Thread-178] hikari.HikariDataSource: objectstore-secondary - Shutdown completed.
2023-02-15T14:44:29,754  INFO [Metastore-Handler-Pool: Thread-178] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: objectstore
2023-02-15T14:44:29,755  WARN [Metastore-Handler-Pool: Thread-178] hikari.HikariConfig: objectstore - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:44:29,755  INFO [Metastore-Handler-Pool: Thread-178] hikari.HikariDataSource: objectstore - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:44:29,756  INFO [Metastore-Handler-Pool: Thread-178] pool.PoolBase: objectstore - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:44:29,756  INFO [Metastore-Handler-Pool: Thread-178] hikari.HikariDataSource: objectstore - Start completed.
2023-02-15T14:44:29,756  INFO [Metastore-Handler-Pool: Thread-178] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 2, name: objectstore-secondary
2023-02-15T14:44:29,756  WARN [Metastore-Handler-Pool: Thread-178] hikari.HikariConfig: objectstore-secondary - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:44:29,756  INFO [Metastore-Handler-Pool: Thread-178] hikari.HikariDataSource: objectstore-secondary - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:44:29,757  INFO [Metastore-Handler-Pool: Thread-178] pool.PoolBase: objectstore-secondary - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:44:29,757  INFO [Metastore-Handler-Pool: Thread-178] hikari.HikariDataSource: objectstore-secondary - Start completed.
2023-02-15T14:44:30,051  INFO [Metastore-Handler-Pool: Thread-178] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2023-02-15T14:44:30,051  INFO [Metastore-Handler-Pool: Thread-178] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60d0906c, with PersistenceManager: null will be shutdown
2023-02-15T14:44:30,051  INFO [Metastore-Handler-Pool: Thread-178] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60d0906c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ade3d60 created in the thread with id: 178
2023-02-15T14:44:30,226  INFO [Metastore-Handler-Pool: Thread-178] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60d0906c
2023-02-15T14:44:30,228  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2023-02-15T14:44:30,238  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:30,238  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:30,238  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:30,238  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:30,238  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:30,238  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:30,238  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:30,238  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:30,238  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:30,238  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:30,238  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:30,238  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:30,238  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:30,239  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:30,239  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2023-02-15T14:44:30,239  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:30,240  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:myDb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2023-02-15T14:44:30,242  INFO [Metastore-Handler-Pool: Thread-178] metastore.HMSHandler: Creating database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/37795/mydb.db
2023-02-15T14:44:30,242  INFO [Metastore-Handler-Pool: Thread-178] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/37795/mydb.db
2023-02-15T14:44:30,243  INFO [Metastore-Handler-Pool: Thread-178] metastore.HMSHandler: Created database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/37795/mydb.db
2023-02-15T14:44:30,255  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:30,255  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:30,255  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:30,255  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:30,255  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:30,255  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:30,255  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:30,255  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:30,255  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:30,255  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:30,255  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:30,255  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:30,255  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:30,256  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:30,256  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2023-02-15T14:44:30,256  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:30,266  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:30,266  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:30,266  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:30,266  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:30,266  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:30,266  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:30,266  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:30,266  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:30,266  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:30,266  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:30,266  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:30,266  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:30,266  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:30,266  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:30,266  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 4 HCatClient: thread: 1 users=4 expired=false closed=false
2023-02-15T14:44:30,267  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:30,268  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:mytable, dbName:mydb, owner:rizky, createTime:1676501070, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:int, comment:), FieldSchema(name:bar, type:string, comment:)], location:pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:dt, type:string, comment:), FieldSchema(name:grid, type:string, comment:)], parameters:{transient_lastDdlTime=1676501069, bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:44:30,272  WARN [Metastore-Handler-Pool: Thread-178] metastore.HMSHandler: Location: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable specified for non-external table:mytable
2023-02-15T14:44:30,298  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:30,298  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:30,298  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:30,298  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:30,298  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:30,298  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:30,298  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:30,298  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:30,298  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:30,298  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:30,298  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:30,298  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:30,298  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:30,299  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:30,299  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 5 HCatClient: thread: 1 users=5 expired=false closed=false
2023-02-15T14:44:30,299  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:30,300  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:44:30,315  INFO [Metastore-Handler-Pool: Thread-178] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:30,324  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:30,324  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:30,324  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:30,324  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:30,324  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:30,324  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:30,324  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:30,324  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:30,324  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:30,324  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:30,324  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:30,324  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:30,324  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:30,325  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:30,325  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 6 HCatClient: thread: 1 users=6 expired=false closed=false
2023-02-15T14:44:30,325  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:30,326 ERROR [Metastore-Handler-Pool: Thread-163] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:32,326  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:32,327 ERROR [Metastore-Handler-Pool: Thread-163] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:34,328  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:34,329 ERROR [Metastore-Handler-Pool: Thread-163] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:36,329  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:36,330 ERROR [Metastore-Handler-Pool: Thread-163] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:38,331  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:38,332 ERROR [Metastore-Handler-Pool: Thread-163] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:40,332  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:40,333 ERROR [Metastore-Handler-Pool: Thread-163] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:42,334  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:42,335 ERROR [Metastore-Handler-Pool: Thread-163] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:44,335  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:44,336 ERROR [Metastore-Handler-Pool: Thread-163] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:46,337  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:46,338 ERROR [Metastore-Handler-Pool: Thread-163] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:48,338  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:48,339 ERROR [Metastore-Handler-Pool: Thread-163] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:50,340  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:50,354 ERROR [Metastore-Handler-Pool: Thread-163] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:50,355  WARN [main] metastore.HiveMetaStoreClient: Evicted client has non-zero user count: 6
2023-02-15T14:44:50,355  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=6 expired=true
2023-02-15T14:44:50,355  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=5 expired=true
2023-02-15T14:44:50,356  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T14:44:50,356  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:42647]
2023-02-15T14:44:50,356  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:42647) in binary transport mode
2023-02-15T14:44:50,357  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:42647) current connections: 5
2023-02-15T14:44:50,359  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
2023-02-15T14:44:50,360  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: hive.myDb.myTable newtbl=mytable	
2023-02-15T14:44:50,361  INFO [Metastore-Handler-Pool: Thread-193] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T14:44:50,362  INFO [Metastore-Handler-Pool: Thread-193] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2023-02-15T14:44:50,365  INFO [Metastore-Handler-Pool: Thread-193] hikari.HikariDataSource: objectstore - Shutdown initiated...
2023-02-15T14:44:50,368  INFO [Metastore-Handler-Pool: Thread-193] hikari.HikariDataSource: objectstore - Shutdown completed.
2023-02-15T14:44:50,368  INFO [Metastore-Handler-Pool: Thread-193] hikari.HikariDataSource: objectstore-secondary - Shutdown initiated...
2023-02-15T14:44:50,370  INFO [Metastore-Handler-Pool: Thread-193] hikari.HikariDataSource: objectstore-secondary - Shutdown completed.
2023-02-15T14:44:50,370  INFO [Metastore-Handler-Pool: Thread-193] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: objectstore
2023-02-15T14:44:50,371  WARN [Metastore-Handler-Pool: Thread-193] hikari.HikariConfig: objectstore - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:44:50,373  INFO [Metastore-Handler-Pool: Thread-193] hikari.HikariDataSource: objectstore - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:44:50,376  INFO [Metastore-Handler-Pool: Thread-193] pool.PoolBase: objectstore - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:44:50,376  INFO [Metastore-Handler-Pool: Thread-193] hikari.HikariDataSource: objectstore - Start completed.
2023-02-15T14:44:50,377  INFO [Metastore-Handler-Pool: Thread-193] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 2, name: objectstore-secondary
2023-02-15T14:44:50,377  WARN [Metastore-Handler-Pool: Thread-193] hikari.HikariConfig: objectstore-secondary - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:44:50,379  INFO [Metastore-Handler-Pool: Thread-193] hikari.HikariDataSource: objectstore-secondary - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:44:50,381  INFO [Metastore-Handler-Pool: Thread-193] pool.PoolBase: objectstore-secondary - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:44:50,383  INFO [Metastore-Handler-Pool: Thread-193] hikari.HikariDataSource: objectstore-secondary - Start completed.
2023-02-15T14:44:50,676  INFO [Metastore-Handler-Pool: Thread-193] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2023-02-15T14:44:50,676  INFO [Metastore-Handler-Pool: Thread-193] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@80b8753, with PersistenceManager: null will be shutdown
2023-02-15T14:44:50,676  INFO [Metastore-Handler-Pool: Thread-193] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@80b8753, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d6bf97e created in the thread with id: 193
2023-02-15T14:44:50,747  WARN [Finalizer] metastore.HiveMetaStoreClient: Closing client with non-zero user count: users=5 expired=true
2023-02-15T14:44:50,748  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 4
2023-02-15T14:44:50,748  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2023-02-15T14:44:50,748  INFO [Metastore-Handler-Pool: Thread-163] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@70c49209, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@477151c5 will be shutdown
2023-02-15T14:44:50,748  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T14:44:50,749  INFO [Metastore-Handler-Pool: Thread-163] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T14:44:50,840  INFO [Metastore-Handler-Pool: Thread-193] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@80b8753
2023-02-15T14:44:50,852  WARN [Metastore-Handler-Pool: Thread-193] metastore.HiveAlterHandler: Alter table not cascaded to partitions.
2023-02-15T14:44:50,862  INFO [Metastore-Handler-Pool: Thread-193] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:44:50,862  INFO [Metastore-Handler-Pool: Thread-193] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:44:50,875  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:50,875  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:50,875  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:50,875  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:50,875  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:50,875  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:50,875  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:50,875  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:50,875  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:50,875  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:50,875  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:50,875  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:50,876  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:50,876  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:50,876  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2023-02-15T14:44:50,876  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:50,878  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:44:50,881  INFO [Metastore-Handler-Pool: Thread-193] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:44:50,891  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:44:50,891  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:44:50,891  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:44:50,891  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:44:50,891  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:44:50,891  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:44:50,891  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:44:50,892  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:44:50,892  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:44:50,892  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:44:50,892  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:44:50,892  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:44:50,892  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:44:50,892  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:44:50,892  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 6 HCatClient: thread: 1 users=6 expired=false closed=false
2023-02-15T14:44:50,892  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:50,892 ERROR [Metastore-Handler-Pool: Thread-178] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:52,893  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:52,894 ERROR [Metastore-Handler-Pool: Thread-178] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:54,894  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:54,895 ERROR [Metastore-Handler-Pool: Thread-178] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:56,896  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:56,896 ERROR [Metastore-Handler-Pool: Thread-178] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:44:58,897  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:44:58,898 ERROR [Metastore-Handler-Pool: Thread-178] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:00,898  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:00,899 ERROR [Metastore-Handler-Pool: Thread-178] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:02,900  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:02,900 ERROR [Metastore-Handler-Pool: Thread-178] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:04,901  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:04,902 ERROR [Metastore-Handler-Pool: Thread-178] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:06,902  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:06,903 ERROR [Metastore-Handler-Pool: Thread-178] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:08,904  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:08,905 ERROR [Metastore-Handler-Pool: Thread-178] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:10,905  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:10,906 ERROR [Metastore-Handler-Pool: Thread-178] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:10,907  WARN [main] metastore.HiveMetaStoreClient: Evicted client has non-zero user count: 6
2023-02-15T14:45:10,907  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=6 expired=true
2023-02-15T14:45:10,907  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=5 expired=true
2023-02-15T14:45:10,908  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T14:45:10,908  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:37795]
2023-02-15T14:45:10,909  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:37795) in binary transport mode
2023-02-15T14:45:10,910  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:37795) current connections: 5
2023-02-15T14:45:10,912  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
2023-02-15T14:45:10,913  INFO [Metastore-Handler-Pool: Thread-206] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: hive.myDb.myTable newtbl=mytable	
2023-02-15T14:45:10,915  INFO [Metastore-Handler-Pool: Thread-206] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T14:45:10,915  INFO [Metastore-Handler-Pool: Thread-206] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T14:45:10,916  INFO [Metastore-Handler-Pool: Thread-206] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2023-02-15T14:45:10,919  INFO [Metastore-Handler-Pool: Thread-206] hikari.HikariDataSource: objectstore - Shutdown initiated...
2023-02-15T14:45:10,921  INFO [Metastore-Handler-Pool: Thread-206] hikari.HikariDataSource: objectstore - Shutdown completed.
2023-02-15T14:45:10,921  INFO [Metastore-Handler-Pool: Thread-206] hikari.HikariDataSource: objectstore-secondary - Shutdown initiated...
2023-02-15T14:45:10,923  INFO [Metastore-Handler-Pool: Thread-206] hikari.HikariDataSource: objectstore-secondary - Shutdown completed.
2023-02-15T14:45:10,923  INFO [Metastore-Handler-Pool: Thread-206] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: objectstore
2023-02-15T14:45:10,924  WARN [Metastore-Handler-Pool: Thread-206] hikari.HikariConfig: objectstore - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:45:10,926  INFO [Metastore-Handler-Pool: Thread-206] hikari.HikariDataSource: objectstore - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:45:10,929  INFO [Metastore-Handler-Pool: Thread-206] pool.PoolBase: objectstore - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:45:10,930  INFO [Metastore-Handler-Pool: Thread-206] hikari.HikariDataSource: objectstore - Start completed.
2023-02-15T14:45:10,930  INFO [Metastore-Handler-Pool: Thread-206] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 2, name: objectstore-secondary
2023-02-15T14:45:10,931  WARN [Metastore-Handler-Pool: Thread-206] hikari.HikariConfig: objectstore-secondary - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:45:10,932  INFO [Metastore-Handler-Pool: Thread-206] hikari.HikariDataSource: objectstore-secondary - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:45:10,935  INFO [Metastore-Handler-Pool: Thread-206] pool.PoolBase: objectstore-secondary - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:45:10,936  INFO [Metastore-Handler-Pool: Thread-206] hikari.HikariDataSource: objectstore-secondary - Start completed.
2023-02-15T14:45:11,221  INFO [Metastore-Handler-Pool: Thread-206] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2023-02-15T14:45:11,221  INFO [Metastore-Handler-Pool: Thread-206] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63193911, with PersistenceManager: null will be shutdown
2023-02-15T14:45:11,221  INFO [Metastore-Handler-Pool: Thread-206] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63193911, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d531747 created in the thread with id: 206
2023-02-15T14:45:11,282  WARN [Finalizer] metastore.HiveMetaStoreClient: Closing client with non-zero user count: users=5 expired=true
2023-02-15T14:45:11,282  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 4
2023-02-15T14:45:11,282  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2023-02-15T14:45:11,282  INFO [Metastore-Handler-Pool: Thread-178] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@60d0906c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1ade3d60 will be shutdown
2023-02-15T14:45:11,282  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T14:45:11,282  INFO [Metastore-Handler-Pool: Thread-178] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T14:45:11,380  INFO [Metastore-Handler-Pool: Thread-206] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63193911
2023-02-15T14:45:11,391  WARN [Metastore-Handler-Pool: Thread-206] metastore.HiveAlterHandler: Alter table not cascaded to partitions.
2023-02-15T14:45:11,415  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:11,415  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:11,415  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:11,415  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:11,415  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:11,415  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:11,415  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:11,415  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:11,415  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:11,415  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:11,415  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:11,415  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:11,415  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:11,416  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:11,416  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2023-02-15T14:45:11,416  INFO [Metastore-Handler-Pool: Thread-206] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:11,418  INFO [Metastore-Handler-Pool: Thread-206] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:45:11,420  INFO [Metastore-Handler-Pool: Thread-206] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:11,429  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:11,429  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:11,429  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:11,429  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:11,429  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:11,429  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:11,429  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:11,430  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:11,430  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:11,430  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:11,430  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:11,430  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:11,430  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:11,430  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:11,430  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2023-02-15T14:45:11,430  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:11,430 ERROR [Metastore-Handler-Pool: Thread-193] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:13,431  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:13,432 ERROR [Metastore-Handler-Pool: Thread-193] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:15,432  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:15,433 ERROR [Metastore-Handler-Pool: Thread-193] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:17,434  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:17,434 ERROR [Metastore-Handler-Pool: Thread-193] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:19,435  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:19,436 ERROR [Metastore-Handler-Pool: Thread-193] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:21,436  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:21,437 ERROR [Metastore-Handler-Pool: Thread-193] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:23,437  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:23,438 ERROR [Metastore-Handler-Pool: Thread-193] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:25,439  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:25,439 ERROR [Metastore-Handler-Pool: Thread-193] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 8 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:27,440  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:27,441 ERROR [Metastore-Handler-Pool: Thread-193] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 9 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:29,441  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:29,442 ERROR [Metastore-Handler-Pool: Thread-193] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 10 of 10) with error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:31,443  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:31,443 ERROR [Metastore-Handler-Pool: Thread-193] metastore.RetryingHMSHandler: HMSHandler Fatal error: javax.jdo.JDOFatalUserException: Persistence Manager has been closed
	at org.datanucleus.api.jdo.JDOPersistenceManager.assertIsOpen(JDOPersistenceManager.java:2232)
	at org.datanucleus.api.jdo.JDOPersistenceManager.evictAll(JDOPersistenceManager.java:482)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackTransaction(ObjectStore.java:670)
	at org.apache.hadoop.hive.metastore.ObjectStore.rollbackAndCleanup(ObjectStore.java:13121)
	at org.apache.hadoop.hive.metastore.ObjectStore.getDatabases(ObjectStore.java:1040)
	at sun.reflect.GeneratedMethodAccessor223.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy31.getDatabases(Unknown Source)
	at org.apache.hadoop.hive.metastore.HMSHandler.get_databases(HMSHandler.java:1824)
	at sun.reflect.GeneratedMethodAccessor205.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:146)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy32.get_databases(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18760)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_databases.getResult(ThriftHiveMetastore.java:18739)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2023-02-15T14:45:31,444  WARN [main] metastore.HiveMetaStoreClient: Evicted client has non-zero user count: 3
2023-02-15T14:45:31,444  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=3 expired=true
2023-02-15T14:45:31,444  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=2 expired=true
2023-02-15T14:45:31,445  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T14:45:31,445  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:42647]
2023-02-15T14:45:31,446  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:42647) in binary transport mode
2023-02-15T14:45:31,446  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:42647) current connections: 5
2023-02-15T14:45:31,448  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
2023-02-15T14:45:31,450  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testEmptyCreate	
2023-02-15T14:45:31,450  INFO [Metastore-Handler-Pool: Thread-219] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T14:45:31,451  INFO [Metastore-Handler-Pool: Thread-219] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2023-02-15T14:45:31,454  INFO [Metastore-Handler-Pool: Thread-219] hikari.HikariDataSource: objectstore - Shutdown initiated...
2023-02-15T14:45:31,457  INFO [Metastore-Handler-Pool: Thread-219] hikari.HikariDataSource: objectstore - Shutdown completed.
2023-02-15T14:45:31,457  INFO [Metastore-Handler-Pool: Thread-219] hikari.HikariDataSource: objectstore-secondary - Shutdown initiated...
2023-02-15T14:45:31,459  INFO [Metastore-Handler-Pool: Thread-219] hikari.HikariDataSource: objectstore-secondary - Shutdown completed.
2023-02-15T14:45:31,459  INFO [Metastore-Handler-Pool: Thread-219] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: objectstore
2023-02-15T14:45:31,460  WARN [Metastore-Handler-Pool: Thread-219] hikari.HikariConfig: objectstore - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:45:31,468  INFO [Metastore-Handler-Pool: Thread-219] hikari.HikariDataSource: objectstore - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:45:31,470  INFO [Metastore-Handler-Pool: Thread-219] pool.PoolBase: objectstore - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:45:31,471  INFO [Metastore-Handler-Pool: Thread-219] hikari.HikariDataSource: objectstore - Start completed.
2023-02-15T14:45:31,471  INFO [Metastore-Handler-Pool: Thread-219] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 2, name: objectstore-secondary
2023-02-15T14:45:31,471  WARN [Metastore-Handler-Pool: Thread-219] hikari.HikariConfig: objectstore-secondary - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T14:45:31,473  INFO [Metastore-Handler-Pool: Thread-219] hikari.HikariDataSource: objectstore-secondary - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.com.zaxxer.hikari.pool.HikariPool
2023-02-15T14:45:31,476  INFO [Metastore-Handler-Pool: Thread-219] pool.PoolBase: objectstore-secondary - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T14:45:31,476  INFO [Metastore-Handler-Pool: Thread-219] hikari.HikariDataSource: objectstore-secondary - Start completed.
2023-02-15T14:45:31,769  INFO [Metastore-Handler-Pool: Thread-219] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2023-02-15T14:45:31,769  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@724ca2af, with PersistenceManager: null will be shutdown
2023-02-15T14:45:31,769  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@724ca2af, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66bd07e9 created in the thread with id: 219
2023-02-15T14:45:31,807  WARN [Finalizer] metastore.HiveMetaStoreClient: Closing client with non-zero user count: users=2 expired=true
2023-02-15T14:45:31,808  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 4
2023-02-15T14:45:31,808  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2023-02-15T14:45:31,808  INFO [Metastore-Handler-Pool: Thread-193] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@80b8753, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7d6bf97e will be shutdown
2023-02-15T14:45:31,808  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T14:45:31,808  INFO [Metastore-Handler-Pool: Thread-193] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T14:45:31,923  INFO [Metastore-Handler-Pool: Thread-219] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@724ca2af
2023-02-15T14:45:31,926  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:45:31,940  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:31,940  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:31,940  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:31,940  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:31,940  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:31,940  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:31,940  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:31,940  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:31,940  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:31,940  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:31,940  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:31,940  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:31,940  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testEmptyCreate, dbName:default, owner:rizky, createTime:1676501131, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id comment), FieldSchema(name:value, type:string, comment:value comment)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:45:31,941  INFO [Metastore-Handler-Pool: Thread-219] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testemptycreate
2023-02-15T14:45:31,948  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:31,948  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:31,950  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.testEmptyCreate	
2023-02-15T14:45:31,954  INFO [Metastore-Handler-Pool: Thread-219] metastore.HMSHandler: Skipping translation for processor with null
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.metadata.Table
2023-02-15T14:45:31,965  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:31,965  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:31,965  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:31,965  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:31,965  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:31,965  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:31,966  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:31,966  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:31,966  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:31,966  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:31,966  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:31,966  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:31,966  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:31,966  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:31,966  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2023-02-15T14:45:31,966  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:31,969  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: ptnDB	
2023-02-15T14:45:31,969  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:ptnDB, description:null, locationUri:null, parameters:null, catalogName:hive)	
2023-02-15T14:45:31,971  INFO [Metastore-Handler-Pool: Thread-219] metastore.HMSHandler: Creating database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/ptndb.db
2023-02-15T14:45:31,971  INFO [Metastore-Handler-Pool: Thread-219] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/ptndb.db
2023-02-15T14:45:31,972  INFO [Metastore-Handler-Pool: Thread-219] metastore.HMSHandler: Created database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/ptndb.db
2023-02-15T14:45:31,974  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:31,974  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:31,975  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:45:31,989  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:31,989  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:31,989  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:31,989  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:31,989  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:31,989  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:31,989  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:31,989  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:31,989  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:31,989  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:31,989  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:31,989  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:31,989  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:pageView, dbName:ptnDB, owner:rizky, createTime:1676501131, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:userid, type:int, comment:id columns), FieldSchema(name:viewtime, type:bigint, comment:view time columns), FieldSchema(name:pageurl, type:string, comment:), FieldSchema(name:ip, type:string, comment:IP Address of the User)], location:null, inputFormat:org.apache.hadoop.mapred.SequenceFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:dt, type:string, comment:date column), FieldSchema(name:country, type:string, comment:country column)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:45:31,990  INFO [Metastore-Handler-Pool: Thread-219] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/ptndb.db/pageview
2023-02-15T14:45:31,993  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:31,993  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:31,995  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptnDB.pageView	
2023-02-15T14:45:31,997  INFO [Metastore-Handler-Pool: Thread-219] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:31,997  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptndb.pageview	
2023-02-15T14:45:31,999  INFO [Metastore-Handler-Pool: Thread-219] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:31,999  WARN [main] api.HCatPartition: Partition location is not set! Attempting to construct default partition location.
2023-02-15T14:45:31,999  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.ptndb.pageview	
2023-02-15T14:45:32,005  INFO [Metastore-Handler-Pool: Thread-219] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/ptndb.db/pageview/dt=04%2F30%2F2012/country=usa
2023-02-15T14:45:32,012  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:32,012  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:32,013 ERROR [main] api.HCatAddPartitionDesc: Unsupported! HCatAddPartitionDesc requires HCatTable to be specified explicitly.
2023-02-15T14:45:32,013  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptnDB.pageView	
2023-02-15T14:45:32,015  INFO [Metastore-Handler-Pool: Thread-219] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:32,015  WARN [main] api.HCatPartition: Partition location is not set! Attempting to construct default partition location.
2023-02-15T14:45:32,015  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.ptndb.pageview	
2023-02-15T14:45:32,017  INFO [Metastore-Handler-Pool: Thread-219] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/ptndb.db/pageview/dt=04%2F12%2F2012/country=brazil
2023-02-15T14:45:32,020  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:32,020  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:32,021 ERROR [main] api.HCatAddPartitionDesc: Unsupported! HCatAddPartitionDesc requires HCatTable to be specified explicitly.
2023-02-15T14:45:32,021  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptnDB.pageView	
2023-02-15T14:45:32,022  INFO [Metastore-Handler-Pool: Thread-219] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:32,023  WARN [main] api.HCatPartition: Partition location is not set! Attempting to construct default partition location.
2023-02-15T14:45:32,023  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.ptndb.pageview	
2023-02-15T14:45:32,024  INFO [Metastore-Handler-Pool: Thread-219] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/ptndb.db/pageview/dt=04%2F13%2F2012/country=argentina
2023-02-15T14:45:32,027  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:32,027  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:32,028  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptnDB.pageView	
2023-02-15T14:45:32,030  INFO [Metastore-Handler-Pool: Thread-219] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:32,030  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions_by_filter : tbl=hive.ptndb.pageview	
2023-02-15T14:45:32,042  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.ptnDB.pageView	
2023-02-15T14:45:32,044  INFO [Metastore-Handler-Pool: Thread-219] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:32,044  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2023-02-15T14:45:32,044  INFO [Metastore-Handler-Pool: Thread-219] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@724ca2af, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66bd07e9 will be shutdown
2023-02-15T14:45:32,044  INFO [Metastore-Handler-Pool: Thread-219] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Exception in thread "Metastore-Handler-Pool: Thread-219" java.lang.NoSuchMethodError: org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_partition_args.access$6(Lorg/apache/hadoop/hive/metastore/api/ThriftHiveMetastore$get_partition_args;)Ljava/lang/String;
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:20846)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:1)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-15T14:45:32,044  WARN [main] metastore.RetryingMetaStoreClient: MetaStoreClient lost connection. Attempting to reconnect (1 of 1) after 1s. getPartition
org.apache.thrift.transport.TTransportException: Socket is closed by peer.
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:184) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:109) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:464) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:362) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:245) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_partition(ThriftHiveMetastore.java:3477) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_partition(ThriftHiveMetastore.java:3462) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2468) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2450) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at com.sun.proxy.$Proxy33.getPartition(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getPartition(HCatClientHMSImpl.java:455) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testPartitionsHCatClientImpl(TestHCatClient.java:370) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T14:45:33,045  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient trying reconnect as rizky (auth:SIMPLE)
2023-02-15T14:45:33,045  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=1 expired=false
2023-02-15T14:45:33,045  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:42647) in binary transport mode
2023-02-15T14:45:33,046  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:42647) current connections: 5
2023-02-15T14:45:33,049  INFO [Metastore-Handler-Pool: Thread-243] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Exception in thread "Metastore-Handler-Pool: Thread-243" java.lang.NoSuchMethodError: org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_partition_args.access$6(Lorg/apache/hadoop/hive/metastore/api/ThriftHiveMetastore$get_partition_args;)Ljava/lang/String;
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:20846)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:1)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-15T14:45:33,075  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:33,075  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:33,075  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:33,075  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:33,075  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:33,075  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:33,075  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:33,075  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:33,075  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:33,075  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:33,075  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:33,075  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:33,075  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:33,075  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:33,076  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2023-02-15T14:45:33,076  WARN [main] metastore.HiveMetaStoreClient: Evicted client has non-zero user count: 2
2023-02-15T14:45:33,076  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=2 expired=true
2023-02-15T14:45:33,076  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=1 expired=true
2023-02-15T14:45:33,076  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T14:45:33,076  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:42647]
2023-02-15T14:45:33,076  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:42647) in binary transport mode
2023-02-15T14:45:33,076  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:42647) current connections: 6
2023-02-15T14:45:33,077  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
2023-02-15T14:45:33,077  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.tableone	
2023-02-15T14:45:33,077  INFO [Metastore-Handler-Pool: Thread-245] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T14:45:33,077  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e85cca, with PersistenceManager: null will be shutdown
2023-02-15T14:45:33,077  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e85cca, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a2b6f1d created in the thread with id: 245
2023-02-15T14:45:33,078  INFO [Metastore-Handler-Pool: Thread-245] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e85cca
2023-02-15T14:45:33,079  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.tabletwo	
2023-02-15T14:45:33,079  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:45:33,093  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:33,093  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:33,093  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:33,093  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:33,093  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:33,093  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:33,093  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:33,093  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:33,093  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:33,093  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:33,093  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:33,093  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:33,093  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:tableone, dbName:default, owner:rizky, createTime:1676501133, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id columns), FieldSchema(name:value, type:string, comment:id columns)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:45:33,094  INFO [Metastore-Handler-Pool: Thread-245] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/tableone
2023-02-15T14:45:33,097  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:33,097  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:33,098  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.tableone	
2023-02-15T14:45:33,100  INFO [Metastore-Handler-Pool: Thread-245] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:33,100  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:tabletwo, dbName:default, owner:null, createTime:1676501133, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id columns), FieldSchema(name:value, type:string, comment:id columns)], location:pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/tableone, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:null, parameters:{transient_lastDdlTime=1676501133, bucketing_version=2, EXTERNAL=TRUE}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, catName:hive, ownerType:USER)	
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.StatsSetupConst
2023-02-15T14:45:33,104  INFO [Metastore-Handler-Pool: Thread-245] utils.MetaStoreServerUtils: Updating table stats for tabletwo
2023-02-15T14:45:33,104  INFO [Metastore-Handler-Pool: Thread-245] utils.MetaStoreServerUtils: Updated size of table tabletwo to 0
2023-02-15T14:45:33,106  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:33,106  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:33,108  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=default tbls=null	
2023-02-15T14:45:33,141  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:33,141  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:33,141  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:33,141  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:33,141  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:33,141  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:33,141  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:33,141  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:33,141  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:33,141  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:33,141  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:33,141  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:33,141  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:33,142  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:33,142  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:33,143  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.Temptable	
2023-02-15T14:45:33,143  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:45:33,156  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:33,156  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:33,156  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:33,156  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:33,156  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:33,156  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:33,156  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:33,156  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:33,156  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:33,156  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:33,156  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:33,157  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:33,157  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:Temptable, dbName:default, owner:rizky, createTime:1676501133, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id columns), FieldSchema(name:value, type:string, comment:id columns)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:45:33,158  INFO [Metastore-Handler-Pool: Thread-245] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/temptable
2023-02-15T14:45:33,160  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:33,160  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:33,162  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.foo.Temptable	
2023-02-15T14:45:33,162  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.goodTable	
2023-02-15T14:45:33,164  INFO [Metastore-Handler-Pool: Thread-245] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:33,164  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.default.goodTable	
2023-02-15T14:45:33,204  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:33,204  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:33,206  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:45:33,221  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:33,221  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:33,221  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:33,221  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:33,221  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:33,221  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:33,221  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:33,221  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:33,221  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:33,221  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:33,221  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:33,221  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:33,221  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:goodTable, dbName:default, owner:rizky, createTime:1676501133, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id, type:int, comment:id columns), FieldSchema(name:value, type:string, comment:id columns)], location:null, inputFormat:org.apache.hadoop.hive.ql.io.RCFileInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.RCFileOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:45:33,223  INFO [Metastore-Handler-Pool: Thread-245] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/goodtable
2023-02-15T14:45:33,226  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:33,226  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:33,235  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.default.goodTable	
2023-02-15T14:45:33,241  INFO [Metastore-Handler-Pool: Thread-245] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:33,251  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:33,251  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:33,251  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:33,251  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:33,251  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:33,251  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:33,251  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:33,251  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:33,251  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:33,251  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:33,251  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:33,251  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:33,251  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:33,251  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:33,252  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:33,254  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2023-02-15T14:45:33,254  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:33,254  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:33,255  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2023-02-15T14:45:33,257  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2023-02-15T14:45:33,262  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: myDb	
2023-02-15T14:45:33,263  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2023-02-15T14:45:33,263  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2023-02-15T14:45:33,267  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2023-02-15T14:45:33,269  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2023-02-15T14:45:33,282  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:33,284  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.mydb.mytable	
2023-02-15T14:45:33,288  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:33,288  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:33,288  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2023-02-15T14:45:33,307  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:33,307  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:33,310  WARN [Metastore-Handler-Pool: Thread-245] utils.FileUtils: File file:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db does not exist; Force to delete it.
2023-02-15T14:45:33,310 ERROR [Metastore-Handler-Pool: Thread-245] utils.FileUtils: Failed to delete pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:45:33,319  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:33,319  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:33,319  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:33,319  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:33,319  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:33,319  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:33,319  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:33,319  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:33,319  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:33,319  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:33,319  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:33,319  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:33,319  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:33,320  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:33,320  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2023-02-15T14:45:33,320  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:33,321  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:myDb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2023-02-15T14:45:33,323  INFO [Metastore-Handler-Pool: Thread-245] metastore.HMSHandler: Creating database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:45:33,323  INFO [Metastore-Handler-Pool: Thread-245] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:45:33,324  INFO [Metastore-Handler-Pool: Thread-245] metastore.HMSHandler: Created database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:45:33,325  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:33,325  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:33,335  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:33,335  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:33,335  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:33,335  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:33,335  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:33,335  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:33,335  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:33,335  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:33,335  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:33,335  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:33,335  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:33,335  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:33,335  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:33,335  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:33,335  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2023-02-15T14:45:33,336  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:33,336  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:45:33,349  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:33,349  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:33,349  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:33,349  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:33,349  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:33,349  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:33,349  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:33,349  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:33,349  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:33,349  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:33,349  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:33,349  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:33,350  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:myTable, dbName:myDb, owner:rizky, createTime:1676501133, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:int, comment:), FieldSchema(name:bar, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:dt, type:string, comment:), FieldSchema(name:grid, type:string, comment:)], parameters:{bucketing_version=2, comment=Source table.}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:45:33,351  INFO [Metastore-Handler-Pool: Thread-245] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable
2023-02-15T14:45:33,355  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:33,355  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:33,365  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:33,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:33,365  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:33,365  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:33,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:33,365  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:33,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:33,365  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:33,365  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:33,365  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:33,365  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:33,365  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:33,365  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:33,366  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:33,366  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 4 HCatClient: thread: 1 users=4 expired=false closed=false
2023-02-15T14:45:33,366  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:33,367  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:45:33,369  INFO [Metastore-Handler-Pool: Thread-245] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:33,378  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:33,378  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:33,378  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:33,379  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:33,379  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:33,379  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:33,379  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:33,379  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:33,379  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:33,379  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:33,379  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:33,379  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:33,379  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:33,379  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:33,379  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 5 HCatClient: thread: 1 users=5 expired=false closed=false
2023-02-15T14:45:33,379  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:33,380  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2023-02-15T14:45:33,382  INFO [Metastore-Handler-Pool: Thread-245] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:33,383  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2023-02-15T14:45:33,386  INFO [Metastore-Handler-Pool: Thread-245] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable/dt=2011_12_31/grid=AB
2023-02-15T14:45:33,394  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:33,394  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:33,404  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:33,404  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:33,404  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:33,404  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:33,404  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:33,404  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:33,404  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:33,404  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:33,404  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:33,404  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:33,404  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:33,404  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:33,404  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:33,404  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:33,405  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 6 HCatClient: thread: 1 users=6 expired=false closed=false
2023-02-15T14:45:33,405  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:33,406  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:45:33,408  INFO [Metastore-Handler-Pool: Thread-245] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:33,408  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions : tbl=hive.myDb.myTable	
2023-02-15T14:45:33,430  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:33,430  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:33,430  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:33,430  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:33,430  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:33,430  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:33,430  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:33,430  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:33,430  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:33,430  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:33,430  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:33,430  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:33,430  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:33,431  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:33,431  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 7 HCatClient: thread: 1 users=7 expired=false closed=false
2023-02-15T14:45:33,431  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:33,432  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:45:33,433  INFO [Metastore-Handler-Pool: Thread-245] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:33,434  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2023-02-15T14:45:33,434  INFO [Metastore-Handler-Pool: Thread-245] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3e85cca, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5a2b6f1d will be shutdown
2023-02-15T14:45:33,434  INFO [Metastore-Handler-Pool: Thread-245] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Exception in thread "Metastore-Handler-Pool: Thread-245" java.lang.NoSuchMethodError: org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_partition_args.access$6(Lorg/apache/hadoop/hive/metastore/api/ThriftHiveMetastore$get_partition_args;)Ljava/lang/String;
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:20846)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:1)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-15T14:45:33,434  WARN [main] metastore.RetryingMetaStoreClient: MetaStoreClient lost connection. Attempting to reconnect (1 of 1) after 1s. getPartition
org.apache.thrift.transport.TTransportException: Socket is closed by peer.
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:184) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:109) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:464) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:362) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:245) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_partition(ThriftHiveMetastore.java:3477) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_partition(ThriftHiveMetastore.java:3462) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2468) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2450) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at com.sun.proxy.$Proxy33.getPartition(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getPartition(HCatClientHMSImpl.java:455) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema(TestHCatClient.java:1271) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T14:45:34,435  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient trying reconnect as rizky (auth:SIMPLE)
2023-02-15T14:45:34,435  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=6 expired=false
2023-02-15T14:45:34,435  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:42647) in binary transport mode
2023-02-15T14:45:34,436  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:42647) current connections: 7
2023-02-15T14:45:34,438  INFO [Metastore-Handler-Pool: Thread-258] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Exception in thread "Metastore-Handler-Pool: Thread-258" java.lang.NoSuchMethodError: org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_partition_args.access$6(Lorg/apache/hadoop/hive/metastore/api/ThriftHiveMetastore$get_partition_args;)Ljava/lang/String;
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:20846)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:1)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-15T14:45:34,439 ERROR [main] api.TestHCatClient: Unexpected exception! 
org.apache.hive.hcatalog.api.ConnectionFailureException: org.apache.hive.hcatalog.common.HCatException : 9001 : Exception occurred while processing HCat request : TException while retrieving partition.. Cause : org.apache.thrift.transport.TTransportException: Socket is closed by peer.
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getPartition(HCatClientHMSImpl.java:467) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testPartitionSpecRegistrationWithCustomSchema(TestHCatClient.java:1271) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.thrift.transport.TTransportException: Socket is closed by peer.
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:184) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:109) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:464) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:362) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:245) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_partition(ThriftHiveMetastore.java:3477) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_partition(ThriftHiveMetastore.java:3462) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2468) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2450) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at com.sun.proxy.$Proxy33.getPartition(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getPartition(HCatClientHMSImpl.java:455) ~[classes/:?]
	... 31 more
2023-02-15T14:45:34,465  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:34,465  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:34,465  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:34,465  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:34,465  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:34,465  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:34,465  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:34,465  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:34,465  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:34,465  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:34,465  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:34,465  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:34,465  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:34,465  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:34,465  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 7 HCatClient: thread: 1 users=7 expired=false closed=false
2023-02-15T14:45:34,466  WARN [main] metastore.HiveMetaStoreClient: Evicted client has non-zero user count: 7
2023-02-15T14:45:34,466  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=7 expired=true
2023-02-15T14:45:34,466  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=6 expired=true
2023-02-15T14:45:34,466  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T14:45:34,466  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:42647]
2023-02-15T14:45:34,466  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:42647) in binary transport mode
2023-02-15T14:45:34,466  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:42647) current connections: 8
2023-02-15T14:45:34,466  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
2023-02-15T14:45:34,467  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testUpdateTableSchema_DBName	
2023-02-15T14:45:34,467  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T14:45:34,467  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1784fc4c, with PersistenceManager: null will be shutdown
2023-02-15T14:45:34,467  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1784fc4c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ab07d64 created in the thread with id: 260
2023-02-15T14:45:34,477  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1784fc4c
2023-02-15T14:45:34,477  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:testUpdateTableSchema_DBName, description:null, locationUri:null, parameters:null, catalogName:hive)	
2023-02-15T14:45:34,478  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Creating database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testupdatetableschema_dbname.db
2023-02-15T14:45:34,478  INFO [Metastore-Handler-Pool: Thread-260] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testupdatetableschema_dbname.db
2023-02-15T14:45:34,479  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Created database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testupdatetableschema_dbname.db
2023-02-15T14:45:34,480  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:34,480  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:34,481  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:45:34,496  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:34,496  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:34,496  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:34,496  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:34,496  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:34,496  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:34,496  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:34,496  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:34,496  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:34,496  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:34,496  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:34,496  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:34,496  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testUpdateTableSchema_TableName, dbName:testUpdateTableSchema_DBName, owner:rizky, createTime:1676501134, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:int, comment:), FieldSchema(name:bar, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:45:34,497  INFO [Metastore-Handler-Pool: Thread-260] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testupdatetableschema_dbname.db/testupdatetableschema_tablename
2023-02-15T14:45:34,499  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:34,499  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:34,501  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testUpdateTableSchema_DBName.testUpdateTableSchema_TableName	
2023-02-15T14:45:34,502  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:34,502  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 alter_table: hive.testUpdateTableSchema_DBName.testUpdateTableSchema_TableName newtbl=testupdatetableschema_tablename	
2023-02-15T14:45:34,508  INFO [Metastore-Handler-Pool: Thread-260] utils.MetaStoreServerUtils: Updating table stats for testupdatetableschema_tablename
2023-02-15T14:45:34,508  INFO [Metastore-Handler-Pool: Thread-260] utils.MetaStoreServerUtils: Updated size of table testupdatetableschema_tablename to 0
2023-02-15T14:45:34,515  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:34,515  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:34,516  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testUpdateTableSchema_DBName.testUpdateTableSchema_TableName	
2023-02-15T14:45:34,518  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:34,518  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testUpdateTableSchema_DBName	
2023-02-15T14:45:34,519  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:34,519  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:34,519  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2023-02-15T14:45:34,519  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=testUpdateTableSchema_DBName tbls=testupdatetableschema_tablename	
2023-02-15T14:45:34,524  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: testUpdateTableSchema_DBName	
2023-02-15T14:45:34,524  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testUpdateTableSchema_DBName	
2023-02-15T14:45:34,524  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testUpdateTableSchema_DBName pat=*	
2023-02-15T14:45:34,524  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2023-02-15T14:45:34,525  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2023-02-15T14:45:34,525  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testUpdateTableSchema_DBName pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:34,528  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.testupdatetableschema_dbname.testupdatetableschema_tablename	
2023-02-15T14:45:34,553  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:34,553  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:34,554  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore: Dropping database hive.testUpdateTableSchema_DBName along with all tables
2023-02-15T14:45:34,562  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:34,562  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:34,566  WARN [Metastore-Handler-Pool: Thread-260] utils.FileUtils: File file:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testupdatetableschema_dbname.db does not exist; Force to delete it.
2023-02-15T14:45:34,566 ERROR [Metastore-Handler-Pool: Thread-260] utils.FileUtils: Failed to delete pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testupdatetableschema_dbname.db
2023-02-15T14:45:34,575  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:34,575  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:34,575  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:34,575  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:34,575  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:34,575  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:34,575  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:34,575  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:34,575  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:34,575  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:34,575  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:34,575  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:34,575  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:34,576  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:34,576  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2023-02-15T14:45:34,576  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:34,577  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testGetMessageBusTopicName_DBName	
2023-02-15T14:45:34,577  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:testGetMessageBusTopicName_DBName, description:null, locationUri:null, parameters:null, catalogName:hive)	
2023-02-15T14:45:34,578  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Creating database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testgetmessagebustopicname_dbname.db
2023-02-15T14:45:34,578  INFO [Metastore-Handler-Pool: Thread-260] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testgetmessagebustopicname_dbname.db
2023-02-15T14:45:34,579  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Created database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testgetmessagebustopicname_dbname.db
2023-02-15T14:45:34,579  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:34,579  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:34,580  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:45:34,593  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:34,593  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:34,593  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:34,593  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:34,593  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:34,593  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:34,593  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:34,593  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:34,593  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:34,593  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:34,593  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:34,593  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:34,593  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:testGetMessageBusTopicName_TableName, dbName:testGetMessageBusTopicName_DBName, owner:rizky, createTime:1676501134, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[], parameters:{hcat.msgbus.topic.name=MY.topic.name, bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:45:34,595  INFO [Metastore-Handler-Pool: Thread-260] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testgetmessagebustopicname_dbname.db/testgetmessagebustopicname_tablename
2023-02-15T14:45:34,598  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:34,598  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:34,605  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.testGetMessageBusTopicName_DBName.testGetMessageBusTopicName_TableName	
2023-02-15T14:45:34,611  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:34,611  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: testGetMessageBusTopicName_DBName	
2023-02-15T14:45:34,612  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:34,612  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:34,613  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2023-02-15T14:45:34,615  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=testGetMessageBusTopicName_DBName tbls=testgetmessagebustopicname_tablename	
2023-02-15T14:45:34,619  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: testGetMessageBusTopicName_DBName	
2023-02-15T14:45:34,619  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#testGetMessageBusTopicName_DBName	
2023-02-15T14:45:34,619  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#testGetMessageBusTopicName_DBName pat=*	
2023-02-15T14:45:34,621  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2023-02-15T14:45:34,622  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2023-02-15T14:45:34,623  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=testGetMessageBusTopicName_DBName pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:34,625  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.testgetmessagebustopicname_dbname.testgetmessagebustopicname_tablename	
2023-02-15T14:45:34,630  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:34,630  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:34,630  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore: Dropping database hive.testGetMessageBusTopicName_DBName along with all tables
2023-02-15T14:45:34,636  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:34,636  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:34,638  WARN [Metastore-Handler-Pool: Thread-260] utils.FileUtils: File file:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testgetmessagebustopicname_dbname.db does not exist; Force to delete it.
2023-02-15T14:45:34,638 ERROR [Metastore-Handler-Pool: Thread-260] utils.FileUtils: Failed to delete pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/testgetmessagebustopicname_dbname.db
2023-02-15T14:45:34,639  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=1 expired=false
2023-02-15T14:45:34,648  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:34,648  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:34,648  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:34,648  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:34,648  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:34,648  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:34,648  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:34,648  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:34,648  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:34,648  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:34,648  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:34,648  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:34,648  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:34,648  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:34,648  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 2 HCatClient: thread: 1 users=2 expired=false closed=false
2023-02-15T14:45:34,648  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:34,649  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2023-02-15T14:45:34,649  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:34,649  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:34,650  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2023-02-15T14:45:34,650  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2023-02-15T14:45:34,652  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: myDb	
2023-02-15T14:45:34,653  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2023-02-15T14:45:34,653  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2023-02-15T14:45:34,653  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2023-02-15T14:45:34,653  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2023-02-15T14:45:34,654  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:34,668  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.mydb.mytable	
2023-02-15T14:45:34,672  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:34,672  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:34,672  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2023-02-15T14:45:34,677  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:34,677  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:34,680  WARN [Metastore-Handler-Pool: Thread-260] utils.FileUtils: File file:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db does not exist; Force to delete it.
2023-02-15T14:45:34,680 ERROR [Metastore-Handler-Pool: Thread-260] utils.FileUtils: Failed to delete pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:45:34,689  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:34,689  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:34,689  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:34,689  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:34,689  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:34,689  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:34,689  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:34,689  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:34,689  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:34,689  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:34,689  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:34,689  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:34,689  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:34,690  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:34,690  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 3 HCatClient: thread: 1 users=3 expired=false closed=false
2023-02-15T14:45:34,690  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:34,691  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:myDb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2023-02-15T14:45:34,692  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Creating database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:45:34,692  INFO [Metastore-Handler-Pool: Thread-260] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:45:34,693  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Created database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:45:34,694  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:34,694  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:34,704  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:34,704  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:34,704  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:34,704  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:34,704  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:34,704  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:34,704  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:34,704  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:34,704  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:34,704  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:34,704  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:34,704  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:34,704  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:34,704  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:34,704  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 4 HCatClient: thread: 1 users=4 expired=false closed=false
2023-02-15T14:45:34,704  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:34,705  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:45:34,718  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:34,718  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:34,718  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:34,718  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:34,718  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:34,718  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:34,718  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:34,718  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:34,718  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:34,718  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:34,718  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:34,718  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:34,718  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:myTable, dbName:myDb, owner:rizky, createTime:1676501134, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:int, comment:), FieldSchema(name:bar, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:dt, type:string, comment:), FieldSchema(name:grid, type:string, comment:)], parameters:{bucketing_version=2, comment=Source table.}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:45:34,719  INFO [Metastore-Handler-Pool: Thread-260] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable
2023-02-15T14:45:34,729  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:34,729  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:34,743  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:34,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:34,743  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:34,743  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:34,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:34,743  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:34,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:34,743  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:34,743  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:34,743  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:34,743  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:34,743  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:34,744  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:34,744  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:34,744  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 5 HCatClient: thread: 1 users=5 expired=false closed=false
2023-02-15T14:45:34,744  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:34,745  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:45:34,751  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:34,760  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:34,760  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:34,760  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:34,760  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:34,760  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:34,760  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:34,760  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:34,760  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:34,760  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:34,760  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:34,760  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:34,760  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:34,760  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:34,760  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:34,761  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 6 HCatClient: thread: 1 users=6 expired=false closed=false
2023-02-15T14:45:34,761  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:34,761  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.mydb.mytable	
2023-02-15T14:45:34,763  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:34,764  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 add_partition : tbl=hive.mydb.mytable	
2023-02-15T14:45:34,767  INFO [Metastore-Handler-Pool: Thread-260] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable/dt=2011_12_31/grid=AB
2023-02-15T14:45:34,773  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:34,773  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:34,787  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:34,787  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:34,787  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:34,787  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:34,787  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:34,787  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:34,787  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:34,787  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:34,787  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:34,787  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:34,787  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:34,787  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:34,787  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:34,788  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:34,788  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 7 HCatClient: thread: 1 users=7 expired=false closed=false
2023-02-15T14:45:34,788  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:34,789  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:45:34,791  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:34,792  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_partitions : tbl=hive.myDb.myTable	
2023-02-15T14:45:34,811  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:34,811  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:34,811  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:34,811  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:34,811  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:34,811  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:34,811  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:34,811  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:34,811  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:34,811  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:34,811  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:34,811  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:34,811  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:34,811  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:34,811  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 8 HCatClient: thread: 1 users=8 expired=false closed=false
2023-02-15T14:45:34,812  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T14:45:34,812  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:45:34,814  INFO [Metastore-Handler-Pool: Thread-260] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:34,814  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2023-02-15T14:45:34,814  INFO [Metastore-Handler-Pool: Thread-260] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1784fc4c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5ab07d64 will be shutdown
2023-02-15T14:45:34,814  INFO [Metastore-Handler-Pool: Thread-260] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Exception in thread "Metastore-Handler-Pool: Thread-260" java.lang.NoSuchMethodError: org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_partition_args.access$6(Lorg/apache/hadoop/hive/metastore/api/ThriftHiveMetastore$get_partition_args;)Ljava/lang/String;
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:20846)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:1)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-15T14:45:34,815  WARN [main] metastore.RetryingMetaStoreClient: MetaStoreClient lost connection. Attempting to reconnect (1 of 1) after 1s. getPartition
org.apache.thrift.transport.TTransportException: Socket is closed by peer.
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:184) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:109) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:464) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:362) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:245) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_partition(ThriftHiveMetastore.java:3477) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_partition(ThriftHiveMetastore.java:3462) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2468) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2450) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at com.sun.proxy.$Proxy33.getPartition(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getPartition(HCatClientHMSImpl.java:455) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema(TestHCatClient.java:1145) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T14:45:35,816  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient trying reconnect as rizky (auth:SIMPLE)
2023-02-15T14:45:35,816  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=7 expired=false
2023-02-15T14:45:35,816  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:42647) in binary transport mode
2023-02-15T14:45:35,817  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:42647) current connections: 9
2023-02-15T14:45:35,820  INFO [Metastore-Handler-Pool: Thread-274] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
Exception in thread "Metastore-Handler-Pool: Thread-274" java.lang.NoSuchMethodError: org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$get_partition_args.access$6(Lorg/apache/hadoop/hive/metastore/api/ThriftHiveMetastore$get_partition_args;)Ljava/lang/String;
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:20846)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partition.getResult(ThriftHiveMetastore.java:1)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:250)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-15T14:45:35,821 ERROR [main] api.TestHCatClient: Unexpected exception! 
org.apache.hive.hcatalog.api.ConnectionFailureException: org.apache.hive.hcatalog.common.HCatException : 9001 : Exception occurred while processing HCat request : TException while retrieving partition.. Cause : org.apache.thrift.transport.TTransportException: Socket is closed by peer.
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getPartition(HCatClientHMSImpl.java:467) ~[classes/:?]
	at org.apache.hive.hcatalog.api.TestHCatClient.testPartitionRegistrationWithCustomSchema(TestHCatClient.java:1145) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159) ~[surefire-junit4-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
Caused by: org.apache.thrift.transport.TTransportException: Socket is closed by peer.
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:184) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:109) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:464) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:362) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:245) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.recv_get_partition(ThriftHiveMetastore.java:3477) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Client.get_partition(ThriftHiveMetastore.java:3462) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2468) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.getPartition(HiveMetaStoreClient.java:2450) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:214) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at com.sun.proxy.$Proxy33.getPartition(Unknown Source) ~[?:?]
	at org.apache.hive.hcatalog.api.HCatClientHMSImpl.getPartition(HCatClientHMSImpl.java:455) ~[classes/:?]
	... 31 more
2023-02-15T14:45:35,836  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:35,836  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:35,836  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:35,836  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:35,836  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:35,836  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:35,836  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:35,837  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:35,837  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:35,837  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:35,837  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:35,837  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:35,837  INFO [main] common.HCatUtil: mapreduce.lib.hcatoutput.hive.conf not set. Generating configuration differences.
2023-02-15T14:45:35,837  INFO [main] common.HCatUtil: Configuration differences={datanucleus.schema.autoCreateAll=true, hive.exec.scratchdir=${test.tmp.dir}/scratchdir, hive.strict.timestamp.conversion=false, hive.async.cleanup.service.thread.count=4, datanucleus.connectionPool.maxPoolSize=4, hive.ignore.mapjoin.hint=false, hive.query.reexecution.stats.persist.scope=query, hive.users.in.admin.role=hive_admin_user, hive.cbo.fallback.strategy=TEST, hive.metastore.warehouse.dir=${test.warehouse.dir}, hive.server2.operation.log.purgePolicy.timeToLive=5s, hive.llap.io.allocator.direct=false, hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe, javax.jdo.option.ConnectionURL=jdbc:derby:memory:${test.tmp.dir}/junit_metastore_db;create=true, hive.test.dummystats.aggregator=value2, hive.scheduled.queries.executor.enabled=false, hive.querylog.location=${test.tmp.dir}/tmp, hive.jar.path=${maven.local.repository}/org/apache/hive/hive-exec/${hive.version}/hive-exec-${hive.version}.jar, hive.exec.local.scratchdir=${test.tmp.dir}/localscratchdir/, hive.fetch.task.conversion=minimal, hive.server2.thrift.resultset.max.fetch.size=1000000, hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest, hive.in.test=true, hive.server2.webui.max.threads=4, hive.stats.fetch.bitvector=true, hive.query.results.cache.enabled=false, hive.metastore.client.cache.enabled=true, hive.auto.convert.join=false, hive.txn.xlock.ctas=false, hive.exec.submit.local.task.via.child=false, hive.conf.restricted.list=from.hivemetastore-site.xml, hive.metastore.schema.verification=false}
2023-02-15T14:45:35,837  WARN [main] metastore.HiveMetaStoreClient: Unexpected increment of user count beyond one: 8 HCatClient: thread: 1 users=8 expired=false closed=false
2023-02-15T14:45:35,837  WARN [main] metastore.HiveMetaStoreClient: Evicted client has non-zero user count: 8
2023-02-15T14:45:35,837  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=8 expired=true
2023-02-15T14:45:35,837  WARN [main] metastore.HiveMetaStoreClient: Non-zero user count preventing client tear down: users=7 expired=true
2023-02-15T14:45:35,838  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T14:45:35,838  INFO [main] metastore.HiveMetaStoreClient: Resolved metastore uris: [thrift://localhost:42647]
2023-02-15T14:45:35,838  INFO [main] metastore.HiveMetaStoreClient: Trying to connect to metastore with URI (thrift://localhost:42647) in binary transport mode
2023-02-15T14:45:35,838  INFO [main] metastore.HiveMetaStoreClient: Opened a connection to metastore, URI (thrift://localhost:42647) current connections: 10
2023-02-15T14:45:35,839  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hive.hcatalog.common.HiveClientCache$CacheableHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
2023-02-15T14:45:35,839  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2023-02-15T14:45:35,839  INFO [Metastore-Handler-Pool: Thread-276] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T14:45:35,839  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@9683508, with PersistenceManager: null will be shutdown
2023-02-15T14:45:35,839  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@9683508, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5966bbf5 created in the thread with id: 276
2023-02-15T14:45:35,848  INFO [Metastore-Handler-Pool: Thread-276] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@9683508
2023-02-15T14:45:35,849  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:35,849  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:35,850  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2023-02-15T14:45:35,852  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2023-02-15T14:45:35,856  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: myDb	
2023-02-15T14:45:35,856  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2023-02-15T14:45:35,856  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2023-02-15T14:45:35,857  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2023-02-15T14:45:35,858  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2023-02-15T14:45:35,859  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:35,874  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.mydb.mytable	
2023-02-15T14:45:35,902  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:35,902  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:35,905  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2023-02-15T14:45:35,915  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:35,915  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:35,918  WARN [Metastore-Handler-Pool: Thread-276] utils.FileUtils: File file:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db does not exist; Force to delete it.
2023-02-15T14:45:35,918 ERROR [Metastore-Handler-Pool: Thread-276] utils.FileUtils: Failed to delete pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:45:35,918  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_database: Database(name:myDb, description:null, locationUri:null, parameters:null, catalogName:hive)	
2023-02-15T14:45:35,920  INFO [Metastore-Handler-Pool: Thread-276] metastore.HMSHandler: Creating database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:45:35,920  INFO [Metastore-Handler-Pool: Thread-276] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:45:35,921  INFO [Metastore-Handler-Pool: Thread-276] metastore.HMSHandler: Created database path in external directory pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:45:35,922  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:35,922  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:35,923  WARN [main] api.HCatTable: Conf hasn't been set yet. Using defaults.
2023-02-15T14:45:35,938  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T14:45:35,938  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T14:45:35,938  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T14:45:35,938  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T14:45:35,938  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T14:45:35,938  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T14:45:35,938  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T14:45:35,938  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T14:45:35,938  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T14:45:35,938  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T14:45:35,938  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T14:45:35,938  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T14:45:35,938  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 create_table_req: Table(tableName:myTable, dbName:myDb, owner:rizky, createTime:1676501135, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:foo, type:int, comment:), FieldSchema(name:bar, type:string, comment:)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:0, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{serialization.format=1}), bucketCols:null, sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:dt, type:string, comment:), FieldSchema(name:grid, type:string, comment:)], parameters:{bucketing_version=2}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T14:45:35,939  INFO [Metastore-Handler-Pool: Thread-276] utils.FileUtils: Creating directory if it doesn't exist: pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db/mytable
2023-02-15T14:45:35,948  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:35,948  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:35,955  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_table : tbl=hive.myDb.myTable	
2023-02-15T14:45:35,961  INFO [Metastore-Handler-Pool: Thread-276] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T14:45:35,962  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_database: myDb	
2023-02-15T14:45:35,962  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_tables_by_type: db=@hive#myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:35,962  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:35,964  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2023-02-15T14:45:35,966  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_multi_table : db=myDb tbls=mytable	
2023-02-15T14:45:35,970  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_database: myDb	
2023-02-15T14:45:35,970  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_tables: db=@hive#myDb	
2023-02-15T14:45:35,971  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_functions: db=@hive#myDb pat=*	
2023-02-15T14:45:35,972  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_stored_procedures	
2023-02-15T14:45:35,973  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 get_all_packages	
2023-02-15T14:45:35,975  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 getTablesByTypeCore: catName=hive: db=myDb pat=.*,type=MATERIALIZED_VIEW	
2023-02-15T14:45:35,978  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=source:127.0.0.1 drop_table : tbl=hive.mydb.mytable	
2023-02-15T14:45:35,982  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:35,982  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:35,982  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore: Dropping database hive.myDb along with all tables
2023-02-15T14:45:35,983  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11729
2023-02-15T14:45:35,983  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore$RetryingExecutor: [wasabi] ObjectStore 11731
2023-02-15T14:45:35,986  WARN [Metastore-Handler-Pool: Thread-276] utils.FileUtils: File file:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db does not exist; Force to delete it.
2023-02-15T14:45:35,986 ERROR [Metastore-Handler-Pool: Thread-276] utils.FileUtils: Failed to delete pfile:/home/rizky/hive/hcatalog/webhcat/java-client/target/warehouse/42647/mydb.db
2023-02-15T14:45:35,986  INFO [main] api.TestHCatClient: Shutting down metastore.
2023-02-15T14:45:36,005  INFO [shutdown-hook-0] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 9
2023-02-15T14:45:36,005  INFO [Metastore-Handler-Pool: Thread-206] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2023-02-15T14:45:36,005  INFO [Metastore-Handler-Pool: Thread-206] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@63193911, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1d531747 will be shutdown
2023-02-15T14:45:36,005  INFO [Metastore-Handler-Pool: Thread-206] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T14:45:36,005  INFO [Metastore-Handler-Pool: Thread-206] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T14:45:36,005  INFO [shutdown-hook-0] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: 8
2023-02-15T14:45:36,006  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=127.0.0.1	cmd=Cleaning up thread local RawStore...	
2023-02-15T14:45:36,006  INFO [Metastore-Handler-Pool: Thread-276] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@9683508, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5966bbf5 will be shutdown
2023-02-15T14:45:36,006  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T14:45:36,006  INFO [Metastore-Handler-Pool: Thread-276] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
