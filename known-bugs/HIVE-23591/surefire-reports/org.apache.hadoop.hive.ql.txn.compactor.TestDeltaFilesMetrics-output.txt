SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/rizky/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.18.0/log4j-slf4j-impl-2.18.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/rizky/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactorTest
DEBUG StatusLogger Took 0.036121 seconds to load 266 plugins from sun.misc.Launcher$AppClassLoader@677327b6
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Converter' found 48 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=677327b6, org.apache.logging.log4j.core.LoggerContext@6a8658ff]...
DEBUG StatusLogger Reconfiguration started for context[name=677327b6] at URI null (org.apache.logging.log4j.core.LoggerContext@6a8658ff) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@126253fd
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Apache Log4j Core 2.18.0 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@147e2ae7
INFO StatusLogger Scanning for classes in '/home/rizky/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/rizky/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/rizky/hive/common/target/hive-common-4.0.0-SNAPSHOT.jar' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0.007215 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 141 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="${sys:test.tmp.dir}/log", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/rizky/hive/ql/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="ERROR", levelAndRefs="null", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="ERROR", levelAndRefs="null", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="ERROR", levelAndRefs="null", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="ERROR", levelAndRefs="null", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="DEBUG", levelAndRefs="null", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.logging.log4j.core.filter.MarkerFilter].
ERROR StatusLogger MarkerFilter contains an invalid element or attribute "onMismatch"
DEBUG StatusLogger createFilter(marker="FULL_PLAN", onMatch="DENY", onMismatch="NEUTRAL")
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="OFF", levelAndRefs="null", name="org.apache.hadoop.hive.ql.optimizer.calcite.RuleEventLogger", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), MarkerFilter(FULL_PLAN))
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger LoggerConfig$RootLogger$Builder(additivity="null", level="DEBUG", levelAndRefs="null", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, org.apache.hadoop.hive.ql.optimizer.calcite.RuleEventLogger, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 48 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/rizky/hive/ql/target/tmp/log/hive.log", filePattern="/home/rizky/hive/ql/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/rizky/hive/ql/target/tmp/log/hive.log seek to 1949891418
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/rizky/hive/ql/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2023-02-15T13:38:48.038-0800
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2023/02/16-00:00:00.000, nextFileTime=2023/02/15-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2023/02/15-13:38:48.904, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2023/02/16-00:00:00.000, nextFileTime=2023/02/15-00:00:00.000, prevFileTime=2023/02/15-00:00:00.000, current=2023/02/15-13:38:48.904, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@147e2ae7 initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@147e2ae7
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@147e2ae7 OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@268f106e...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@268f106e OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@3eb77ea8
TRACE StatusLogger Reregistering context (1/1): '677327b6' org.apache.logging.log4j.core.LoggerContext@6a8658ff
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.calcite.RuleEventLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=677327b6] at URI /home/rizky/hive/ql/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@6a8658ff) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=677327b6, org.apache.logging.log4j.core.LoggerContext@6a8658ff] started OK.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.common.util.HiveVersionInfo
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.conf.Configuration
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.conf.Configuration
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.conf.HiveConf
2023-02-15T13:38:48,944  INFO [main] conf.HiveConf: Found configuration file file:/home/rizky/hive/ql/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.conf.SystemVariables
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.conf.valcoersion.JavaIOTmpdirVariableCoercion
log4j: Trying to find [log4j.xml] using context classloader sun.misc.Launcher$AppClassLoader@677327b6.
log4j: Trying to find [log4j.xml] using sun.misc.Launcher$AppClassLoader@677327b6 class loader.
log4j: Trying to find [log4j.xml] using ClassLoader.getSystemResource().
log4j: Trying to find [log4j.properties] using context classloader sun.misc.Launcher$AppClassLoader@677327b6.
log4j: Trying to find [log4j.properties] using sun.misc.Launcher$AppClassLoader@677327b6 class loader.
log4j: Trying to find [log4j.properties] using ClassLoader.getSystemResource().
log4j: Could not find resource: [null].
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.FileSystem
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.FileUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.common.HiveCompat
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.JobConf
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.lib.output.FileOutputFormat
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.Credentials
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.UserGroupInformation
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.impl.MetricsSystemImpl
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.lib.Interns
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.lib.MetricsSourceBuilder
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.lib.MutableMetricsFactory
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.conf.HiveConfUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.Shell
2023-02-15T13:38:49,126  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:38:49,126  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:38:49,126  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:38:49,127  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:38:49,127  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:38:49,127  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:38:49,127  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:38:49,127  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:38:49,127  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:38:49,127  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:38:49,127  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:38:49,127  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.conf.MetastoreConf
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.SecurityUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.authentication.util.KerberosName
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.HadoopKerberosName
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.Groups
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.NativeCodeLoader
2023-02-15T13:38:49,150  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.PerformanceAdvisory
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.ShellBasedUnixGroupsMapping
log4j:WARN No appenders could be found for logger (org.apache.htrace.core.Tracer).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.HarFileSystem
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hdfs.DistributedFileSystem
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hdfs.web.WebHdfsFileSystem
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.ShutdownHookManager
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.TestTxnDbUtil
2023-02-15T13:38:49,195  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.calcite.avatica.remote.Driver
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.DatabaseProduct
2023-02-15T13:38:49,473  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.MetaStoreSchemaInfoFactory
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.MetastoreVersionInfo
2023-02-15T13:38:49,478  INFO [main] utils.TestTxnDbUtil: Reinitializing the metastore db with hive-schema-4.0.0.derby.sql on the database jdbc:derby:memory:/home/rizky/hive/ql/target/tmp/junit_metastore_db;create=true
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveMetaStoreClient
2023-02-15T13:38:49,840  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveMetaStore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HMSHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HMSHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.RetryingHMSHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.MetaStoreInit
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.metrics.PerfLogger
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.metrics.Metrics
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.Deadline
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.codahale.metrics.jvm.BufferPoolMetricSet
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.codahale.metrics.ScheduledReporter
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.metrics.JsonReporter
2023-02-15T13:38:49,933  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.codahale.metrics.JmxReporter
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.codahale.metrics.DefaultObjectNameFactory
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.JavaUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveAlterHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.Warehouse
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.ReplChangeManager
2023-02-15T13:38:50,013  INFO [main] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.ObjectStore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.PersistenceManagerProvider
2023-02-15T13:38:50,033  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:38:50,035  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.datasource.HikariCPDataSourceProvider
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.datasource.DbCPDataSourceProvider
2023-02-15T13:38:50,038  INFO [main] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: objectstore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.HikariConfig
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.HikariDataSource
2023-02-15T13:38:50,045  WARN [main] hikari.HikariConfig: objectstore - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T13:38:50,047  INFO [main] hikari.HikariDataSource: objectstore - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.util.DriverDataSource
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.HikariPool
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.util.ConcurrentBag
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.PoolEntry
2023-02-15T13:38:50,055  INFO [main] pool.PoolBase: objectstore - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T13:38:50,060  INFO [main] hikari.HikariDataSource: objectstore - Start completed.
2023-02-15T13:38:50,060  INFO [main] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 2, name: objectstore-secondary
2023-02-15T13:38:50,061  WARN [main] hikari.HikariConfig: objectstore-secondary - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T13:38:50,062  INFO [main] hikari.HikariDataSource: objectstore-secondary - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.HikariPool
2023-02-15T13:38:50,063  INFO [main] pool.PoolBase: objectstore-secondary - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T13:38:50,063  INFO [main] hikari.HikariDataSource: objectstore-secondary - Start completed.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.ProxyLeakTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.ProxyConnection
2023-02-15T13:38:50,255  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2023-02-15T13:38:50,255  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72543547, with PersistenceManager: null will be shutdown
2023-02-15T13:38:50,267  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72543547, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@162c1dfb created in the thread with id: 1
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.MetaStoreDirectSql
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.tools.SQLGenerator
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.PartFilterExprUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.DirectSqlUpdateStat
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.MetastoreDirectSqlUtils
2023-02-15T13:38:51,178  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72543547
2023-02-15T13:38:51,184  INFO [main] metastore.HMSHandler: Setting location of default catalog, as it hasn't been done after upgrade
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.shims.ShimLoader
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.VersionInfo
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.ThreadUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.io.IOUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.shims.HadoopShimsSecure
2023-02-15T13:38:51,205  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2023-02-15T13:38:51,223  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2023-02-15T13:38:51,230  INFO [main] metastore.HMSHandler: Added admin role in metastore
2023-02-15T13:38:51,231  INFO [main] metastore.HMSHandler: Added public role in metastore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.MetaStoreUtils
2023-02-15T13:38:51,262  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
2023-02-15T13:38:51,262  INFO [main] metastore.HMSHandler: Begin calculating metadata count metrics.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.TransactionalValidationListener
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HMSMetricsListener
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.leader.HostLeaderElection
2023-02-15T13:38:51,276  INFO [main] leader.HostLeaderElection: metastore.housekeeping.leader.hostname is empty. Start all the housekeeping threads.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.ThreadPool
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.metrics.AcidMetricLogger
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.metrics.AcidMetricService
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.events.EventCleanerTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.txn.TxnUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.txn.TxnHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler
2023-02-15T13:38:51,294  INFO [main] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: txnhandler
2023-02-15T13:38:51,295  WARN [main] hikari.HikariConfig: txnhandler - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T13:38:51,296  INFO [main] hikari.HikariDataSource: txnhandler - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.HikariPool
2023-02-15T13:38:51,296  INFO [main] pool.PoolBase: txnhandler - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T13:38:51,297  INFO [main] hikari.HikariDataSource: txnhandler - Start completed.
2023-02-15T13:38:51,297  INFO [main] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: mutex
2023-02-15T13:38:51,297  WARN [main] hikari.HikariConfig: mutex - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T13:38:51,298  INFO [main] hikari.HikariDataSource: mutex - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.HikariPool
2023-02-15T13:38:51,298  INFO [main] pool.PoolBase: mutex - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T13:38:51,299  INFO [main] hikari.HikariDataSource: mutex - Start completed.
2023-02-15T13:38:51,301  INFO [main] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 5, name: compactor
2023-02-15T13:38:51,301  WARN [main] hikari.HikariConfig: compactor - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T13:38:51,302  INFO [main] hikari.HikariDataSource: compactor - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.HikariPool
2023-02-15T13:38:51,303  INFO [main] pool.PoolBase: compactor - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T13:38:51,303  INFO [main] hikari.HikariDataSource: compactor - Start completed.
2023-02-15T13:38:51,303  INFO [main] metastore.HiveMetaStore: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricLogger service.
2023-02-15T13:38:51,303  INFO [main] metastore.HiveMetaStore: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service.
2023-02-15T13:38:51,304  INFO [main] metastore.HiveMetaStore: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service.
2023-02-15T13:38:51,305  INFO [main] metastore.HiveMetaStore: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service.
2023-02-15T13:38:51,305  INFO [main] metastore.HiveMetaStore: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service.
2023-02-15T13:38:51,305  INFO [main] metastore.HiveMetaStore: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.FileMetadataManager
2023-02-15T13:38:51,305  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.dataconnector.DataConnectorProviderFactory
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.permission.FsPermission
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.io.nativeio.NativeIO
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.FileUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.metrics.metrics2.CodahaleMetrics
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.metrics.metrics2.JsonFileMetricsReporter
2023-02-15T13:38:51,379  INFO [main] metrics2.JsonFileMetricsReporter: Reporting metrics to /tmp/report.json
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.SecurityUtils
2023-02-15T13:38:51,396  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.dp	
2023-02-15T13:38:51,410  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:dp, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_0/dp, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:38:51,414  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_0/dp specified for non-external table:dp
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.FileUtils
2023-02-15T13:38:51,415  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_0/dp
2023-02-15T13:38:51,464  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.dp	
2023-02-15T13:38:51,483  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_0/dp/ds=part1
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.StatsSetupConst
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.io.AcidUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.DataChecksum
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl
2023-02-15T13:38:51,539  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]) with min_open_txn: 1
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 21
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 22
2023-02-15T13:38:51,546  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 23
2023-02-15T13:38:51,547  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=dp (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])
2023-02-15T13:38:51,557  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:38:51,564  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,566  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:38:51,569  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2023-02-15T13:38:51,572  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,573  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2023-02-15T13:38:51,575  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:38:51,579  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,579  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:38:51,582  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2023-02-15T13:38:51,585  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,586  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2023-02-15T13:38:51,588  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:38:51,592  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,592  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:38:51,595  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:38:51,598  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,598  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:38:51,601  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2023-02-15T13:38:51,604  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,604  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:38:51,607  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2023-02-15T13:38:51,610  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,611  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:38:51,613  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2023-02-15T13:38:51,617  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,617  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:38:51,619  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2023-02-15T13:38:51,622  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,623  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:38:51,625  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2023-02-15T13:38:51,628  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,629  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2023-02-15T13:38:51,631  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2023-02-15T13:38:51,634  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,634  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2023-02-15T13:38:51,637  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:13
2023-02-15T13:38:51,640  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,640  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2023-02-15T13:38:51,643  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:14
2023-02-15T13:38:51,646  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,646  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:14
2023-02-15T13:38:51,649  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2023-02-15T13:38:51,652  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,652  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2023-02-15T13:38:51,655  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2023-02-15T13:38:51,658  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,658  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:38:51,661  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2023-02-15T13:38:51,664  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,664  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:38:51,667  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2023-02-15T13:38:51,670  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,670  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:38:51,673  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2023-02-15T13:38:51,676  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,676  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:38:51,679  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2023-02-15T13:38:51,682  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,682  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:38:51,685  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:21
2023-02-15T13:38:51,687  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,687  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:21
2023-02-15T13:38:51,692  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:22
2023-02-15T13:38:51,698  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,698  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:22
2023-02-15T13:38:51,701  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:23
2023-02-15T13:38:51,705  INFO [main] txn.TxnHandler: Removed transactions: ([23]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,706  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:23
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.ServerUtils
2023-02-15T13:38:51,712  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([24]) with min_open_txn: 1
2023-02-15T13:38:51,739  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 24
2023-02-15T13:38:51,739  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=dp (txnIds: [24])
2023-02-15T13:38:51,748  INFO [main] txn.TxnHandler: Removed transactions: ([24]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:51,748  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:24
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactorThread
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.Initiator
2023-02-15T13:38:51,761  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:38:51,761  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:38:51,761  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:38:51,761  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:38:51,761  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:38:51,761  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:38:51,761  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:38:51,761  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:38:51,761  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:38:51,761  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:38:51,761  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:38:51,761  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:38:51,763  INFO [main] compactor.Initiator: Starting Initiator thread
2023-02-15T13:38:51,767  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410731765
2023-02-15T13:38:51,784  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:38:51,784  INFO [Initiator-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:38:51,784  INFO [Initiator-executor-thread-1] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2023-02-15T13:38:51,784  INFO [Initiator-executor-thread-1] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 5, name: objectstore-compactor
2023-02-15T13:38:51,785  WARN [Initiator-executor-thread-1] hikari.HikariConfig: objectstore-compactor - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T13:38:51,785  INFO [Initiator-executor-thread-1] hikari.HikariDataSource: objectstore-compactor - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.HikariPool
2023-02-15T13:38:51,786  INFO [Initiator-executor-thread-1] pool.PoolBase: objectstore-compactor - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T13:38:51,786  INFO [Initiator-executor-thread-1] hikari.HikariDataSource: objectstore-compactor - Start completed.
2023-02-15T13:38:51,943  INFO [Initiator-executor-thread-1] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2023-02-15T13:38:51,943  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1d3acec5, with PersistenceManager: null will be shutdown
2023-02-15T13:38:51,943  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1d3acec5, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c2f0da5 created in the thread with id: 83
2023-02-15T13:38:52,133  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1d3acec5
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.exec.repl.util.ReplUtils
2023-02-15T13:38:52,137  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.dp.ds=part1
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.Batchable
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.io.HdfsUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.functional.RemoteIterators
2023-02-15T13:38:52,210  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:dp, partitionname:ds=part1, type:MAJOR, runas:rizky, initiatorId:labdas-83)
2023-02-15T13:38:52,219  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410732218
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.Worker
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactorFactory
2023-02-15T13:38:54,240  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:38:54,240  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:38:54,240  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:38:54,240  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:38:54,240  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:38:54,240  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:38:54,240  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:38:54,240  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:38:54,240  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:38:54,240  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:38:54,240  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:38:54,240  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveMetaStoreUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveClientCache
2023-02-15T13:38:54,242  INFO [main] metastore.HiveClientCache: Initializing cache: eviction-timeout=120 initial-capacity=50 maximum-capacity=50
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.common.util.ShutdownHookManager
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.shims.Utils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.RetryingMetaStoreClient
2023-02-15T13:38:54,255  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:38:54,255  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:38:54,255  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72543547, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@162c1dfb will be shutdown
2023-02-15T13:38:54,255  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72543547, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@105c6c9e created in the thread with id: 1
2023-02-15T13:38:54,259  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:38:54,259  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.metastore.HiveClientCache$CacheableHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
2023-02-15T13:38:54,271  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T13:38:54,277  INFO [main] compactor.Worker: Starting Worker thread
2023-02-15T13:38:54,277  INFO [main] compactor.Worker: [wasabi] Worker 111
2023-02-15T13:38:54,277  INFO [main] compactor.Worker: [wasabi] Worker 117
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.session.SessionState
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.log.PerfLogger
2023-02-15T13:38:54,280  INFO [main_timeout_executor] compactor.Worker: [wasabi] Worker 281
2023-02-15T13:38:54,284  INFO [main_timeout_executor] compactor.Worker: Processing compaction request id:1,dbname:default,tableName:dp,partName:ds=part1,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:,workerId: labdas-103,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:38:54,285  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.dp	
2023-02-15T13:38:54,285  INFO [main_timeout_executor] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:38:54,286  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@681e7c99, with PersistenceManager: null will be shutdown
2023-02-15T13:38:54,286  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@681e7c99, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7795e69a created in the thread with id: 106
2023-02-15T13:38:54,288  INFO [main_timeout_executor] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@681e7c99
2023-02-15T13:38:54,291  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:38:54,292  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_partitions_by_names : tbl=hive.default.dp	
2023-02-15T13:38:54,296  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:38:54,301  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([25]) with min_open_txn: 25
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactionHeartbeatService
2023-02-15T13:38:54,326  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Submitting heartbeat task for TXN 25
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactionHeartbeatService$CompactionHeartbeater
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.MRCompactor
2023-02-15T13:38:54,345  INFO [main_timeout_executor] compactor.Worker: Starting MAJOR compaction for default.dp.ds=part1, id:1 in txnId=25, lockId=2 (TxnStatus: 'o') with compute stats set to false
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.security.TokenCache
2023-02-15T13:38:54,350  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MAJOR compaction job 'labdas-103-compactor-default.dp.ds=part1' to default queue. (current delta dirs count=2, obsolete delta dirs count=0. TxnIdRange[21,24}]
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.tools.CLI
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.Cluster
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.LocalJobRunner
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.impl.MetricsConfig
2023-02-15T13:38:54,376  WARN [main_timeout_executor] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.impl.MetricsSourceAdapter
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.util.MBeans
2023-02-15T13:38:54,382  INFO [main_timeout_executor] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-15T13:38:54,382  INFO [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system started
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.Job
2023-02-15T13:38:54,388  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.JobSubmitter
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.JobSubmissionFiles
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.CryptoUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.JobResourceUploader
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.SharedCacheConfig
2023-02-15T13:38:54,406  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:38:54,410  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.FSInputStream
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.FSInputChecker
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.split.JobSplitWriter
2023-02-15T13:38:54,425  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.QueueManager
2023-02-15T13:38:54,448  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local277463145_0001
2023-02-15T13:38:54,448  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.LocalDistributedCacheManager
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.v2.util.MRApps
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.FileContext
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.AbstractFileSystem
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.DiskChecker
2023-02-15T13:38:54,516  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:38:54,517  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-103-compactor-default.dp.ds=part1' with jobID=job_local277463145_0001 compaction ID=1
2023-02-15T13:38:54,517  INFO [Thread-86] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:38:54,517  INFO [Thread-86] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.io.FastByteComparisons
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.counters.AbstractCounters
2023-02-15T13:38:54,531  INFO [Thread-86] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:38:54,532  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local277463145_0001_m_000000_0
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.Task
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.MapTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.SortedRanges
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.Progress
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.TaskStatus
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.util.MRJobConfUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.yarn.util.ResourceCalculatorProcessTree
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.yarn.util.ProcfsBasedProcessTree
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.SysInfoLinux
2023-02-15T13:38:54,546  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.io.serializer.SerializationFactory
2023-02-15T13:38:54,549  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_0/dp/ds=part1/base_20, bucket: 0, length: 3024, deltas: [delta_0000021_0000022, delta_0000023_0000024]}
2023-02-15T13:38:54,551  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.JavaUtils
2023-02-15T13:38:54,561  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup
2023-02-15T13:38:54,564  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local277463145_0001_m_000000_0 is done. And is in the process of committing
2023-02-15T13:38:54,564  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:38:54,564  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local277463145_0001_m_000000_0' done.
2023-02-15T13:38:54,567  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local277463145_0001_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=4039
		FILE: Number of bytes written=1229992
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=417
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=617086976
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:38:54,567  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local277463145_0001_m_000000_0
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.concurrent.ExecutorHelper
2023-02-15T13:38:54,568  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local277463145_0001_m_000001_0
2023-02-15T13:38:54,568  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:38:54,568  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_0/dp/ds=part1/base_20, bucket: 1, length: 3024, deltas: [delta_0000021_0000022, delta_0000023_0000024]}
2023-02-15T13:38:54,568  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:38:54,572  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:38:54,572  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local277463145_0001_m_000001_0 is done. And is in the process of committing
2023-02-15T13:38:54,572  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:38:54,572  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local277463145_0001_m_000001_0' done.
2023-02-15T13:38:54,572  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local277463145_0001_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=7984
		FILE: Number of bytes written=1231104
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=417
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=617086976
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:38:54,572  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local277463145_0001_m_000001_0
2023-02-15T13:38:54,572  INFO [Thread-86] mapred.LocalJobRunner: map task executor complete.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.JobEndNotifier
2023-02-15T13:38:59,521  INFO [main_timeout_executor] compactor.Worker: Completed MAJOR compaction for default.dp.ds=part1 in txnId=25, lockId=2 (TxnStatus: 'o'), marking as compacted.
2023-02-15T13:38:59,530  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Stopping heartbeat task for TXN 25
2023-02-15T13:38:59,530  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Shutting down compaction txn heartbeater instance.
2023-02-15T13:38:59,530  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Compaction txn heartbeater instance is successfully stopped.
2023-02-15T13:38:59,534  INFO [main_timeout_executor] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:25
2023-02-15T13:38:59,543  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([25]) from MIN_HISTORY_LEVEL
2023-02-15T13:38:59,544  INFO [main] compactor.Worker: [wasabi] Worker 163
2023-02-15T13:38:59,544  INFO [main] compactor.Worker: [wasabi] Worker 170
2023-02-15T13:39:01,613  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]) with min_open_txn: 26
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 26
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 26 for txnId: 27
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 27 for txnId: 28
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 28 for txnId: 29
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 29 for txnId: 30
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 30 for txnId: 31
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 31 for txnId: 32
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 32 for txnId: 33
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 33 for txnId: 34
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 34 for txnId: 35
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 35 for txnId: 36
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 36 for txnId: 37
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 37 for txnId: 38
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 38 for txnId: 39
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 39 for txnId: 40
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 40 for txnId: 41
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 41 for txnId: 42
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 42 for txnId: 43
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 43 for txnId: 44
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 44 for txnId: 45
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 45 for txnId: 46
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 46 for txnId: 47
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 47 for txnId: 48
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 48 for txnId: 49
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 49 for txnId: 50
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 50 for txnId: 51
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 51 for txnId: 52
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 52 for txnId: 53
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 53 for txnId: 54
2023-02-15T13:39:01,618  INFO [main] txn.TxnHandler: Allocated writeId: 54 for txnId: 55
2023-02-15T13:39:01,619  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=dp (txnIds: [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55])
2023-02-15T13:39:01,621  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:26
2023-02-15T13:39:01,624  INFO [main] txn.TxnHandler: Removed transactions: ([26]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,625  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:26
2023-02-15T13:39:01,627  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:27
2023-02-15T13:39:01,629  INFO [main] txn.TxnHandler: Removed transactions: ([27]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,630  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:27
2023-02-15T13:39:01,632  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:28
2023-02-15T13:39:01,635  INFO [main] txn.TxnHandler: Removed transactions: ([28]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,635  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:28
2023-02-15T13:39:01,637  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:29
2023-02-15T13:39:01,640  INFO [main] txn.TxnHandler: Removed transactions: ([29]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,640  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:29
2023-02-15T13:39:01,642  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:30
2023-02-15T13:39:01,645  INFO [main] txn.TxnHandler: Removed transactions: ([30]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,645  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:30
2023-02-15T13:39:01,648  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:31
2023-02-15T13:39:01,652  INFO [main] txn.TxnHandler: Removed transactions: ([31]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,652  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:31
2023-02-15T13:39:01,654  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:32
2023-02-15T13:39:01,658  INFO [main] txn.TxnHandler: Removed transactions: ([32]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,658  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:32
2023-02-15T13:39:01,660  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:33
2023-02-15T13:39:01,663  INFO [main] txn.TxnHandler: Removed transactions: ([33]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,663  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:33
2023-02-15T13:39:01,665  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:34
2023-02-15T13:39:01,668  INFO [main] txn.TxnHandler: Removed transactions: ([34]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,668  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:34
2023-02-15T13:39:01,671  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:35
2023-02-15T13:39:01,674  INFO [main] txn.TxnHandler: Removed transactions: ([35]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,674  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:35
2023-02-15T13:39:01,676  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:36
2023-02-15T13:39:01,679  INFO [main] txn.TxnHandler: Removed transactions: ([36]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,679  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:36
2023-02-15T13:39:01,681  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:37
2023-02-15T13:39:01,684  INFO [main] txn.TxnHandler: Removed transactions: ([37]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,684  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:37
2023-02-15T13:39:01,687  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:38
2023-02-15T13:39:01,689  INFO [main] txn.TxnHandler: Removed transactions: ([38]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,690  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:38
2023-02-15T13:39:01,692  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:39
2023-02-15T13:39:01,695  INFO [main] txn.TxnHandler: Removed transactions: ([39]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,695  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:39
2023-02-15T13:39:01,697  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:40
2023-02-15T13:39:01,699  INFO [main] txn.TxnHandler: Removed transactions: ([40]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,700  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:40
2023-02-15T13:39:01,702  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:41
2023-02-15T13:39:01,704  INFO [main] txn.TxnHandler: Removed transactions: ([41]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,704  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:41
2023-02-15T13:39:01,707  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:42
2023-02-15T13:39:01,709  INFO [main] txn.TxnHandler: Removed transactions: ([42]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,709  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:42
2023-02-15T13:39:01,711  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:43
2023-02-15T13:39:01,714  INFO [main] txn.TxnHandler: Removed transactions: ([43]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,714  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:43
2023-02-15T13:39:01,716  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:44
2023-02-15T13:39:01,718  INFO [main] txn.TxnHandler: Removed transactions: ([44]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,719  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:44
2023-02-15T13:39:01,721  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:45
2023-02-15T13:39:01,723  INFO [main] txn.TxnHandler: Removed transactions: ([45]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,723  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:45
2023-02-15T13:39:01,780  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:46
2023-02-15T13:39:01,783  INFO [main] txn.TxnHandler: Removed transactions: ([46]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,784  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:46
2023-02-15T13:39:01,786  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:47
2023-02-15T13:39:01,788  INFO [main] txn.TxnHandler: Removed transactions: ([47]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,789  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:47
2023-02-15T13:39:01,791  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:48
2023-02-15T13:39:01,793  INFO [main] txn.TxnHandler: Removed transactions: ([48]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,793  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:48
2023-02-15T13:39:01,795  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:49
2023-02-15T13:39:01,797  INFO [main] txn.TxnHandler: Removed transactions: ([49]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,797  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:49
2023-02-15T13:39:01,800  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:50
2023-02-15T13:39:01,802  INFO [main] txn.TxnHandler: Removed transactions: ([50]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,802  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:50
2023-02-15T13:39:01,804  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:51
2023-02-15T13:39:01,806  INFO [main] txn.TxnHandler: Removed transactions: ([51]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,806  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:51
2023-02-15T13:39:01,808  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:52
2023-02-15T13:39:01,810  INFO [main] txn.TxnHandler: Removed transactions: ([52]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,810  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:52
2023-02-15T13:39:01,812  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:53
2023-02-15T13:39:01,815  INFO [main] txn.TxnHandler: Removed transactions: ([53]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,815  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:53
2023-02-15T13:39:01,817  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:54
2023-02-15T13:39:01,819  INFO [main] txn.TxnHandler: Removed transactions: ([54]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,819  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:54
2023-02-15T13:39:01,821  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:55
2023-02-15T13:39:01,824  INFO [main] txn.TxnHandler: Removed transactions: ([55]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,824  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:55
2023-02-15T13:39:01,828  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([56]) with min_open_txn: 26
2023-02-15T13:39:01,844  INFO [main] txn.TxnHandler: Allocated writeId: 55 for txnId: 56
2023-02-15T13:39:01,844  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=dp (txnIds: [56])
2023-02-15T13:39:01,851  INFO [main] txn.TxnHandler: Removed transactions: ([56]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:01,851  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:56
2023-02-15T13:39:01,861  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:39:01,861  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:39:01,861  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:39:01,861  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:39:01,861  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:39:01,861  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:39:01,861  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:39:01,861  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:39:01,861  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:39:01,861  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:39:01,861  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:39:01,861  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:39:01,862  INFO [main] compactor.Initiator: Starting Initiator thread
2023-02-15T13:39:01,864  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410741864
2023-02-15T13:39:01,876  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:39:01,876  INFO [Initiator-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:39:01,876  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@652fd5f9, with PersistenceManager: null will be shutdown
2023-02-15T13:39:01,877  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@652fd5f9, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@c14dc55 created in the thread with id: 176
2023-02-15T13:39:01,886  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@652fd5f9
2023-02-15T13:39:01,888  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.dp.ds=part1
2023-02-15T13:39:01,939  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:dp, partitionname:ds=part1, type:MINOR, runas:rizky, initiatorId:labdas-176)
2023-02-15T13:39:01,946  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410741944
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.Cleaner
2023-02-15T13:39:03,967  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:39:03,967  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:39:03,967  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:39:03,967  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:39:03,967  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:39:03,967  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:39:03,967  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:39:03,967  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:39:03,967  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:39:03,967  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:39:03,967  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:39:03,969  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:39:03,970  INFO [main] compactor.Cleaner: Starting Cleaner thread
2023-02-15T13:39:03,976  INFO [main] compactor.Cleaner: Cleaning based on min open txn id: 57
2023-02-15T13:39:03,977  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:1,dbname:default,tableName:dp,partName:ds=part1,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:24,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:39:03,978  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:39:03,978  INFO [Cleaner-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:39:03,978  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d05121c, with PersistenceManager: null will be shutdown
2023-02-15T13:39:03,979  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d05121c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3945fd4a created in the thread with id: 202
2023-02-15T13:39:03,982  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4d05121c
2023-02-15T13:39:03,992  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=1 About to remove 3 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_0/dp/ds=part1. [base_20,delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:39:03,999  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:39:06,015  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:39:06,015  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:39:06,015  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:39:06,015  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:39:06,015  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:39:06,015  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:39:06,015  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:39:06,015  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:39:06,015  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:39:06,015  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:39:06,015  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:39:06,015  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:39:06,016  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T13:39:06,018  INFO [main] compactor.Worker: Starting Worker thread
2023-02-15T13:39:06,018  INFO [main] compactor.Worker: [wasabi] Worker 111
2023-02-15T13:39:06,018  INFO [main] compactor.Worker: [wasabi] Worker 117
2023-02-15T13:39:06,018  INFO [main_timeout_executor] compactor.Worker: [wasabi] Worker 281
2023-02-15T13:39:06,021  INFO [main_timeout_executor] compactor.Worker: Processing compaction request id:2,dbname:default,tableName:dp,partName:ds=part1,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:,workerId: labdas-203,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:39:06,021  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.dp	
2023-02-15T13:39:06,022  INFO [main_timeout_executor] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:39:06,022  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7904b44, with PersistenceManager: null will be shutdown
2023-02-15T13:39:06,022  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7904b44, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@63a8a3ae created in the thread with id: 204
2023-02-15T13:39:06,023  INFO [main_timeout_executor] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7904b44
2023-02-15T13:39:06,028  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:39:06,029  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_partitions_by_names : tbl=hive.default.dp	
2023-02-15T13:39:06,035  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:39:06,039  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([57]) with min_open_txn: 57
2023-02-15T13:39:06,053  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Submitting heartbeat task for TXN 57
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactionHeartbeatService$CompactionHeartbeater
2023-02-15T13:39:06,071  INFO [main_timeout_executor] compactor.Worker: Starting MINOR compaction for default.dp.ds=part1, id:2 in txnId=57, lockId=4 (TxnStatus: 'o') with compute stats set to false
2023-02-15T13:39:06,072  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-203-compactor-default.dp.ds=part1' to default queue. (current delta dirs count=3, obsolete delta dirs count=0. TxnIdRange[25,30}]
2023-02-15T13:39:06,072  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:39:06,073  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:39:06,075  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:39:06,077  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:39:06,085  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:39:06,099  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local138453321_0002
2023-02-15T13:39:06,099  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:39:06,140  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:39:06,140  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-203-compactor-default.dp.ds=part1' with jobID=job_local138453321_0002 compaction ID=2
2023-02-15T13:39:06,141  INFO [Thread-171] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:39:06,141  INFO [Thread-171] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:39:06,142  INFO [Thread-171] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:39:06,142  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local138453321_0002_m_000000_0
2023-02-15T13:39:06,142  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:39:06,143  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 1728, deltas: [delta_0000025_0000026, delta_0000027_0000028, delta_0000029_0000030]}
2023-02-15T13:39:06,143  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:39:06,150  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:39:06,150  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local138453321_0002_m_000000_0 is done. And is in the process of committing
2023-02-15T13:39:06,150  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:39:06,150  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local138453321_0002_m_000000_0' done.
2023-02-15T13:39:06,151  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local138453321_0002_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=10755
		FILE: Number of bytes written=2458260
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=435
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=761266176
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:39:06,151  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local138453321_0002_m_000000_0
2023-02-15T13:39:06,151  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local138453321_0002_m_000001_0
2023-02-15T13:39:06,151  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:39:06,151  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 1728, deltas: [delta_0000025_0000026, delta_0000027_0000028, delta_0000029_0000030]}
2023-02-15T13:39:06,151  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:39:06,156  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:39:06,156  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local138453321_0002_m_000001_0 is done. And is in the process of committing
2023-02-15T13:39:06,156  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:39:06,157  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local138453321_0002_m_000001_0' done.
2023-02-15T13:39:06,157  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local138453321_0002_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=13432
		FILE: Number of bytes written=2459540
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=435
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=761266176
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:39:06,157  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local138453321_0002_m_000001_0
2023-02-15T13:39:06,157  INFO [Thread-171] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:39:11,143  INFO [main_timeout_executor] compactor.Worker: Completed MINOR compaction for default.dp.ds=part1 in txnId=57, lockId=4 (TxnStatus: 'o'), marking as compacted.
2023-02-15T13:39:11,149  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Stopping heartbeat task for TXN 57
2023-02-15T13:39:11,149  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Shutting down compaction txn heartbeater instance.
2023-02-15T13:39:11,149  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Compaction txn heartbeater instance is successfully stopped.
2023-02-15T13:39:11,151  INFO [main_timeout_executor] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:57
2023-02-15T13:39:11,157  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([57]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:11,159  INFO [main] compactor.Worker: [wasabi] Worker 163
2023-02-15T13:39:11,159  INFO [main] compactor.Worker: [wasabi] Worker 170
2023-02-15T13:39:13,173  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:39:13,173  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:39:13,173  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:39:13,173  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:39:13,173  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:39:13,173  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:39:13,173  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:39:13,173  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:39:13,173  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:39:13,173  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:39:13,173  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:39:13,173  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:39:13,174  INFO [main] compactor.Cleaner: Starting Cleaner thread
2023-02-15T13:39:13,178  INFO [main] compactor.Cleaner: Cleaning based on min open txn id: 58
2023-02-15T13:39:13,178  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:2,dbname:default,tableName:dp,partName:ds=part1,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:55,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:39:13,179  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:39:13,179  INFO [Cleaner-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:39:13,179  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6614fb10, with PersistenceManager: null will be shutdown
2023-02-15T13:39:13,179  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6614fb10, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@57492d7c created in the thread with id: 260
2023-02-15T13:39:13,180  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6614fb10
2023-02-15T13:39:13,187  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=2 About to remove 3 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_0/dp/ds=part1. [delta_0000025_0000026,delta_0000027_0000028,delta_0000029_0000030]
2023-02-15T13:39:13,189  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:39:15,212  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:39:15,212  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:39:15,212  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:39:15,212  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:39:15,212  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:39:15,212  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:39:15,212  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:39:15,212  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:39:15,212  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:39:15,212  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:39:15,212  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:39:15,212  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:39:15,212  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:39:15,229  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:39:15,230  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:39:15,230  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:39:15,230  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72543547, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@105c6c9e will be shutdown
2023-02-15T13:39:15,230  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72543547, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f1574c created in the thread with id: 1
2023-02-15T13:39:15,232  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:39:15,233  INFO [main] metrics2.JsonFileMetricsReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:39:15,240  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.dp	
2023-02-15T13:39:15,243  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:39:15,243  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.dp	
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.Trash
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.TrashPolicyDefault
2023-02-15T13:39:15,337  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:dp, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_1/dp, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:null, parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:39:15,338  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_1/dp specified for non-external table:dp
2023-02-15T13:39:15,338  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_1/dp
2023-02-15T13:39:15,390  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]) with min_open_txn: 1
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 21
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 22
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 23
2023-02-15T13:39:15,395  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 24
2023-02-15T13:39:15,396  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=dp (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24])
2023-02-15T13:39:15,398  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:39:15,401  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,402  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:39:15,404  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2023-02-15T13:39:15,407  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,407  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2023-02-15T13:39:15,410  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:39:15,412  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,413  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:39:15,415  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2023-02-15T13:39:15,417  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,417  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2023-02-15T13:39:15,419  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:39:15,422  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,422  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:39:15,424  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:39:15,426  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,427  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:39:15,429  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2023-02-15T13:39:15,431  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,431  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:39:15,433  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2023-02-15T13:39:15,435  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,436  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:39:15,438  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2023-02-15T13:39:15,441  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,441  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:39:15,443  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2023-02-15T13:39:15,446  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,446  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:39:15,448  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2023-02-15T13:39:15,451  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,451  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2023-02-15T13:39:15,453  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2023-02-15T13:39:15,457  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,457  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2023-02-15T13:39:15,459  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:13
2023-02-15T13:39:15,461  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,462  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2023-02-15T13:39:15,464  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:14
2023-02-15T13:39:15,466  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,466  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:14
2023-02-15T13:39:15,468  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2023-02-15T13:39:15,471  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,471  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2023-02-15T13:39:15,473  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2023-02-15T13:39:15,476  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,476  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:39:15,478  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2023-02-15T13:39:15,481  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,481  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:39:15,483  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2023-02-15T13:39:15,486  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,486  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:39:15,488  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2023-02-15T13:39:15,490  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,490  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:39:15,493  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2023-02-15T13:39:15,495  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,495  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:39:15,497  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:21
2023-02-15T13:39:15,499  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,499  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:21
2023-02-15T13:39:15,501  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:22
2023-02-15T13:39:15,504  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,504  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:22
2023-02-15T13:39:15,506  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:23
2023-02-15T13:39:15,508  INFO [main] txn.TxnHandler: Removed transactions: ([23]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,508  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:23
2023-02-15T13:39:15,510  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:24
2023-02-15T13:39:15,512  INFO [main] txn.TxnHandler: Removed transactions: ([24]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,512  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:24
2023-02-15T13:39:15,516  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([25]) with min_open_txn: 1
2023-02-15T13:39:15,531  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 25
2023-02-15T13:39:15,531  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=dp (txnIds: [25])
2023-02-15T13:39:15,538  INFO [main] txn.TxnHandler: Removed transactions: ([25]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:15,538  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:25
2023-02-15T13:39:15,547  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:39:15,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:39:15,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:39:15,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:39:15,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:39:15,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:39:15,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:39:15,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:39:15,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:39:15,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:39:15,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:39:15,547  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:39:15,548  INFO [main] compactor.Initiator: Starting Initiator thread
2023-02-15T13:39:15,550  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410755550
2023-02-15T13:39:15,555  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:39:15,555  INFO [Initiator-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:39:15,555  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fd73cae, with PersistenceManager: null will be shutdown
2023-02-15T13:39:15,555  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fd73cae, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@779df49f created in the thread with id: 283
2023-02-15T13:39:15,565  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1fd73cae
2023-02-15T13:39:15,567  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.dp
2023-02-15T13:39:15,595  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:dp, type:MAJOR, runas:rizky, initiatorId:labdas-283)
2023-02-15T13:39:15,602  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410755601
2023-02-15T13:39:17,618  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:39:17,618  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:39:17,618  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:39:17,618  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:39:17,618  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:39:17,618  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:39:17,618  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:39:17,618  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:39:17,618  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:39:17,618  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:39:17,618  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:39:17,618  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:39:17,618  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T13:39:17,620  INFO [main] compactor.Worker: Starting Worker thread
2023-02-15T13:39:17,620  INFO [main] compactor.Worker: [wasabi] Worker 111
2023-02-15T13:39:17,620  INFO [main] compactor.Worker: [wasabi] Worker 117
2023-02-15T13:39:17,620  INFO [main_timeout_executor] compactor.Worker: [wasabi] Worker 281
2023-02-15T13:39:17,623  INFO [main_timeout_executor] compactor.Worker: Processing compaction request id:1,dbname:default,tableName:dp,partName:null,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:,workerId: labdas-294,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:39:17,623  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.dp	
2023-02-15T13:39:17,624  INFO [main_timeout_executor] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:39:17,624  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13282049, with PersistenceManager: null will be shutdown
2023-02-15T13:39:17,624  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13282049, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@709660e5 created in the thread with id: 295
2023-02-15T13:39:17,626  INFO [main_timeout_executor] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@13282049
2023-02-15T13:39:17,629  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:39:17,632  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([26]) with min_open_txn: 26
2023-02-15T13:39:17,639  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Submitting heartbeat task for TXN 26
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactionHeartbeatService$CompactionHeartbeater
2023-02-15T13:39:17,652  INFO [main_timeout_executor] compactor.Worker: Starting MAJOR compaction for default.dp, id:1 in txnId=26, lockId=2 (TxnStatus: 'o') with compute stats set to false
2023-02-15T13:39:17,653  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MAJOR compaction job 'labdas-294-compactor-default.dp' to default queue. (current delta dirs count=2, obsolete delta dirs count=0. TxnIdRange[21,24}]
2023-02-15T13:39:17,653  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:39:17,653  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:39:17,656  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:39:17,658  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:39:17,667  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:39:17,680  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local495152532_0003
2023-02-15T13:39:17,680  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:39:17,716  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:39:17,717  INFO [Thread-248] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:39:17,717  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-294-compactor-default.dp' with jobID=job_local495152532_0003 compaction ID=1
2023-02-15T13:39:17,717  INFO [Thread-248] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:39:17,718  INFO [Thread-248] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:39:17,718  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local495152532_0003_m_000000_0
2023-02-15T13:39:17,720  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:39:17,720  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_1/dp/base_20, bucket: 0, length: 3024, deltas: [delta_0000021_0000022, delta_0000023_0000024]}
2023-02-15T13:39:17,720  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:39:17,725  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:39:17,725  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local495152532_0003_m_000000_0 is done. And is in the process of committing
2023-02-15T13:39:17,725  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:39:17,725  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local495152532_0003_m_000000_0' done.
2023-02-15T13:39:17,725  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local495152532_0003_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=17417
		FILE: Number of bytes written=3689342
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=390
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=768081920
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:39:17,725  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local495152532_0003_m_000000_0
2023-02-15T13:39:17,725  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local495152532_0003_m_000001_0
2023-02-15T13:39:17,726  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:39:17,726  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_1/dp/base_20, bucket: 1, length: 3024, deltas: [delta_0000021_0000022, delta_0000023_0000024]}
2023-02-15T13:39:17,726  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:39:17,729  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:39:17,729  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local495152532_0003_m_000001_0 is done. And is in the process of committing
2023-02-15T13:39:17,730  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:39:17,730  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local495152532_0003_m_000001_0' done.
2023-02-15T13:39:17,730  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local495152532_0003_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=21308
		FILE: Number of bytes written=3690454
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=390
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=768081920
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:39:17,730  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local495152532_0003_m_000001_0
2023-02-15T13:39:17,730  INFO [Thread-248] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:39:22,719  INFO [main_timeout_executor] compactor.Worker: Completed MAJOR compaction for default.dp in txnId=26, lockId=2 (TxnStatus: 'o'), marking as compacted.
2023-02-15T13:39:22,732  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Stopping heartbeat task for TXN 26
2023-02-15T13:39:22,732  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Shutting down compaction txn heartbeater instance.
2023-02-15T13:39:22,733  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Compaction txn heartbeater instance is successfully stopped.
2023-02-15T13:39:22,739  INFO [main_timeout_executor] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:26
2023-02-15T13:39:22,748  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([26]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:22,749  INFO [main] compactor.Worker: [wasabi] Worker 163
2023-02-15T13:39:22,749  INFO [main] compactor.Worker: [wasabi] Worker 170
2023-02-15T13:39:24,762  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:39:24,762  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:39:24,762  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:39:24,762  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:39:24,762  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:39:24,762  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:39:24,762  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:39:24,762  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:39:24,762  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:39:24,762  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:39:24,762  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:39:24,763  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:39:24,763  INFO [main] compactor.Cleaner: Starting Cleaner thread
2023-02-15T13:39:24,768  INFO [main] compactor.Cleaner: Cleaning based on min open txn id: 27
2023-02-15T13:39:24,768  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:1,dbname:default,tableName:dp,partName:null,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:39:24,768  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:39:24,768  INFO [Cleaner-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:39:24,769  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240374bb, with PersistenceManager: null will be shutdown
2023-02-15T13:39:24,769  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240374bb, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6b884db3 created in the thread with id: 340
2023-02-15T13:39:24,770  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@240374bb
2023-02-15T13:39:24,775  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=1 About to remove 3 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_1/dp. [base_20,delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:39:24,779  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:39:26,798  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:39:26,798  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:39:26,798  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:39:26,798  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:39:26,798  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:39:26,798  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:39:26,798  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:39:26,798  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:39:26,798  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:39:26,798  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:39:26,798  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:39:26,798  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:39:26,798  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:39:26,810  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:39:26,812  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:39:26,812  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:39:26,812  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72543547, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f1574c will be shutdown
2023-02-15T13:39:26,812  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@72543547, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77acc95a created in the thread with id: 1
2023-02-15T13:39:26,813  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:39:26,815  INFO [main] metrics2.JsonFileMetricsReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:39:26,821  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.dp	
2023-02-15T13:39:26,824  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:39:26,824  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.dp	
2023-02-15T13:39:26,863  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:dp, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_2/dp, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:39:26,864  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_2/dp specified for non-external table:dp
2023-02-15T13:39:26,864  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_2/dp
2023-02-15T13:39:26,880  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.dp	
2023-02-15T13:39:26,883  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_2/dp/ds=part1
2023-02-15T13:39:26,899  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.dp	
2023-02-15T13:39:26,901  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_2/dp/ds=part2
2023-02-15T13:39:26,922  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.dp	
2023-02-15T13:39:26,924  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_2/dp/ds=part3
2023-02-15T13:39:26,965  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]) with min_open_txn: 1
2023-02-15T13:39:26,968  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:39:26,968  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:39:26,968  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:39:26,968  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:39:26,968  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:39:26,969  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=dp (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
2023-02-15T13:39:26,971  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:39:26,974  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:26,974  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:39:26,976  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2023-02-15T13:39:26,978  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:26,978  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2023-02-15T13:39:26,984  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:39:26,987  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:26,987  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:39:26,989  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2023-02-15T13:39:26,991  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:26,991  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2023-02-15T13:39:26,993  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:39:26,995  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:26,995  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:39:26,997  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:39:27,000  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,000  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:39:27,002  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2023-02-15T13:39:27,004  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,004  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:39:27,006  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2023-02-15T13:39:27,008  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,008  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:39:27,010  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2023-02-15T13:39:27,013  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,013  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:39:27,015  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2023-02-15T13:39:27,017  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,017  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:39:27,019  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2023-02-15T13:39:27,021  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,021  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2023-02-15T13:39:27,023  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2023-02-15T13:39:27,025  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,025  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2023-02-15T13:39:27,027  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:13
2023-02-15T13:39:27,029  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,029  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2023-02-15T13:39:27,031  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:14
2023-02-15T13:39:27,034  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,034  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:14
2023-02-15T13:39:27,036  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2023-02-15T13:39:27,038  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,038  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2023-02-15T13:39:27,040  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2023-02-15T13:39:27,042  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,042  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:39:27,044  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2023-02-15T13:39:27,046  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,046  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:39:27,048  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2023-02-15T13:39:27,051  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,051  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:39:27,053  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2023-02-15T13:39:27,055  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,055  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:39:27,058  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([20]) with min_open_txn: 1
2023-02-15T13:39:27,070  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:39:27,071  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=dp (txnIds: [20])
2023-02-15T13:39:27,077  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:27,077  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:39:27,087  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:39:27,087  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:39:27,087  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:39:27,087  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:39:27,087  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:39:27,087  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:39:27,087  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:39:27,087  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:39:27,087  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:39:27,087  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:39:27,087  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:39:27,087  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:39:27,088  INFO [main] compactor.Initiator: Starting Initiator thread
2023-02-15T13:39:27,090  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410767089
2023-02-15T13:39:27,096  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:39:27,096  INFO [Initiator-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:39:27,096  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e90f44f, with PersistenceManager: null will be shutdown
2023-02-15T13:39:27,096  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e90f44f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7b96c50a created in the thread with id: 401
2023-02-15T13:39:27,105  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e90f44f
2023-02-15T13:39:27,106  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.dp.ds=part1
2023-02-15T13:39:27,116  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.dp.ds=part2
2023-02-15T13:39:27,116  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.dp.ds=part3
2023-02-15T13:39:27,150  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:dp, partitionname:ds=part2, type:MINOR, runas:rizky, initiatorId:labdas-401)
2023-02-15T13:39:27,169  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:dp, partitionname:ds=part3, type:MAJOR, runas:rizky, initiatorId:labdas-401)
2023-02-15T13:39:27,173  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410767172
2023-02-15T13:39:29,190  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:39:29,190  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:39:29,190  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:39:29,190  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:39:29,190  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:39:29,190  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:39:29,190  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:39:29,190  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:39:29,190  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:39:29,190  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:39:29,190  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:39:29,190  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:39:29,190  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T13:39:29,192  INFO [main] compactor.Worker: Starting Worker thread
2023-02-15T13:39:29,192  INFO [main] compactor.Worker: [wasabi] Worker 111
2023-02-15T13:39:29,192  INFO [main] compactor.Worker: [wasabi] Worker 117
2023-02-15T13:39:29,192  INFO [main_timeout_executor] compactor.Worker: [wasabi] Worker 281
2023-02-15T13:39:29,195  INFO [main_timeout_executor] compactor.Worker: Processing compaction request id:1,dbname:default,tableName:dp,partName:ds=part2,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:,workerId: labdas-433,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:39:29,195  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.dp	
2023-02-15T13:39:29,195  INFO [main_timeout_executor] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:39:29,195  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7146453f, with PersistenceManager: null will be shutdown
2023-02-15T13:39:29,195  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7146453f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@9988ffe created in the thread with id: 434
2023-02-15T13:39:29,197  INFO [main_timeout_executor] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7146453f
2023-02-15T13:39:29,200  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:39:29,201  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_partitions_by_names : tbl=hive.default.dp	
2023-02-15T13:39:29,206  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:39:29,213  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([21]) with min_open_txn: 21
2023-02-15T13:39:29,222  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Submitting heartbeat task for TXN 21
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactionHeartbeatService$CompactionHeartbeater
2023-02-15T13:39:29,245  INFO [main_timeout_executor] compactor.Worker: Starting MINOR compaction for default.dp.ds=part2, id:1 in txnId=21, lockId=2 (TxnStatus: 'o') with compute stats set to false
2023-02-15T13:39:29,246  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-433-compactor-default.dp.ds=part2' to default queue. (current delta dirs count=3, obsolete delta dirs count=0. TxnIdRange[6,11}]
2023-02-15T13:39:29,247  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:39:29,248  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:39:29,254  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:39:29,258  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:39:29,279  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:39:29,305  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local1832685853_0004
2023-02-15T13:39:29,305  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:39:29,340  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:39:29,340  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-433-compactor-default.dp.ds=part2' with jobID=job_local1832685853_0004 compaction ID=1
2023-02-15T13:39:29,341  INFO [Thread-380] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:39:29,341  INFO [Thread-380] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:39:29,342  INFO [Thread-380] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:39:29,342  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1832685853_0004_m_000000_0
2023-02-15T13:39:29,342  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:39:29,342  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 432, deltas: [delta_0000006_0000007, delta_0000008_0000009, delta_0000010_0000011]}
2023-02-15T13:39:29,342  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:39:29,349  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:39:29,349  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1832685853_0004_m_000000_0 is done. And is in the process of committing
2023-02-15T13:39:29,350  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:39:29,350  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1832685853_0004_m_000000_0' done.
2023-02-15T13:39:29,350  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1832685853_0004_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=22775
		FILE: Number of bytes written=4934190
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=435
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=783286272
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:39:29,350  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1832685853_0004_m_000000_0
2023-02-15T13:39:29,350  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1832685853_0004_m_000001_0
2023-02-15T13:39:29,350  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:39:29,350  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 432, deltas: [delta_0000006_0000007, delta_0000008_0000009, delta_0000010_0000011]}
2023-02-15T13:39:29,350  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:39:29,354  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:39:29,354  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1832685853_0004_m_000001_0 is done. And is in the process of committing
2023-02-15T13:39:29,355  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:39:29,355  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1832685853_0004_m_000001_0' done.
2023-02-15T13:39:29,355  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1832685853_0004_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=24148
		FILE: Number of bytes written=4934526
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=435
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=783286272
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:39:29,355  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1832685853_0004_m_000001_0
2023-02-15T13:39:29,355  INFO [Thread-380] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:39:34,343  INFO [main_timeout_executor] compactor.Worker: Completed MINOR compaction for default.dp.ds=part2 in txnId=21, lockId=2 (TxnStatus: 'o'), marking as compacted.
2023-02-15T13:39:34,350  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Stopping heartbeat task for TXN 21
2023-02-15T13:39:34,350  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Shutting down compaction txn heartbeater instance.
2023-02-15T13:39:34,350  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Compaction txn heartbeater instance is successfully stopped.
2023-02-15T13:39:34,356  INFO [main_timeout_executor] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:21
2023-02-15T13:39:34,363  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:34,364  INFO [main] compactor.Worker: [wasabi] Worker 163
2023-02-15T13:39:34,364  INFO [main] compactor.Worker: [wasabi] Worker 170
2023-02-15T13:39:34,374  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:39:34,374  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:39:34,374  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:39:34,374  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:39:34,374  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:39:34,374  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:39:34,374  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:39:34,374  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:39:34,374  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:39:34,374  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:39:34,374  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:39:34,374  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:39:34,374  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T13:39:34,375  INFO [main] compactor.Worker: Starting Worker thread
2023-02-15T13:39:34,375  INFO [main] compactor.Worker: [wasabi] Worker 111
2023-02-15T13:39:34,375  INFO [main] compactor.Worker: [wasabi] Worker 117
2023-02-15T13:39:34,375  INFO [main_timeout_executor] compactor.Worker: [wasabi] Worker 281
2023-02-15T13:39:34,377  INFO [main_timeout_executor] compactor.Worker: Processing compaction request id:2,dbname:default,tableName:dp,partName:ds=part3,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:,workerId: labdas-487,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:39:34,377  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.dp	
2023-02-15T13:39:34,378  INFO [main_timeout_executor] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:39:34,378  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@728d7bdd, with PersistenceManager: null will be shutdown
2023-02-15T13:39:34,378  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@728d7bdd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@463164d2 created in the thread with id: 488
2023-02-15T13:39:34,380  INFO [main_timeout_executor] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@728d7bdd
2023-02-15T13:39:34,384  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:39:34,384  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_partitions_by_names : tbl=hive.default.dp	
2023-02-15T13:39:34,388  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:39:34,391  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([22]) with min_open_txn: 22
2023-02-15T13:39:34,398  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Submitting heartbeat task for TXN 22
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactionHeartbeatService$CompactionHeartbeater
2023-02-15T13:39:34,414  INFO [main_timeout_executor] compactor.Worker: Starting MAJOR compaction for default.dp.ds=part3, id:2 in txnId=22, lockId=3 (TxnStatus: 'o') with compute stats set to false
2023-02-15T13:39:34,414  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MAJOR compaction job 'labdas-487-compactor-default.dp.ds=part3' to default queue. (current delta dirs count=4, obsolete delta dirs count=0. TxnIdRange[12,19}]
2023-02-15T13:39:34,415  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:39:34,415  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:39:34,417  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:39:34,419  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:39:34,425  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:39:34,439  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local1014182612_0005
2023-02-15T13:39:34,439  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:39:34,475  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:39:34,475  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-487-compactor-default.dp.ds=part3' with jobID=job_local1014182612_0005 compaction ID=2
2023-02-15T13:39:34,475  INFO [Thread-429] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:39:34,475  INFO [Thread-429] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:39:34,476  INFO [Thread-429] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:39:34,476  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1014182612_0005_m_000000_0
2023-02-15T13:39:34,476  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:39:34,476  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 5400, deltas: [delta_0000012_0000013, delta_0000014_0000015, delta_0000016_0000017, delta_0000018_0000019]}
2023-02-15T13:39:34,476  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:39:34,481  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:39:34,481  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1014182612_0005_m_000000_0 is done. And is in the process of committing
2023-02-15T13:39:34,482  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:39:34,482  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1014182612_0005_m_000000_0' done.
2023-02-15T13:39:34,482  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1014182612_0005_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=30885
		FILE: Number of bytes written=6164837
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=548
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=783286272
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:39:34,482  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1014182612_0005_m_000000_0
2023-02-15T13:39:34,482  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1014182612_0005_m_000001_0
2023-02-15T13:39:34,482  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:39:34,482  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 5400, deltas: [delta_0000012_0000013, delta_0000014_0000015, delta_0000016_0000017, delta_0000018_0000019]}
2023-02-15T13:39:34,482  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:39:34,485  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:39:34,485  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1014182612_0005_m_000001_0 is done. And is in the process of committing
2023-02-15T13:39:34,485  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:39:34,485  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1014182612_0005_m_000001_0' done.
2023-02-15T13:39:34,485  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1014182612_0005_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=36996
		FILE: Number of bytes written=6166837
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=548
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=783286272
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:39:34,485  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1014182612_0005_m_000001_0
2023-02-15T13:39:34,485  INFO [Thread-429] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:39:39,477  INFO [main_timeout_executor] compactor.Worker: Completed MAJOR compaction for default.dp.ds=part3 in txnId=22, lockId=3 (TxnStatus: 'o'), marking as compacted.
2023-02-15T13:39:39,480  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Stopping heartbeat task for TXN 22
2023-02-15T13:39:39,480  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Shutting down compaction txn heartbeater instance.
2023-02-15T13:39:39,480  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Compaction txn heartbeater instance is successfully stopped.
2023-02-15T13:39:39,486  INFO [main_timeout_executor] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:22
2023-02-15T13:39:39,499  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:39:39,500  INFO [main] compactor.Worker: [wasabi] Worker 163
2023-02-15T13:39:39,500  INFO [main] compactor.Worker: [wasabi] Worker 170
2023-02-15T13:39:41,513  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:39:41,513  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:39:41,513  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:39:41,513  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:39:41,513  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:39:41,513  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:39:41,513  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:39:41,514  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:39:41,514  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:39:41,514  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:39:41,514  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:39:41,514  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:39:41,514  INFO [main] compactor.Cleaner: Starting Cleaner thread
2023-02-15T13:39:41,520  INFO [main] compactor.Cleaner: Cleaning based on min open txn id: 23
2023-02-15T13:39:41,520  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:1,dbname:default,tableName:dp,partName:ds=part2,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:20,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:39:41,520  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:39:41,521  INFO [Cleaner-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:39:41,521  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61f72d2e, with PersistenceManager: null will be shutdown
2023-02-15T13:39:41,521  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61f72d2e, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49e6e8aa created in the thread with id: 536
2023-02-15T13:39:41,522  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@61f72d2e
2023-02-15T13:39:41,542  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=1 About to remove 3 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_2/dp/ds=part2. [delta_0000006_0000007,delta_0000008_0000009,delta_0000010_0000011]
2023-02-15T13:39:41,547  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:39:41,548  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:2,dbname:default,tableName:dp,partName:ds=part3,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:20,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:39:41,551  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=2 About to remove 4 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_2/dp/ds=part3. [delta_0000012_0000013,delta_0000014_0000015,delta_0000016_0000017,delta_0000018_0000019]
2023-02-15T13:39:41,552  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:39:41,563  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:39:41,563  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:39:41,563  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:39:41,563  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:39:41,563  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:39:41,563  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:39:41,563  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:39:41,563  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:39:41,563  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:39:41,563  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:39:41,563  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:39:41,563  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:39:41,563  INFO [main] compactor.Cleaner: Starting Cleaner thread
2023-02-15T13:39:43,594  INFO [shutdown-hook-0] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T13:39:43,595  INFO [shutdown-hook-0] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2023-02-15T13:39:43,596  INFO [shutdown-hook-0] compactor.CompactionHeartbeatService: Shutting down compaction txn heartbeater service.
2023-02-15T13:39:43,598  INFO [shutdown-hook-0] compactor.CompactionHeartbeatService: Compaction txn heartbeater service is successfully stopped.
