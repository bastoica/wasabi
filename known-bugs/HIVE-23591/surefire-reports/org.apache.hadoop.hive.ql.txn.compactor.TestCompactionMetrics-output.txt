SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/rizky/.m2/repository/org/apache/logging/log4j/log4j-slf4j-impl/2.18.0/log4j-slf4j-impl-2.18.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/rizky/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DEBUG StatusLogger Using ShutdownCallbackRegistry class org.apache.logging.log4j.core.util.DefaultShutdownCallbackRegistry
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactorTest
DEBUG StatusLogger Took 0.036295 seconds to load 266 plugins from sun.misc.Launcher$AppClassLoader@677327b6
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Converter' found 48 plugins
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger Starting LoggerContext[name=677327b6, org.apache.logging.log4j.core.LoggerContext@c05fddc]...
DEBUG StatusLogger Reconfiguration started for context[name=677327b6] at URI null (org.apache.logging.log4j.core.LoggerContext@c05fddc) with optional ClassLoader: null
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'ConfigurationFactory' found 6 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Using configurationFactory org.apache.logging.log4j.core.config.ConfigurationFactory$Factory@7fb4f2a9
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Apache Log4j Core 2.18.0 initializing configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@3bcd05cb
INFO StatusLogger Scanning for classes in '/home/rizky/hive/ql/target/test-classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestLog4j2Appenders matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.TestSyslogInputFormat matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/rizky/hive/ql/target/classes/org/apache/hadoop/hive/ql/log' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$EventCounts matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender$NameFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppenderForTest$TestFilter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter$1 matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.NullAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HushableRandomAccessFileAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogSerDe matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogParser matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat$Location matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogStorageHandler matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.syslog.SyslogInputFormat matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PidFilePatternConverter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.LogDivertAppender matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.HiveEventCounter matches criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.SlidingFilenameRolloverStrategy matches criteria annotated with @Plugin
INFO StatusLogger Scanning for classes in '/home/rizky/hive/common/target/hive-common-4.0.0-SNAPSHOT.jar' matching criteria annotated with @Plugin
DEBUG StatusLogger Checking to see if class org.apache.hadoop.hive.ql.log.PerfLogger matches criteria annotated with @Plugin
DEBUG StatusLogger Took 0.007446 seconds to load 7 plugins from package org.apache.hadoop.hive.ql.log
DEBUG StatusLogger PluginManager 'Core' found 141 plugins
DEBUG StatusLogger PluginManager 'Level' found 0 plugins
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
TRACE StatusLogger TypeConverterRegistry initializing.
DEBUG StatusLogger PluginManager 'TypeConverter' found 26 plugins
DEBUG StatusLogger createProperty(name="hive.log.file", value="hive.log", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.dir", value="${sys:test.tmp.dir}/log", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.root.logger", value="DRFA", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.log.level", value="DEBUG", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=property, class=org.apache.logging.log4j.core.config.Property].
DEBUG StatusLogger createProperty(name="hive.test.console.log.level", value="INFO", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=properties, class=org.apache.logging.log4j.core.config.PropertiesPlugin].
DEBUG StatusLogger configureSubstitutor(={hive.log.file=hive.log, hive.log.dir=/home/rizky/hive/ql/target/tmp/log, hive.root.logger=DRFA, hive.log.level=DEBUG, hive.test.console.log.level=INFO}, Configuration(HiveLog4j2Test))
DEBUG StatusLogger PluginManager 'Lookup' found 17 plugins
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.hadoop.ipc", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.security", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.hdfs", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.hadoop.hdfs.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.metrics2", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.mortbay", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.yarn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.hadoop.yarn.server", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.tez", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="ERROR", levelAndRefs="null", name="org.apache.hadoop.conf.Configuration", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.zookeeper", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.server.ServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.server.NIOServerCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.ClientCnxn", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.ClientCnxnSocket", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.zookeeper.ClientCnxnSocketNIO", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="ERROR", levelAndRefs="null", name="DataNucleus", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="ERROR", levelAndRefs="null", name="Datastore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="ERROR", levelAndRefs="null", name="JPOX", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.hive.ql.exec.Operator", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.hive.serde2.lazy", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.hadoop.hive.metastore.ObjectStore", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.calcite.plan.RelOptPlanner", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="com.amazonaws", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="INFO", levelAndRefs="null", name="org.apache.http", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.apache.thrift", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="org.eclipse.jetty", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="WARN", levelAndRefs="null", name="BlockStateChange", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="DEBUG", levelAndRefs="null", name="org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=filter, class=org.apache.logging.log4j.core.filter.MarkerFilter].
ERROR StatusLogger MarkerFilter contains an invalid element or attribute "onMismatch"
DEBUG StatusLogger createFilter(marker="FULL_PLAN", onMatch="DENY", onMismatch="NEUTRAL")
DEBUG StatusLogger Building Plugin[name=logger, class=org.apache.logging.log4j.core.config.LoggerConfig].
DEBUG StatusLogger LoggerConfig$Builder(additivity="null", level="OFF", levelAndRefs="null", name="org.apache.hadoop.hive.ql.optimizer.calcite.RuleEventLogger", includeLocation="null", ={}, ={}, Configuration(HiveLog4j2Test), MarkerFilter(FULL_PLAN))
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="console", level="INFO", Filter=null)
DEBUG StatusLogger Building Plugin[name=AppenderRef, class=org.apache.logging.log4j.core.config.AppenderRef].
DEBUG StatusLogger createAppenderRef(ref="DRFA", level="null", Filter=null)
DEBUG StatusLogger Building Plugin[name=root, class=org.apache.logging.log4j.core.config.LoggerConfig$RootLogger].
DEBUG StatusLogger LoggerConfig$RootLogger$Builder(additivity="null", level="DEBUG", levelAndRefs="null", includeLocation="null", ={console, DRFA}, ={}, Configuration(HiveLog4j2Test), Filter=null)
DEBUG StatusLogger Building Plugin[name=loggers, class=org.apache.logging.log4j.core.config.LoggersPlugin].
DEBUG StatusLogger createLoggers(={org.apache.hadoop.ipc, org.apache.hadoop.security, org.apache.hadoop.hdfs, org.apache.hadoop.hdfs.server, org.apache.hadoop.metrics2, org.mortbay, org.apache.hadoop.yarn, org.apache.hadoop.yarn.server, org.apache.tez, org.apache.hadoop.conf.Configuration, org.apache.zookeeper, org.apache.zookeeper.server.ServerCnxn, org.apache.zookeeper.server.NIOServerCnxn, org.apache.zookeeper.ClientCnxn, org.apache.zookeeper.ClientCnxnSocket, org.apache.zookeeper.ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, org.apache.hadoop.hive.ql.exec.Operator, org.apache.hadoop.hive.serde2.lazy, org.apache.hadoop.hive.metastore.ObjectStore, org.apache.calcite.plan.RelOptPlanner, com.amazonaws, org.apache.http, org.apache.thrift, org.eclipse.jetty, BlockStateChange, org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer, org.apache.hadoop.hive.ql.optimizer.calcite.RuleEventLogger, root})
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger PluginManager 'Converter' found 48 plugins
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.ConsoleAppender].
DEBUG StatusLogger ConsoleAppender$Builder(target="SYSTEM_ERR", follow="null", direct="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="console", Configuration(HiveLog4j2Test), Filter=null, ={})
DEBUG StatusLogger Starting OutputStreamManager SYSTEM_ERR.false.false
DEBUG StatusLogger Building Plugin[name=layout, class=org.apache.logging.log4j.core.layout.PatternLayout].
DEBUG StatusLogger PatternLayout$Builder(pattern="%d{ISO8601} %5p [%t] %c{2}: %m%n", PatternSelector=null, Configuration(HiveLog4j2Test), Replace=null, charset="null", alwaysWriteExceptions="null", disableAnsi="null", noConsoleNoAnsi="null", header="null", footer="null")
DEBUG StatusLogger Building Plugin[name=TimeBasedTriggeringPolicy, class=org.apache.logging.log4j.core.appender.rolling.TimeBasedTriggeringPolicy].
DEBUG StatusLogger TimeBasedTriggeringPolicy$Builder(interval="1", modulate="true", maxRandomDelay="null")
DEBUG StatusLogger Building Plugin[name=Policies, class=org.apache.logging.log4j.core.appender.rolling.CompositeTriggeringPolicy].
DEBUG StatusLogger createPolicy(={TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)})
DEBUG StatusLogger Building Plugin[name=DefaultRolloverStrategy, class=org.apache.logging.log4j.core.appender.rolling.DefaultRolloverStrategy].
DEBUG StatusLogger DefaultRolloverStrategy$Builder(max="30", min="null", fileIndex="null", compressionLevel="null", ={}, stopCustomActionsOnError="null", tempCompressedFilePattern="null", Configuration(HiveLog4j2Test))
DEBUG StatusLogger Building Plugin[name=appender, class=org.apache.logging.log4j.core.appender.RollingRandomAccessFileAppender].
DEBUG StatusLogger RollingRandomAccessFileAppender$Builder(fileName="/home/rizky/hive/ql/target/tmp/log/hive.log", filePattern="/home/rizky/hive/ql/target/tmp/log/hive.log.%d{yyyy-MM-dd}", append="null", Policies(CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])), DefaultRolloverStrategy(DefaultRolloverStrategy(min=1, max=30, useMax=true)), advertise="null", advertiseURI="null", filePermissions="null", fileOwner="null", fileGroup="null", bufferedIo="null", bufferSize="null", immediateFlush="null", ignoreExceptions="null", PatternLayout(%d{ISO8601} %5p [%t] %c{2}: %m%n), name="DRFA", Configuration(HiveLog4j2Test), Filter=null, ={})
TRACE StatusLogger RandomAccessFile /home/rizky/hive/ql/target/tmp/log/hive.log seek to 1919159094
DEBUG StatusLogger Starting RollingRandomAccessFileManager /home/rizky/hive/ql/target/tmp/log/hive.log
DEBUG StatusLogger PluginManager 'FileConverter' found 3 plugins
DEBUG StatusLogger Setting prev file time to 2023-02-15T13:33:26.250-0800
DEBUG StatusLogger Initializing triggering policy CompositeTriggeringPolicy(policies=[TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)])
DEBUG StatusLogger Initializing triggering policy TimeBasedTriggeringPolicy(nextRolloverMillis=0, interval=1, modulate=true)
TRACE StatusLogger PatternProcessor.getNextTime returning 2023/02/16-00:00:00.000, nextFileTime=2023/02/15-00:00:00.000, prevFileTime=1969/12/31-16:00:00.000, current=2023/02/15-13:33:27.136, freq=DAILY
TRACE StatusLogger PatternProcessor.getNextTime returning 2023/02/16-00:00:00.000, nextFileTime=2023/02/15-00:00:00.000, prevFileTime=2023/02/15-00:00:00.000, current=2023/02/15-13:33:27.136, freq=DAILY
DEBUG StatusLogger Building Plugin[name=appenders, class=org.apache.logging.log4j.core.config.AppendersPlugin].
DEBUG StatusLogger createAppenders(={console, DRFA})
DEBUG StatusLogger Configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@3bcd05cb initialized
DEBUG StatusLogger Starting configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@3bcd05cb
DEBUG StatusLogger Started configuration org.apache.logging.log4j.core.config.properties.PropertiesConfiguration@3bcd05cb OK.
TRACE StatusLogger Stopping org.apache.logging.log4j.core.config.DefaultConfiguration@7d9d0818...
TRACE StatusLogger DefaultConfiguration notified 1 ReliabilityStrategies that config will be stopped.
TRACE StatusLogger DefaultConfiguration stopping root LoggerConfig.
TRACE StatusLogger DefaultConfiguration notifying ReliabilityStrategies that appenders will be stopped.
TRACE StatusLogger DefaultConfiguration stopping remaining Appenders.
DEBUG StatusLogger Shutting down OutputStreamManager SYSTEM_OUT.false.false-1
DEBUG StatusLogger OutputStream closed
DEBUG StatusLogger Shut down OutputStreamManager SYSTEM_OUT.false.false-1, all resources released: true
DEBUG StatusLogger Appender DefaultConsole-1 stopped with status true
TRACE StatusLogger DefaultConfiguration stopped 1 remaining Appenders.
TRACE StatusLogger DefaultConfiguration cleaning Appenders from 1 LoggerConfigs.
DEBUG StatusLogger Stopped org.apache.logging.log4j.core.config.DefaultConfiguration@7d9d0818 OK
TRACE StatusLogger Reregistering MBeans after reconfigure. Selector=org.apache.logging.log4j.core.selector.ClassLoaderContextSelector@225129c
TRACE StatusLogger Reregistering context (1/1): '677327b6' org.apache.logging.log4j.core.LoggerContext@c05fddc
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=StatusLogger'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=ContextSelector'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=Loggers,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=Appenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=AsyncAppenders,name=*'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=AsyncLoggerRingBuffer'
TRACE StatusLogger Unregistering but no MBeans found matching 'org.apache.logging.log4j2:type=677327b6,component=Loggers,name=*,subtype=RingBuffer'
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=StatusLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=ContextSelector
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.tez
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=com.amazonaws
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.thrift
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.eclipse.jetty
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=BlockStateChange
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.metrics2
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.ClientCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.security
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=JPOX
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.SharedWorkOptimizer
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.yarn.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.conf.Configuration
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.yarn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocketNIO
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.server.ServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hdfs
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hdfs.server
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.serde2.lazy
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.ClientCnxnSocket
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.mortbay
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.ql.optimizer.calcite.RuleEventLogger
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.http
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.ql.exec.Operator
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=DataNucleus
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=Datastore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.hive.metastore.ObjectStore
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.hadoop.ipc
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.zookeeper.server.NIOServerCnxn
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Loggers,name=org.apache.calcite.plan.RelOptPlanner
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Appenders,name=console
DEBUG StatusLogger Registering MBean org.apache.logging.log4j2:type=677327b6,component=Appenders,name=DRFA
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Using DummyNanoClock for nanosecond timestamps.
DEBUG StatusLogger Reconfiguration complete for context[name=677327b6] at URI /home/rizky/hive/ql/target/testconf/hive-log4j2.properties (org.apache.logging.log4j.core.LoggerContext@c05fddc) with optional ClassLoader: null
DEBUG StatusLogger Shutdown hook enabled. Registering a new one.
DEBUG StatusLogger LoggerContext[name=677327b6, org.apache.logging.log4j.core.LoggerContext@c05fddc] started OK.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.common.util.HiveVersionInfo
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.conf.Configuration
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.conf.Configuration
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.conf.HiveConf
2023-02-15T13:33:27,176  INFO [main] conf.HiveConf: Found configuration file file:/home/rizky/hive/ql/target/testconf/hive-site.xml
DEBUG StatusLogger AsyncLogger.ThreadNameStrategy=UNCACHED (user specified null, default is UNCACHED)
TRACE StatusLogger Using default SystemClock for timestamps.
DEBUG StatusLogger org.apache.logging.log4j.core.util.SystemClock does not support precise timestamps.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.conf.SystemVariables
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.conf.valcoersion.JavaIOTmpdirVariableCoercion
log4j: Trying to find [log4j.xml] using context classloader sun.misc.Launcher$AppClassLoader@677327b6.
log4j: Trying to find [log4j.xml] using sun.misc.Launcher$AppClassLoader@677327b6 class loader.
log4j: Trying to find [log4j.xml] using ClassLoader.getSystemResource().
log4j: Trying to find [log4j.properties] using context classloader sun.misc.Launcher$AppClassLoader@677327b6.
log4j: Trying to find [log4j.properties] using sun.misc.Launcher$AppClassLoader@677327b6 class loader.
log4j: Trying to find [log4j.properties] using ClassLoader.getSystemResource().
log4j: Could not find resource: [null].
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.FileSystem
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.FileUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.common.HiveCompat
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.JobConf
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.lib.output.FileOutputFormat
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.Credentials
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.UserGroupInformation
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.impl.MetricsSystemImpl
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.lib.Interns
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.lib.MetricsSourceBuilder
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.lib.MutableMetricsFactory
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.conf.HiveConfUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.Shell
2023-02-15T13:33:27,369  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:33:27,369  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:33:27,369  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:33:27,369  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:33:27,369  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:33:27,369  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:33:27,369  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:33:27,370  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:33:27,370  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:33:27,370  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:33:27,370  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:33:27,370  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.SecurityUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.authentication.util.KerberosName
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.HadoopKerberosName
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.Groups
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.NativeCodeLoader
2023-02-15T13:33:27,385  WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.PerformanceAdvisory
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.security.ShellBasedUnixGroupsMapping
log4j:WARN No appenders could be found for logger (org.apache.htrace.core.Tracer).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.HarFileSystem
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hdfs.DistributedFileSystem
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hdfs.web.WebHdfsFileSystem
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.ShutdownHookManager
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.conf.MetastoreConf
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.TestTxnDbUtil
2023-02-15T13:33:27,438  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.calcite.avatica.remote.Driver
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.DatabaseProduct
2023-02-15T13:33:27,722  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.MetaStoreSchemaInfoFactory
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.MetastoreVersionInfo
2023-02-15T13:33:27,727  INFO [main] utils.TestTxnDbUtil: Reinitializing the metastore db with hive-schema-4.0.0.derby.sql on the database jdbc:derby:memory:/home/rizky/hive/ql/target/tmp/junit_metastore_db;create=true
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveMetaStoreClient
2023-02-15T13:33:28,077  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveMetaStore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HMSHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HMSHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.RetryingHMSHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.MetaStoreInit
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.metrics.PerfLogger
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.metrics.Metrics
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.Deadline
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.MetaStoreServerUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.JavaUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveAlterHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.Warehouse
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.ReplChangeManager
2023-02-15T13:33:28,168  INFO [main] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.ObjectStore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.PersistenceManagerProvider
2023-02-15T13:33:28,187  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:33:28,189  INFO [main] metastore.PersistenceManagerProvider: Current pmf properties are uninitialized
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.datasource.HikariCPDataSourceProvider
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.datasource.DbCPDataSourceProvider
2023-02-15T13:33:28,194  INFO [main] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: objectstore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.HikariConfig
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.HikariDataSource
2023-02-15T13:33:28,200  WARN [main] hikari.HikariConfig: objectstore - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T13:33:28,203  INFO [main] hikari.HikariDataSource: objectstore - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.util.DriverDataSource
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.HikariPool
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.util.ConcurrentBag
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.PoolEntry
2023-02-15T13:33:28,210  INFO [main] pool.PoolBase: objectstore - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T13:33:28,212  INFO [main] hikari.HikariDataSource: objectstore - Start completed.
2023-02-15T13:33:28,212  INFO [main] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 2, name: objectstore-secondary
2023-02-15T13:33:28,212  WARN [main] hikari.HikariConfig: objectstore-secondary - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T13:33:28,213  INFO [main] hikari.HikariDataSource: objectstore-secondary - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.HikariPool
2023-02-15T13:33:28,214  INFO [main] pool.PoolBase: objectstore-secondary - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T13:33:28,214  INFO [main] hikari.HikariDataSource: objectstore-secondary - Start completed.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.ProxyLeakTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.ProxyConnection
2023-02-15T13:33:28,421  INFO [main] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2023-02-15T13:33:28,421  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: null will be shutdown
2023-02-15T13:33:28,435  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@d919544 created in the thread with id: 1
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.MetaStoreDirectSql
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.tools.SQLGenerator
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.PartFilterExprUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.DirectSqlUpdateStat
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.MetastoreDirectSqlUtils
2023-02-15T13:33:29,290  INFO [main] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b
2023-02-15T13:33:29,296  INFO [main] metastore.HMSHandler: Setting location of default catalog, as it hasn't been done after upgrade
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.shims.ShimLoader
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.VersionInfo
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.ThreadUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.io.IOUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.shims.HadoopShimsSecure
2023-02-15T13:33:29,316  INFO [main] metastore.HMSHandler: Started creating a default database with name: default
2023-02-15T13:33:29,335  INFO [main] metastore.HMSHandler: Successfully created a default database with name: default
2023-02-15T13:33:29,342  INFO [main] metastore.HMSHandler: Added admin role in metastore
2023-02-15T13:33:29,343  INFO [main] metastore.HMSHandler: Added public role in metastore
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.MetaStoreUtils
2023-02-15T13:33:29,373  INFO [main] metastore.HMSHandler: Added hive_admin_user to admin role
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.TransactionalValidationListener
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.leader.HostLeaderElection
2023-02-15T13:33:29,380  INFO [main] leader.HostLeaderElection: metastore.housekeeping.leader.hostname is empty. Start all the housekeeping threads.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.ThreadPool
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.metrics.AcidMetricLogger
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.metrics.AcidMetricService
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.events.EventCleanerTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.txn.TxnUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.txn.TxnHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler
2023-02-15T13:33:29,394  INFO [main] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: txnhandler
2023-02-15T13:33:29,395  WARN [main] hikari.HikariConfig: txnhandler - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T13:33:29,396  INFO [main] hikari.HikariDataSource: txnhandler - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.HikariPool
2023-02-15T13:33:29,397  INFO [main] pool.PoolBase: txnhandler - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T13:33:29,397  INFO [main] hikari.HikariDataSource: txnhandler - Start completed.
2023-02-15T13:33:29,397  INFO [main] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 4, name: mutex
2023-02-15T13:33:29,398  WARN [main] hikari.HikariConfig: mutex - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T13:33:29,398  INFO [main] hikari.HikariDataSource: mutex - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.HikariPool
2023-02-15T13:33:29,399  INFO [main] pool.PoolBase: mutex - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T13:33:29,399  INFO [main] hikari.HikariDataSource: mutex - Start completed.
2023-02-15T13:33:29,401  INFO [main] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 5, name: compactor
2023-02-15T13:33:29,401  WARN [main] hikari.HikariConfig: compactor - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T13:33:29,402  INFO [main] hikari.HikariDataSource: compactor - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.HikariPool
2023-02-15T13:33:29,402  INFO [main] pool.PoolBase: compactor - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T13:33:29,402  INFO [main] hikari.HikariDataSource: compactor - Start completed.
2023-02-15T13:33:29,403  INFO [main] metastore.HiveMetaStore: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricLogger service.
2023-02-15T13:33:29,403  INFO [main] metastore.HiveMetaStore: Scheduling for org.apache.hadoop.hive.metastore.HiveProtoEventsCleanerTask service.
2023-02-15T13:33:29,403  INFO [main] metastore.HiveMetaStore: Scheduling for org.apache.hadoop.hive.metastore.metrics.AcidMetricService service.
2023-02-15T13:33:29,403  INFO [main] metastore.HiveMetaStore: Scheduling for org.apache.hadoop.hive.metastore.ReplicationMetricsMaintTask service.
2023-02-15T13:33:29,403  INFO [main] metastore.HiveMetaStore: Scheduling for org.apache.hadoop.hive.metastore.ScheduledQueryExecutionsMaintTask service.
2023-02-15T13:33:29,403  INFO [main] metastore.HiveMetaStore: Scheduling for org.apache.hadoop.hive.metastore.RuntimeStatsCleanerTask service.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.FileMetadataManager
2023-02-15T13:33:29,404  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.dataconnector.DataConnectorProviderFactory
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.permission.FsPermission
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.io.nativeio.NativeIO
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.FileUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.codahale.metrics.jvm.BufferPoolMetricSet
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.codahale.metrics.ScheduledReporter
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.metrics.JsonReporter
2023-02-15T13:33:29,476  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.codahale.metrics.JmxReporter
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.codahale.metrics.DefaultObjectNameFactory
2023-02-15T13:33:29,574  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:33:29,574  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:33:29,575  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:33:29,575  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:33:29,575  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:33:29,575  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:33:29,575  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:33:29,575  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:33:29,575  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:33:29,575  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:33:29,575  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:33:29,575  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:33:29,575  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:33:29,596  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:33:29,598  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:33:29,598  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:33:29,598  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@d919544 will be shutdown
2023-02-15T13:33:29,598  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49986178 created in the thread with id: 1
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HMSMetricsListener
2023-02-15T13:33:29,604  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:33:29,607  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.ServerUtils
2023-02-15T13:33:29,633  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:33:29,633  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:33:29,633  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:33:29,633  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:33:29,633  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:33:29,633  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:33:29,633  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:33:29,634  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:33:29,634  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:33:29,634  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:33:29,634  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:33:29,634  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:33:29,634  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:33:29,638  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:33:29,640  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:33:29,640  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:33:29,640  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@49986178 will be shutdown
2023-02-15T13:33:29,640  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d3163a6 created in the thread with id: 1
2023-02-15T13:33:29,644  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:33:29,646  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactorThread
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.Cleaner
2023-02-15T13:33:29,662  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:33:29,662  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:33:29,662  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:33:29,662  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:33:29,662  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:33:29,662  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:33:29,662  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:33:29,663  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:33:29,663  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:33:29,663  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:33:29,663  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:33:29,663  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:33:29,672  INFO [main] compactor.Cleaner: Starting Cleaner thread
2023-02-15T13:33:29,704  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:33:29,704  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:33:29,704  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:33:29,704  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:33:29,704  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:33:29,704  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:33:29,704  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:33:29,705  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:33:29,705  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:33:29,705  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:33:29,705  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:33:29,705  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:33:29,707  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:33:29,712  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:33:29,713  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:33:29,713  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:33:29,714  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6d3163a6 will be shutdown
2023-02-15T13:33:29,714  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4a336377 created in the thread with id: 1
2023-02-15T13:33:29,717  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:33:29,719  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.SecurityUtils
2023-02-15T13:33:29,728  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.old_rfc	
2023-02-15T13:33:29,741  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:old_rfc, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_3/old_rfc, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:33:29,744  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_3/old_rfc specified for non-external table:old_rfc
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.utils.FileUtils
2023-02-15T13:33:29,746  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_3/old_rfc
2023-02-15T13:33:29,795  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.old_rfc	
2023-02-15T13:33:29,814  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_3/old_rfc/ds=part
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.StatsSetupConst
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.io.AcidUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.DataChecksum
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.statistics.impl.IOStatisticsStoreImpl
2023-02-15T13:33:29,867  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]) with min_open_txn: 1
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 21
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 22
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 23
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 24
2023-02-15T13:33:29,874  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 25
2023-02-15T13:33:29,875  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=old_rfc (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])
2023-02-15T13:33:29,881  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:33:29,885  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,887  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:33:29,890  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2023-02-15T13:33:29,893  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,893  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2023-02-15T13:33:29,896  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:33:29,900  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,900  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:33:29,902  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2023-02-15T13:33:29,906  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,906  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2023-02-15T13:33:29,909  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:33:29,913  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,913  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:33:29,916  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:33:29,919  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,919  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:33:29,922  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2023-02-15T13:33:29,925  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,925  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:33:29,928  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2023-02-15T13:33:29,931  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,931  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:33:29,934  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2023-02-15T13:33:29,937  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,937  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:33:29,940  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2023-02-15T13:33:29,943  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,943  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:33:29,946  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2023-02-15T13:33:29,949  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,950  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2023-02-15T13:33:29,952  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2023-02-15T13:33:29,956  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,956  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2023-02-15T13:33:29,959  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:13
2023-02-15T13:33:29,962  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,962  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2023-02-15T13:33:29,965  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:14
2023-02-15T13:33:29,968  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,968  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:14
2023-02-15T13:33:29,971  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2023-02-15T13:33:29,974  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,974  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2023-02-15T13:33:29,977  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2023-02-15T13:33:29,980  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,980  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:33:29,983  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2023-02-15T13:33:29,986  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,986  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:33:29,988  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2023-02-15T13:33:29,992  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:29,992  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:33:30,001  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2023-02-15T13:33:30,005  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:30,005  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:33:30,007  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2023-02-15T13:33:30,010  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:30,011  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:33:30,013  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:21
2023-02-15T13:33:30,016  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:30,016  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:21
2023-02-15T13:33:30,019  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:22
2023-02-15T13:33:30,022  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:30,022  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:22
2023-02-15T13:33:30,025  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:23
2023-02-15T13:33:30,028  INFO [main] txn.TxnHandler: Removed transactions: ([23]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:30,028  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:23
2023-02-15T13:33:30,030  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:24
2023-02-15T13:33:30,033  INFO [main] txn.TxnHandler: Removed transactions: ([24]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:30,033  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:24
2023-02-15T13:33:30,036  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:25
2023-02-15T13:33:30,038  INFO [main] txn.TxnHandler: Removed transactions: ([25]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:30,039  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:25
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.Worker
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactorFactory
2023-02-15T13:33:30,065  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:33:30,065  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:33:30,065  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:33:30,065  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:33:30,065  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:33:30,065  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:33:30,065  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:33:30,065  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:33:30,065  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:33:30,065  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:33:30,065  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:33:30,065  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveMetaStoreUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.HiveClientCache
2023-02-15T13:33:30,066  INFO [main] metastore.HiveClientCache: Initializing cache: eviction-timeout=120 initial-capacity=50 maximum-capacity=50
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hive.common.util.ShutdownHookManager
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.shims.Utils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.RetryingMetaStoreClient
2023-02-15T13:33:30,082  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:33:30,082  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:33:30,082  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4a336377 will be shutdown
2023-02-15T13:33:30,082  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27dc81be created in the thread with id: 1
2023-02-15T13:33:30,108  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:33:30,108  INFO [main] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.metastore.HiveClientCache$CacheableHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
2023-02-15T13:33:30,122  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T13:33:30,128  INFO [main] compactor.Worker: Starting Worker thread
2023-02-15T13:33:30,128  INFO [main] compactor.Worker: [wasabi] Worker 111
2023-02-15T13:33:30,129  INFO [main] compactor.Worker: [wasabi] Worker 117
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.session.SessionState
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.log.PerfLogger
2023-02-15T13:33:30,131  INFO [main_timeout_executor] compactor.Worker: [wasabi] Worker 281
2023-02-15T13:33:30,137  INFO [main_timeout_executor] compactor.Worker: Processing compaction request id:1,dbname:default,tableName:old_rfc,partName:ds=part,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:,workerId: labdas-94,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:33:30,137  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.old_rfc	
2023-02-15T13:33:30,138  INFO [main_timeout_executor] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:33:30,138  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@242db2ce, with PersistenceManager: null will be shutdown
2023-02-15T13:33:30,138  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@242db2ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23abb8be created in the thread with id: 97
2023-02-15T13:33:30,139  INFO [main_timeout_executor] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@242db2ce
2023-02-15T13:33:30,153  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:33:30,154  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_partitions_by_names : tbl=hive.default.old_rfc	
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.metastore.Batchable
2023-02-15T13:33:30,174  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:33:30,182  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([26]) with min_open_txn: 1
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactionHeartbeatService
2023-02-15T13:33:30,208  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Submitting heartbeat task for TXN 26
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactionHeartbeatService$CompactionHeartbeater
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.io.HdfsUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.functional.RemoteIterators
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.MRCompactor
2023-02-15T13:33:30,230  INFO [main_timeout_executor] compactor.Worker: Starting MINOR compaction for default.old_rfc.ds=part, id:1 in txnId=26, lockId=1 (TxnStatus: 'o') with compute stats set to true
2023-02-15T13:33:30,233  WARN [main_timeout_executor] compactor.MRCompactor: 2 delta files found for default.old_rfc.ds=part located at file:/home/rizky/hive/ql/target/tmp/compactor_test_table_3/old_rfc/ds=part! This is likely a sign of misconfiguration, especially if this message repeats.  Check that compaction is running properly.  Check for any runaway/mis-configured process writing to ACID tables, especially using Streaming Ingest API.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.security.TokenCache
2023-02-15T13:33:30,235  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-94-compactor-default.old_rfc.ds=part_0' to default queue. (current delta dirs count=1, obsolete delta dirs count=-1. TxnIdRange[21,22}]
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.tools.CLI
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.Cluster
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.LocalJobRunner
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.impl.MetricsConfig
2023-02-15T13:33:30,259  WARN [main_timeout_executor] impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.impl.MetricsSourceAdapter
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.metrics2.util.MBeans
2023-02-15T13:33:30,264  INFO [main_timeout_executor] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-02-15T13:33:30,264  INFO [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system started
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.Job
2023-02-15T13:33:30,269  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.JobSubmitter
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.JobSubmissionFiles
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.CryptoUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.JobResourceUploader
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.SharedCacheConfig
2023-02-15T13:33:30,287  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:33:30,289  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.split.JobSplitWriter
2023-02-15T13:33:30,301  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.QueueManager
2023-02-15T13:33:30,323  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local46962761_0001
2023-02-15T13:33:30,323  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.LocalDistributedCacheManager
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.v2.util.MRApps
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.v2.util.LocalResourceBuilder
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.FileContext
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.AbstractFileSystem
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.DiskChecker
2023-02-15T13:33:30,385  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:33:30,386  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-94-compactor-default.old_rfc.ds=part_0' with jobID=job_local46962761_0001 compaction ID=1
2023-02-15T13:33:30,386  INFO [Thread-80] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:33:30,386  INFO [Thread-80] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.FSInputStream
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.FSInputChecker
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.io.FastByteComparisons
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.counters.AbstractCounters
2023-02-15T13:33:30,400  INFO [Thread-80] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:33:30,401  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local46962761_0001_m_000000_0
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.Task
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.MapTask
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.SortedRanges
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.Progress
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.TaskStatus
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.util.MRJobConfUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.yarn.util.ResourceCalculatorProcessTree
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.yarn.util.ProcfsBasedProcessTree
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.SysInfoLinux
2023-02-15T13:33:30,417  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.io.serializer.SerializationFactory
2023-02-15T13:33:30,421  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 144, deltas: [delta_0000021_0000022]}
2023-02-15T13:33:30,422  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.JavaUtils
2023-02-15T13:33:30,436  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup
2023-02-15T13:33:30,439  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local46962761_0001_m_000000_0 is done. And is in the process of committing
2023-02-15T13:33:30,439  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:33:30,439  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local46962761_0001_m_000000_0' done.
2023-02-15T13:33:30,442  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local46962761_0001_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=656
		FILE: Number of bytes written=1218259
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=213
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=605552640
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:33:30,442  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local46962761_0001_m_000000_0
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.util.concurrent.ExecutorHelper
2023-02-15T13:33:30,443  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local46962761_0001_m_000001_0
2023-02-15T13:33:30,443  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:33:30,443  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 144, deltas: [delta_0000021_0000022]}
2023-02-15T13:33:30,443  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:33:30,448  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:33:30,448  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local46962761_0001_m_000001_0 is done. And is in the process of committing
2023-02-15T13:33:30,449  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:33:30,449  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local46962761_0001_m_000001_0' done.
2023-02-15T13:33:30,449  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local46962761_0001_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=1261
		FILE: Number of bytes written=1218387
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=213
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=605552640
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:33:30,449  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local46962761_0001_m_000001_0
2023-02-15T13:33:30,449  INFO [Thread-80] mapred.LocalJobRunner: map task executor complete.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.mapred.JobEndNotifier
2023-02-15T13:33:35,400  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-94-compactor-default.old_rfc.ds=part_1' to default queue. (current delta dirs count=1, obsolete delta dirs count=-1. TxnIdRange[23,24}]
2023-02-15T13:33:35,402  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:33:35,406  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:33:35,414  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:33:35,416  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:33:35,448  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:33:35,484  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local1149358914_0002
2023-02-15T13:33:35,484  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:33:35,525  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:33:35,525  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-94-compactor-default.old_rfc.ds=part_1' with jobID=job_local1149358914_0002 compaction ID=1
2023-02-15T13:33:35,525  INFO [Thread-117] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:33:35,525  INFO [Thread-117] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:33:35,526  INFO [Thread-117] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:33:35,526  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1149358914_0002_m_000000_0
2023-02-15T13:33:35,527  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:33:35,527  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 144, deltas: [delta_0000023_0000024]}
2023-02-15T13:33:35,527  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:33:35,535  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:33:35,535  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1149358914_0002_m_000000_0 is done. And is in the process of committing
2023-02-15T13:33:35,535  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:33:35,535  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1149358914_0002_m_000000_0' done.
2023-02-15T13:33:35,535  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1149358914_0002_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=1917
		FILE: Number of bytes written=2443780
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=213
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=605552640
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:33:35,536  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1149358914_0002_m_000000_0
2023-02-15T13:33:35,536  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1149358914_0002_m_000001_0
2023-02-15T13:33:35,536  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:33:35,536  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 144, deltas: [delta_0000023_0000024]}
2023-02-15T13:33:35,536  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:33:35,541  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:33:35,541  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1149358914_0002_m_000001_0 is done. And is in the process of committing
2023-02-15T13:33:35,541  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:33:35,541  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1149358914_0002_m_000001_0' done.
2023-02-15T13:33:35,541  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1149358914_0002_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=2522
		FILE: Number of bytes written=2443908
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=213
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=605552640
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:33:35,541  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1149358914_0002_m_000001_0
2023-02-15T13:33:35,541  INFO [Thread-117] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:33:40,608  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-94-compactor-default.old_rfc.ds=part' to default queue. (current delta dirs count=6, obsolete delta dirs count=0. TxnIdRange[21,24}]
2023-02-15T13:33:40,609  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:33:40,610  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:33:40,616  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:33:40,619  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:33:40,633  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:33:40,662  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local816048246_0003
2023-02-15T13:33:40,662  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:33:40,699  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:33:40,699  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-94-compactor-default.old_rfc.ds=part' with jobID=job_local816048246_0003 compaction ID=1
2023-02-15T13:33:40,700  INFO [Thread-177] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:33:40,700  INFO [Thread-177] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:33:40,701  INFO [Thread-177] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:33:40,701  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local816048246_0003_m_000000_0
2023-02-15T13:33:40,701  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:33:40,702  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 496, deltas: [delete_delta_0000021_0000022_v0000026, delta_0000021_0000022, delta_0000021_0000022_v0000026, delete_delta_0000023_0000024_v0000026, delta_0000023_0000024, delta_0000023_0000024_v0000026]}
2023-02-15T13:33:40,702  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:33:40,709  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:33:40,709  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local816048246_0003_m_000000_0 is done. And is in the process of committing
2023-02-15T13:33:40,709  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:33:40,709  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local816048246_0003_m_000000_0' done.
2023-02-15T13:33:40,709  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local816048246_0003_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=4995
		FILE: Number of bytes written=3667798
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=848
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=643825664
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:33:40,709  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local816048246_0003_m_000000_0
2023-02-15T13:33:40,709  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local816048246_0003_m_000001_0
2023-02-15T13:33:40,710  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:33:40,710  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 496, deltas: [delete_delta_0000021_0000022_v0000026, delta_0000021_0000022, delta_0000021_0000022_v0000026, delete_delta_0000023_0000024_v0000026, delta_0000023_0000024, delta_0000023_0000024_v0000026]}
2023-02-15T13:33:40,710  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:33:40,715  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:33:40,715  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local816048246_0003_m_000001_0 is done. And is in the process of committing
2023-02-15T13:33:40,715  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:33:40,715  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local816048246_0003_m_000001_0' done.
2023-02-15T13:33:40,715  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local816048246_0003_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=6802
		FILE: Number of bytes written=3668158
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=848
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=643825664
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:33:40,715  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local816048246_0003_m_000001_0
2023-02-15T13:33:40,715  INFO [Thread-177] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:33:45,702  INFO [main_timeout_executor] compactor.Worker: Completed MINOR compaction for default.old_rfc.ds=part in txnId=26, lockId=1 (TxnStatus: 'o'), marking as compacted.
2023-02-15T13:33:45,712  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Stopping heartbeat task for TXN 26
2023-02-15T13:33:45,712  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Shutting down compaction txn heartbeater instance.
2023-02-15T13:33:45,712  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Compaction txn heartbeater instance is successfully stopped.
2023-02-15T13:33:45,714  INFO [main_timeout_executor] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:26
2023-02-15T13:33:45,720  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([26]) from MIN_HISTORY_LEVEL
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.stats.StatsUtils
2023-02-15T13:33:45,724  INFO [main_timeout_executor] compactor.StatsUpdater: id:1,dbname:default,tableName:old_rfc,partName:ds=part,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:,workerId: labdas-94,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0: running 'analyze table default.old_rfc partition(ds='part') compute statistics noscan'
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.DriverUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.cleanup.SyncCleanupService
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.exec.Registry
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.session.SessionState
Hive Session ID = f96b1b40-96f9-4437-85e1-08ee05066d9d
2023-02-15T13:33:45,728  INFO [main_timeout_executor] SessionState: Hive Session ID = f96b1b40-96f9-4437-85e1-08ee05066d9d
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.util.ResourceDownloader
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.util.DependencyResolver
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/rizky/hive/conf/ivysettings.xml will be used
2023-02-15T13:33:45,734  INFO [main_timeout_executor] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/rizky/hive/conf/ivysettings.xml will be used
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.exec.Task
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.QueryPlan
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.exec.Utilities
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.exec.Utilities
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.exec.Utilities
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.io.HiveFileFormatUtils
2023-02-15T13:33:45,746  INFO [main_timeout_executor] session.SessionState: Created HDFS directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/f96b1b40-96f9-4437-85e1-08ee05066d9d
2023-02-15T13:33:45,747  INFO [main_timeout_executor] session.SessionState: Created local directory: /home/rizky/hive/ql/target/tmp/localscratchdir/f96b1b40-96f9-4437-85e1-08ee05066d9d
2023-02-15T13:33:45,748  INFO [main_timeout_executor] session.SessionState: Created HDFS directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/f96b1b40-96f9-4437-85e1-08ee05066d9d/_tmp_space.db
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.QueryState
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.Driver
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.hooks.HiveHooks
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.HiveQueryLifeTimeHook
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.DriverTxnHandler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.lock.CompileLock
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.lockmgr.DbTxnManager
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.Context
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.wm.WmContext
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.Compiler
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.conf.VariableSubstitution
2023-02-15T13:33:45,769  INFO [main_timeout_executor] ql.Driver: Compiling command(queryId=rizky_20230215133345_fe3c8fce-3f8e-4652-b3c7-82ced7b98726): analyze table default.old_rfc partition(ds='part') compute statistics noscan
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.parse.ParseUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.parse.ParseDriver
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.metadata.Hive
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.exec.FunctionRegistry
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.type.TimestampTZUtil
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.serde2.objectinspector.primitive.WritableHiveVarcharObjectInspector
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.UDFPI
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.UDFE
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFRegExp
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.serde2.io.HiveIntervalYearMonthWritable
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.serde2.io.HiveIntervalDayTimeWritable
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFRestrictInformationSchema
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFCurrentAuthorizer
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFToString
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFToVarchar
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFToChar
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMax
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFMin
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFSum
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFAverage
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFVariance
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFHistogramNumeric
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFPercentileApprox
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFnGrams
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFContextNGrams
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFComputeStats
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFExceptionInVertex
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.calcite.util.trace.CalciteTrace
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.calcite.util.trace.CalciteTrace
2023-02-15T13:33:46,362  WARN [main_timeout_executor] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.cpc.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2023-02-15T13:33:46,364  WARN [main_timeout_executor] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.hll.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2023-02-15T13:33:46,365  WARN [main_timeout_executor] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.IntersectSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2023-02-15T13:33:46,365  WARN [main_timeout_executor] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.EstimateSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2023-02-15T13:33:46,365  WARN [main_timeout_executor] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.ExcludeSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2023-02-15T13:33:46,366  WARN [main_timeout_executor] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.theta.UnionSketchUDF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
2023-02-15T13:33:46,366  WARN [main_timeout_executor] exec.FunctionRegistry: UDF Class org.apache.datasketches.hive.tuple.ArrayOfDoublesSketchToValuesUDTF does not have description. Please annotate the class with the org.apache.hadoop.hive.ql.exec.Description annotation and provide the description of the function.
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFReflect
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFExceptionInVertex
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFFromUtcTimestamp
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDFCastFormat
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDTFJSONTuple
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDTFParseUrlTuple
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDTFGetSplits
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDTFGetSplits2
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDTFGetSQLSchema
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFRowNumber
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFRank
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFPercentRank
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFNTile
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFFirstValue
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFLastValue
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFLeadLag
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFLead
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.GenericUDAFLag
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.BaseMaskUDF
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.generic.MaskHashTransformer
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Length
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_LineString
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Point
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_AsText
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Aggr_ConvexHull
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Aggr_Union
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Area
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_AsBinary
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_AsGeoJson
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_AsJson
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_AsShape
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Boundary
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Buffer
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Centroid
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_ConvexHull
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_CoordDim
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Difference
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Dimension
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Distance
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_EndPoint
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Envelope
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_EnvIntersects
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_ExteriorRing
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeodesicLengthWGS84
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeomCollection
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeometryN
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeomFromGeoJson
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeomFromShape
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeomFromText
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeomFromWKB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_GeometryType
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_InteriorRingN
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Intersection
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Is3D
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_IsClosed
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_IsEmpty
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_IsMeasured
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_IsRing
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_IsSimple
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_LineFromWKB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_M
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MaxM
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MaxX
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MaxY
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MaxZ
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MinM
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MinX
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MinY
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MinZ
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MLineFromWKB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MPointFromWKB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MPolyFromWKB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MultiLineString
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MultiPoint
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_MultiPolygon
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_NumGeometries
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_NumInteriorRing
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_NumPoints
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_PointFromWKB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_PointN
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_PolyFromWKB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Polygon
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Relate
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_SetSRID
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_SRID
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_StartPoint
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_SymmetricDiff
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Union
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_X
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Y
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.udf.esri.ST_Z
2023-02-15T13:33:46,403  WARN [main_timeout_executor] exec.FunctionRegistry: iceberg_bucket function could not be registered
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.metadata.HiveMetaStoreClientWithLocalCache
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient
2023-02-15T13:33:46,407  INFO [main_timeout_executor] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:33:46,407  INFO [main_timeout_executor] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:33:46,407  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@242db2ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@23abb8be will be shutdown
2023-02-15T13:33:46,407  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@242db2ce, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@a22551d created in the thread with id: 97
2023-02-15T13:33:46,409  INFO [main_timeout_executor] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:33:46,409  INFO [main_timeout_executor] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
2023-02-15T13:33:46,420  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_all_functions	
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.parse.SemanticAnalyzerFactory
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.reflections.Reflections
2023-02-15T13:33:46,524  INFO [main_timeout_executor] reflections.Reflections: Reflections took 66 ms to scan 2 urls, producing 53 keys and 798 values
2023-02-15T13:33:46,581  INFO [main_timeout_executor] reflections.Reflections: Reflections took 32 ms to scan 2 urls, producing 53 keys and 798 values
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.parse.CacheTableHelper
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.lockmgr.DbLockManager
2023-02-15T13:33:46,613  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([27]) with min_open_txn: 27
2023-02-15T13:33:46,613  INFO [main_timeout_executor] lockmgr.DbTxnManager: Opened txnid:27
2023-02-15T13:33:46,614  INFO [main_timeout_executor] ql.QueryState: Query-level HMS cache created for rizky_20230215133345_fe3c8fce-3f8e-4652-b3c7-82ced7b98726
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.parse.QB
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.parse.QBParseInfo
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.parse.QBMetaData
2023-02-15T13:33:46,617  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.old_rfc	
2023-02-15T13:33:46,621  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.metadata.HiveUtils
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.metadata.Table
2023-02-15T13:33:46,624  INFO [main_timeout_executor] parse.ColumnStatsSemanticAnalyzer: Invoking analyze on original query
2023-02-15T13:33:46,624  INFO [main_timeout_executor] parse.ColumnStatsSemanticAnalyzer: Starting Semantic Analysis
2023-02-15T13:33:46,637 ERROR [main_timeout_executor] session.SessionState: Error setting up authorization: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	... 22 more
FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
2023-02-15T13:33:46,637 ERROR [main_timeout_executor] ql.Driver: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001)
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331)
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141)
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96)
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81)
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93)
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530)
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360)
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977)
	... 21 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350)
	... 22 more

2023-02-15T13:33:46,638  INFO [main_timeout_executor] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2023-02-15T13:33:46,638  INFO [main_timeout_executor] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=3, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=6, flushCache_()=0, getValidTxns_(long)=0, getAllFunctions_()=20}
2023-02-15T13:33:46,638  INFO [main_timeout_executor] ql.Driver: Completed compiling command(queryId=rizky_20230215133345_fe3c8fce-3f8e-4652-b3c7-82ced7b98726); Time taken: 0.87 seconds
2023-02-15T13:33:46,638  INFO [main_timeout_executor] lockmgr.DbTxnManager: Stopped heartbeat for query: rizky_20230215133345_fe3c8fce-3f8e-4652-b3c7-82ced7b98726
2023-02-15T13:33:46,641  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([27]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,644  WARN [main_timeout_executor] txn.TxnHandler: Aborted 1 transaction(s) [27] due to rollback
2023-02-15T13:33:46,646 ERROR [main_timeout_executor] ql.Driver: Failed to run analyze table default.old_rfc partition(ds='part') compute statistics noscan
org.apache.hadoop.hive.ql.processors.CommandProcessorException: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.DriverUtils.createProcessorException(DriverUtils.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.handleException(Compiler.java:479) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:121) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
2023-02-15T13:33:46,647  INFO [main_timeout_executor] cleanup.SyncCleanupService: Deleted directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/f96b1b40-96f9-4437-85e1-08ee05066d9d on fs with scheme file
2023-02-15T13:33:46,647  INFO [main_timeout_executor] cleanup.SyncCleanupService: Deleted directory: /home/rizky/hive/ql/target/tmp/localscratchdir/f96b1b40-96f9-4437-85e1-08ee05066d9d on fs with scheme file
2023-02-15T13:33:46,652 ERROR [main_timeout_executor] compactor.StatsUpdater: id:1,dbname:default,tableName:old_rfc,partName:ds=part,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:,workerId: labdas-94,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0: gatherStats(default,old_rfc,ds=part) failed due to: Failed to run analyze table default.old_rfc partition(ds='part') compute statistics noscan
org.apache.hadoop.hive.ql.metadata.HiveException: Failed to run analyze table default.old_rfc partition(ds='part') compute statistics noscan
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:99) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: org.apache.hadoop.hive.ql.processors.CommandProcessorException: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.DriverUtils.createProcessorException(DriverUtils.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.handleException(Compiler.java:479) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:121) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
2023-02-15T13:33:46,653  INFO [main] compactor.Worker: [wasabi] Worker 163
2023-02-15T13:33:46,653  INFO [main] compactor.Worker: [wasabi] Worker 170
2023-02-15T13:33:46,653  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.young_rfc	
2023-02-15T13:33:46,654  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:young_rfc, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_3/young_rfc, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:33:46,656  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_3/young_rfc specified for non-external table:young_rfc
2023-02-15T13:33:46,656  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_3/young_rfc
2023-02-15T13:33:46,680  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.young_rfc	
2023-02-15T13:33:46,685  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_3/young_rfc/ds=part
2023-02-15T13:33:46,716  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52]) with min_open_txn: 27
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 28
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 29
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 30
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 31
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 32
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 33
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 34
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 35
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 36
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 37
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 38
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 39
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 40
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 41
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 42
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 43
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 44
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 45
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 46
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 47
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 48
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 49
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 50
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 51
2023-02-15T13:33:46,720  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 52
2023-02-15T13:33:46,721  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=young_rfc (txnIds: [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52])
2023-02-15T13:33:46,723  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:28
2023-02-15T13:33:46,726  INFO [main] txn.TxnHandler: Removed transactions: ([28]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,726  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:28
2023-02-15T13:33:46,729  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:29
2023-02-15T13:33:46,731  INFO [main] txn.TxnHandler: Removed transactions: ([29]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,732  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:29
2023-02-15T13:33:46,734  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:30
2023-02-15T13:33:46,737  INFO [main] txn.TxnHandler: Removed transactions: ([30]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,737  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:30
2023-02-15T13:33:46,739  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:31
2023-02-15T13:33:46,742  INFO [main] txn.TxnHandler: Removed transactions: ([31]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,742  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:31
2023-02-15T13:33:46,744  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:32
2023-02-15T13:33:46,747  INFO [main] txn.TxnHandler: Removed transactions: ([32]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,747  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:32
2023-02-15T13:33:46,750  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:33
2023-02-15T13:33:46,752  INFO [main] txn.TxnHandler: Removed transactions: ([33]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,752  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:33
2023-02-15T13:33:46,755  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:34
2023-02-15T13:33:46,758  INFO [main] txn.TxnHandler: Removed transactions: ([34]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,758  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:34
2023-02-15T13:33:46,760  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:35
2023-02-15T13:33:46,763  INFO [main] txn.TxnHandler: Removed transactions: ([35]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,763  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:35
2023-02-15T13:33:46,765  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:36
2023-02-15T13:33:46,768  INFO [main] txn.TxnHandler: Removed transactions: ([36]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,768  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:36
2023-02-15T13:33:46,770  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:37
2023-02-15T13:33:46,772  INFO [main] txn.TxnHandler: Removed transactions: ([37]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,773  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:37
2023-02-15T13:33:46,775  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:38
2023-02-15T13:33:46,777  INFO [main] txn.TxnHandler: Removed transactions: ([38]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,777  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:38
2023-02-15T13:33:46,779  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:39
2023-02-15T13:33:46,782  INFO [main] txn.TxnHandler: Removed transactions: ([39]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,782  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:39
2023-02-15T13:33:46,784  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:40
2023-02-15T13:33:46,787  INFO [main] txn.TxnHandler: Removed transactions: ([40]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,787  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:40
2023-02-15T13:33:46,789  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:41
2023-02-15T13:33:46,791  INFO [main] txn.TxnHandler: Removed transactions: ([41]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,792  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:41
2023-02-15T13:33:46,794  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:42
2023-02-15T13:33:46,797  INFO [main] txn.TxnHandler: Removed transactions: ([42]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,797  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:42
2023-02-15T13:33:46,799  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:43
2023-02-15T13:33:46,802  INFO [main] txn.TxnHandler: Removed transactions: ([43]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,802  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:43
2023-02-15T13:33:46,804  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:44
2023-02-15T13:33:46,807  INFO [main] txn.TxnHandler: Removed transactions: ([44]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,807  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:44
2023-02-15T13:33:46,809  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:45
2023-02-15T13:33:46,812  INFO [main] txn.TxnHandler: Removed transactions: ([45]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,812  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:45
2023-02-15T13:33:46,814  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:46
2023-02-15T13:33:46,816  INFO [main] txn.TxnHandler: Removed transactions: ([46]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,816  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:46
2023-02-15T13:33:46,819  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:47
2023-02-15T13:33:46,821  INFO [main] txn.TxnHandler: Removed transactions: ([47]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,821  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:47
2023-02-15T13:33:46,823  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:48
2023-02-15T13:33:46,826  INFO [main] txn.TxnHandler: Removed transactions: ([48]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,826  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:48
2023-02-15T13:33:46,828  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:49
2023-02-15T13:33:46,831  INFO [main] txn.TxnHandler: Removed transactions: ([49]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,831  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:49
2023-02-15T13:33:46,833  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:50
2023-02-15T13:33:46,836  INFO [main] txn.TxnHandler: Removed transactions: ([50]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,836  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:50
2023-02-15T13:33:46,838  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:51
2023-02-15T13:33:46,840  INFO [main] txn.TxnHandler: Removed transactions: ([51]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,840  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:51
2023-02-15T13:33:46,843  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:52
2023-02-15T13:33:46,846  INFO [main] txn.TxnHandler: Removed transactions: ([52]) from MIN_HISTORY_LEVEL
2023-02-15T13:33:46,846  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:52
2023-02-15T13:33:46,863  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:33:46,863  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:33:46,863  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:33:46,863  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:33:46,863  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:33:46,863  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:33:46,863  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:33:46,863  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:33:46,863  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:33:46,863  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:33:46,863  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:33:46,863  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:33:46,864  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T13:33:46,866  INFO [main] compactor.Worker: Starting Worker thread
2023-02-15T13:33:46,866  INFO [main] compactor.Worker: [wasabi] Worker 111
2023-02-15T13:33:46,866  INFO [main] compactor.Worker: [wasabi] Worker 117
2023-02-15T13:33:46,866  INFO [main_timeout_executor] compactor.Worker: [wasabi] Worker 281
2023-02-15T13:33:46,870  INFO [main_timeout_executor] compactor.Worker: Processing compaction request id:2,dbname:default,tableName:young_rfc,partName:ds=part,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:,workerId: labdas-275,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:33:46,871  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.young_rfc	
2023-02-15T13:33:46,871  INFO [main_timeout_executor] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:33:46,871  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f1e684, with PersistenceManager: null will be shutdown
2023-02-15T13:33:46,871  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f1e684, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58542391 created in the thread with id: 276
2023-02-15T13:33:46,882  INFO [main_timeout_executor] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f1e684
2023-02-15T13:33:46,894  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:33:46,895  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_partitions_by_names : tbl=hive.default.young_rfc	
2023-02-15T13:33:46,907  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:33:46,914  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([53]) with min_open_txn: 27
2023-02-15T13:33:46,926  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Submitting heartbeat task for TXN 53
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactionHeartbeatService$CompactionHeartbeater
2023-02-15T13:33:46,940  INFO [main_timeout_executor] compactor.Worker: Starting MINOR compaction for default.young_rfc.ds=part, id:2 in txnId=53, lockId=2 (TxnStatus: 'o') with compute stats set to true
2023-02-15T13:33:46,941  WARN [main_timeout_executor] compactor.MRCompactor: 2 delta files found for default.young_rfc.ds=part located at file:/home/rizky/hive/ql/target/tmp/compactor_test_table_3/young_rfc/ds=part! This is likely a sign of misconfiguration, especially if this message repeats.  Check that compaction is running properly.  Check for any runaway/mis-configured process writing to ACID tables, especially using Streaming Ingest API.
2023-02-15T13:33:46,941  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-275-compactor-default.young_rfc.ds=part_0' to default queue. (current delta dirs count=1, obsolete delta dirs count=-1. TxnIdRange[21,22}]
2023-02-15T13:33:46,941  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:33:46,942  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:33:46,944  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:33:46,946  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:33:46,952  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:33:46,961  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local570916258_0004
2023-02-15T13:33:46,961  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:33:47,001  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:33:47,001  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-275-compactor-default.young_rfc.ds=part_0' with jobID=job_local570916258_0004 compaction ID=2
2023-02-15T13:33:47,001  INFO [Thread-245] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:33:47,001  INFO [Thread-245] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:33:47,002  INFO [Thread-245] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:33:47,003  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local570916258_0004_m_000000_0
2023-02-15T13:33:47,003  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:33:47,003  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 144, deltas: [delta_0000021_0000022]}
2023-02-15T13:33:47,003  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:33:47,010  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:33:47,010  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local570916258_0004_m_000000_0 is done. And is in the process of committing
2023-02-15T13:33:47,010  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:33:47,010  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local570916258_0004_m_000000_0' done.
2023-02-15T13:33:47,010  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local570916258_0004_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=7462
		FILE: Number of bytes written=4891801
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=215
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=755499008
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:33:47,010  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local570916258_0004_m_000000_0
2023-02-15T13:33:47,010  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local570916258_0004_m_000001_0
2023-02-15T13:33:47,011  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:33:47,011  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 144, deltas: [delta_0000021_0000022]}
2023-02-15T13:33:47,011  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:33:47,015  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:33:47,016  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local570916258_0004_m_000001_0 is done. And is in the process of committing
2023-02-15T13:33:47,016  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:33:47,016  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local570916258_0004_m_000001_0' done.
2023-02-15T13:33:47,016  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local570916258_0004_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=8071
		FILE: Number of bytes written=4891929
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=215
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=755499008
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:33:47,016  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local570916258_0004_m_000001_0
2023-02-15T13:33:47,016  INFO [Thread-245] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:33:52,006  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-275-compactor-default.young_rfc.ds=part_1' to default queue. (current delta dirs count=1, obsolete delta dirs count=-1. TxnIdRange[23,24}]
2023-02-15T13:33:52,007  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:33:52,010  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:33:52,016  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:33:52,018  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:33:52,024  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:33:52,037  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local1234793024_0005
2023-02-15T13:33:52,037  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:33:52,072  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:33:52,072  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-275-compactor-default.young_rfc.ds=part_1' with jobID=job_local1234793024_0005 compaction ID=2
2023-02-15T13:33:52,073  INFO [Thread-280] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:33:52,073  INFO [Thread-280] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:33:52,074  INFO [Thread-280] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:33:52,074  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1234793024_0005_m_000000_0
2023-02-15T13:33:52,075  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:33:52,075  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 144, deltas: [delta_0000023_0000024]}
2023-02-15T13:33:52,075  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:33:52,082  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:33:52,082  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1234793024_0005_m_000000_0 is done. And is in the process of committing
2023-02-15T13:33:52,083  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:33:52,083  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1234793024_0005_m_000000_0' done.
2023-02-15T13:33:52,083  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1234793024_0005_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=8731
		FILE: Number of bytes written=6117356
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=215
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=805830656
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:33:52,083  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1234793024_0005_m_000000_0
2023-02-15T13:33:52,083  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1234793024_0005_m_000001_0
2023-02-15T13:33:52,083  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:33:52,083  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 144, deltas: [delta_0000023_0000024]}
2023-02-15T13:33:52,083  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:33:52,088  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:33:52,088  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1234793024_0005_m_000001_0 is done. And is in the process of committing
2023-02-15T13:33:52,088  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:33:52,088  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1234793024_0005_m_000001_0' done.
2023-02-15T13:33:52,088  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1234793024_0005_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=9340
		FILE: Number of bytes written=6117484
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=215
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=805830656
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:33:52,088  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1234793024_0005_m_000001_0
2023-02-15T13:33:52,088  INFO [Thread-280] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:33:57,142  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-275-compactor-default.young_rfc.ds=part' to default queue. (current delta dirs count=6, obsolete delta dirs count=0. TxnIdRange[21,24}]
2023-02-15T13:33:57,143  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:33:57,146  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:33:57,153  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:33:57,159  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:33:57,181  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:33:57,193  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local1981775907_0006
2023-02-15T13:33:57,193  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:33:57,227  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:33:57,227  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-275-compactor-default.young_rfc.ds=part' with jobID=job_local1981775907_0006 compaction ID=2
2023-02-15T13:33:57,227  INFO [Thread-340] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:33:57,228  INFO [Thread-340] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:33:57,229  INFO [Thread-340] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:33:57,229  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1981775907_0006_m_000000_0
2023-02-15T13:33:57,229  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:33:57,229  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 496, deltas: [delete_delta_0000021_0000022_v0000053, delta_0000021_0000022, delta_0000021_0000022_v0000053, delete_delta_0000023_0000024_v0000053, delta_0000023_0000024, delta_0000023_0000024_v0000053]}
2023-02-15T13:33:57,229  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:33:57,236  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:33:57,236  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1981775907_0006_m_000000_0 is done. And is in the process of committing
2023-02-15T13:33:57,236  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:33:57,236  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1981775907_0006_m_000000_0' done.
2023-02-15T13:33:57,236  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1981775907_0006_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=11837
		FILE: Number of bytes written=7346796
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=860
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=805830656
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:33:57,236  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1981775907_0006_m_000000_0
2023-02-15T13:33:57,236  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1981775907_0006_m_000001_0
2023-02-15T13:33:57,236  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:33:57,237  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 496, deltas: [delete_delta_0000021_0000022_v0000053, delta_0000021_0000022, delta_0000021_0000022_v0000053, delete_delta_0000023_0000024_v0000053, delta_0000023_0000024, delta_0000023_0000024_v0000053]}
2023-02-15T13:33:57,237  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:33:57,241  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:33:57,241  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1981775907_0006_m_000001_0 is done. And is in the process of committing
2023-02-15T13:33:57,241  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:33:57,241  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1981775907_0006_m_000001_0' done.
2023-02-15T13:33:57,241  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1981775907_0006_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=13668
		FILE: Number of bytes written=7347156
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=860
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=805830656
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:33:57,241  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1981775907_0006_m_000001_0
2023-02-15T13:33:57,241  INFO [Thread-340] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:34:02,230  INFO [main_timeout_executor] compactor.Worker: Completed MINOR compaction for default.young_rfc.ds=part in txnId=53, lockId=2 (TxnStatus: 'o'), marking as compacted.
2023-02-15T13:34:02,241  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Stopping heartbeat task for TXN 53
2023-02-15T13:34:02,241  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Shutting down compaction txn heartbeater instance.
2023-02-15T13:34:02,241  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Compaction txn heartbeater instance is successfully stopped.
2023-02-15T13:34:02,248  INFO [main_timeout_executor] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:53
2023-02-15T13:34:02,256  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([53]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,257  INFO [main_timeout_executor] compactor.StatsUpdater: id:2,dbname:default,tableName:young_rfc,partName:ds=part,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:,workerId: labdas-275,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0: running 'analyze table default.young_rfc partition(ds='part') compute statistics noscan'
Hive Session ID = 24cf6c85-fcc9-46ba-9180-e0603a744601
2023-02-15T13:34:02,257  INFO [main_timeout_executor] SessionState: Hive Session ID = 24cf6c85-fcc9-46ba-9180-e0603a744601
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/rizky/hive/conf/ivysettings.xml will be used
2023-02-15T13:34:02,257  INFO [main_timeout_executor] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/rizky/hive/conf/ivysettings.xml will be used
2023-02-15T13:34:02,260  INFO [main_timeout_executor] session.SessionState: Created HDFS directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/24cf6c85-fcc9-46ba-9180-e0603a744601
2023-02-15T13:34:02,260  INFO [main_timeout_executor] session.SessionState: Created local directory: /home/rizky/hive/ql/target/tmp/localscratchdir/24cf6c85-fcc9-46ba-9180-e0603a744601
2023-02-15T13:34:02,261  INFO [main_timeout_executor] session.SessionState: Created HDFS directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/24cf6c85-fcc9-46ba-9180-e0603a744601/_tmp_space.db
2023-02-15T13:34:02,262  INFO [main_timeout_executor] ql.Driver: Compiling command(queryId=rizky_20230215133402_e7c91dab-408c-4091-ac4c-2a9a0d69e67a): analyze table default.young_rfc partition(ds='part') compute statistics noscan
2023-02-15T13:34:02,263  INFO [main_timeout_executor] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:34:02,263  INFO [main_timeout_executor] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:34:02,263  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f1e684, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@58542391 will be shutdown
2023-02-15T13:34:02,263  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1f1e684, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@681749bf created in the thread with id: 276
2023-02-15T13:34:02,266  INFO [main_timeout_executor] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:34:02,266  INFO [main_timeout_executor] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer
2023-02-15T13:34:02,268  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([54]) with min_open_txn: 54
2023-02-15T13:34:02,268  INFO [main_timeout_executor] lockmgr.DbTxnManager: Opened txnid:54
2023-02-15T13:34:02,269  INFO [main_timeout_executor] ql.QueryState: Query-level HMS cache created for rizky_20230215133402_e7c91dab-408c-4091-ac4c-2a9a0d69e67a
2023-02-15T13:34:02,269  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.young_rfc	
2023-02-15T13:34:02,272  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:34:02,272  INFO [main_timeout_executor] parse.ColumnStatsSemanticAnalyzer: Invoking analyze on original query
2023-02-15T13:34:02,272  INFO [main_timeout_executor] parse.ColumnStatsSemanticAnalyzer: Starting Semantic Analysis
2023-02-15T13:34:02,273 ERROR [main_timeout_executor] session.SessionState: Error setting up authorization: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	... 22 more
FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
2023-02-15T13:34:02,273 ERROR [main_timeout_executor] ql.Driver: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001)
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331)
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141)
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96)
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81)
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93)
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530)
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360)
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977)
	... 21 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350)
	... 22 more

2023-02-15T13:34:02,273  INFO [main_timeout_executor] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2023-02-15T13:34:02,273  INFO [main_timeout_executor] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=2, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=3, flushCache_()=0, getValidTxns_(long)=1}
2023-02-15T13:34:02,273  INFO [main_timeout_executor] ql.Driver: Completed compiling command(queryId=rizky_20230215133402_e7c91dab-408c-4091-ac4c-2a9a0d69e67a); Time taken: 0.011 seconds
2023-02-15T13:34:02,273  INFO [main_timeout_executor] lockmgr.DbTxnManager: Stopped heartbeat for query: rizky_20230215133402_e7c91dab-408c-4091-ac4c-2a9a0d69e67a
2023-02-15T13:34:02,275  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([54]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,278  WARN [main_timeout_executor] txn.TxnHandler: Aborted 1 transaction(s) [54] due to rollback
2023-02-15T13:34:02,279 ERROR [main_timeout_executor] ql.Driver: Failed to run analyze table default.young_rfc partition(ds='part') compute statistics noscan
org.apache.hadoop.hive.ql.processors.CommandProcessorException: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.DriverUtils.createProcessorException(DriverUtils.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.handleException(Compiler.java:479) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:121) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
2023-02-15T13:34:02,279  INFO [main_timeout_executor] cleanup.SyncCleanupService: Deleted directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/24cf6c85-fcc9-46ba-9180-e0603a744601 on fs with scheme file
2023-02-15T13:34:02,279  INFO [main_timeout_executor] cleanup.SyncCleanupService: Deleted directory: /home/rizky/hive/ql/target/tmp/localscratchdir/24cf6c85-fcc9-46ba-9180-e0603a744601 on fs with scheme file
2023-02-15T13:34:02,280 ERROR [main_timeout_executor] compactor.StatsUpdater: id:2,dbname:default,tableName:young_rfc,partName:ds=part,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:,workerId: labdas-275,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0: gatherStats(default,young_rfc,ds=part) failed due to: Failed to run analyze table default.young_rfc partition(ds='part') compute statistics noscan
org.apache.hadoop.hive.ql.metadata.HiveException: Failed to run analyze table default.young_rfc partition(ds='part') compute statistics noscan
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:99) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: org.apache.hadoop.hive.ql.processors.CommandProcessorException: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.DriverUtils.createProcessorException(DriverUtils.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.handleException(Compiler.java:479) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:121) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
2023-02-15T13:34:02,280  INFO [main] compactor.Worker: [wasabi] Worker 163
2023-02-15T13:34:02,280  INFO [main] compactor.Worker: [wasabi] Worker 170
2023-02-15T13:34:02,463  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:34:02,463  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:34:02,463  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:34:02,463  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:34:02,463  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:34:02,463  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:34:02,463  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:34:02,463  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:34:02,463  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:34:02,463  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:34:02,463  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:34:02,463  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:34:02,463  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:34:02,479  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:34:02,480  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:34:02,480  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:34:02,480  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@27dc81be will be shutdown
2023-02-15T13:34:02,480  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2914a328 created in the thread with id: 1
2023-02-15T13:34:02,483  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:34:02,484  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:34:02,494  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.ime	
2023-02-15T13:34:02,496  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:ime, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_4/ime, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:34:02,497  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_4/ime specified for non-external table:ime
2023-02-15T13:34:02,497  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_4/ime
2023-02-15T13:34:02,521  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.ime	
2023-02-15T13:34:02,532  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_4/ime/ds=part1
2023-02-15T13:34:02,555  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.ime	
2023-02-15T13:34:02,557  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_4/ime/ds=part2
2023-02-15T13:34:02,575  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.ime	
2023-02-15T13:34:02,578  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_4/ime/ds=part3
2023-02-15T13:34:02,598  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.ime	
2023-02-15T13:34:02,600  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_4/ime/ds=part4
2023-02-15T13:34:02,618  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.ime	
2023-02-15T13:34:02,621  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_4/ime/ds=part5
2023-02-15T13:34:02,640  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.ime	
2023-02-15T13:34:02,642  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_4/ime/ds=part6
2023-02-15T13:34:02,666  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.ime	
2023-02-15T13:34:02,673  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_4/ime/ds=part7
2023-02-15T13:34:02,688  INFO [Finalizer] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T13:34:02,688  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -1
2023-02-15T13:34:02,697  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.ime	
2023-02-15T13:34:02,699  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_4/ime/ds=part8
2023-02-15T13:34:02,718  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.ime	
2023-02-15T13:34:02,721  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_4/ime/ds=part9
2023-02-15T13:34:02,738  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.ime	
2023-02-15T13:34:02,741  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_4/ime/ds=part10
2023-02-15T13:34:02,766  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]) with min_open_txn: 1
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 21
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 22
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 23
2023-02-15T13:34:02,770  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=ime (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])
2023-02-15T13:34:02,773  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:34:02,776  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,777  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:34:02,779  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2023-02-15T13:34:02,782  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,782  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2023-02-15T13:34:02,784  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:34:02,787  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,787  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:34:02,789  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2023-02-15T13:34:02,792  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,792  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2023-02-15T13:34:02,794  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:34:02,797  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,797  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:34:02,799  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:34:02,802  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,802  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:34:02,804  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2023-02-15T13:34:02,807  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,807  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:34:02,809  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2023-02-15T13:34:02,812  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,812  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:34:02,814  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2023-02-15T13:34:02,817  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,817  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:34:02,820  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2023-02-15T13:34:02,823  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,823  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:34:02,825  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2023-02-15T13:34:02,828  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,828  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2023-02-15T13:34:02,831  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2023-02-15T13:34:02,834  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,834  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2023-02-15T13:34:02,836  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:13
2023-02-15T13:34:02,838  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,838  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2023-02-15T13:34:02,840  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:14
2023-02-15T13:34:02,843  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,843  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:14
2023-02-15T13:34:02,845  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2023-02-15T13:34:02,847  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,847  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2023-02-15T13:34:02,849  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2023-02-15T13:34:02,851  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,852  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:34:02,854  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2023-02-15T13:34:02,856  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,856  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:34:02,858  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2023-02-15T13:34:02,860  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,860  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:34:02,863  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2023-02-15T13:34:02,865  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,865  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:34:02,867  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2023-02-15T13:34:02,870  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,870  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:34:02,872  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:21
2023-02-15T13:34:02,875  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,875  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:21
2023-02-15T13:34:02,878  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:22
2023-02-15T13:34:02,880  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,880  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:22
2023-02-15T13:34:02,883  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:23
2023-02-15T13:34:02,885  INFO [main] txn.TxnHandler: Removed transactions: ([23]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,886  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:23
2023-02-15T13:34:02,890  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([24]) with min_open_txn: 1
2023-02-15T13:34:02,910  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 24
2023-02-15T13:34:02,910  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=ime (txnIds: [24])
2023-02-15T13:34:02,918  INFO [main] txn.TxnHandler: Removed transactions: ([24]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:02,919  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:24
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.Initiator
2023-02-15T13:34:02,930  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:34:02,930  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:34:02,930  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:34:02,930  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:34:02,930  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:34:02,930  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:34:02,930  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:34:02,930  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:34:02,930  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:34:02,930  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:34:02,930  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:34:02,930  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:34:02,931  INFO [main] compactor.Initiator: Starting Initiator thread
2023-02-15T13:34:02,935  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410442933
2023-02-15T13:34:02,946  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:34:02,946  INFO [Initiator-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:34:02,946  INFO [Initiator-executor-thread-1] metastore.PersistenceManagerProvider: Updating the pmf due to property change
2023-02-15T13:34:02,946  INFO [Initiator-executor-thread-1] datasource.HikariCPDataSourceProvider: Creating Hikari connection pool for the MetaStore, maxPoolSize: 5, name: objectstore-compactor
2023-02-15T13:34:02,947  WARN [Initiator-executor-thread-1] hikari.HikariConfig: objectstore-compactor - leakDetectionThreshold is less than 2000ms or more than maxLifetime, disabling it.
2023-02-15T13:34:02,947  INFO [Initiator-executor-thread-1] hikari.HikariDataSource: objectstore-compactor - Starting...
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.PoolBase
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class com.zaxxer.hikari.pool.HikariPool
2023-02-15T13:34:02,948  INFO [Initiator-executor-thread-1] pool.PoolBase: objectstore-compactor - Driver does not support get/set network timeout for connections. (Feature not implemented: No details.)
2023-02-15T13:34:02,950  INFO [Initiator-executor-thread-1] hikari.HikariDataSource: objectstore-compactor - Start completed.
2023-02-15T13:34:03,114  INFO [Initiator-executor-thread-1] metastore.PersistenceManagerProvider: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2023-02-15T13:34:03,114  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@197d3d53, with PersistenceManager: null will be shutdown
2023-02-15T13:34:03,114  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@197d3d53, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2002d212 created in the thread with id: 599
2023-02-15T13:34:03,304  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@197d3d53
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.exec.repl.util.ReplUtils
2023-02-15T13:34:03,307  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.ime.ds=part10
2023-02-15T13:34:03,327  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.ime.ds=part7
2023-02-15T13:34:03,327  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.ime.ds=part6
2023-02-15T13:34:03,327  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.ime.ds=part5
2023-02-15T13:34:03,328  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.ime.ds=part4
2023-02-15T13:34:03,328  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.ime.ds=part3
2023-02-15T13:34:03,328  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.ime.ds=part2
2023-02-15T13:34:03,329  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.ime.ds=part1
2023-02-15T13:34:03,329  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.ime.ds=part9
2023-02-15T13:34:03,329  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.ime.ds=part8
2023-02-15T13:34:03,360  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:ime, partitionname:ds=part9, type:MAJOR, runas:rizky, initiatorId:labdas-599)
2023-02-15T13:34:03,377  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:ime, partitionname:ds=part8, type:MAJOR, runas:rizky, initiatorId:labdas-599)
2023-02-15T13:34:03,392  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:ime, partitionname:ds=part10, type:MAJOR, runas:rizky, initiatorId:labdas-599)
2023-02-15T13:34:03,405  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:ime, partitionname:ds=part7, type:MAJOR, runas:rizky, initiatorId:labdas-599)
2023-02-15T13:34:03,417  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:ime, partitionname:ds=part6, type:MAJOR, runas:rizky, initiatorId:labdas-599)
2023-02-15T13:34:03,429  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:ime, partitionname:ds=part5, type:MAJOR, runas:rizky, initiatorId:labdas-599)
2023-02-15T13:34:03,441  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:ime, partitionname:ds=part4, type:MAJOR, runas:rizky, initiatorId:labdas-599)
2023-02-15T13:34:03,453  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:ime, partitionname:ds=part3, type:MAJOR, runas:rizky, initiatorId:labdas-599)
2023-02-15T13:34:03,469  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:ime, partitionname:ds=part2, type:MAJOR, runas:rizky, initiatorId:labdas-599)
2023-02-15T13:34:03,484  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:ime, partitionname:ds=part1, type:MAJOR, runas:rizky, initiatorId:labdas-599)
2023-02-15T13:34:03,490  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410443488
2023-02-15T13:34:03,495 ERROR [main] metrics.AcidMetricService: Cannot initialize delta file metrics mbean server. AcidMetricService initialization aborted.
javax.management.InstanceAlreadyExistsException: metrics:type=compaction,name=compaction_num_obsolete_deltas
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324) ~[?:1.8.0_352]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.initObjectsForMetrics(AcidMetricService.java:404) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.setConf(AcidMetricService.java:380) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runAcidMetricService(CompactorTest.java:165) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testInitiatorPerfMetricsEnabled(TestCompactionMetrics.java:134) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_352]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_352]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_352]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T13:34:03,623  WARN [main] metrics.AcidMetricService: Caught exception while trying to fetch compaction metrics from metastore backend db.
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.updateDeltaMBeanAndMetric(AcidMetricService.java:289) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.updateDeltaMetrics(AcidMetricService.java:270) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.run(AcidMetricService.java:119) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runAcidMetricService(CompactorTest.java:166) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testInitiatorPerfMetricsEnabled(TestCompactionMetrics.java:134) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_352]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_352]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_352]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T13:34:03,637  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:34:03,637  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:34:03,637  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:34:03,637  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:34:03,637  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:34:03,637  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:34:03,637  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:34:03,638  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:34:03,638  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:34:03,638  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:34:03,638  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:34:03,638  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:34:03,638  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:34:03,652  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:34:03,653  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:34:03,653  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:34:03,653  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2914a328 will be shutdown
2023-02-15T13:34:03,653  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3af6c672 created in the thread with id: 1
2023-02-15T13:34:03,664  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:34:03,665  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.metrics.metrics2.CodahaleMetrics
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.common.metrics.metrics2.JsonFileMetricsReporter
2023-02-15T13:34:03,672  INFO [main] metrics2.JsonFileMetricsReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:34:03,679  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.mapwb	
2023-02-15T13:34:03,683  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:mapwb, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_5/mapwb, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:34:03,684  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_5/mapwb specified for non-external table:mapwb
2023-02-15T13:34:03,684  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_5/mapwb
2023-02-15T13:34:03,703  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.mapwb	
2023-02-15T13:34:03,711  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_5/mapwb/ds=today
2023-02-15T13:34:03,737  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]) with min_open_txn: 1
2023-02-15T13:34:03,740  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 21
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 22
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 23
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 24
2023-02-15T13:34:03,741  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 25
2023-02-15T13:34:03,742  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=mapwb (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])
2023-02-15T13:34:03,744  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:34:03,747  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,747  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:34:03,750  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2023-02-15T13:34:03,752  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,752  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2023-02-15T13:34:03,754  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:34:03,756  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,756  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:34:03,758  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2023-02-15T13:34:03,761  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,761  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2023-02-15T13:34:03,763  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:34:03,765  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,765  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:34:03,767  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:34:03,769  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,769  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:34:03,771  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2023-02-15T13:34:03,774  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,774  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:34:03,776  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2023-02-15T13:34:03,778  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,778  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:34:03,780  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2023-02-15T13:34:03,782  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,782  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:34:03,784  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2023-02-15T13:34:03,786  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,786  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:34:03,788  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2023-02-15T13:34:03,790  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,790  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2023-02-15T13:34:03,792  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2023-02-15T13:34:03,794  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,794  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2023-02-15T13:34:03,796  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:13
2023-02-15T13:34:03,798  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,798  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2023-02-15T13:34:03,800  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:14
2023-02-15T13:34:03,802  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,802  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:14
2023-02-15T13:34:03,804  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2023-02-15T13:34:03,807  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,807  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2023-02-15T13:34:03,809  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2023-02-15T13:34:03,811  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,811  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:34:03,813  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2023-02-15T13:34:03,815  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,815  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:34:03,817  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2023-02-15T13:34:03,820  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,820  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:34:03,822  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2023-02-15T13:34:03,824  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,824  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:34:03,826  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2023-02-15T13:34:03,829  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,829  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:34:03,831  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:21
2023-02-15T13:34:03,833  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,833  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:21
2023-02-15T13:34:03,836  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:22
2023-02-15T13:34:03,838  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,838  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:22
2023-02-15T13:34:03,840  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:23
2023-02-15T13:34:03,842  INFO [main] txn.TxnHandler: Removed transactions: ([23]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,842  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:23
2023-02-15T13:34:03,844  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:24
2023-02-15T13:34:03,847  INFO [main] txn.TxnHandler: Removed transactions: ([24]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,847  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:24
2023-02-15T13:34:03,849  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:25
2023-02-15T13:34:03,851  INFO [main] txn.TxnHandler: Removed transactions: ([25]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:03,851  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:25
2023-02-15T13:34:03,867  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:34:03,867  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:34:03,867  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:34:03,867  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:34:03,867  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:34:03,867  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:34:03,867  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:34:03,867  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:34:03,867  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:34:03,867  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:34:03,867  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:34:03,867  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:34:03,868  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T13:34:03,870  INFO [main] compactor.Worker: Starting Worker thread
2023-02-15T13:34:03,870  INFO [main] compactor.Worker: [wasabi] Worker 111
2023-02-15T13:34:03,870  INFO [main] compactor.Worker: [wasabi] Worker 117
2023-02-15T13:34:03,870  INFO [main_timeout_executor] compactor.Worker: [wasabi] Worker 281
2023-02-15T13:34:03,874  INFO [main_timeout_executor] compactor.Worker: Processing compaction request id:1,dbname:default,tableName:mapwb,partName:ds=today,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:,workerId: labdas-720,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:34:03,875  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.mapwb	
2023-02-15T13:34:03,875  INFO [main_timeout_executor] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:34:03,875  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a952884, with PersistenceManager: null will be shutdown
2023-02-15T13:34:03,875  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a952884, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@22834e97 created in the thread with id: 721
2023-02-15T13:34:03,884  INFO [main_timeout_executor] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a952884
2023-02-15T13:34:03,894  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:34:03,894  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_partitions_by_names : tbl=hive.default.mapwb	
2023-02-15T13:34:03,905  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:34:03,911  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([26]) with min_open_txn: 1
2023-02-15T13:34:03,921  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Submitting heartbeat task for TXN 26
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactionHeartbeatService$CompactionHeartbeater
2023-02-15T13:34:03,934  INFO [main_timeout_executor] compactor.Worker: Starting MINOR compaction for default.mapwb.ds=today, id:1 in txnId=26, lockId=1 (TxnStatus: 'o') with compute stats set to true
2023-02-15T13:34:03,934  WARN [main_timeout_executor] compactor.MRCompactor: 2 delta files found for default.mapwb.ds=today located at file:/home/rizky/hive/ql/target/tmp/compactor_test_table_5/mapwb/ds=today! This is likely a sign of misconfiguration, especially if this message repeats.  Check that compaction is running properly.  Check for any runaway/mis-configured process writing to ACID tables, especially using Streaming Ingest API.
2023-02-15T13:34:03,935  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-720-compactor-default.mapwb.ds=today_0' to default queue. (current delta dirs count=1, obsolete delta dirs count=-1. TxnIdRange[21,22}]
2023-02-15T13:34:03,935  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:34:03,936  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:34:03,938  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:34:03,939  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:34:03,945  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:34:03,954  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local718020102_0007
2023-02-15T13:34:03,954  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:34:03,990  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:34:03,990  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-720-compactor-default.mapwb.ds=today_0' with jobID=job_local718020102_0007 compaction ID=1
2023-02-15T13:34:03,990  INFO [Thread-671] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:34:03,990  INFO [Thread-671] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:34:03,991  INFO [Thread-671] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:34:03,991  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local718020102_0007_m_000000_0
2023-02-15T13:34:03,991  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:34:03,991  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 144, deltas: [delta_0000021_0000022]}
2023-02-15T13:34:03,991  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:34:03,998  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:34:03,998  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local718020102_0007_m_000000_0 is done. And is in the process of committing
2023-02-15T13:34:03,998  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:34:03,998  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local718020102_0007_m_000000_0' done.
2023-02-15T13:34:03,998  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local718020102_0007_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=14322
		FILE: Number of bytes written=8606129
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=212
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=856162304
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:34:03,998  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local718020102_0007_m_000000_0
2023-02-15T13:34:03,998  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local718020102_0007_m_000001_0
2023-02-15T13:34:03,998  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:34:03,998  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 144, deltas: [delta_0000021_0000022]}
2023-02-15T13:34:03,998  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:34:04,002  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:34:04,002  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local718020102_0007_m_000001_0 is done. And is in the process of committing
2023-02-15T13:34:04,002  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:34:04,002  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local718020102_0007_m_000001_0' done.
2023-02-15T13:34:04,002  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local718020102_0007_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=14925
		FILE: Number of bytes written=8606257
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=212
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=856162304
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:34:04,002  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local718020102_0007_m_000001_0
2023-02-15T13:34:04,002  INFO [Thread-671] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:34:08,994  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-720-compactor-default.mapwb.ds=today_1' to default queue. (current delta dirs count=1, obsolete delta dirs count=-1. TxnIdRange[23,24}]
2023-02-15T13:34:08,995  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:34:08,998  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:34:09,003  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:34:09,007  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:34:09,034  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:34:09,056  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local2092409056_0008
2023-02-15T13:34:09,056  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:34:09,093  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:34:09,093  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-720-compactor-default.mapwb.ds=today_1' with jobID=job_local2092409056_0008 compaction ID=1
2023-02-15T13:34:09,093  INFO [Thread-706] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:34:09,093  INFO [Thread-706] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:34:09,094  INFO [Thread-706] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:34:09,094  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2092409056_0008_m_000000_0
2023-02-15T13:34:09,095  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:34:09,095  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 144, deltas: [delta_0000023_0000024]}
2023-02-15T13:34:09,095  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:34:09,101  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:34:09,101  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2092409056_0008_m_000000_0 is done. And is in the process of committing
2023-02-15T13:34:09,102  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:34:09,102  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2092409056_0008_m_000000_0' done.
2023-02-15T13:34:09,102  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2092409056_0008_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=15579
		FILE: Number of bytes written=9831570
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=212
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=856162304
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:34:09,102  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2092409056_0008_m_000000_0
2023-02-15T13:34:09,102  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2092409056_0008_m_000001_0
2023-02-15T13:34:09,102  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:34:09,102  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 144, deltas: [delta_0000023_0000024]}
2023-02-15T13:34:09,103  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:34:09,106  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:34:09,106  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2092409056_0008_m_000001_0 is done. And is in the process of committing
2023-02-15T13:34:09,107  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:34:09,107  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2092409056_0008_m_000001_0' done.
2023-02-15T13:34:09,107  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2092409056_0008_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=16182
		FILE: Number of bytes written=9831698
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=212
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=856162304
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:34:09,107  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2092409056_0008_m_000001_0
2023-02-15T13:34:09,107  INFO [Thread-706] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:34:14,200  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-720-compactor-default.mapwb.ds=today' to default queue. (current delta dirs count=6, obsolete delta dirs count=0. TxnIdRange[21,24}]
2023-02-15T13:34:14,201  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:34:14,203  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:34:14,210  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:34:14,212  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:34:14,226  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:34:14,258  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local1066715176_0009
2023-02-15T13:34:14,258  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:34:14,294  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:34:14,294  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-720-compactor-default.mapwb.ds=today' with jobID=job_local1066715176_0009 compaction ID=1
2023-02-15T13:34:14,294  INFO [Thread-766] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:34:14,294  INFO [Thread-766] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:34:14,295  INFO [Thread-766] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:34:14,295  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1066715176_0009_m_000000_0
2023-02-15T13:34:14,296  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:34:14,296  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 496, deltas: [delete_delta_0000021_0000022_v0000026, delta_0000021_0000022, delta_0000021_0000022_v0000026, delete_delta_0000023_0000024_v0000026, delta_0000023_0000024, delta_0000023_0000024_v0000026]}
2023-02-15T13:34:14,296  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:34:14,303  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:34:14,303  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1066715176_0009_m_000000_0 is done. And is in the process of committing
2023-02-15T13:34:14,303  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:34:14,303  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1066715176_0009_m_000000_0' done.
2023-02-15T13:34:14,303  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1066715176_0009_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=18643
		FILE: Number of bytes written=11060810
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=842
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=855638016
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:34:14,303  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1066715176_0009_m_000000_0
2023-02-15T13:34:14,303  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1066715176_0009_m_000001_0
2023-02-15T13:34:14,303  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:34:14,303  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 496, deltas: [delete_delta_0000021_0000022_v0000026, delta_0000021_0000022, delta_0000021_0000022_v0000026, delete_delta_0000023_0000024_v0000026, delta_0000023_0000024, delta_0000023_0000024_v0000026]}
2023-02-15T13:34:14,303  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:34:14,307  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:34:14,307  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1066715176_0009_m_000001_0 is done. And is in the process of committing
2023-02-15T13:34:14,308  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:34:14,308  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1066715176_0009_m_000001_0' done.
2023-02-15T13:34:14,308  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1066715176_0009_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=20438
		FILE: Number of bytes written=11061170
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=842
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=855638016
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:34:14,308  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1066715176_0009_m_000001_0
2023-02-15T13:34:14,308  INFO [Thread-766] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:34:19,296  INFO [main_timeout_executor] compactor.Worker: Completed MINOR compaction for default.mapwb.ds=today in txnId=26, lockId=1 (TxnStatus: 'o'), marking as compacted.
2023-02-15T13:34:19,304  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Stopping heartbeat task for TXN 26
2023-02-15T13:34:19,304  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Shutting down compaction txn heartbeater instance.
2023-02-15T13:34:19,304  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Compaction txn heartbeater instance is successfully stopped.
2023-02-15T13:34:19,309  INFO [main_timeout_executor] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:26
2023-02-15T13:34:19,317  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([26]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:19,318  INFO [main_timeout_executor] compactor.StatsUpdater: id:1,dbname:default,tableName:mapwb,partName:ds=today,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:,workerId: labdas-720,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0: running 'analyze table default.mapwb partition(ds='today') compute statistics noscan'
Hive Session ID = b1effd10-3cac-488c-aa06-78a2b6a465dc
2023-02-15T13:34:19,318  INFO [main_timeout_executor] SessionState: Hive Session ID = b1effd10-3cac-488c-aa06-78a2b6a465dc
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/rizky/hive/conf/ivysettings.xml will be used
2023-02-15T13:34:19,318  INFO [main_timeout_executor] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/rizky/hive/conf/ivysettings.xml will be used
2023-02-15T13:34:19,321  INFO [main_timeout_executor] session.SessionState: Created HDFS directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/b1effd10-3cac-488c-aa06-78a2b6a465dc
2023-02-15T13:34:19,321  INFO [main_timeout_executor] session.SessionState: Created local directory: /home/rizky/hive/ql/target/tmp/localscratchdir/b1effd10-3cac-488c-aa06-78a2b6a465dc
2023-02-15T13:34:19,322  INFO [main_timeout_executor] session.SessionState: Created HDFS directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/b1effd10-3cac-488c-aa06-78a2b6a465dc/_tmp_space.db
2023-02-15T13:34:19,323  INFO [main_timeout_executor] ql.Driver: Compiling command(queryId=rizky_20230215133419_86737a5c-5d94-41f8-ad44-3fee5b14fd07): analyze table default.mapwb partition(ds='today') compute statistics noscan
2023-02-15T13:34:19,324  INFO [main_timeout_executor] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:34:19,324  INFO [main_timeout_executor] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:34:19,325  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a952884, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@22834e97 will be shutdown
2023-02-15T13:34:19,325  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a952884, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@497f93f2 created in the thread with id: 721
2023-02-15T13:34:19,327  INFO [main_timeout_executor] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:34:19,327  INFO [main_timeout_executor] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer
2023-02-15T13:34:19,329  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([27]) with min_open_txn: 27
2023-02-15T13:34:19,329  INFO [main_timeout_executor] lockmgr.DbTxnManager: Opened txnid:27
2023-02-15T13:34:19,329  INFO [main_timeout_executor] ql.QueryState: Query-level HMS cache created for rizky_20230215133419_86737a5c-5d94-41f8-ad44-3fee5b14fd07
2023-02-15T13:34:19,329  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.mapwb	
2023-02-15T13:34:19,332  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:34:19,332  INFO [main_timeout_executor] parse.ColumnStatsSemanticAnalyzer: Invoking analyze on original query
2023-02-15T13:34:19,332  INFO [main_timeout_executor] parse.ColumnStatsSemanticAnalyzer: Starting Semantic Analysis
2023-02-15T13:34:19,333 ERROR [main_timeout_executor] session.SessionState: Error setting up authorization: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	... 22 more
FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
2023-02-15T13:34:19,333 ERROR [main_timeout_executor] ql.Driver: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001)
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331)
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141)
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96)
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81)
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93)
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530)
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360)
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977)
	... 21 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350)
	... 22 more

2023-02-15T13:34:19,333  INFO [main_timeout_executor] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2023-02-15T13:34:19,333  INFO [main_timeout_executor] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=1, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=3, flushCache_()=0, getValidTxns_(long)=0}
2023-02-15T13:34:19,333  INFO [main_timeout_executor] ql.Driver: Completed compiling command(queryId=rizky_20230215133419_86737a5c-5d94-41f8-ad44-3fee5b14fd07); Time taken: 0.01 seconds
2023-02-15T13:34:19,333  INFO [main_timeout_executor] lockmgr.DbTxnManager: Stopped heartbeat for query: rizky_20230215133419_86737a5c-5d94-41f8-ad44-3fee5b14fd07
2023-02-15T13:34:19,335  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([27]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:19,338  WARN [main_timeout_executor] txn.TxnHandler: Aborted 1 transaction(s) [27] due to rollback
2023-02-15T13:34:19,338 ERROR [main_timeout_executor] ql.Driver: Failed to run analyze table default.mapwb partition(ds='today') compute statistics noscan
org.apache.hadoop.hive.ql.processors.CommandProcessorException: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.DriverUtils.createProcessorException(DriverUtils.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.handleException(Compiler.java:479) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:121) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
2023-02-15T13:34:19,339  INFO [main_timeout_executor] cleanup.SyncCleanupService: Deleted directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/b1effd10-3cac-488c-aa06-78a2b6a465dc on fs with scheme file
2023-02-15T13:34:19,339  INFO [main_timeout_executor] cleanup.SyncCleanupService: Deleted directory: /home/rizky/hive/ql/target/tmp/localscratchdir/b1effd10-3cac-488c-aa06-78a2b6a465dc on fs with scheme file
2023-02-15T13:34:19,339 ERROR [main_timeout_executor] compactor.StatsUpdater: id:1,dbname:default,tableName:mapwb,partName:ds=today,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:,workerId: labdas-720,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0: gatherStats(default,mapwb,ds=today) failed due to: Failed to run analyze table default.mapwb partition(ds='today') compute statistics noscan
org.apache.hadoop.hive.ql.metadata.HiveException: Failed to run analyze table default.mapwb partition(ds='today') compute statistics noscan
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:99) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: org.apache.hadoop.hive.ql.processors.CommandProcessorException: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.DriverUtils.createProcessorException(DriverUtils.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.handleException(Compiler.java:479) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:121) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
2023-02-15T13:34:19,339  INFO [main] compactor.Worker: [wasabi] Worker 163
2023-02-15T13:34:19,339  INFO [main] compactor.Worker: [wasabi] Worker 170
2023-02-15T13:34:19,360  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:34:19,360  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:34:19,360  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:34:19,360  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:34:19,360  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:34:19,360  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:34:19,360  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:34:19,360  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:34:19,360  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:34:19,360  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:34:19,360  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:34:19,360  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:34:19,360  INFO [main] compactor.Cleaner: Starting Cleaner thread
2023-02-15T13:34:19,365  INFO [main] compactor.Cleaner: Cleaning based on min open txn id: 27
2023-02-15T13:34:19,366  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:1,dbname:default,tableName:mapwb,partName:ds=today,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:34:19,367  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:34:19,367  INFO [Cleaner-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:34:19,367  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7f4f1c3d, with PersistenceManager: null will be shutdown
2023-02-15T13:34:19,367  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7f4f1c3d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@b3d856e created in the thread with id: 879
2023-02-15T13:34:19,369  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7f4f1c3d
2023-02-15T13:34:19,377  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=1 About to remove 6 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_5/mapwb/ds=today. [delete_delta_0000021_0000022_v0000026,delta_0000021_0000022,delta_0000021_0000022_v0000026,delete_delta_0000023_0000024_v0000026,delta_0000023_0000024,delta_0000023_0000024_v0000026]
2023-02-15T13:34:19,382  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:34:19,397  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:34:19,397  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:34:19,397  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:34:19,397  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:34:19,397  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:34:19,397  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:34:19,397  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:34:19,397  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:34:19,397  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:34:19,397  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:34:19,397  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:34:19,397  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:34:19,397  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T13:34:19,398  INFO [main] compactor.Worker: Starting Worker thread
2023-02-15T13:34:19,398  INFO [main] compactor.Worker: [wasabi] Worker 111
2023-02-15T13:34:19,398  INFO [main] compactor.Worker: [wasabi] Worker 117
2023-02-15T13:34:19,398  INFO [main_timeout_executor] compactor.Worker: [wasabi] Worker 281
2023-02-15T13:34:19,399  INFO [main_timeout_executor] compactor.Worker: Processing compaction request id:2,dbname:default,tableName:mapwb,partName:ds=today,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:,workerId: labdas-880,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:34:19,400  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.mapwb	
2023-02-15T13:34:19,400  INFO [main_timeout_executor] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:34:19,400  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e1218cd, with PersistenceManager: null will be shutdown
2023-02-15T13:34:19,400  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e1218cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@63d263cb created in the thread with id: 881
2023-02-15T13:34:19,401  INFO [main_timeout_executor] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e1218cd
2023-02-15T13:34:19,404  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:34:19,404  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_partitions_by_names : tbl=hive.default.mapwb	
2023-02-15T13:34:19,406  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:34:19,409  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([28]) with min_open_txn: 27
2023-02-15T13:34:19,417  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Submitting heartbeat task for TXN 28
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactionHeartbeatService$CompactionHeartbeater
2023-02-15T13:34:19,431  INFO [main_timeout_executor] compactor.Worker: Starting MAJOR compaction for default.mapwb.ds=today, id:2 in txnId=28, lockId=2 (TxnStatus: 'o') with compute stats set to true
2023-02-15T13:34:19,432  WARN [main_timeout_executor] compactor.MRCompactor: 2 delta files found for default.mapwb.ds=today located at file:/home/rizky/hive/ql/target/tmp/compactor_test_table_5/mapwb/ds=today! This is likely a sign of misconfiguration, especially if this message repeats.  Check that compaction is running properly.  Check for any runaway/mis-configured process writing to ACID tables, especially using Streaming Ingest API.
2023-02-15T13:34:19,432  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-880-compactor-default.mapwb.ds=today_0' to default queue. (current delta dirs count=0, obsolete delta dirs count=-1. TxnIdRange[9223372036854775807,-9223372036854775808}]
2023-02-15T13:34:19,432  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:34:19,433  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:34:19,435  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:34:19,437  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:34:19,443  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:0
2023-02-15T13:34:19,451  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local1350935493_0010
2023-02-15T13:34:19,451  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:34:19,485  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:34:19,485  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-880-compactor-default.mapwb.ds=today_0' with jobID=job_local1350935493_0010 compaction ID=2
2023-02-15T13:34:19,485  INFO [Thread-819] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:34:19,485  INFO [Thread-819] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:34:19,486  INFO [Thread-819] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:34:19,486  INFO [Thread-819] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:34:19,486  INFO [Thread-819] compactor.MRCompactor: job_local1350935493_0010: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_5/mapwb/ds=today/_tmp_4d1c4b70-466d-46eb-8728-2d046d70b0b3 not found.  Assuming 0 splits.  Creating file:/home/rizky/hive/ql/target/tmp/compactor_test_table_5/mapwb/ds=today/delta_9223372036854775807_-9223372036854775808_v0000028
2023-02-15T13:34:24,490  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-880-compactor-default.mapwb.ds=today_1' to default queue. (current delta dirs count=0, obsolete delta dirs count=-1. TxnIdRange[9223372036854775807,-9223372036854775808}]
2023-02-15T13:34:24,491  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:34:24,493  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:34:24,502  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:34:24,511  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:34:24,541  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:0
2023-02-15T13:34:24,573  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local82038217_0011
2023-02-15T13:34:24,573  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:34:24,613  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:34:24,613  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-880-compactor-default.mapwb.ds=today_1' with jobID=job_local82038217_0011 compaction ID=2
2023-02-15T13:34:24,613  INFO [Thread-842] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:34:24,613  INFO [Thread-842] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:34:24,613  INFO [Thread-842] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:34:24,613  INFO [Thread-842] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:34:24,614  INFO [Thread-842] compactor.MRCompactor: job_local82038217_0011: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_5/mapwb/ds=today/_tmp_494f02c4-0a50-4de2-a11f-80a6ea742eaa not found.  Assuming 0 splits.  Creating file:/home/rizky/hive/ql/target/tmp/compactor_test_table_5/mapwb/ds=today/delta_9223372036854775807_-9223372036854775808_v0000028
2023-02-15T13:34:24,629  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MAJOR compaction job 'labdas-880-compactor-default.mapwb.ds=today' to default queue. (current delta dirs count=2, obsolete delta dirs count=1. TxnIdRange[21,24}]
2023-02-15T13:34:24,629  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:34:24,630  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:34:24,632  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:34:24,633  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:34:24,640  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:34:24,650  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local1366292787_0012
2023-02-15T13:34:24,650  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:34:24,686  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:34:24,686  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-880-compactor-default.mapwb.ds=today' with jobID=job_local1366292787_0012 compaction ID=2
2023-02-15T13:34:24,686  INFO [Thread-875] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:34:24,686  INFO [Thread-875] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:34:24,687  INFO [Thread-875] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:34:24,687  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1366292787_0012_m_000000_0
2023-02-15T13:34:24,688  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:34:24,688  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_5/mapwb/ds=today/base_20, bucket: 0, length: 1776, deltas: [delete_delta_0000021_0000024_v0000026, delta_0000021_0000024_v0000026]}
2023-02-15T13:34:24,688  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:34:24,692  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:34:24,692  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1366292787_0012_m_000000_0 is done. And is in the process of committing
2023-02-15T13:34:24,692  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:34:24,692  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1366292787_0012_m_000000_0' done.
2023-02-15T13:34:24,692  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1366292787_0012_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=23333
		FILE: Number of bytes written=14726866
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=451
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=855638016
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:34:24,692  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1366292787_0012_m_000000_0
2023-02-15T13:34:24,692  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1366292787_0012_m_000001_0
2023-02-15T13:34:24,692  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:34:24,693  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_5/mapwb/ds=today/base_20, bucket: 1, length: 1776, deltas: [delete_delta_0000021_0000024_v0000026, delta_0000021_0000024_v0000026]}
2023-02-15T13:34:24,693  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:34:24,695  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:34:24,695  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1366292787_0012_m_000001_0 is done. And is in the process of committing
2023-02-15T13:34:24,695  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:34:24,695  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1366292787_0012_m_000001_0' done.
2023-02-15T13:34:24,695  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1366292787_0012_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=26090
		FILE: Number of bytes written=14727490
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=451
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=855638016
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:34:24,695  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1366292787_0012_m_000001_0
2023-02-15T13:34:24,695  INFO [Thread-875] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:34:29,405  INFO [Metastore Scheduled Worker 1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:34:29,407  INFO [Metastore Scheduled Worker 1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a1e3509, with PersistenceManager: null will be shutdown
2023-02-15T13:34:29,407  INFO [Metastore Scheduled Worker 1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a1e3509, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16fcb79 created in the thread with id: 45
2023-02-15T13:34:29,411  INFO [Metastore Scheduled Worker 1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3a1e3509
2023-02-15T13:34:29,689  INFO [main_timeout_executor] compactor.Worker: Completed MAJOR compaction for default.mapwb.ds=today in txnId=28, lockId=2 (TxnStatus: 'o'), marking as compacted.
2023-02-15T13:34:29,691  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Stopping heartbeat task for TXN 28
2023-02-15T13:34:29,691  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Shutting down compaction txn heartbeater instance.
2023-02-15T13:34:29,692  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Compaction txn heartbeater instance is successfully stopped.
2023-02-15T13:34:29,695  INFO [main_timeout_executor] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:28
2023-02-15T13:34:29,701  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([28]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:29,702  INFO [main_timeout_executor] compactor.StatsUpdater: id:2,dbname:default,tableName:mapwb,partName:ds=today,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:,workerId: labdas-880,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0: running 'analyze table default.mapwb partition(ds='today') compute statistics noscan'
Hive Session ID = 3962d578-88d3-4f9e-aed2-b196e78a9d97
2023-02-15T13:34:29,702  INFO [main_timeout_executor] SessionState: Hive Session ID = 3962d578-88d3-4f9e-aed2-b196e78a9d97
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/rizky/hive/conf/ivysettings.xml will be used
2023-02-15T13:34:29,702  INFO [main_timeout_executor] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/rizky/hive/conf/ivysettings.xml will be used
2023-02-15T13:34:29,707  INFO [main_timeout_executor] session.SessionState: Created HDFS directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/3962d578-88d3-4f9e-aed2-b196e78a9d97
2023-02-15T13:34:29,708  INFO [main_timeout_executor] session.SessionState: Created local directory: /home/rizky/hive/ql/target/tmp/localscratchdir/3962d578-88d3-4f9e-aed2-b196e78a9d97
2023-02-15T13:34:29,710  INFO [main_timeout_executor] session.SessionState: Created HDFS directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/3962d578-88d3-4f9e-aed2-b196e78a9d97/_tmp_space.db
2023-02-15T13:34:29,711  INFO [main_timeout_executor] ql.Driver: Compiling command(queryId=rizky_20230215133429_f6d6850c-88eb-4a51-ba01-f482e748fad9): analyze table default.mapwb partition(ds='today') compute statistics noscan
2023-02-15T13:34:29,712  INFO [main_timeout_executor] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:34:29,712  INFO [main_timeout_executor] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:34:29,713  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e1218cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@63d263cb will be shutdown
2023-02-15T13:34:29,713  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2e1218cd, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@63baa938 created in the thread with id: 881
2023-02-15T13:34:29,715  INFO [main_timeout_executor] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:34:29,715  INFO [main_timeout_executor] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer
2023-02-15T13:34:29,718  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([29]) with min_open_txn: 29
2023-02-15T13:34:29,718  INFO [main_timeout_executor] lockmgr.DbTxnManager: Opened txnid:29
2023-02-15T13:34:29,719  INFO [main_timeout_executor] ql.QueryState: Query-level HMS cache created for rizky_20230215133429_f6d6850c-88eb-4a51-ba01-f482e748fad9
2023-02-15T13:34:29,719  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.mapwb	
2023-02-15T13:34:29,731  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:34:29,731  INFO [main_timeout_executor] parse.ColumnStatsSemanticAnalyzer: Invoking analyze on original query
2023-02-15T13:34:29,731  INFO [main_timeout_executor] parse.ColumnStatsSemanticAnalyzer: Starting Semantic Analysis
2023-02-15T13:34:29,731 ERROR [main_timeout_executor] session.SessionState: Error setting up authorization: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	... 22 more
FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
2023-02-15T13:34:29,732 ERROR [main_timeout_executor] ql.Driver: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001)
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331)
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141)
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96)
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81)
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93)
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530)
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360)
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977)
	... 21 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350)
	... 22 more

2023-02-15T13:34:29,732  INFO [main_timeout_executor] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2023-02-15T13:34:29,732  INFO [main_timeout_executor] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=2, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=12, flushCache_()=0, getValidTxns_(long)=0}
2023-02-15T13:34:29,732  INFO [main_timeout_executor] ql.Driver: Completed compiling command(queryId=rizky_20230215133429_f6d6850c-88eb-4a51-ba01-f482e748fad9); Time taken: 0.021 seconds
2023-02-15T13:34:29,732  INFO [main_timeout_executor] lockmgr.DbTxnManager: Stopped heartbeat for query: rizky_20230215133429_f6d6850c-88eb-4a51-ba01-f482e748fad9
2023-02-15T13:34:29,734  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([29]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:29,736  WARN [main_timeout_executor] txn.TxnHandler: Aborted 1 transaction(s) [29] due to rollback
2023-02-15T13:34:29,737 ERROR [main_timeout_executor] ql.Driver: Failed to run analyze table default.mapwb partition(ds='today') compute statistics noscan
org.apache.hadoop.hive.ql.processors.CommandProcessorException: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.DriverUtils.createProcessorException(DriverUtils.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.handleException(Compiler.java:479) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:121) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
2023-02-15T13:34:29,737  INFO [main_timeout_executor] cleanup.SyncCleanupService: Deleted directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/3962d578-88d3-4f9e-aed2-b196e78a9d97 on fs with scheme file
2023-02-15T13:34:29,738  INFO [main_timeout_executor] cleanup.SyncCleanupService: Deleted directory: /home/rizky/hive/ql/target/tmp/localscratchdir/3962d578-88d3-4f9e-aed2-b196e78a9d97 on fs with scheme file
2023-02-15T13:34:29,738 ERROR [main_timeout_executor] compactor.StatsUpdater: id:2,dbname:default,tableName:mapwb,partName:ds=today,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:,workerId: labdas-880,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0: gatherStats(default,mapwb,ds=today) failed due to: Failed to run analyze table default.mapwb partition(ds='today') compute statistics noscan
org.apache.hadoop.hive.ql.metadata.HiveException: Failed to run analyze table default.mapwb partition(ds='today') compute statistics noscan
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:99) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: org.apache.hadoop.hive.ql.processors.CommandProcessorException: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.DriverUtils.createProcessorException(DriverUtils.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.handleException(Compiler.java:479) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:121) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
2023-02-15T13:34:29,738  INFO [main] compactor.Worker: [wasabi] Worker 163
2023-02-15T13:34:29,738  INFO [main] compactor.Worker: [wasabi] Worker 170
2023-02-15T13:34:29,756  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:34:29,756  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:34:29,756  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:34:29,756  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:34:29,756  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:34:29,756  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:34:29,756  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:34:29,756  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:34:29,756  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:34:29,756  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:34:29,756  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:34:29,756  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:34:29,756  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:34:29,769  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:34:29,770  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:34:29,770  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:34:29,770  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3af6c672 will be shutdown
2023-02-15T13:34:29,770  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@d79a69b created in the thread with id: 1
2023-02-15T13:34:29,772  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:34:29,773  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:34:29,792  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:34:29,792  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:34:29,792  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:34:29,792  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:34:29,792  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:34:29,792  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:34:29,792  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:34:29,793  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:34:29,793  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:34:29,793  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:34:29,793  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:34:29,793  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:34:29,793  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:34:29,796  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:34:29,798  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:34:29,798  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:34:29,798  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@d79a69b will be shutdown
2023-02-15T13:34:29,798  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2fda92e0 created in the thread with id: 1
2023-02-15T13:34:29,801  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:34:29,802  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:34:29,823  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:34:29,823  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:34:29,823  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:34:29,823  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:34:29,823  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:34:29,823  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:34:29,823  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:34:29,823  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:34:29,823  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:34:29,823  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:34:29,823  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:34:29,823  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:34:29,823  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:34:29,827  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:34:29,828  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:34:29,829  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:34:29,829  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2fda92e0 will be shutdown
2023-02-15T13:34:29,829  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a641f6 created in the thread with id: 1
2023-02-15T13:34:29,832  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:34:29,834  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:34:29,839  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.failing_table	
2023-02-15T13:34:29,840  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:failing_table, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/failing_table, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:34:29,841  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/failing_table specified for non-external table:failing_table
2023-02-15T13:34:29,841  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/failing_table
2023-02-15T13:34:29,859  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.success_table	
2023-02-15T13:34:29,860  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:success_table, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:34:29,861  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table specified for non-external table:success_table
2023-02-15T13:34:29,861  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table
2023-02-15T13:34:29,865  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:34:29,869  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part0
2023-02-15T13:34:29,893  INFO [Finalizer] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T13:34:29,893  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -2
2023-02-15T13:34:29,893  INFO [Finalizer] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T13:34:29,893  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -3
2023-02-15T13:34:29,899  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:34:29,901  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part1
2023-02-15T13:34:29,925  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:34:29,929  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part2
2023-02-15T13:34:29,966  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:34:29,970  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part3
2023-02-15T13:34:29,996  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:34:29,999  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part4
2023-02-15T13:34:30,033  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:34:30,037  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part5
2023-02-15T13:34:30,068  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:34:30,071  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part6
2023-02-15T13:34:30,099  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:34:30,102  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part7
2023-02-15T13:34:30,139  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:34:30,143  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part8
2023-02-15T13:34:30,175  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:34:30,177  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part9
2023-02-15T13:34:30,212  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]) with min_open_txn: 1
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 21
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 22
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 23
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 24
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 25
2023-02-15T13:34:30,216  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=success_table (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])
2023-02-15T13:34:30,219  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:34:30,221  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,222  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:34:30,224  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2023-02-15T13:34:30,227  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,227  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2023-02-15T13:34:30,229  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:34:30,231  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,231  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:34:30,233  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2023-02-15T13:34:30,235  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,235  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2023-02-15T13:34:30,237  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:34:30,240  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,240  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:34:30,242  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:34:30,244  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,244  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:34:30,246  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2023-02-15T13:34:30,249  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,249  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:34:30,251  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2023-02-15T13:34:30,253  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,253  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:34:30,255  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2023-02-15T13:34:30,257  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,258  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:34:30,260  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2023-02-15T13:34:30,262  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,262  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:34:30,264  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2023-02-15T13:34:30,267  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,267  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2023-02-15T13:34:30,269  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2023-02-15T13:34:30,272  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,272  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2023-02-15T13:34:30,274  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:13
2023-02-15T13:34:30,276  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,276  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2023-02-15T13:34:30,278  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:14
2023-02-15T13:34:30,280  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,280  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:14
2023-02-15T13:34:30,282  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2023-02-15T13:34:30,285  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,285  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2023-02-15T13:34:30,287  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2023-02-15T13:34:30,289  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,289  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:34:30,291  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2023-02-15T13:34:30,293  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,293  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:34:30,295  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2023-02-15T13:34:30,297  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,297  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:34:30,299  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2023-02-15T13:34:30,301  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,301  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:34:30,303  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2023-02-15T13:34:30,305  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,305  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:34:30,307  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:21
2023-02-15T13:34:30,309  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,309  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:21
2023-02-15T13:34:30,311  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:22
2023-02-15T13:34:30,314  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,314  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:22
2023-02-15T13:34:30,315  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:23
2023-02-15T13:34:30,317  INFO [main] txn.TxnHandler: Removed transactions: ([23]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,318  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:23
2023-02-15T13:34:30,319  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:24
2023-02-15T13:34:30,321  INFO [main] txn.TxnHandler: Removed transactions: ([24]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,321  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:24
2023-02-15T13:34:30,323  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:25
2023-02-15T13:34:30,325  INFO [main] txn.TxnHandler: Removed transactions: ([25]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:30,325  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:25
2023-02-15T13:34:30,337  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([26]) with min_open_txn: 1
2023-02-15T13:34:30,343  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:26
2023-02-15T13:34:30,347  INFO [main] txn.TxnHandler: Removed transactions: ([26]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:32,356  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([27]) with min_open_txn: 27
2023-02-15T13:34:32,360  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:27
2023-02-15T13:34:32,364  INFO [main] txn.TxnHandler: Removed transactions: ([27]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:34,373  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([28]) with min_open_txn: 28
2023-02-15T13:34:34,378  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:28
2023-02-15T13:34:34,382  INFO [main] txn.TxnHandler: Removed transactions: ([28]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:36,392  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([29]) with min_open_txn: 29
2023-02-15T13:34:36,396  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:29
2023-02-15T13:34:36,400  INFO [main] txn.TxnHandler: Removed transactions: ([29]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:38,411  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([30]) with min_open_txn: 30
2023-02-15T13:34:38,420  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:30
2023-02-15T13:34:38,424  INFO [main] txn.TxnHandler: Removed transactions: ([30]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:40,434  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([31]) with min_open_txn: 31
2023-02-15T13:34:40,438  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:31
2023-02-15T13:34:40,442  INFO [main] txn.TxnHandler: Removed transactions: ([31]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:42,451  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([32]) with min_open_txn: 32
2023-02-15T13:34:42,456  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:32
2023-02-15T13:34:42,460  INFO [main] txn.TxnHandler: Removed transactions: ([32]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:44,469  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([33]) with min_open_txn: 33
2023-02-15T13:34:44,474  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:33
2023-02-15T13:34:44,478  INFO [main] txn.TxnHandler: Removed transactions: ([33]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:46,488  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([34]) with min_open_txn: 34
2023-02-15T13:34:46,492  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:34
2023-02-15T13:34:46,496  INFO [main] txn.TxnHandler: Removed transactions: ([34]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:48,506  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([35]) with min_open_txn: 35
2023-02-15T13:34:48,510  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:35
2023-02-15T13:34:48,514  INFO [main] txn.TxnHandler: Removed transactions: ([35]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,514  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.failing_table	
2023-02-15T13:34:50,528  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/failing_table/ds=part0
2023-02-15T13:34:50,618  INFO [Finalizer] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T13:34:50,618  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -4
2023-02-15T13:34:50,637  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.failing_table	
2023-02-15T13:34:50,639  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/failing_table/ds=part1
2023-02-15T13:34:50,659  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.failing_table	
2023-02-15T13:34:50,661  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/failing_table/ds=part2
2023-02-15T13:34:50,680  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.failing_table	
2023-02-15T13:34:50,682  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/failing_table/ds=part3
2023-02-15T13:34:50,700  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.failing_table	
2023-02-15T13:34:50,702  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/failing_table/ds=part4
2023-02-15T13:34:50,721  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.failing_table	
2023-02-15T13:34:50,723  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/failing_table/ds=part5
2023-02-15T13:34:50,754  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60]) with min_open_txn: 36
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 36
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 37
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 38
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 39
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 40
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 41
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 42
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 43
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 44
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 45
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 46
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 47
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 48
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 49
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 50
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 51
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 52
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 53
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 54
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 55
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 56
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 57
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 58
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 59
2023-02-15T13:34:50,758  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 60
2023-02-15T13:34:50,759  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=failing_table (txnIds: [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60])
2023-02-15T13:34:50,761  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:36
2023-02-15T13:34:50,763  INFO [main] txn.TxnHandler: Removed transactions: ([36]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,764  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:36
2023-02-15T13:34:50,766  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:37
2023-02-15T13:34:50,768  INFO [main] txn.TxnHandler: Removed transactions: ([37]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,768  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:37
2023-02-15T13:34:50,770  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:38
2023-02-15T13:34:50,772  INFO [main] txn.TxnHandler: Removed transactions: ([38]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,772  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:38
2023-02-15T13:34:50,774  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:39
2023-02-15T13:34:50,776  INFO [main] txn.TxnHandler: Removed transactions: ([39]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,776  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:39
2023-02-15T13:34:50,778  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:40
2023-02-15T13:34:50,780  INFO [main] txn.TxnHandler: Removed transactions: ([40]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,780  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:40
2023-02-15T13:34:50,781  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:41
2023-02-15T13:34:50,783  INFO [main] txn.TxnHandler: Removed transactions: ([41]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,784  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:41
2023-02-15T13:34:50,785  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:42
2023-02-15T13:34:50,787  INFO [main] txn.TxnHandler: Removed transactions: ([42]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,787  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:42
2023-02-15T13:34:50,789  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:43
2023-02-15T13:34:50,791  INFO [main] txn.TxnHandler: Removed transactions: ([43]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,792  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:43
2023-02-15T13:34:50,793  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:44
2023-02-15T13:34:50,796  INFO [main] txn.TxnHandler: Removed transactions: ([44]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,796  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:44
2023-02-15T13:34:50,798  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:45
2023-02-15T13:34:50,800  INFO [main] txn.TxnHandler: Removed transactions: ([45]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,800  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:45
2023-02-15T13:34:50,802  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:46
2023-02-15T13:34:50,804  INFO [main] txn.TxnHandler: Removed transactions: ([46]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,804  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:46
2023-02-15T13:34:50,806  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:47
2023-02-15T13:34:50,809  INFO [main] txn.TxnHandler: Removed transactions: ([47]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,809  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:47
2023-02-15T13:34:50,811  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:48
2023-02-15T13:34:50,813  INFO [main] txn.TxnHandler: Removed transactions: ([48]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,813  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:48
2023-02-15T13:34:50,815  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:49
2023-02-15T13:34:50,818  INFO [main] txn.TxnHandler: Removed transactions: ([49]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,818  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:49
2023-02-15T13:34:50,820  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:50
2023-02-15T13:34:50,822  INFO [main] txn.TxnHandler: Removed transactions: ([50]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,822  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:50
2023-02-15T13:34:50,824  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:51
2023-02-15T13:34:50,826  INFO [main] txn.TxnHandler: Removed transactions: ([51]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,827  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:51
2023-02-15T13:34:50,828  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:52
2023-02-15T13:34:50,830  INFO [main] txn.TxnHandler: Removed transactions: ([52]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,830  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:52
2023-02-15T13:34:50,832  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:53
2023-02-15T13:34:50,834  INFO [main] txn.TxnHandler: Removed transactions: ([53]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,834  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:53
2023-02-15T13:34:50,836  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:54
2023-02-15T13:34:50,838  INFO [main] txn.TxnHandler: Removed transactions: ([54]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,838  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:54
2023-02-15T13:34:50,840  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:55
2023-02-15T13:34:50,842  INFO [main] txn.TxnHandler: Removed transactions: ([55]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,842  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:55
2023-02-15T13:34:50,843  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:56
2023-02-15T13:34:50,845  INFO [main] txn.TxnHandler: Removed transactions: ([56]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,845  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:56
2023-02-15T13:34:50,847  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:57
2023-02-15T13:34:50,849  INFO [main] txn.TxnHandler: Removed transactions: ([57]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,849  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:57
2023-02-15T13:34:50,851  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:58
2023-02-15T13:34:50,853  INFO [main] txn.TxnHandler: Removed transactions: ([58]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,853  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:58
2023-02-15T13:34:50,855  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:59
2023-02-15T13:34:50,856  INFO [main] txn.TxnHandler: Removed transactions: ([59]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,857  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:59
2023-02-15T13:34:50,858  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:60
2023-02-15T13:34:50,860  INFO [main] txn.TxnHandler: Removed transactions: ([60]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:50,860  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:60
2023-02-15T13:34:50,871  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([61]) with min_open_txn: 36
2023-02-15T13:34:50,877  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:61
2023-02-15T13:34:50,880  INFO [main] txn.TxnHandler: Removed transactions: ([61]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:52,890  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([62]) with min_open_txn: 62
2023-02-15T13:34:52,898  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:62
2023-02-15T13:34:52,902  INFO [main] txn.TxnHandler: Removed transactions: ([62]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:54,911  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([63]) with min_open_txn: 63
2023-02-15T13:34:54,915  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:63
2023-02-15T13:34:54,918  INFO [main] txn.TxnHandler: Removed transactions: ([63]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:56,927  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([64]) with min_open_txn: 64
2023-02-15T13:34:56,931  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:64
2023-02-15T13:34:56,934  INFO [main] txn.TxnHandler: Removed transactions: ([64]) from MIN_HISTORY_LEVEL
2023-02-15T13:34:58,944  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([65]) with min_open_txn: 65
2023-02-15T13:34:58,948  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:65
2023-02-15T13:34:58,951  INFO [main] txn.TxnHandler: Removed transactions: ([65]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:00,960  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([66]) with min_open_txn: 66
2023-02-15T13:35:00,964  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:66
2023-02-15T13:35:00,967  INFO [main] txn.TxnHandler: Removed transactions: ([66]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:02,980  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:02,980  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:02,980  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:02,980  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:02,980  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:02,980  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:02,980  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:02,980  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:02,980  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:02,980  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:02,980  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:02,980  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:02,982  INFO [main] compactor.Cleaner: Starting Cleaner thread
2023-02-15T13:35:02,989  INFO [main] compactor.Cleaner: Cleaning based on min open txn id: 67
2023-02-15T13:35:02,989  INFO [Cleaner-executor-thread-3] compactor.Cleaner: Starting cleaning for id:3,dbname:default,tableName:success_table,partName:ds=part2,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:02,989  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:1,dbname:default,tableName:success_table,partName:ds=part0,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:02,989  INFO [Cleaner-executor-thread-4] compactor.Cleaner: Starting cleaning for id:4,dbname:default,tableName:success_table,partName:ds=part3,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:02,989  INFO [Cleaner-executor-thread-2] compactor.Cleaner: Starting cleaning for id:2,dbname:default,tableName:success_table,partName:ds=part1,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:02,990  INFO [Cleaner-executor-thread-5] compactor.Cleaner: Starting cleaning for id:5,dbname:default,tableName:success_table,partName:ds=part4,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:02,990  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:02,990  INFO [Cleaner-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:02,990  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20c396e3, with PersistenceManager: null will be shutdown
2023-02-15T13:35:02,990  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20c396e3, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6c9d1b41 created in the thread with id: 1340
2023-02-15T13:35:03,000  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@20c396e3
2023-02-15T13:35:03,009  INFO [Cleaner-executor-thread-2] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:03,010  INFO [Cleaner-executor-thread-4] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:03,010  INFO [Cleaner-executor-thread-3] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:03,010  INFO [Cleaner-executor-thread-5] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:03,010  INFO [Cleaner-executor-thread-3] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@28eea99c, with PersistenceManager: null will be shutdown
2023-02-15T13:35:03,011  INFO [Cleaner-executor-thread-3] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@28eea99c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@50f95bf created in the thread with id: 1342
2023-02-15T13:35:03,011  INFO [Cleaner-executor-thread-5] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6fef19c0, with PersistenceManager: null will be shutdown
2023-02-15T13:35:03,011  INFO [Cleaner-executor-thread-5] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6fef19c0, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@88031f7 created in the thread with id: 1344
2023-02-15T13:35:03,011  INFO [Cleaner-executor-thread-2] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1afea041, with PersistenceManager: null will be shutdown
2023-02-15T13:35:03,011  INFO [Cleaner-executor-thread-4] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@437514bc, with PersistenceManager: null will be shutdown
2023-02-15T13:35:03,011  INFO [Cleaner-executor-thread-2] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1afea041, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@5c10148 created in the thread with id: 1341
2023-02-15T13:35:03,011  INFO [Cleaner-executor-thread-4] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@437514bc, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@583b9487 created in the thread with id: 1343
2023-02-15T13:35:03,013  INFO [Cleaner-executor-thread-5] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6fef19c0
2023-02-15T13:35:03,014  INFO [Cleaner-executor-thread-4] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@437514bc
2023-02-15T13:35:03,014  INFO [Cleaner-executor-thread-2] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1afea041
2023-02-15T13:35:03,016  INFO [Cleaner-executor-thread-3] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@28eea99c
2023-02-15T13:35:03,040  INFO [Cleaner-executor-thread-2] compactor.Cleaner:  id=2 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part1. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:03,040  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=1 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part0. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:03,040  INFO [Cleaner-executor-thread-4] compactor.Cleaner:  id=4 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part3. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:03,040  INFO [Cleaner-executor-thread-5] compactor.Cleaner:  id=5 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part4. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:03,040  INFO [Cleaner-executor-thread-3] compactor.Cleaner:  id=3 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part2. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:03,048  WARN [Cleaner-executor-thread-4] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:03,048  WARN [Cleaner-executor-thread-3] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:03,048  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:03,048  WARN [Cleaner-executor-thread-2] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:03,048  WARN [Cleaner-executor-thread-5] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:03,049  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:7,dbname:default,tableName:success_table,partName:ds=part6,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:03,049  INFO [Cleaner-executor-thread-2] compactor.Cleaner: Starting cleaning for id:8,dbname:default,tableName:success_table,partName:ds=part7,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:03,049  INFO [Cleaner-executor-thread-5] compactor.Cleaner: Starting cleaning for id:6,dbname:default,tableName:success_table,partName:ds=part5,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:03,049  INFO [Cleaner-executor-thread-3] compactor.Cleaner: Starting cleaning for id:9,dbname:default,tableName:success_table,partName:ds=part8,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:03,049  INFO [Cleaner-executor-thread-4] compactor.Cleaner: Starting cleaning for id:10,dbname:default,tableName:success_table,partName:ds=part9,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:03,073  INFO [Cleaner-executor-thread-5] compactor.Cleaner:  id=6 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part5. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:03,073  INFO [Cleaner-executor-thread-3] compactor.Cleaner:  id=9 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part8. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:03,073  INFO [Cleaner-executor-thread-2] compactor.Cleaner:  id=8 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part7. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:03,073  INFO [Cleaner-executor-thread-4] compactor.Cleaner:  id=10 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part9. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:03,074  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=7 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_8/success_table/ds=part6. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:03,075  WARN [Cleaner-executor-thread-3] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:03,075  WARN [Cleaner-executor-thread-5] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:03,076  WARN [Cleaner-executor-thread-4] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:03,076  INFO [Cleaner-executor-thread-3] compactor.Cleaner: Starting cleaning for id:11,dbname:default,tableName:failing_table,partName:ds=part0,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:03,076  INFO [Cleaner-executor-thread-5] compactor.Cleaner: Starting cleaning for id:12,dbname:default,tableName:failing_table,partName:ds=part1,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:03,076  WARN [Cleaner-executor-thread-2] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:03,076  INFO [Cleaner-executor-thread-4] compactor.Cleaner: Starting cleaning for id:13,dbname:default,tableName:failing_table,partName:ds=part2,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:03,077  INFO [Cleaner-executor-thread-2] compactor.Cleaner: Starting cleaning for id:14,dbname:default,tableName:failing_table,partName:ds=part3,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:03,077  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:03,077  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:15,dbname:default,tableName:failing_table,partName:ds=part4,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:03,109 ERROR [Cleaner-executor-thread-3] compactor.Cleaner: Caught exception when cleaning, unable to complete cleaning of id:11,dbname:default,tableName:failing_table,partName:ds=part0,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0 java.lang.RuntimeException: TxnHandler fails during MarkCleaned
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics$ControlledFailingTxHandler.markCleanerStart(TestCompactionMetrics.java:1123)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.clean(Cleaner.java:262)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.lambda$run$0(Cleaner.java:172)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorUtil$ThrowingRunnable.lambda$unchecked$0(CompactorUtil.java:55)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.CompletableFuture$AsyncRun.exec(CompletableFuture.java:1632)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)

2023-02-15T13:35:03,109 ERROR [Cleaner-executor-thread-5] compactor.Cleaner: Caught exception when cleaning, unable to complete cleaning of id:12,dbname:default,tableName:failing_table,partName:ds=part1,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0 java.lang.RuntimeException: TxnHandler fails during MarkCleaned
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics$ControlledFailingTxHandler.markCleanerStart(TestCompactionMetrics.java:1123)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.clean(Cleaner.java:262)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.lambda$run$0(Cleaner.java:172)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorUtil$ThrowingRunnable.lambda$unchecked$0(CompactorUtil.java:55)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.CompletableFuture$AsyncRun.exec(CompletableFuture.java:1632)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)

2023-02-15T13:35:03,110 ERROR [Cleaner-executor-thread-1] compactor.Cleaner: Caught exception when cleaning, unable to complete cleaning of id:15,dbname:default,tableName:failing_table,partName:ds=part4,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0 java.lang.RuntimeException: TxnHandler fails during MarkCleaned
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics$ControlledFailingTxHandler.markCleanerStart(TestCompactionMetrics.java:1123)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.clean(Cleaner.java:262)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.lambda$run$0(Cleaner.java:172)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorUtil$ThrowingRunnable.lambda$unchecked$0(CompactorUtil.java:55)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.CompletableFuture$AsyncRun.exec(CompletableFuture.java:1632)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)

2023-02-15T13:35:03,110  INFO [Cleaner-executor-thread-5] compactor.Cleaner: Starting cleaning for id:16,dbname:default,tableName:failing_table,partName:ds=part5,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:03,113 ERROR [Cleaner-executor-thread-2] compactor.Cleaner: Caught exception when cleaning, unable to complete cleaning of id:14,dbname:default,tableName:failing_table,partName:ds=part3,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0 java.lang.RuntimeException: TxnHandler fails during MarkCleaned
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics$ControlledFailingTxHandler.markCleanerStart(TestCompactionMetrics.java:1123)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.clean(Cleaner.java:262)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.lambda$run$0(Cleaner.java:172)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorUtil$ThrowingRunnable.lambda$unchecked$0(CompactorUtil.java:55)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.CompletableFuture$AsyncRun.exec(CompletableFuture.java:1632)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)

2023-02-15T13:35:03,113 ERROR [Cleaner-executor-thread-4] compactor.Cleaner: Caught exception when cleaning, unable to complete cleaning of id:13,dbname:default,tableName:failing_table,partName:ds=part2,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0 java.lang.RuntimeException: TxnHandler fails during MarkCleaned
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics$ControlledFailingTxHandler.markCleanerStart(TestCompactionMetrics.java:1123)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.clean(Cleaner.java:262)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.lambda$run$0(Cleaner.java:172)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorUtil$ThrowingRunnable.lambda$unchecked$0(CompactorUtil.java:55)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.CompletableFuture$AsyncRun.exec(CompletableFuture.java:1632)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)

2023-02-15T13:35:03,117 ERROR [Cleaner-executor-thread-5] compactor.Cleaner: Caught exception when cleaning, unable to complete cleaning of id:16,dbname:default,tableName:failing_table,partName:ds=part5,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0 java.lang.RuntimeException: TxnHandler fails during MarkCleaned
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics$ControlledFailingTxHandler.markCleanerStart(TestCompactionMetrics.java:1123)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.clean(Cleaner.java:262)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.lambda$run$0(Cleaner.java:172)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorUtil$ThrowingRunnable.lambda$unchecked$0(CompactorUtil.java:55)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.CompletableFuture$AsyncRun.exec(CompletableFuture.java:1632)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:175)

2023-02-15T13:35:03,135  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:03,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:03,135  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:03,135  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:03,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:03,135  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:03,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:03,135  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:03,135  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:03,135  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:03,135  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:03,135  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:03,135  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:35:03,150  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:35:03,151  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:35:03,151  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:03,151  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3a641f6 will be shutdown
2023-02-15T13:35:03,151  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@36deacfc created in the thread with id: 1
2023-02-15T13:35:03,163  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:35:03,165  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:35:03,184  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:03,184  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:03,184  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:03,184  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:03,184  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:03,184  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:03,184  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:03,184  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:03,184  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:03,184  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:03,184  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:03,184  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:03,185  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:35:03,189  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:35:03,190  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:35:03,190  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:03,190  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@36deacfc will be shutdown
2023-02-15T13:35:03,191  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56f1db5f created in the thread with id: 1
2023-02-15T13:35:03,194  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:35:03,195  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:35:03,200  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.table1	
2023-02-15T13:35:03,203  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:table1, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_10/table1, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:null, parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:35:03,204  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_10/table1 specified for non-external table:table1
2023-02-15T13:35:03,204  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_10/table1
2023-02-15T13:35:03,226  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.table2	
2023-02-15T13:35:03,227  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:table2, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_10/table2, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:null, parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:35:03,228  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_10/table2 specified for non-external table:table2
2023-02-15T13:35:03,228  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_10/table2
2023-02-15T13:35:03,233  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.table3	
2023-02-15T13:35:03,233  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:table3, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_10/table3, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:null, parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:35:03,234  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_10/table3 specified for non-external table:table3
2023-02-15T13:35:03,234  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_10/table3
2023-02-15T13:35:03,246  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]) with min_open_txn: 1
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:35:03,250  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=table1 (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])
2023-02-15T13:35:03,261  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,264  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [1] due to none
2023-02-15T13:35:03,272  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,274  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [2] due to none
2023-02-15T13:35:03,282  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,285  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [3] due to none
2023-02-15T13:35:03,292  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,294  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [4] due to none
2023-02-15T13:35:03,302  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,305  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [5] due to none
2023-02-15T13:35:03,312  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,315  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [6] due to none
2023-02-15T13:35:03,323  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,326  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [7] due to none
2023-02-15T13:35:03,334  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,337  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [8] due to none
2023-02-15T13:35:03,345  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,347  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [9] due to none
2023-02-15T13:35:03,354  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,357  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [10] due to none
2023-02-15T13:35:03,365  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,368  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [11] due to none
2023-02-15T13:35:03,375  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,377  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [12] due to none
2023-02-15T13:35:03,384  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,386  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [13] due to none
2023-02-15T13:35:03,394  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,397  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [14] due to none
2023-02-15T13:35:03,405  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,407  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [15] due to none
2023-02-15T13:35:03,419  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,420  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:35:03,431  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,431  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:35:03,442  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,442  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:35:03,453  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,453  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:35:03,465  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,465  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:35:03,471  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]) with min_open_txn: 1
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 21
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 22
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 23
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 24
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 25
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 26
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 27
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 28
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 29
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 30
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 31
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 32
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 33
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 34
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 35
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 36
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 37
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 38
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 39
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 40
2023-02-15T13:35:03,474  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=table2 (txnIds: [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40])
2023-02-15T13:35:03,481  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,483  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [21] due to none
2023-02-15T13:35:03,490  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,492  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [22] due to none
2023-02-15T13:35:03,500  INFO [main] txn.TxnHandler: Removed transactions: ([23]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,502  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [23] due to none
2023-02-15T13:35:03,510  INFO [main] txn.TxnHandler: Removed transactions: ([24]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,512  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [24] due to none
2023-02-15T13:35:03,520  INFO [main] txn.TxnHandler: Removed transactions: ([25]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,522  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [25] due to none
2023-02-15T13:35:03,529  INFO [main] txn.TxnHandler: Removed transactions: ([26]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,532  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [26] due to none
2023-02-15T13:35:03,539  INFO [main] txn.TxnHandler: Removed transactions: ([27]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,541  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [27] due to none
2023-02-15T13:35:03,548  INFO [main] txn.TxnHandler: Removed transactions: ([28]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,550  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [28] due to none
2023-02-15T13:35:03,557  INFO [main] txn.TxnHandler: Removed transactions: ([29]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,559  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [29] due to none
2023-02-15T13:35:03,566  INFO [main] txn.TxnHandler: Removed transactions: ([30]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,568  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [30] due to none
2023-02-15T13:35:03,579  INFO [main] txn.TxnHandler: Removed transactions: ([31]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,579  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:31
2023-02-15T13:35:03,589  INFO [main] txn.TxnHandler: Removed transactions: ([32]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,589  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:32
2023-02-15T13:35:03,598  INFO [main] txn.TxnHandler: Removed transactions: ([33]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,598  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:33
2023-02-15T13:35:03,608  INFO [main] txn.TxnHandler: Removed transactions: ([34]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,608  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:34
2023-02-15T13:35:03,617  INFO [main] txn.TxnHandler: Removed transactions: ([35]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,617  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:35
2023-02-15T13:35:03,627  INFO [main] txn.TxnHandler: Removed transactions: ([36]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,627  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:36
2023-02-15T13:35:03,637  INFO [main] txn.TxnHandler: Removed transactions: ([37]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,637  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:37
2023-02-15T13:35:03,648  INFO [main] txn.TxnHandler: Removed transactions: ([38]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,648  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:38
2023-02-15T13:35:03,659  INFO [main] txn.TxnHandler: Removed transactions: ([39]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,659  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:39
2023-02-15T13:35:03,670  INFO [main] txn.TxnHandler: Removed transactions: ([40]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,670  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:40
2023-02-15T13:35:03,676  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70]) with min_open_txn: 1
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 41
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 42
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 43
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 44
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 45
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 46
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 47
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 48
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 49
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 50
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 51
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 52
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 53
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 54
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 55
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 56
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 57
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 58
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 59
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 60
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 61
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 62
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 63
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 64
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 65
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 26 for txnId: 66
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 27 for txnId: 67
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 28 for txnId: 68
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 29 for txnId: 69
2023-02-15T13:35:03,680  INFO [main] txn.TxnHandler: Allocated writeId: 30 for txnId: 70
2023-02-15T13:35:03,681  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=table3 (txnIds: [41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70])
2023-02-15T13:35:03,688  INFO [main] txn.TxnHandler: Removed transactions: ([41]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,691  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [41] due to none
2023-02-15T13:35:03,699  INFO [main] txn.TxnHandler: Removed transactions: ([42]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,702  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [42] due to none
2023-02-15T13:35:03,710  INFO [main] txn.TxnHandler: Removed transactions: ([43]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,712  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [43] due to none
2023-02-15T13:35:03,720  INFO [main] txn.TxnHandler: Removed transactions: ([44]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,722  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [44] due to none
2023-02-15T13:35:03,730  INFO [main] txn.TxnHandler: Removed transactions: ([45]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,732  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [45] due to none
2023-02-15T13:35:03,740  INFO [main] txn.TxnHandler: Removed transactions: ([46]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,742  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [46] due to none
2023-02-15T13:35:03,749  INFO [main] txn.TxnHandler: Removed transactions: ([47]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,752  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [47] due to none
2023-02-15T13:35:03,759  INFO [main] txn.TxnHandler: Removed transactions: ([48]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,761  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [48] due to none
2023-02-15T13:35:03,769  INFO [main] txn.TxnHandler: Removed transactions: ([49]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,771  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [49] due to none
2023-02-15T13:35:03,779  INFO [main] txn.TxnHandler: Removed transactions: ([50]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,781  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [50] due to none
2023-02-15T13:35:03,788  INFO [main] txn.TxnHandler: Removed transactions: ([51]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,791  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [51] due to none
2023-02-15T13:35:03,798  INFO [main] txn.TxnHandler: Removed transactions: ([52]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,800  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [52] due to none
2023-02-15T13:35:03,807  INFO [main] txn.TxnHandler: Removed transactions: ([53]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,809  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [53] due to none
2023-02-15T13:35:03,816  INFO [main] txn.TxnHandler: Removed transactions: ([54]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,818  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [54] due to none
2023-02-15T13:35:03,825  INFO [main] txn.TxnHandler: Removed transactions: ([55]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,827  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [55] due to none
2023-02-15T13:35:03,833  INFO [main] txn.TxnHandler: Removed transactions: ([56]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,835  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [56] due to none
2023-02-15T13:35:03,842  INFO [main] txn.TxnHandler: Removed transactions: ([57]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,844  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [57] due to none
2023-02-15T13:35:03,851  INFO [main] txn.TxnHandler: Removed transactions: ([58]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,853  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [58] due to none
2023-02-15T13:35:03,861  INFO [main] txn.TxnHandler: Removed transactions: ([59]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,863  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [59] due to none
2023-02-15T13:35:03,870  INFO [main] txn.TxnHandler: Removed transactions: ([60]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,872  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [60] due to none
2023-02-15T13:35:03,881  INFO [main] txn.TxnHandler: Removed transactions: ([61]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,882  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:61
2023-02-15T13:35:03,891  INFO [main] txn.TxnHandler: Removed transactions: ([62]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,891  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:62
2023-02-15T13:35:03,900  INFO [main] txn.TxnHandler: Removed transactions: ([63]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,900  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:63
2023-02-15T13:35:03,910  INFO [main] txn.TxnHandler: Removed transactions: ([64]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,910  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:64
2023-02-15T13:35:03,919  INFO [main] txn.TxnHandler: Removed transactions: ([65]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,919  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:65
2023-02-15T13:35:03,928  INFO [main] txn.TxnHandler: Removed transactions: ([66]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,928  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:66
2023-02-15T13:35:03,937  INFO [main] txn.TxnHandler: Removed transactions: ([67]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,937  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:67
2023-02-15T13:35:03,946  INFO [main] txn.TxnHandler: Removed transactions: ([68]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,946  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:68
2023-02-15T13:35:03,955  INFO [main] txn.TxnHandler: Removed transactions: ([69]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,955  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:69
2023-02-15T13:35:03,964  INFO [main] txn.TxnHandler: Removed transactions: ([70]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:03,964  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:70
2023-02-15T13:35:03,965 ERROR [main] metrics.AcidMetricService: Cannot initialize delta file metrics mbean server. AcidMetricService initialization aborted.
javax.management.InstanceAlreadyExistsException: metrics:type=compaction,name=compaction_num_obsolete_deltas
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324) ~[?:1.8.0_352]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.initObjectsForMetrics(AcidMetricService.java:404) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.setConf(AcidMetricService.java:380) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runAcidMetricService(CompactorTest.java:165) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testTablesWithXAbortedTxns(TestCompactionMetrics.java:781) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_352]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_352]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_352]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T13:35:04,089  WARN [main] metrics.AcidMetricService: Caught exception while trying to fetch compaction metrics from metastore backend db.
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.updateDeltaMBeanAndMetric(AcidMetricService.java:289) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.updateDeltaMetrics(AcidMetricService.java:270) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.run(AcidMetricService.java:119) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runAcidMetricService(CompactorTest.java:166) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testTablesWithXAbortedTxns(TestCompactionMetrics.java:781) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_352]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_352]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_352]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T13:35:04,102  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:04,102  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:04,102  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:04,102  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:04,102  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:04,102  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:04,102  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:04,102  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:04,102  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:04,102  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:04,102  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:04,102  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:04,103  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:35:04,116  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:35:04,117  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:35:04,117  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:04,117  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@56f1db5f will be shutdown
2023-02-15T13:35:04,117  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b36c5aa created in the thread with id: 1
2023-02-15T13:35:04,135  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:35:04,142  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:35:04,147  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.txnhandlercounters	
2023-02-15T13:35:04,152  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:txnhandlercounters, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_11/txnhandlercounters, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:null, parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:35:04,153  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_11/txnhandlercounters specified for non-external table:txnhandlercounters
2023-02-15T13:35:04,153  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_11/txnhandlercounters
2023-02-15T13:35:04,174  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3]) with min_open_txn: 1
2023-02-15T13:35:04,180  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:35:04,180  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:35:04,180  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:35:04,180  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=txnhandlercounters (txnIds: [1, 2, 3])
2023-02-15T13:35:04,182  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:35:04,184  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,185  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:35:04,186  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,189  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [2] due to none
2023-02-15T13:35:04,191  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,193  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [3] due to none
2023-02-15T13:35:04,195  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([4, 5, 6]) with min_open_txn: 1
2023-02-15T13:35:04,198  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:35:04,198  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:35:04,198  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:35:04,198  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=txnhandlercounters (txnIds: [4, 5, 6])
2023-02-15T13:35:04,199  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,202  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [4] due to none
2023-02-15T13:35:04,204  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:35:04,207  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,207  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:35:04,209  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:35:04,211  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,212  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:35:04,225  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:04,225  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:04,225  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:04,225  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:04,226  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:04,226  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:04,226  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:04,226  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:04,226  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:04,226  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:04,226  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:04,226  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:04,226  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:35:04,237  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:35:04,239  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:35:04,239  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:04,239  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1b36c5aa will be shutdown
2023-02-15T13:35:04,239  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16e483d9 created in the thread with id: 1
2023-02-15T13:35:04,254  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:35:04,256  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:35:04,261  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.camipc	
2023-02-15T13:35:04,265  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:camipc, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_12/camipc, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:35:04,266  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_12/camipc specified for non-external table:camipc
2023-02-15T13:35:04,266  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_12/camipc
2023-02-15T13:35:04,283  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.camipc	
2023-02-15T13:35:04,292  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_12/camipc/ds=today
2023-02-15T13:35:04,318  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]) with min_open_txn: 1
2023-02-15T13:35:04,321  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:35:04,321  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:35:04,321  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:35:04,321  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:35:04,321  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:35:04,321  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:35:04,321  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:35:04,321  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:35:04,321  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:35:04,321  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:35:04,321  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:35:04,321  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:35:04,322  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:35:04,322  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:35:04,322  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:35:04,322  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:35:04,322  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:35:04,322  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:35:04,322  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:35:04,322  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:35:04,322  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 21
2023-02-15T13:35:04,322  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 22
2023-02-15T13:35:04,322  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 23
2023-02-15T13:35:04,322  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 24
2023-02-15T13:35:04,322  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 25
2023-02-15T13:35:04,322  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=camipc (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])
2023-02-15T13:35:04,324  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:35:04,326  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,327  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:35:04,329  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2023-02-15T13:35:04,331  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,331  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2023-02-15T13:35:04,333  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:35:04,335  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,335  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:35:04,337  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2023-02-15T13:35:04,339  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,339  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2023-02-15T13:35:04,341  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:35:04,343  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,343  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:35:04,344  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:35:04,346  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,346  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:35:04,348  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2023-02-15T13:35:04,351  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,351  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:35:04,353  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2023-02-15T13:35:04,355  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,355  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:35:04,357  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2023-02-15T13:35:04,359  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,359  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:35:04,361  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2023-02-15T13:35:04,363  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,363  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:35:04,365  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2023-02-15T13:35:04,367  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,367  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2023-02-15T13:35:04,369  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2023-02-15T13:35:04,371  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,371  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2023-02-15T13:35:04,373  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:13
2023-02-15T13:35:04,375  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,376  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2023-02-15T13:35:04,377  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:14
2023-02-15T13:35:04,380  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,380  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:14
2023-02-15T13:35:04,382  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2023-02-15T13:35:04,384  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,384  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2023-02-15T13:35:04,386  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2023-02-15T13:35:04,388  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,388  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:35:04,390  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2023-02-15T13:35:04,392  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,392  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:35:04,394  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2023-02-15T13:35:04,396  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,396  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:35:04,398  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2023-02-15T13:35:04,400  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,400  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:35:04,402  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2023-02-15T13:35:04,404  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,404  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:35:04,406  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:21
2023-02-15T13:35:04,407  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,408  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:21
2023-02-15T13:35:04,409  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:22
2023-02-15T13:35:04,411  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,411  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:22
2023-02-15T13:35:04,413  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:23
2023-02-15T13:35:04,415  INFO [main] txn.TxnHandler: Removed transactions: ([23]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,415  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:23
2023-02-15T13:35:04,416  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:24
2023-02-15T13:35:04,418  INFO [main] txn.TxnHandler: Removed transactions: ([24]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,418  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:24
2023-02-15T13:35:04,420  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:25
2023-02-15T13:35:04,422  INFO [main] txn.TxnHandler: Removed transactions: ([25]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:04,422  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:25
2023-02-15T13:35:04,433  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([26]) with min_open_txn: 1
2023-02-15T13:35:04,438  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:26
2023-02-15T13:35:04,441  INFO [main] txn.TxnHandler: Removed transactions: ([26]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:06,495  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:06,495  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:06,495  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:06,495  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:06,495  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:06,495  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:06,495  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:06,495  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:06,495  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:06,495  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:06,495  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:06,495  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:06,497  INFO [main] compactor.Cleaner: Starting Cleaner thread
2023-02-15T13:35:06,501  INFO [main] compactor.Cleaner: Cleaning based on min open txn id: 27
2023-02-15T13:35:06,501  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:1,dbname:default,tableName:camipc,partName:ds=today,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:06,502  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:06,502  INFO [Cleaner-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:06,502  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@679b6010, with PersistenceManager: null will be shutdown
2023-02-15T13:35:06,502  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@679b6010, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2bedf36f created in the thread with id: 1389
2023-02-15T13:35:06,510  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@679b6010
2023-02-15T13:35:06,530  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=1 About to remove 3 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_12/camipc/ds=today. [base_20,delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:06,535  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:06,550  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:06,550  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:06,550  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:06,550  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:06,550  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:06,550  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:06,550  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:06,551  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:06,551  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:06,551  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:06,551  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:06,551  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:06,551  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:35:06,563  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:35:06,564  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:35:06,564  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:06,564  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16e483d9 will be shutdown
2023-02-15T13:35:06,564  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2aea50a6 created in the thread with id: 1
2023-02-15T13:35:06,572  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:35:06,574  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:35:06,593  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:06,593  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:06,593  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:06,593  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:06,593  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:06,593  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:06,593  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:06,593  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:06,593  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:06,593  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:06,593  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:06,593  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:06,593  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:35:06,597  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:35:06,598  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:35:06,598  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:06,599  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@2aea50a6 will be shutdown
2023-02-15T13:35:06,599  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@de58d71 created in the thread with id: 1
2023-02-15T13:35:06,608  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:35:06,609  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:35:06,628  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:06,628  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:06,628  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:06,628  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:06,628  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:06,628  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:06,628  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:06,629  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:06,629  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:06,629  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:06,629  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:06,629  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:06,629  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:35:06,633  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:35:06,634  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:35:06,634  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:06,634  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@de58d71 will be shutdown
2023-02-15T13:35:06,634  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4245e409 created in the thread with id: 1
2023-02-15T13:35:06,643  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:35:06,645  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:35:06,650  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.failing_table	
2023-02-15T13:35:06,654  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:35:06,655  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.failing_table	
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.Trash
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.fs.TrashPolicyDefault
2023-02-15T13:35:06,753  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:failing_table, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/failing_table, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:35:06,754  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/failing_table specified for non-external table:failing_table
2023-02-15T13:35:06,754  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/failing_table
2023-02-15T13:35:06,771  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.success_table	
2023-02-15T13:35:06,777  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:35:06,777  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.success_table	
2023-02-15T13:35:06,804  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:success_table, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/success_table, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:35:06,805  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/success_table specified for non-external table:success_table
2023-02-15T13:35:06,805  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/success_table
2023-02-15T13:35:06,810  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:35:06,815  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/success_table/ds=part0
2023-02-15T13:35:06,841  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:35:06,843  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/success_table/ds=part1
2023-02-15T13:35:06,861  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:35:06,863  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/success_table/ds=part2
2023-02-15T13:35:06,883  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:35:06,885  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/success_table/ds=part3
2023-02-15T13:35:06,903  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:35:06,905  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/success_table/ds=part4
2023-02-15T13:35:06,923  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:35:06,925  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/success_table/ds=part5
2023-02-15T13:35:06,943  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:35:06,945  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/success_table/ds=part6
2023-02-15T13:35:06,967  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:35:06,968  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/success_table/ds=part7
2023-02-15T13:35:06,991  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:35:06,996  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/success_table/ds=part8
2023-02-15T13:35:07,017  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.success_table	
2023-02-15T13:35:07,019  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/success_table/ds=part9
2023-02-15T13:35:07,044  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]) with min_open_txn: 1
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 21
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 22
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 23
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 24
2023-02-15T13:35:07,047  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 25
2023-02-15T13:35:07,048  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=success_table (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])
2023-02-15T13:35:07,050  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:35:07,053  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,053  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:35:07,056  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2023-02-15T13:35:07,059  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,059  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2023-02-15T13:35:07,061  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:35:07,063  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,063  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:35:07,065  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2023-02-15T13:35:07,068  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,068  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2023-02-15T13:35:07,070  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:35:07,072  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,072  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:35:07,074  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:35:07,077  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,077  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:35:07,079  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2023-02-15T13:35:07,081  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,081  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:35:07,083  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2023-02-15T13:35:07,086  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,086  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:35:07,088  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2023-02-15T13:35:07,090  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,090  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:35:07,092  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2023-02-15T13:35:07,094  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,095  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:35:07,096  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2023-02-15T13:35:07,099  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,099  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2023-02-15T13:35:07,100  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2023-02-15T13:35:07,103  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,103  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2023-02-15T13:35:07,105  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:13
2023-02-15T13:35:07,107  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,107  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2023-02-15T13:35:07,109  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:14
2023-02-15T13:35:07,111  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,111  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:14
2023-02-15T13:35:07,113  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2023-02-15T13:35:07,115  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,115  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2023-02-15T13:35:07,117  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2023-02-15T13:35:07,119  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,120  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:35:07,121  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2023-02-15T13:35:07,124  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,124  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:35:07,125  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2023-02-15T13:35:07,128  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,128  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:35:07,129  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2023-02-15T13:35:07,131  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,132  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:35:07,133  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2023-02-15T13:35:07,136  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,136  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:35:07,138  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:21
2023-02-15T13:35:07,140  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,140  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:21
2023-02-15T13:35:07,142  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:22
2023-02-15T13:35:07,144  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,144  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:22
2023-02-15T13:35:07,146  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:23
2023-02-15T13:35:07,148  INFO [main] txn.TxnHandler: Removed transactions: ([23]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,148  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:23
2023-02-15T13:35:07,150  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:24
2023-02-15T13:35:07,152  INFO [main] txn.TxnHandler: Removed transactions: ([24]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,152  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:24
2023-02-15T13:35:07,154  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:25
2023-02-15T13:35:07,156  INFO [main] txn.TxnHandler: Removed transactions: ([25]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,156  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:25
2023-02-15T13:35:07,160  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([26]) with min_open_txn: 1
2023-02-15T13:35:07,173  INFO [main] txn.TxnHandler: Allocated writeId: 26 for txnId: 26
2023-02-15T13:35:07,173  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=success_table (txnIds: [26])
2023-02-15T13:35:07,179  INFO [main] txn.TxnHandler: Removed transactions: ([26]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,180  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:26
2023-02-15T13:35:07,180  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.failing_table	
2023-02-15T13:35:07,189  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/failing_table/ds=part0
2023-02-15T13:35:07,219  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.failing_table	
2023-02-15T13:35:07,221  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/failing_table/ds=part1
2023-02-15T13:35:07,239  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.failing_table	
2023-02-15T13:35:07,241  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/failing_table/ds=part2
2023-02-15T13:35:07,259  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.failing_table	
2023-02-15T13:35:07,261  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/failing_table/ds=part3
2023-02-15T13:35:07,284  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.failing_table	
2023-02-15T13:35:07,286  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/failing_table/ds=part4
2023-02-15T13:35:07,304  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.failing_table	
2023-02-15T13:35:07,306  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_15/failing_table/ds=part5
2023-02-15T13:35:07,328  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51]) with min_open_txn: 1
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 27
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 28
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 29
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 30
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 31
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 32
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 33
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 34
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 35
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 36
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 37
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 38
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 39
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 40
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 41
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 42
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 43
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 44
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 45
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 46
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 47
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 48
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 49
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 50
2023-02-15T13:35:07,330  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 51
2023-02-15T13:35:07,331  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=failing_table (txnIds: [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51])
2023-02-15T13:35:07,333  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:27
2023-02-15T13:35:07,336  INFO [main] txn.TxnHandler: Removed transactions: ([27]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,336  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:27
2023-02-15T13:35:07,338  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:28
2023-02-15T13:35:07,341  INFO [main] txn.TxnHandler: Removed transactions: ([28]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,341  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:28
2023-02-15T13:35:07,343  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:29
2023-02-15T13:35:07,346  INFO [main] txn.TxnHandler: Removed transactions: ([29]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,346  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:29
2023-02-15T13:35:07,349  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:30
2023-02-15T13:35:07,351  INFO [main] txn.TxnHandler: Removed transactions: ([30]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,351  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:30
2023-02-15T13:35:07,354  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:31
2023-02-15T13:35:07,356  INFO [main] txn.TxnHandler: Removed transactions: ([31]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,356  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:31
2023-02-15T13:35:07,358  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:32
2023-02-15T13:35:07,361  INFO [main] txn.TxnHandler: Removed transactions: ([32]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,361  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:32
2023-02-15T13:35:07,364  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:33
2023-02-15T13:35:07,366  INFO [main] txn.TxnHandler: Removed transactions: ([33]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,366  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:33
2023-02-15T13:35:07,369  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:34
2023-02-15T13:35:07,372  INFO [main] txn.TxnHandler: Removed transactions: ([34]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,372  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:34
2023-02-15T13:35:07,374  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:35
2023-02-15T13:35:07,377  INFO [main] txn.TxnHandler: Removed transactions: ([35]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,377  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:35
2023-02-15T13:35:07,379  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:36
2023-02-15T13:35:07,381  INFO [main] txn.TxnHandler: Removed transactions: ([36]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,381  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:36
2023-02-15T13:35:07,383  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:37
2023-02-15T13:35:07,386  INFO [main] txn.TxnHandler: Removed transactions: ([37]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,386  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:37
2023-02-15T13:35:07,388  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:38
2023-02-15T13:35:07,390  INFO [main] txn.TxnHandler: Removed transactions: ([38]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,390  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:38
2023-02-15T13:35:07,392  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:39
2023-02-15T13:35:07,394  INFO [main] txn.TxnHandler: Removed transactions: ([39]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,394  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:39
2023-02-15T13:35:07,396  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:40
2023-02-15T13:35:07,399  INFO [main] txn.TxnHandler: Removed transactions: ([40]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,399  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:40
2023-02-15T13:35:07,401  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:41
2023-02-15T13:35:07,403  INFO [main] txn.TxnHandler: Removed transactions: ([41]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,403  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:41
2023-02-15T13:35:07,405  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:42
2023-02-15T13:35:07,407  INFO [main] txn.TxnHandler: Removed transactions: ([42]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,407  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:42
2023-02-15T13:35:07,409  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:43
2023-02-15T13:35:07,411  INFO [main] txn.TxnHandler: Removed transactions: ([43]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,412  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:43
2023-02-15T13:35:07,414  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:44
2023-02-15T13:35:07,416  INFO [main] txn.TxnHandler: Removed transactions: ([44]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,416  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:44
2023-02-15T13:35:07,418  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:45
2023-02-15T13:35:07,421  INFO [main] txn.TxnHandler: Removed transactions: ([45]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,421  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:45
2023-02-15T13:35:07,423  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:46
2023-02-15T13:35:07,425  INFO [main] txn.TxnHandler: Removed transactions: ([46]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,425  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:46
2023-02-15T13:35:07,428  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:47
2023-02-15T13:35:07,430  INFO [main] txn.TxnHandler: Removed transactions: ([47]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,430  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:47
2023-02-15T13:35:07,432  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:48
2023-02-15T13:35:07,435  INFO [main] txn.TxnHandler: Removed transactions: ([48]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,435  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:48
2023-02-15T13:35:07,437  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:49
2023-02-15T13:35:07,440  INFO [main] txn.TxnHandler: Removed transactions: ([49]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,440  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:49
2023-02-15T13:35:07,442  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:50
2023-02-15T13:35:07,444  INFO [main] txn.TxnHandler: Removed transactions: ([50]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,444  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:50
2023-02-15T13:35:07,446  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:51
2023-02-15T13:35:07,449  INFO [main] txn.TxnHandler: Removed transactions: ([51]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,449  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:51
2023-02-15T13:35:07,453  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([52]) with min_open_txn: 1
2023-02-15T13:35:07,467  INFO [main] txn.TxnHandler: Allocated writeId: 26 for txnId: 52
2023-02-15T13:35:07,467  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=failing_table (txnIds: [52])
2023-02-15T13:35:07,474  INFO [main] txn.TxnHandler: Removed transactions: ([52]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,474  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:52
2023-02-15T13:35:07,483  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:07,483  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:07,483  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:07,483  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:07,483  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:07,483  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:07,483  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:07,483  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:07,483  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:07,483  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:07,483  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:07,483  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:07,484  INFO [main] compactor.Initiator: Starting Initiator thread
2023-02-15T13:35:07,487  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410507486
2023-02-15T13:35:07,493  INFO [Initiator-executor-thread-5] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:07,493  INFO [Initiator-executor-thread-2] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:07,493  INFO [Initiator-executor-thread-2] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:07,494  INFO [Initiator-executor-thread-4] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:07,494  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:07,494  INFO [Initiator-executor-thread-2] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6111ce00, with PersistenceManager: null will be shutdown
2023-02-15T13:35:07,494  INFO [Initiator-executor-thread-3] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:07,494  INFO [Initiator-executor-thread-2] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6111ce00, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@7ec887d9 created in the thread with id: 1743
2023-02-15T13:35:07,494  INFO [Initiator-executor-thread-5] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@620c93a8, with PersistenceManager: null will be shutdown
2023-02-15T13:35:07,494  INFO [Initiator-executor-thread-5] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@620c93a8, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@16e3c79f created in the thread with id: 1746
2023-02-15T13:35:07,494  INFO [Initiator-executor-thread-3] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e2a097f, with PersistenceManager: null will be shutdown
2023-02-15T13:35:07,494  INFO [Initiator-executor-thread-4] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b4fa111, with PersistenceManager: null will be shutdown
2023-02-15T13:35:07,494  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d46fa48, with PersistenceManager: null will be shutdown
2023-02-15T13:35:07,494  INFO [Initiator-executor-thread-4] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b4fa111, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6f59507f created in the thread with id: 1745
2023-02-15T13:35:07,494  INFO [Initiator-executor-thread-3] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e2a097f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@202d58dd created in the thread with id: 1744
2023-02-15T13:35:07,494  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d46fa48, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@131cc42 created in the thread with id: 1742
2023-02-15T13:35:07,506  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@d46fa48
2023-02-15T13:35:07,506  INFO [Initiator-executor-thread-4] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@1b4fa111
2023-02-15T13:35:07,506  INFO [Initiator-executor-thread-3] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@7e2a097f
2023-02-15T13:35:07,506  INFO [Initiator-executor-thread-2] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6111ce00
2023-02-15T13:35:07,506  INFO [Initiator-executor-thread-5] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@620c93a8
2023-02-15T13:35:07,508  INFO [Initiator-executor-thread-2] compactor.Initiator: Checking to see if we should compact default.success_table.ds=part0
2023-02-15T13:35:07,508  INFO [Initiator-executor-thread-4] compactor.Initiator: Checking to see if we should compact default.success_table.ds=part9
2023-02-15T13:35:07,508  INFO [Initiator-executor-thread-3] compactor.Initiator: Checking to see if we should compact default.failing_table.ds=part2
2023-02-15T13:35:07,508  INFO [Initiator-executor-thread-5] compactor.Initiator: Checking to see if we should compact default.success_table.ds=part5
2023-02-15T13:35:07,508  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.failing_table.ds=part0
2023-02-15T13:35:07,517  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.failing_table.ds=part1
2023-02-15T13:35:07,517  INFO [Initiator-executor-thread-2] compactor.Initiator: Checking to see if we should compact default.success_table.ds=part3
2023-02-15T13:35:07,517  INFO [Initiator-executor-thread-3] compactor.Initiator: Checking to see if we should compact default.failing_table.ds=part3
2023-02-15T13:35:07,517  INFO [Initiator-executor-thread-4] compactor.Initiator: Checking to see if we should compact default.failing_table.ds=part4
2023-02-15T13:35:07,517  INFO [Initiator-executor-thread-5] compactor.Initiator: Checking to see if we should compact default.success_table.ds=part6
2023-02-15T13:35:07,518  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.success_table.ds=part1
2023-02-15T13:35:07,518  INFO [Initiator-executor-thread-3] compactor.Initiator: Checking to see if we should compact default.success_table.ds=part7
2023-02-15T13:35:07,518  INFO [Initiator-executor-thread-2] compactor.Initiator: Checking to see if we should compact default.success_table.ds=part4
2023-02-15T13:35:07,518  INFO [Initiator-executor-thread-4] compactor.Initiator: Checking to see if we should compact default.failing_table.ds=part5
2023-02-15T13:35:07,518  INFO [Initiator-executor-thread-3] compactor.Initiator: Checking to see if we should compact default.success_table.ds=part8
2023-02-15T13:35:07,518  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.success_table.ds=part2
2023-02-15T13:35:07,548  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:success_table, partitionname:ds=part1, type:MAJOR, runas:rizky, initiatorId:labdas-1742)
2023-02-15T13:35:07,550  INFO [Initiator-executor-thread-3] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:success_table, partitionname:ds=part2, type:MAJOR, runas:rizky, initiatorId:labdas-1744)
2023-02-15T13:35:07,557  INFO [Initiator-executor-thread-4] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:success_table, partitionname:ds=part3, type:MAJOR, runas:rizky, initiatorId:labdas-1745)
2023-02-15T13:35:07,565  INFO [Initiator-executor-thread-2] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:success_table, partitionname:ds=part4, type:MAJOR, runas:rizky, initiatorId:labdas-1743)
2023-02-15T13:35:07,574  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:success_table, partitionname:ds=part5, type:MAJOR, runas:rizky, initiatorId:labdas-1742)
2023-02-15T13:35:07,583  INFO [Initiator-executor-thread-4] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:success_table, partitionname:ds=part6, type:MAJOR, runas:rizky, initiatorId:labdas-1745)
2023-02-15T13:35:07,588  INFO [Initiator-executor-thread-2] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:success_table, partitionname:ds=part7, type:MAJOR, runas:rizky, initiatorId:labdas-1743)
2023-02-15T13:35:07,596  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:success_table, partitionname:ds=part8, type:MAJOR, runas:rizky, initiatorId:labdas-1742)
2023-02-15T13:35:07,601 ERROR [Initiator-executor-thread-1] compactor.Initiator: Caught exception while trying to determine if we should compact id:0,dbname:default,tableName:failing_table,partName:ds=part0,state: ,type:null,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0. Marking failed to avoid repeated failures, java.lang.RuntimeException: TxnHandler fails during getValidWriteIds
2023-02-15T13:35:07,604  INFO [Initiator-executor-thread-2] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:success_table, partitionname:ds=part0, type:MAJOR, runas:rizky, initiatorId:labdas-1743)
2023-02-15T13:35:07,608 ERROR [Initiator-executor-thread-2] compactor.Initiator: Caught exception while trying to determine if we should compact id:0,dbname:default,tableName:failing_table,partName:ds=part1,state: ,type:null,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0. Marking failed to avoid repeated failures, java.lang.RuntimeException: TxnHandler fails during getValidWriteIds
2023-02-15T13:35:07,622 ERROR [Initiator-executor-thread-1] compactor.Initiator: Caught exception while trying to determine if we should compact id:0,dbname:default,tableName:failing_table,partName:ds=part4,state: ,type:null,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0. Marking failed to avoid repeated failures, java.lang.RuntimeException: TxnHandler fails during getValidWriteIds
2023-02-15T13:35:07,628 ERROR [Initiator-executor-thread-1] compactor.Initiator: Caught exception while trying to determine if we should compact id:0,dbname:default,tableName:failing_table,partName:ds=part5,state: ,type:null,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0. Marking failed to avoid repeated failures, java.lang.RuntimeException: TxnHandler fails during getValidWriteIds
2023-02-15T13:35:07,629  INFO [Initiator-executor-thread-2] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:success_table, partitionname:ds=part9, type:MAJOR, runas:rizky, initiatorId:labdas-1743)
2023-02-15T13:35:07,635 ERROR [Initiator-executor-thread-2] compactor.Initiator: Caught exception while trying to determine if we should compact id:0,dbname:default,tableName:failing_table,partName:ds=part2,state: ,type:null,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0. Marking failed to avoid repeated failures, java.lang.RuntimeException: TxnHandler fails during getValidWriteIds
2023-02-15T13:35:07,642 ERROR [Initiator-executor-thread-2] compactor.Initiator: Caught exception while trying to determine if we should compact id:0,dbname:default,tableName:failing_table,partName:ds=part3,state: ,type:null,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0. Marking failed to avoid repeated failures, java.lang.RuntimeException: TxnHandler fails during getValidWriteIds
2023-02-15T13:35:07,644  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410507643
2023-02-15T13:35:07,660  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:07,660  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:07,660  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:07,660  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:07,660  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:07,660  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:07,660  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:07,660  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:07,660  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:07,660  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:07,660  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:07,660  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:07,660  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:35:07,673  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:35:07,674  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:35:07,674  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:07,674  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@4245e409 will be shutdown
2023-02-15T13:35:07,674  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f78d2a7 created in the thread with id: 1
2023-02-15T13:35:07,692  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:35:07,694  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:35:07,716  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.comp_disabled	
2023-02-15T13:35:07,720  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:comp_disabled, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_16/comp_disabled, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:null, parameters:{transactional=true, no_auto_compaction=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:35:07,721  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_16/comp_disabled specified for non-external table:comp_disabled
2023-02-15T13:35:07,721  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_16/comp_disabled
2023-02-15T13:35:07,741  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1]) with min_open_txn: 1
2023-02-15T13:35:07,744  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:35:07,750  WARN [main] metastore.HMSMetricsListener: There has been a write to table default.comp_disabled where auto-compaction is disabled "no_auto_compact"="true".
2023-02-15T13:35:07,750  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=comp_disabled (txnIds: [1])
2023-02-15T13:35:07,753  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:35:07,755  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,756  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:35:07,757  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([2]) with min_open_txn: 1
2023-02-15T13:35:07,759  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:35:07,761  WARN [main] metastore.HMSMetricsListener: There has been a write to table default.comp_disabled where auto-compaction is disabled "no_auto_compact"="true".
2023-02-15T13:35:07,761  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=comp_disabled (txnIds: [2])
2023-02-15T13:35:07,762  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,765  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [2] due to none
2023-02-15T13:35:07,766  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.comp_enabled	
2023-02-15T13:35:07,767  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:comp_enabled, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_16/comp_enabled, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:null, parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:35:07,767  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_16/comp_enabled specified for non-external table:comp_enabled
2023-02-15T13:35:07,767  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_16/comp_enabled
2023-02-15T13:35:07,774  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([3]) with min_open_txn: 1
2023-02-15T13:35:07,776  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 3
2023-02-15T13:35:07,778  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=comp_enabled (txnIds: [3])
2023-02-15T13:35:07,780  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:35:07,783  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,783  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:35:07,796  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:07,796  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:07,796  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:07,796  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:07,796  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:07,796  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:07,796  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:07,796  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:07,796  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:07,796  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:07,796  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:07,796  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:07,796  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:35:07,809  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:35:07,810  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:35:07,810  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:07,810  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1f78d2a7 will be shutdown
2023-02-15T13:35:07,810  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@60b4dacc created in the thread with id: 1
2023-02-15T13:35:07,822  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:35:07,824  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:35:07,844  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.x_table	
2023-02-15T13:35:07,846  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:x_table, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_17/x_table, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:35:07,847  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_17/x_table specified for non-external table:x_table
2023-02-15T13:35:07,847  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_17/x_table
2023-02-15T13:35:07,853  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.x_table	
2023-02-15T13:35:07,858  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_17/x_table/ds=part
2023-02-15T13:35:07,885  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]) with min_open_txn: 1
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 21
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 22
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 23
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 24
2023-02-15T13:35:07,888  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 25
2023-02-15T13:35:07,889  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=x_table (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])
2023-02-15T13:35:07,891  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:35:07,894  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,894  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:35:07,897  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2023-02-15T13:35:07,899  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,899  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2023-02-15T13:35:07,900  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:35:07,901  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,901  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:35:07,903  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2023-02-15T13:35:07,905  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,905  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2023-02-15T13:35:07,907  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:35:07,909  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,909  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:35:07,911  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:35:07,913  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,913  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:35:07,915  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2023-02-15T13:35:07,918  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,918  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:35:07,920  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2023-02-15T13:35:07,922  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,922  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:35:07,924  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2023-02-15T13:35:07,926  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,926  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:35:07,928  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2023-02-15T13:35:07,930  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,930  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:35:07,932  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2023-02-15T13:35:07,934  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,934  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2023-02-15T13:35:07,936  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2023-02-15T13:35:07,938  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,938  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2023-02-15T13:35:07,940  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:13
2023-02-15T13:35:07,942  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,942  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2023-02-15T13:35:07,944  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:14
2023-02-15T13:35:07,946  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,946  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:14
2023-02-15T13:35:07,948  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2023-02-15T13:35:07,950  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,950  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2023-02-15T13:35:07,952  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2023-02-15T13:35:07,954  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,954  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:35:07,956  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2023-02-15T13:35:07,958  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,958  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:35:07,960  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2023-02-15T13:35:07,962  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,962  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:35:07,964  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2023-02-15T13:35:07,966  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,966  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:35:07,968  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2023-02-15T13:35:07,970  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,970  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:35:07,972  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:21
2023-02-15T13:35:07,974  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,975  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:21
2023-02-15T13:35:07,977  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:22
2023-02-15T13:35:07,979  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,979  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:22
2023-02-15T13:35:07,981  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:23
2023-02-15T13:35:07,983  INFO [main] txn.TxnHandler: Removed transactions: ([23]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,983  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:23
2023-02-15T13:35:07,986  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:24
2023-02-15T13:35:07,988  INFO [main] txn.TxnHandler: Removed transactions: ([24]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,988  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:24
2023-02-15T13:35:07,990  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:25
2023-02-15T13:35:07,992  INFO [main] txn.TxnHandler: Removed transactions: ([25]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:07,992  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:25
2023-02-15T13:35:08,008  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:08,008  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:08,008  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:08,008  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:08,008  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:08,008  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:08,008  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:08,008  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:08,008  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:08,008  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:08,008  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:08,008  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:08,009  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_databases: @hive#NonExistentDatabaseUsedForHealthCheck	
2023-02-15T13:35:08,011  INFO [main] compactor.Worker: Starting Worker thread
2023-02-15T13:35:08,011  INFO [main] compactor.Worker: [wasabi] Worker 111
2023-02-15T13:35:08,011  INFO [main] compactor.Worker: [wasabi] Worker 117
2023-02-15T13:35:08,011  INFO [main_timeout_executor] compactor.Worker: [wasabi] Worker 281
2023-02-15T13:35:08,015  INFO [main_timeout_executor] compactor.Worker: Processing compaction request id:1,dbname:default,tableName:x_table,partName:ds=part,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:null,tooManyAborts:false,hasOldAbort:false,highestWriteId:0,errorMessage:,workerId: labdas-1898,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:08,015  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.x_table	
2023-02-15T13:35:08,015  INFO [main_timeout_executor] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:08,016  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd19544, with PersistenceManager: null will be shutdown
2023-02-15T13:35:08,016  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd19544, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d6dd6bc created in the thread with id: 1899
2023-02-15T13:35:08,024  INFO [main_timeout_executor] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd19544
2023-02-15T13:35:08,035  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:35:08,035  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_partitions_by_names : tbl=hive.default.x_table	
2023-02-15T13:35:08,046  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:35:08,054  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([26]) with min_open_txn: 1
2023-02-15T13:35:08,064  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Submitting heartbeat task for TXN 26
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.txn.compactor.CompactionHeartbeatService$CompactionHeartbeater
2023-02-15T13:35:08,079  INFO [main_timeout_executor] compactor.Worker: Starting MINOR compaction for default.x_table.ds=part, id:1 in txnId=26, lockId=1 (TxnStatus: 'o') with compute stats set to true
2023-02-15T13:35:08,079  WARN [main_timeout_executor] compactor.MRCompactor: 2 delta files found for default.x_table.ds=part located at file:/home/rizky/hive/ql/target/tmp/compactor_test_table_17/x_table/ds=part! This is likely a sign of misconfiguration, especially if this message repeats.  Check that compaction is running properly.  Check for any runaway/mis-configured process writing to ACID tables, especially using Streaming Ingest API.
2023-02-15T13:35:08,080  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-1898-compactor-default.x_table.ds=part_0' to default queue. (current delta dirs count=1, obsolete delta dirs count=-1. TxnIdRange[21,22}]
2023-02-15T13:35:08,080  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:35:08,081  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:35:08,083  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:35:08,084  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:35:08,091  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:35:08,099  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local2103248374_0013
2023-02-15T13:35:08,099  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:35:08,135  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:35:08,136  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-1898-compactor-default.x_table.ds=part_0' with jobID=job_local2103248374_0013 compaction ID=1
2023-02-15T13:35:08,136  INFO [Thread-1800] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:35:08,136  INFO [Thread-1800] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:35:08,137  INFO [Thread-1800] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:35:08,137  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2103248374_0013_m_000000_0
2023-02-15T13:35:08,137  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:35:08,138  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 144, deltas: [delta_0000021_0000022]}
2023-02-15T13:35:08,138  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:35:08,144  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:35:08,144  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2103248374_0013_m_000000_0 is done. And is in the process of committing
2023-02-15T13:35:08,144  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:35:08,144  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2103248374_0013_m_000000_0' done.
2023-02-15T13:35:08,145  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2103248374_0013_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=26748
		FILE: Number of bytes written=16096228
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=214
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=998768640
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:35:08,145  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2103248374_0013_m_000000_0
2023-02-15T13:35:08,145  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local2103248374_0013_m_000001_0
2023-02-15T13:35:08,145  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:35:08,145  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 144, deltas: [delta_0000021_0000022]}
2023-02-15T13:35:08,145  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:35:08,149  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:35:08,149  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local2103248374_0013_m_000001_0 is done. And is in the process of committing
2023-02-15T13:35:08,149  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:35:08,149  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local2103248374_0013_m_000001_0' done.
2023-02-15T13:35:08,149  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local2103248374_0013_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=27355
		FILE: Number of bytes written=16096356
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=214
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=998768640
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:35:08,149  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local2103248374_0013_m_000001_0
2023-02-15T13:35:08,149  INFO [Thread-1800] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:35:13,141  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-1898-compactor-default.x_table.ds=part_1' to default queue. (current delta dirs count=1, obsolete delta dirs count=-1. TxnIdRange[23,24}]
2023-02-15T13:35:13,142  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:35:13,144  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:35:13,150  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:35:13,152  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:35:13,174  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:35:13,189  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local1515452626_0014
2023-02-15T13:35:13,189  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:35:13,234  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:35:13,234  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-1898-compactor-default.x_table.ds=part_1' with jobID=job_local1515452626_0014 compaction ID=1
2023-02-15T13:35:13,234  INFO [Thread-1835] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:35:13,234  INFO [Thread-1835] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:35:13,235  INFO [Thread-1835] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:35:13,235  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1515452626_0014_m_000000_0
2023-02-15T13:35:13,236  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:35:13,236  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 144, deltas: [delta_0000023_0000024]}
2023-02-15T13:35:13,236  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:35:13,242  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:35:13,242  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1515452626_0014_m_000000_0 is done. And is in the process of committing
2023-02-15T13:35:13,242  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:35:13,242  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1515452626_0014_m_000000_0' done.
2023-02-15T13:35:13,242  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1515452626_0014_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=28013
		FILE: Number of bytes written=17321763
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=214
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1018167296
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:35:13,242  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1515452626_0014_m_000000_0
2023-02-15T13:35:13,242  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local1515452626_0014_m_000001_0
2023-02-15T13:35:13,242  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:35:13,243  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 144, deltas: [delta_0000023_0000024]}
2023-02-15T13:35:13,243  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:35:13,246  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:35:13,246  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local1515452626_0014_m_000001_0 is done. And is in the process of committing
2023-02-15T13:35:13,246  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:35:13,246  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local1515452626_0014_m_000001_0' done.
2023-02-15T13:35:13,246  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local1515452626_0014_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=28620
		FILE: Number of bytes written=17321891
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=214
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1018167296
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:35:13,246  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local1515452626_0014_m_000001_0
2023-02-15T13:35:13,246  INFO [Thread-1835] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:35:18,301  INFO [main_timeout_executor] compactor.MRCompactor: Submitting MINOR compaction job 'labdas-1898-compactor-default.x_table.ds=part' to default queue. (current delta dirs count=6, obsolete delta dirs count=0. TxnIdRange[21,24}]
2023-02-15T13:35:18,301  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:35:18,302  WARN [main_timeout_executor] impl.MetricsSystemImpl: JobTracker metrics system already initialized!
2023-02-15T13:35:18,304  WARN [main_timeout_executor] mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2023-02-15T13:35:18,306  WARN [main_timeout_executor] mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2023-02-15T13:35:18,315  INFO [main_timeout_executor] mapreduce.JobSubmitter: number of splits:2
2023-02-15T13:35:18,332  INFO [main_timeout_executor] mapreduce.JobSubmitter: Submitting tokens for job: job_local575418429_0015
2023-02-15T13:35:18,332  INFO [main_timeout_executor] mapreduce.JobSubmitter: Executing with tokens: []
2023-02-15T13:35:18,367  INFO [main_timeout_executor] mapreduce.Job: The url to track the job: http://localhost:8080/
2023-02-15T13:35:18,367  INFO [main_timeout_executor] compactor.MRCompactor: Submitted compaction job 'labdas-1898-compactor-default.x_table.ds=part' with jobID=job_local575418429_0015 compaction ID=1
2023-02-15T13:35:18,367  INFO [Thread-1895] mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:35:18,368  INFO [Thread-1895] mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.txn.compactor.MRCompactor$CompactorOutputCommitter
2023-02-15T13:35:18,369  INFO [Thread-1895] mapred.LocalJobRunner: Waiting for map tasks
2023-02-15T13:35:18,369  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local575418429_0015_m_000000_0
2023-02-15T13:35:18,369  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:35:18,369  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 0, length: 496, deltas: [delete_delta_0000021_0000022_v0000026, delta_0000021_0000022, delta_0000021_0000022_v0000026, delete_delta_0000023_0000024_v0000026, delta_0000023_0000024, delta_0000023_0000024_v0000026]}
2023-02-15T13:35:18,369  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:35:18,376  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:35:18,376  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local575418429_0015_m_000000_0 is done. And is in the process of committing
2023-02-15T13:35:18,376  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:35:18,376  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local575418429_0015_m_000000_0' done.
2023-02-15T13:35:18,376  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local575418429_0015_m_000000_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=31105
		FILE: Number of bytes written=18545825
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=854
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1018167296
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:35:18,376  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local575418429_0015_m_000000_0
2023-02-15T13:35:18,376  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Starting task: attempt_local575418429_0015_m_000001_0
2023-02-15T13:35:18,376  INFO [LocalJobRunner Map Task Executor #0] mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2023-02-15T13:35:18,377  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: Processing split: CompactorInputSplit{base: null, bucket: 1, length: 496, deltas: [delete_delta_0000021_0000022_v0000026, delta_0000021_0000022, delta_0000021_0000022_v0000026, delete_delta_0000023_0000024_v0000026, delta_0000023_0000024, delta_0000023_0000024_v0000026]}
2023-02-15T13:35:18,377  INFO [LocalJobRunner Map Task Executor #0] mapred.MapTask: numReduceTasks: 0
2023-02-15T13:35:18,381  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: 
2023-02-15T13:35:18,381  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task:attempt_local575418429_0015_m_000001_0 is done. And is in the process of committing
2023-02-15T13:35:18,381  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: map
2023-02-15T13:35:18,381  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Task 'attempt_local575418429_0015_m_000001_0' done.
2023-02-15T13:35:18,381  INFO [LocalJobRunner Map Task Executor #0] mapred.Task: Final Counters for attempt_local575418429_0015_m_000001_0: Counters: 15
	File System Counters
		FILE: Number of bytes read=32924
		FILE: Number of bytes written=18546185
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=854
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1018167296
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2023-02-15T13:35:18,381  INFO [LocalJobRunner Map Task Executor #0] mapred.LocalJobRunner: Finishing task: attempt_local575418429_0015_m_000001_0
2023-02-15T13:35:18,381  INFO [Thread-1895] mapred.LocalJobRunner: map task executor complete.
2023-02-15T13:35:23,370  INFO [main_timeout_executor] compactor.Worker: Completed MINOR compaction for default.x_table.ds=part in txnId=26, lockId=1 (TxnStatus: 'o'), marking as compacted.
2023-02-15T13:35:23,378  INFO [main_timeout_executor] compactor.CompactionHeartbeatService: Stopping heartbeat task for TXN 26
2023-02-15T13:35:23,378  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Shutting down compaction txn heartbeater instance.
2023-02-15T13:35:23,378  INFO [main_timeout_executor] compactor.CompactionHeartbeatService$CompactionHeartbeater: Compaction txn heartbeater instance is successfully stopped.
2023-02-15T13:35:23,380  INFO [main_timeout_executor] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:26
2023-02-15T13:35:23,384  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([26]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:23,384  INFO [main_timeout_executor] compactor.StatsUpdater: id:1,dbname:default,tableName:x_table,partName:ds=part,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:,workerId: labdas-1898,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0: running 'analyze table default.x_table partition(ds='part') compute statistics noscan'
Hive Session ID = ca780c97-d321-4404-af81-166fc20cd0f1
2023-02-15T13:35:23,384  INFO [main_timeout_executor] SessionState: Hive Session ID = ca780c97-d321-4404-af81-166fc20cd0f1
ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/rizky/hive/conf/ivysettings.xml will be used
2023-02-15T13:35:23,385  INFO [main_timeout_executor] DependencyResolver: ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/home/rizky/hive/conf/ivysettings.xml will be used
2023-02-15T13:35:23,387  INFO [main_timeout_executor] session.SessionState: Created HDFS directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/ca780c97-d321-4404-af81-166fc20cd0f1
2023-02-15T13:35:23,388  INFO [main_timeout_executor] session.SessionState: Created local directory: /home/rizky/hive/ql/target/tmp/localscratchdir/ca780c97-d321-4404-af81-166fc20cd0f1
2023-02-15T13:35:23,390  INFO [main_timeout_executor] session.SessionState: Created HDFS directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/ca780c97-d321-4404-af81-166fc20cd0f1/_tmp_space.db
2023-02-15T13:35:23,390  INFO [main_timeout_executor] ql.Driver: Compiling command(queryId=rizky_20230215133523_187f20e7-719a-4a72-9ead-045a09de29cf): analyze table default.x_table partition(ds='part') compute statistics noscan
2023-02-15T13:35:23,391  INFO [main_timeout_executor] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:35:23,391  INFO [main_timeout_executor] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:23,391  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd19544, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d6dd6bc will be shutdown
2023-02-15T13:35:23,391  INFO [main_timeout_executor] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@3cd19544, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@62f3afa created in the thread with id: 1899
2023-02-15T13:35:23,398  INFO [main_timeout_executor] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:35:23,398  INFO [main_timeout_executor] metastore.RetryingMetaStoreClient: RetryingMetaStoreClient proxy=class org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient ugi=rizky (auth:SIMPLE) retries=1 delay=1 lifetime=0
TRACE StatusLogger Log4jLoggerFactory.getContext() found anchor class org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer
2023-02-15T13:35:23,400  INFO [main_timeout_executor] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([27]) with min_open_txn: 27
2023-02-15T13:35:23,400  INFO [main_timeout_executor] lockmgr.DbTxnManager: Opened txnid:27
2023-02-15T13:35:23,400  INFO [main_timeout_executor] ql.QueryState: Query-level HMS cache created for rizky_20230215133523_187f20e7-719a-4a72-9ead-045a09de29cf
2023-02-15T13:35:23,401  INFO [main_timeout_executor] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.x_table	
2023-02-15T13:35:23,403  INFO [main_timeout_executor] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:35:23,403  INFO [main_timeout_executor] parse.ColumnStatsSemanticAnalyzer: Invoking analyze on original query
2023-02-15T13:35:23,403  INFO [main_timeout_executor] parse.ColumnStatsSemanticAnalyzer: Starting Semantic Analysis
2023-02-15T13:35:23,403 ERROR [main_timeout_executor] session.SessionState: Error setting up authorization: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	... 22 more
FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
2023-02-15T13:35:23,404 ERROR [main_timeout_executor] ql.Driver: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001)
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765)
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331)
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649)
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223)
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141)
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96)
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81)
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93)
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530)
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360)
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977)
	... 21 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350)
	... 22 more

2023-02-15T13:35:23,404  INFO [main_timeout_executor] metadata.Hive: Dumping metastore api call timing information for : compilation phase
2023-02-15T13:35:23,404  INFO [main_timeout_executor] metadata.Hive: Total time spent in each metastore function (ms): {openTxn_(String, TxnType)=1, isCompatibleWith_(Configuration)=0, getTable_(GetTableRequest)=3, flushCache_()=1, getValidTxns_(long)=0}
2023-02-15T13:35:23,404  INFO [main_timeout_executor] ql.Driver: Completed compiling command(queryId=rizky_20230215133523_187f20e7-719a-4a72-9ead-045a09de29cf); Time taken: 0.014 seconds
2023-02-15T13:35:23,404  INFO [main_timeout_executor] lockmgr.DbTxnManager: Stopped heartbeat for query: rizky_20230215133523_187f20e7-719a-4a72-9ead-045a09de29cf
2023-02-15T13:35:23,406  INFO [main_timeout_executor] txn.TxnHandler: Removed transactions: ([27]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:23,409  WARN [main_timeout_executor] txn.TxnHandler: Aborted 1 transaction(s) [27] due to rollback
2023-02-15T13:35:23,409 ERROR [main_timeout_executor] ql.Driver: Failed to run analyze table default.x_table partition(ds='part') compute statistics noscan
org.apache.hadoop.hive.ql.processors.CommandProcessorException: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.DriverUtils.createProcessorException(DriverUtils.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.handleException(Compiler.java:479) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:121) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	... 14 more
2023-02-15T13:35:23,410  INFO [main_timeout_executor] cleanup.SyncCleanupService: Deleted directory: /home/rizky/hive/ql/target/tmp/scratchdir/rizky/ca780c97-d321-4404-af81-166fc20cd0f1 on fs with scheme file
2023-02-15T13:35:23,410  INFO [main_timeout_executor] cleanup.SyncCleanupService: Deleted directory: /home/rizky/hive/ql/target/tmp/localscratchdir/ca780c97-d321-4404-af81-166fc20cd0f1 on fs with scheme file
2023-02-15T13:35:23,410 ERROR [main_timeout_executor] compactor.StatsUpdater: id:1,dbname:default,tableName:x_table,partName:ds=part,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:,workerId: labdas-1898,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0: gatherStats(default,x_table,ds=part) failed due to: Failed to run analyze table default.x_table partition(ds='part') compute statistics noscan
org.apache.hadoop.hive.ql.metadata.HiveException: Failed to run analyze table default.x_table partition(ds='part') compute statistics noscan
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:99) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriver(DriverUtils.java:81) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.StatsUpdater.gatherStats(StatsUpdater.java:93) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.findNextCompactionAndExecute(Worker.java:530) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.Worker.lambda$run$0(Worker.java:115) ~[classes/:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_352]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_352]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_352]
Caused by: org.apache.hadoop.hive.ql.processors.CommandProcessorException: FAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.DriverUtils.createProcessorException(DriverUtils.java:181) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.handleException(Compiler.java:479) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:121) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:1001) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:360) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactoryForTest
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[?:1.8.0_352]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[?:1.8.0_352]
	at java.lang.Class.forName0(Native Method) ~[?:1.8.0_352]
	at java.lang.Class.forName(Class.java:348) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.ql.metadata.HiveUtils.getAuthorizeProviderManager(HiveUtils.java:350) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:977) ~[classes/:?]
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthorizerV2(SessionState.java:1740) ~[classes/:?]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.needsTransform(SemanticAnalyzer.java:15471) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12765) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.analyzeInternal(SemanticAnalyzer.java:12331) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.parse.ColumnStatsSemanticAnalyzer.analyze(ColumnStatsSemanticAnalyzer.java:649) ~[classes/:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Compiler.analyze(Compiler.java:223) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Compiler.compile(Compiler.java:106) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:518) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:470) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:182) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:154) ~[classes/:?]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:141) ~[classes/:?]
	at org.apache.hadoop.hive.ql.DriverUtils.runOnDriverInternal(DriverUtils.java:96) ~[classes/:?]
	... 8 more
2023-02-15T13:35:23,410  INFO [main] compactor.Worker: [wasabi] Worker 163
2023-02-15T13:35:23,410  INFO [main] compactor.Worker: [wasabi] Worker 170
2023-02-15T13:35:23,419  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:23,419  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:23,419  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:23,419  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:23,419  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:23,419  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:23,419  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:23,419  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:23,419  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:23,419  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:23,419  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:23,419  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:23,419  INFO [main] compactor.Cleaner: Starting Cleaner thread
2023-02-15T13:35:23,424  INFO [main] compactor.Cleaner: Cleaning based on min open txn id: 27
2023-02-15T13:35:23,425  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:1,dbname:default,tableName:x_table,partName:ds=part,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:23,425  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:23,425  INFO [Cleaner-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:23,425  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2dac1591, with PersistenceManager: null will be shutdown
2023-02-15T13:35:23,425  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2dac1591, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@10fa9a3b created in the thread with id: 2057
2023-02-15T13:35:23,426  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2dac1591
2023-02-15T13:35:23,432  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=1 About to remove 6 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_17/x_table/ds=part. [delete_delta_0000021_0000022_v0000026,delta_0000021_0000022,delta_0000021_0000022_v0000026,delete_delta_0000023_0000024_v0000026,delta_0000023_0000024,delta_0000023_0000024_v0000026]
2023-02-15T13:35:23,435  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:23,450  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:23,450  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:23,450  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:23,450  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:23,450  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:23,450  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:23,450  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:23,450  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:23,450  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:23,450  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:23,450  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:23,450  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:23,450  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:35:23,462  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:35:23,464  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:35:23,464  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:23,464  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@60b4dacc will be shutdown
2023-02-15T13:35:23,464  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77b3a4c0 created in the thread with id: 1
2023-02-15T13:35:23,473  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:35:23,475  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:35:23,504  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:23,504  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:23,504  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:23,504  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:23,504  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:23,504  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:23,504  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:23,504  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:23,504  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:23,504  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:23,504  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:23,504  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:23,505  INFO [main] compactor.Cleaner: Starting Cleaner thread
2023-02-15T13:35:28,502 ERROR [main] compactor.Cleaner: Caught an exception in the main loop of compactor cleaner, MetaException(message:Unable to lock 'Cleaner' due to: nulljava.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
	at java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
	at org.apache.hadoop.hive.metastore.txn.TxnHandler.acquireLock(TxnHandler.java:6062)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.run(Cleaner.java:134)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runOneLoopOfCompactorThread(CompactorTest.java:383)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.startCleaner(CompactorTest.java:159)
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testCleanerAuxFailure(TestCompactionMetrics.java:272)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
)
	at org.apache.hadoop.hive.metastore.txn.TxnHandler.acquireLock(TxnHandler.java:6075)
	at org.apache.hadoop.hive.ql.txn.compactor.Cleaner.run(Cleaner.java:134)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runOneLoopOfCompactorThread(CompactorTest.java:383)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.startCleaner(CompactorTest.java:159)
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testCleanerAuxFailure(TestCompactionMetrics.java:272)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

2023-02-15T13:35:28,502  WARN [main] compactor.CompactorThread: Possible org.apache.hadoop.hive.ql.txn.compactor.Cleaner slowdown, loop took 1676496928 seconds to finish.
2023-02-15T13:35:28,516  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:28,516  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:28,516  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:28,516  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:28,516  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:28,516  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:28,516  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:28,516  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:28,516  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:28,516  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:28,516  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:28,516  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:28,516  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:35:28,520  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:35:28,522  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:35:28,522  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:28,522  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@77b3a4c0 will be shutdown
2023-02-15T13:35:28,522  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@48efa366 created in the thread with id: 1
2023-02-15T13:35:28,534  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:35:28,535  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:35:28,562  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:28,562  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:28,562  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:28,562  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:28,562  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:28,562  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:28,562  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:28,562  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:28,562  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:28,562  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:28,562  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:28,562  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:28,563  INFO [main] compactor.Initiator: Starting Initiator thread
2023-02-15T13:35:28,566  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410528565
2023-02-15T13:35:28,571  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410528571
2023-02-15T13:35:28,586  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:28,586  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:28,586  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:28,586  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:28,586  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:28,586  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:28,586  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:28,586  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:28,586  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:28,586  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:28,586  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:28,586  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:28,586  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:35:28,590  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:35:28,591  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:35:28,591  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:28,591  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@48efa366 will be shutdown
2023-02-15T13:35:28,591  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@144aaab1 created in the thread with id: 1
2023-02-15T13:35:28,602  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:35:28,603  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:35:28,623  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.table	
2023-02-15T13:35:28,628  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:table, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_20/table, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:35:28,629  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_20/table specified for non-external table:table
2023-02-15T13:35:28,629  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_20/table
2023-02-15T13:35:28,648  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.table	
2023-02-15T13:35:28,657  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_20/table/ds=p1
2023-02-15T13:35:28,664  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.table	
2023-02-15T13:35:28,665  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_20/table/ds=p2
2023-02-15T13:35:28,669  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.table	
2023-02-15T13:35:28,670  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_20/table/ds=p3
2023-02-15T13:35:28,679  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) with min_open_txn: 1
2023-02-15T13:35:28,682  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:35:28,682  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:35:28,682  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:35:28,682  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:35:28,682  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:35:28,682  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:35:28,682  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:35:28,682  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:35:28,682  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:35:28,682  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:35:28,682  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=table (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
2023-02-15T13:35:28,692  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,695  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [1] due to none
2023-02-15T13:35:28,702  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,705  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [2] due to none
2023-02-15T13:35:28,712  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,715  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [3] due to none
2023-02-15T13:35:28,722  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,724  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [4] due to none
2023-02-15T13:35:28,731  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,734  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [5] due to none
2023-02-15T13:35:28,745  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,746  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:35:28,756  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,756  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:35:28,767  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,767  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:35:28,778  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,778  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:35:28,789  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,789  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:35:28,794  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([11, 12, 13, 14, 15, 16, 17, 18, 19, 20]) with min_open_txn: 1
2023-02-15T13:35:28,798  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:35:28,798  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:35:28,798  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:35:28,798  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:35:28,798  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:35:28,798  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:35:28,798  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:35:28,798  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:35:28,798  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:35:28,798  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:35:28,798  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=table (txnIds: [11, 12, 13, 14, 15, 16, 17, 18, 19, 20])
2023-02-15T13:35:28,806  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,809  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [11] due to none
2023-02-15T13:35:28,817  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,820  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [12] due to none
2023-02-15T13:35:28,829  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,831  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [13] due to none
2023-02-15T13:35:28,841  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,843  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [14] due to none
2023-02-15T13:35:28,852  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,855  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [15] due to none
2023-02-15T13:35:28,868  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,868  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:35:28,880  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,880  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:35:28,891  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,891  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:35:28,902  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,902  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:35:28,911  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,912  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:35:28,916  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([21, 22, 23, 24, 25, 26, 27, 28, 29, 30]) with min_open_txn: 1
2023-02-15T13:35:28,919  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 21
2023-02-15T13:35:28,919  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 22
2023-02-15T13:35:28,919  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 23
2023-02-15T13:35:28,919  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 24
2023-02-15T13:35:28,919  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 25
2023-02-15T13:35:28,919  INFO [main] txn.TxnHandler: Allocated writeId: 26 for txnId: 26
2023-02-15T13:35:28,919  INFO [main] txn.TxnHandler: Allocated writeId: 27 for txnId: 27
2023-02-15T13:35:28,919  INFO [main] txn.TxnHandler: Allocated writeId: 28 for txnId: 28
2023-02-15T13:35:28,919  INFO [main] txn.TxnHandler: Allocated writeId: 29 for txnId: 29
2023-02-15T13:35:28,919  INFO [main] txn.TxnHandler: Allocated writeId: 30 for txnId: 30
2023-02-15T13:35:28,919  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=table (txnIds: [21, 22, 23, 24, 25, 26, 27, 28, 29, 30])
2023-02-15T13:35:28,930  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,930  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:21
2023-02-15T13:35:28,940  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,940  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:22
2023-02-15T13:35:28,950  INFO [main] txn.TxnHandler: Removed transactions: ([23]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,950  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:23
2023-02-15T13:35:28,959  INFO [main] txn.TxnHandler: Removed transactions: ([24]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,959  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:24
2023-02-15T13:35:28,970  INFO [main] txn.TxnHandler: Removed transactions: ([25]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,970  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:25
2023-02-15T13:35:28,981  INFO [main] txn.TxnHandler: Removed transactions: ([26]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,981  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:26
2023-02-15T13:35:28,992  INFO [main] txn.TxnHandler: Removed transactions: ([27]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:28,992  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:27
2023-02-15T13:35:29,003  INFO [main] txn.TxnHandler: Removed transactions: ([28]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,003  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:28
2023-02-15T13:35:29,013  INFO [main] txn.TxnHandler: Removed transactions: ([29]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,013  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:29
2023-02-15T13:35:29,023  INFO [main] txn.TxnHandler: Removed transactions: ([30]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,023  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:30
2023-02-15T13:35:29,024 ERROR [main] metrics.AcidMetricService: Cannot initialize delta file metrics mbean server. AcidMetricService initialization aborted.
javax.management.InstanceAlreadyExistsException: metrics:type=compaction,name=compaction_num_obsolete_deltas
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324) ~[?:1.8.0_352]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.initObjectsForMetrics(AcidMetricService.java:404) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.setConf(AcidMetricService.java:380) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runAcidMetricService(CompactorTest.java:165) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testPartTablesWithXAbortedTxns(TestCompactionMetrics.java:822) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_352]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_352]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_352]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T13:35:29,135  INFO [Finalizer] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T13:35:29,135  INFO [Finalizer] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -5
2023-02-15T13:35:29,160  WARN [main] metrics.AcidMetricService: Caught exception while trying to fetch compaction metrics from metastore backend db.
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.updateDeltaMBeanAndMetric(AcidMetricService.java:289) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.updateDeltaMetrics(AcidMetricService.java:270) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.run(AcidMetricService.java:119) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runAcidMetricService(CompactorTest.java:166) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testPartTablesWithXAbortedTxns(TestCompactionMetrics.java:822) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_352]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_352]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_352]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T13:35:29,173  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:29,173  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:29,173  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:29,173  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:29,173  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:29,173  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:29,173  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:29,173  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:29,173  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:29,173  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:29,173  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:29,173  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:29,174  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:35:29,186  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:35:29,187  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:35:29,187  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:29,187  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@144aaab1 will be shutdown
2023-02-15T13:35:29,187  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17675c2f created in the thread with id: 1
2023-02-15T13:35:29,207  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:35:29,208  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:35:29,228  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.camipc	
2023-02-15T13:35:29,240  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:35:29,241  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.camipc	
2023-02-15T13:35:29,292  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:camipc, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:35:29,293  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc specified for non-external table:camipc
2023-02-15T13:35:29,293  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc
2023-02-15T13:35:29,308  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.camipc	
2023-02-15T13:35:29,312  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today0
2023-02-15T13:35:29,334  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.camipc	
2023-02-15T13:35:29,335  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today1
2023-02-15T13:35:29,356  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.camipc	
2023-02-15T13:35:29,357  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today2
2023-02-15T13:35:29,378  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.camipc	
2023-02-15T13:35:29,379  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today3
2023-02-15T13:35:29,398  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.camipc	
2023-02-15T13:35:29,400  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today4
2023-02-15T13:35:29,404  INFO [Metastore Scheduled Worker 2] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:29,404  INFO [Metastore Scheduled Worker 2] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4202889d, with PersistenceManager: null will be shutdown
2023-02-15T13:35:29,404  INFO [Metastore Scheduled Worker 2] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4202889d, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@64667b63 created in the thread with id: 46
2023-02-15T13:35:29,408  INFO [Metastore Scheduled Worker 2] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@4202889d
2023-02-15T13:35:29,419  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.camipc	
2023-02-15T13:35:29,420  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today5
2023-02-15T13:35:29,440  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.camipc	
2023-02-15T13:35:29,442  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today6
2023-02-15T13:35:29,466  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.camipc	
2023-02-15T13:35:29,467  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today7
2023-02-15T13:35:29,487  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.camipc	
2023-02-15T13:35:29,489  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today8
2023-02-15T13:35:29,507  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.camipc	
2023-02-15T13:35:29,508  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today9
2023-02-15T13:35:29,540  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]) with min_open_txn: 1
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 21
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 22
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 23
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 24
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 25
2023-02-15T13:35:29,546  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=camipc (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])
2023-02-15T13:35:29,549  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:35:29,551  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,552  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:35:29,555  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2023-02-15T13:35:29,558  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,558  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2023-02-15T13:35:29,560  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:35:29,562  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,562  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:35:29,565  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2023-02-15T13:35:29,567  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,567  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2023-02-15T13:35:29,569  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:35:29,572  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,572  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:35:29,574  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:35:29,576  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,576  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:35:29,578  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2023-02-15T13:35:29,581  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,581  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:35:29,583  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2023-02-15T13:35:29,585  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,585  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:35:29,587  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2023-02-15T13:35:29,590  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,590  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:35:29,592  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2023-02-15T13:35:29,594  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,594  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:35:29,596  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2023-02-15T13:35:29,599  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,599  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2023-02-15T13:35:29,601  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2023-02-15T13:35:29,603  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,604  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2023-02-15T13:35:29,606  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:13
2023-02-15T13:35:29,609  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,609  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2023-02-15T13:35:29,611  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:14
2023-02-15T13:35:29,613  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,613  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:14
2023-02-15T13:35:29,615  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2023-02-15T13:35:29,618  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,618  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2023-02-15T13:35:29,620  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2023-02-15T13:35:29,623  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,623  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:35:29,625  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2023-02-15T13:35:29,628  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,628  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:35:29,630  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2023-02-15T13:35:29,632  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,632  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:35:29,634  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2023-02-15T13:35:29,636  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,636  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:35:29,638  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2023-02-15T13:35:29,640  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,640  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:35:29,642  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:21
2023-02-15T13:35:29,644  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,644  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:21
2023-02-15T13:35:29,646  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:22
2023-02-15T13:35:29,649  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,649  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:22
2023-02-15T13:35:29,651  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:23
2023-02-15T13:35:29,653  INFO [main] txn.TxnHandler: Removed transactions: ([23]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,653  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:23
2023-02-15T13:35:29,655  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:24
2023-02-15T13:35:29,657  INFO [main] txn.TxnHandler: Removed transactions: ([24]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,657  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:24
2023-02-15T13:35:29,659  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:25
2023-02-15T13:35:29,661  INFO [main] txn.TxnHandler: Removed transactions: ([25]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:29,662  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:25
2023-02-15T13:35:29,673  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([26]) with min_open_txn: 1
2023-02-15T13:35:29,678  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:26
2023-02-15T13:35:29,682  INFO [main] txn.TxnHandler: Removed transactions: ([26]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:31,692  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([27]) with min_open_txn: 27
2023-02-15T13:35:31,696  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:27
2023-02-15T13:35:31,700  INFO [main] txn.TxnHandler: Removed transactions: ([27]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:33,717  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([28]) with min_open_txn: 28
2023-02-15T13:35:33,722  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:28
2023-02-15T13:35:33,726  INFO [main] txn.TxnHandler: Removed transactions: ([28]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:35,735  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([29]) with min_open_txn: 29
2023-02-15T13:35:35,738  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:29
2023-02-15T13:35:35,742  INFO [main] txn.TxnHandler: Removed transactions: ([29]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:37,752  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([30]) with min_open_txn: 30
2023-02-15T13:35:37,758  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:30
2023-02-15T13:35:37,762  INFO [main] txn.TxnHandler: Removed transactions: ([30]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:39,778  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([31]) with min_open_txn: 31
2023-02-15T13:35:39,787  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:31
2023-02-15T13:35:39,792  INFO [main] txn.TxnHandler: Removed transactions: ([31]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:41,809  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([32]) with min_open_txn: 32
2023-02-15T13:35:41,814  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:32
2023-02-15T13:35:41,818  INFO [main] txn.TxnHandler: Removed transactions: ([32]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:43,837  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([33]) with min_open_txn: 33
2023-02-15T13:35:43,841  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:33
2023-02-15T13:35:43,845  INFO [main] txn.TxnHandler: Removed transactions: ([33]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:45,854  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([34]) with min_open_txn: 34
2023-02-15T13:35:45,859  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:34
2023-02-15T13:35:45,863  INFO [main] txn.TxnHandler: Removed transactions: ([34]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:47,872  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([35]) with min_open_txn: 35
2023-02-15T13:35:47,876  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:35
2023-02-15T13:35:47,880  INFO [main] txn.TxnHandler: Removed transactions: ([35]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:49,893  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:35:49,893  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:35:49,893  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:35:49,893  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:35:49,893  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:35:49,893  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:35:49,893  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:35:49,893  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:35:49,893  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:35:49,893  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:35:49,893  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:35:49,893  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:35:49,894  INFO [main] compactor.Cleaner: Starting Cleaner thread
2023-02-15T13:35:49,900  INFO [main] compactor.Cleaner: Cleaning based on min open txn id: 36
2023-02-15T13:35:49,900  INFO [Cleaner-executor-thread-2] compactor.Cleaner: Starting cleaning for id:2,dbname:default,tableName:camipc,partName:ds=today1,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:49,900  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:1,dbname:default,tableName:camipc,partName:ds=today0,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:49,900  INFO [Cleaner-executor-thread-3] compactor.Cleaner: Starting cleaning for id:3,dbname:default,tableName:camipc,partName:ds=today2,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:49,900  INFO [Cleaner-executor-thread-2] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:49,900  INFO [Cleaner-executor-thread-2] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:35:49,900  INFO [Cleaner-executor-thread-2] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6562ba25, with PersistenceManager: null will be shutdown
2023-02-15T13:35:49,900  INFO [Cleaner-executor-thread-2] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6562ba25, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@65f209f5 created in the thread with id: 2298
2023-02-15T13:35:49,911  INFO [Cleaner-executor-thread-2] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@6562ba25
2023-02-15T13:35:49,920  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:49,920  INFO [Cleaner-executor-thread-3] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:35:49,920  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a105135, with PersistenceManager: null will be shutdown
2023-02-15T13:35:49,920  INFO [Cleaner-executor-thread-3] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@227d59ec, with PersistenceManager: null will be shutdown
2023-02-15T13:35:49,920  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a105135, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@723d9ce7 created in the thread with id: 2297
2023-02-15T13:35:49,920  INFO [Cleaner-executor-thread-3] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@227d59ec, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1a131f4e created in the thread with id: 2299
2023-02-15T13:35:49,922  INFO [Cleaner-executor-thread-3] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@227d59ec
2023-02-15T13:35:49,922  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a105135
2023-02-15T13:35:49,936  INFO [Cleaner-executor-thread-2] compactor.Cleaner:  id=2 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today1. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:49,936  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=1 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today0. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:49,936  INFO [Cleaner-executor-thread-3] compactor.Cleaner:  id=3 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today2. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:49,942  WARN [Cleaner-executor-thread-3] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:49,942  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:49,942  WARN [Cleaner-executor-thread-2] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:49,944  INFO [Cleaner-executor-thread-2] compactor.Cleaner: Starting cleaning for id:4,dbname:default,tableName:camipc,partName:ds=today3,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:49,944  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:6,dbname:default,tableName:camipc,partName:ds=today5,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:49,944  INFO [Cleaner-executor-thread-3] compactor.Cleaner: Starting cleaning for id:5,dbname:default,tableName:camipc,partName:ds=today4,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:49,954  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=6 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today5. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:49,954  INFO [Cleaner-executor-thread-2] compactor.Cleaner:  id=4 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today3. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:49,954  INFO [Cleaner-executor-thread-3] compactor.Cleaner:  id=5 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today4. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:49,954  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:49,955  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:7,dbname:default,tableName:camipc,partName:ds=today6,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:49,955  WARN [Cleaner-executor-thread-2] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:49,955  WARN [Cleaner-executor-thread-3] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:49,955  INFO [Cleaner-executor-thread-2] compactor.Cleaner: Starting cleaning for id:8,dbname:default,tableName:camipc,partName:ds=today7,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:49,955  INFO [Cleaner-executor-thread-3] compactor.Cleaner: Starting cleaning for id:9,dbname:default,tableName:camipc,partName:ds=today8,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:49,965  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=7 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today6. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:49,965  INFO [Cleaner-executor-thread-2] compactor.Cleaner:  id=8 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today7. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:49,966  INFO [Cleaner-executor-thread-3] compactor.Cleaner:  id=9 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today8. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:49,966  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:49,966  WARN [Cleaner-executor-thread-2] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:49,966  INFO [Cleaner-executor-thread-2] compactor.Cleaner: Starting cleaning for id:10,dbname:default,tableName:camipc,partName:ds=today9,state: ,type:MINOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:35:49,966  WARN [Cleaner-executor-thread-3] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:49,974  INFO [Cleaner-executor-thread-2] compactor.Cleaner:  id=10 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today9. [delta_0000021_0000022,delta_0000023_0000024]
2023-02-15T13:35:49,975  WARN [Cleaner-executor-thread-2] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:35:49,993  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([36]) with min_open_txn: 36
2023-02-15T13:35:49,999  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:36
2023-02-15T13:35:50,003  INFO [main] txn.TxnHandler: Removed transactions: ([36]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:52,043  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([37]) with min_open_txn: 37
2023-02-15T13:35:52,048  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:37
2023-02-15T13:35:52,052  INFO [main] txn.TxnHandler: Removed transactions: ([37]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:54,091  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([38]) with min_open_txn: 38
2023-02-15T13:35:54,097  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:38
2023-02-15T13:35:54,101  INFO [main] txn.TxnHandler: Removed transactions: ([38]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:56,139  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([39]) with min_open_txn: 39
2023-02-15T13:35:56,146  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:39
2023-02-15T13:35:56,150  INFO [main] txn.TxnHandler: Removed transactions: ([39]) from MIN_HISTORY_LEVEL
2023-02-15T13:35:58,184  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([40]) with min_open_txn: 40
2023-02-15T13:35:58,190  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:40
2023-02-15T13:35:58,194  INFO [main] txn.TxnHandler: Removed transactions: ([40]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:00,233  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([41]) with min_open_txn: 41
2023-02-15T13:36:00,239  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:41
2023-02-15T13:36:00,352  INFO [main] txn.TxnHandler: Removed transactions: ([41]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:02,390  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([42]) with min_open_txn: 42
2023-02-15T13:36:02,395  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:42
2023-02-15T13:36:02,398  INFO [main] txn.TxnHandler: Removed transactions: ([42]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:04,434  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([43]) with min_open_txn: 43
2023-02-15T13:36:04,441  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:43
2023-02-15T13:36:04,443  INFO [main] txn.TxnHandler: Removed transactions: ([43]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:06,479  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([44]) with min_open_txn: 44
2023-02-15T13:36:06,485  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:44
2023-02-15T13:36:06,488  INFO [main] txn.TxnHandler: Removed transactions: ([44]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:08,524  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([45]) with min_open_txn: 45
2023-02-15T13:36:08,530  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:45
2023-02-15T13:36:08,534  INFO [main] txn.TxnHandler: Removed transactions: ([45]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:10,547  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:36:10,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:36:10,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:36:10,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:36:10,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:36:10,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:36:10,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:36:10,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:36:10,547  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:36:10,547  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:36:10,547  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:36:10,547  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:36:10,548  INFO [main] compactor.Cleaner: Starting Cleaner thread
2023-02-15T13:36:10,551  INFO [main] compactor.Cleaner: Cleaning based on min open txn id: 46
2023-02-15T13:36:10,552  INFO [Cleaner-executor-thread-2] compactor.Cleaner: Starting cleaning for id:12,dbname:default,tableName:camipc,partName:ds=today1,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:36:10,552  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:11,dbname:default,tableName:camipc,partName:ds=today0,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:36:10,552  INFO [Cleaner-executor-thread-2] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:36:10,552  INFO [Cleaner-executor-thread-2] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:36:10,552  INFO [Cleaner-executor-thread-3] compactor.Cleaner: Starting cleaning for id:13,dbname:default,tableName:camipc,partName:ds=today2,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:36:10,552  INFO [Cleaner-executor-thread-2] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53c2f706, with PersistenceManager: null will be shutdown
2023-02-15T13:36:10,553  INFO [Cleaner-executor-thread-2] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53c2f706, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6799ce16 created in the thread with id: 2353
2023-02-15T13:36:10,560  INFO [Cleaner-executor-thread-2] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@53c2f706
2023-02-15T13:36:10,566  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:36:10,566  INFO [Cleaner-executor-thread-3] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:36:10,567  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a9c162f, with PersistenceManager: null will be shutdown
2023-02-15T13:36:10,567  INFO [Cleaner-executor-thread-3] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39cec594, with PersistenceManager: null will be shutdown
2023-02-15T13:36:10,567  INFO [Cleaner-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a9c162f, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@106780e6 created in the thread with id: 2352
2023-02-15T13:36:10,567  INFO [Cleaner-executor-thread-3] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39cec594, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@66ca4b1 created in the thread with id: 2354
2023-02-15T13:36:10,568  INFO [Cleaner-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@5a9c162f
2023-02-15T13:36:10,568  INFO [Cleaner-executor-thread-3] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@39cec594
2023-02-15T13:36:10,578  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=11 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today0. [base_20,delta_0000021_0000024]
2023-02-15T13:36:10,578  INFO [Cleaner-executor-thread-2] compactor.Cleaner:  id=12 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today1. [base_20,delta_0000021_0000024]
2023-02-15T13:36:10,578  INFO [Cleaner-executor-thread-3] compactor.Cleaner:  id=13 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today2. [base_20,delta_0000021_0000024]
2023-02-15T13:36:10,582  WARN [Cleaner-executor-thread-2] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:36:10,582  WARN [Cleaner-executor-thread-3] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:36:10,582  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:36:10,583  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:14,dbname:default,tableName:camipc,partName:ds=today3,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:36:10,583  INFO [Cleaner-executor-thread-2] compactor.Cleaner: Starting cleaning for id:16,dbname:default,tableName:camipc,partName:ds=today5,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:36:10,583  INFO [Cleaner-executor-thread-3] compactor.Cleaner: Starting cleaning for id:15,dbname:default,tableName:camipc,partName:ds=today4,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:36:10,590  INFO [Cleaner-executor-thread-2] compactor.Cleaner:  id=16 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today5. [base_20,delta_0000021_0000024]
2023-02-15T13:36:10,590  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=14 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today3. [base_20,delta_0000021_0000024]
2023-02-15T13:36:10,590  INFO [Cleaner-executor-thread-3] compactor.Cleaner:  id=15 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today4. [base_20,delta_0000021_0000024]
2023-02-15T13:36:10,591  WARN [Cleaner-executor-thread-3] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:36:10,591  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:36:10,591  WARN [Cleaner-executor-thread-2] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:36:10,591  INFO [Cleaner-executor-thread-3] compactor.Cleaner: Starting cleaning for id:17,dbname:default,tableName:camipc,partName:ds=today6,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:36:10,591  INFO [Cleaner-executor-thread-1] compactor.Cleaner: Starting cleaning for id:19,dbname:default,tableName:camipc,partName:ds=today8,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:36:10,591  INFO [Cleaner-executor-thread-2] compactor.Cleaner: Starting cleaning for id:18,dbname:default,tableName:camipc,partName:ds=today7,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:36:10,597  INFO [Cleaner-executor-thread-3] compactor.Cleaner:  id=17 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today6. [base_20,delta_0000021_0000024]
2023-02-15T13:36:10,597  INFO [Cleaner-executor-thread-1] compactor.Cleaner:  id=19 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today8. [base_20,delta_0000021_0000024]
2023-02-15T13:36:10,597  INFO [Cleaner-executor-thread-2] compactor.Cleaner:  id=18 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today7. [base_20,delta_0000021_0000024]
2023-02-15T13:36:10,598  WARN [Cleaner-executor-thread-2] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:36:10,598  WARN [Cleaner-executor-thread-3] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:36:10,598  WARN [Cleaner-executor-thread-1] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:36:10,598  INFO [Cleaner-executor-thread-3] compactor.Cleaner: Starting cleaning for id:20,dbname:default,tableName:camipc,partName:ds=today9,state: ,type:MAJOR,enqueueTime:0,commitTime:0,start:0,properties:null,runAs:rizky,tooManyAborts:false,hasOldAbort:false,highestWriteId:25,errorMessage:null,workerId: null,workerVersion: null,initiatorId: null,initiatorVersion: null,retryRetention0,txnId0,nextTxnId0,poolnamenull,numberOfBuckets0
2023-02-15T13:36:10,604  INFO [Cleaner-executor-thread-3] compactor.Cleaner:  id=20 About to remove 2 obsolete directories from file:/home/rizky/hive/ql/target/tmp/compactor_test_table_21/camipc/ds=today9. [base_20,delta_0000021_0000024]
2023-02-15T13:36:10,605  WARN [Cleaner-executor-thread-3] txn.CompactionTxnHandler: Expected to remove at least one row from completed_txn_components when marking compaction entry as clean!
2023-02-15T13:36:10,620  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:36:10,620  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:36:10,620  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:36:10,620  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:36:10,620  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:36:10,620  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:36:10,620  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:36:10,620  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:36:10,620  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:36:10,620  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:36:10,620  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:36:10,620  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:36:10,620  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:36:10,629  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:36:10,631  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:36:10,631  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:36:10,631  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@17675c2f will be shutdown
2023-02-15T13:36:10,631  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34ff6543 created in the thread with id: 1
2023-02-15T13:36:10,646  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:36:10,647  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:36:10,665  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.x_table	
2023-02-15T13:36:10,672  INFO [main] metastore.HMSHandler: Skipping translation for processor with null
2023-02-15T13:36:10,673  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=drop_table : tbl=hive.default.x_table	
2023-02-15T13:36:10,715  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:x_table, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_22/x_table, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:36:10,716  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_22/x_table specified for non-external table:x_table
2023-02-15T13:36:10,716  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_22/x_table
2023-02-15T13:36:10,729  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.x_table	
2023-02-15T13:36:10,733  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_22/x_table/ds=part0
2023-02-15T13:36:10,755  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.x_table	
2023-02-15T13:36:10,756  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_22/x_table/ds=part1
2023-02-15T13:36:10,774  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.x_table	
2023-02-15T13:36:10,776  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_22/x_table/ds=part2
2023-02-15T13:36:10,795  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.x_table	
2023-02-15T13:36:10,796  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_22/x_table/ds=part3
2023-02-15T13:36:10,813  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.x_table	
2023-02-15T13:36:10,815  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_22/x_table/ds=part4
2023-02-15T13:36:10,834  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.x_table	
2023-02-15T13:36:10,835  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_22/x_table/ds=part5
2023-02-15T13:36:10,854  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.x_table	
2023-02-15T13:36:10,855  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_22/x_table/ds=part6
2023-02-15T13:36:10,873  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.x_table	
2023-02-15T13:36:10,874  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_22/x_table/ds=part7
2023-02-15T13:36:10,893  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.x_table	
2023-02-15T13:36:10,894  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_22/x_table/ds=part8
2023-02-15T13:36:10,934  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.x_table	
2023-02-15T13:36:10,939  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_22/x_table/ds=part9
2023-02-15T13:36:10,995  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]) with min_open_txn: 1
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 21
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 22
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 23
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 24
2023-02-15T13:36:11,000  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 25
2023-02-15T13:36:11,001  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=x_table (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])
2023-02-15T13:36:11,003  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:36:11,004  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,005  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:36:11,007  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2023-02-15T13:36:11,008  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,008  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2023-02-15T13:36:11,010  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:36:11,012  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,012  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:36:11,013  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2023-02-15T13:36:11,015  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,015  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2023-02-15T13:36:11,016  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:36:11,018  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,018  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:36:11,020  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:36:11,021  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,021  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:36:11,023  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2023-02-15T13:36:11,024  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,024  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:36:11,026  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2023-02-15T13:36:11,027  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,027  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:36:11,029  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2023-02-15T13:36:11,030  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,030  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:36:11,032  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2023-02-15T13:36:11,033  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,033  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:36:11,035  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2023-02-15T13:36:11,036  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,036  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2023-02-15T13:36:11,038  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2023-02-15T13:36:11,039  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,040  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2023-02-15T13:36:11,041  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:13
2023-02-15T13:36:11,042  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,043  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2023-02-15T13:36:11,044  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:14
2023-02-15T13:36:11,045  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,046  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:14
2023-02-15T13:36:11,047  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2023-02-15T13:36:11,048  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,049  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2023-02-15T13:36:11,050  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2023-02-15T13:36:11,052  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,052  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:36:11,053  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2023-02-15T13:36:11,055  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,055  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:36:11,056  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2023-02-15T13:36:11,058  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,058  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:36:11,059  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2023-02-15T13:36:11,061  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,061  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:36:11,063  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2023-02-15T13:36:11,064  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,064  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:36:11,066  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:21
2023-02-15T13:36:11,067  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,067  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:21
2023-02-15T13:36:11,069  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:22
2023-02-15T13:36:11,070  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,070  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:22
2023-02-15T13:36:11,072  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:23
2023-02-15T13:36:11,073  INFO [main] txn.TxnHandler: Removed transactions: ([23]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,073  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:23
2023-02-15T13:36:11,075  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:24
2023-02-15T13:36:11,076  INFO [main] txn.TxnHandler: Removed transactions: ([24]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,076  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:24
2023-02-15T13:36:11,078  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:25
2023-02-15T13:36:11,079  INFO [main] txn.TxnHandler: Removed transactions: ([25]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,079  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:25
2023-02-15T13:36:11,082  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([26]) with min_open_txn: 1
2023-02-15T13:36:11,093  INFO [main] txn.TxnHandler: Allocated writeId: 26 for txnId: 26
2023-02-15T13:36:11,093  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=x_table (txnIds: [26])
2023-02-15T13:36:11,098  INFO [main] txn.TxnHandler: Removed transactions: ([26]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,098  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:26
2023-02-15T13:36:11,106  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:36:11,106  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:36:11,106  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:36:11,106  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:36:11,106  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:36:11,106  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:36:11,106  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:36:11,106  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:36:11,106  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:36:11,106  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:36:11,106  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:36:11,106  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:36:11,107  INFO [main] compactor.Initiator: Starting Initiator thread
2023-02-15T13:36:11,109  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410571108
2023-02-15T13:36:11,113  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:36:11,113  INFO [Initiator-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:36:11,114  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@486d315c, with PersistenceManager: null will be shutdown
2023-02-15T13:36:11,114  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@486d315c, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@105fdbf6 created in the thread with id: 2572
2023-02-15T13:36:11,120  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@486d315c
2023-02-15T13:36:11,122  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.x_table.ds=part0
2023-02-15T13:36:11,129  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.x_table.ds=part1
2023-02-15T13:36:11,129  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.x_table.ds=part2
2023-02-15T13:36:11,129  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.x_table.ds=part3
2023-02-15T13:36:11,129  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.x_table.ds=part4
2023-02-15T13:36:11,129  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.x_table.ds=part5
2023-02-15T13:36:11,129  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.x_table.ds=part6
2023-02-15T13:36:11,130  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.x_table.ds=part7
2023-02-15T13:36:11,130  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.x_table.ds=part8
2023-02-15T13:36:11,130  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.x_table.ds=part9
2023-02-15T13:36:11,153  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:x_table, partitionname:ds=part6, type:MAJOR, runas:rizky, initiatorId:labdas-2572)
2023-02-15T13:36:11,168  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:x_table, partitionname:ds=part7, type:MAJOR, runas:rizky, initiatorId:labdas-2572)
2023-02-15T13:36:11,182  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:x_table, partitionname:ds=part8, type:MAJOR, runas:rizky, initiatorId:labdas-2572)
2023-02-15T13:36:11,196  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:x_table, partitionname:ds=part9, type:MAJOR, runas:rizky, initiatorId:labdas-2572)
2023-02-15T13:36:11,211  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:x_table, partitionname:ds=part0, type:MAJOR, runas:rizky, initiatorId:labdas-2572)
2023-02-15T13:36:11,228  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:x_table, partitionname:ds=part1, type:MAJOR, runas:rizky, initiatorId:labdas-2572)
2023-02-15T13:36:11,243  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:x_table, partitionname:ds=part2, type:MAJOR, runas:rizky, initiatorId:labdas-2572)
2023-02-15T13:36:11,258  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:x_table, partitionname:ds=part3, type:MAJOR, runas:rizky, initiatorId:labdas-2572)
2023-02-15T13:36:11,274  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:x_table, partitionname:ds=part4, type:MAJOR, runas:rizky, initiatorId:labdas-2572)
2023-02-15T13:36:11,292  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:x_table, partitionname:ds=part5, type:MAJOR, runas:rizky, initiatorId:labdas-2572)
2023-02-15T13:36:11,296  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410571295
2023-02-15T13:36:11,312  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:36:11,312  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:36:11,312  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:36:11,312  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:36:11,312  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:36:11,312  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:36:11,312  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:36:11,312  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:36:11,312  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:36:11,312  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:36:11,312  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:36:11,312  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:36:11,312  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:36:11,321  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:36:11,322  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:36:11,322  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:36:11,322  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@34ff6543 will be shutdown
2023-02-15T13:36:11,322  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d07f310 created in the thread with id: 1
2023-02-15T13:36:11,337  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:36:11,339  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:36:11,371  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:36:11,371  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:36:11,371  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:36:11,371  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:36:11,371  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:36:11,371  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:36:11,371  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:36:11,371  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:36:11,371  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:36:11,371  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:36:11,371  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:36:11,371  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:36:11,372  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:36:11,379  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:36:11,380  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:36:11,380  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:36:11,380  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d07f310 will be shutdown
2023-02-15T13:36:11,380  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@203855c2 created in the thread with id: 1
2023-02-15T13:36:11,391  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:36:11,393  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:36:11,411  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.imd	
2023-02-15T13:36:11,415  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:imd, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_24/imd, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:[FieldSchema(name:ds, type:string, comment:no comment)], parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:36:11,416  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_24/imd specified for non-external table:imd
2023-02-15T13:36:11,417  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_24/imd
2023-02-15T13:36:11,431  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.imd	
2023-02-15T13:36:11,438  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_24/imd/ds=part1
2023-02-15T13:36:11,457  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.imd	
2023-02-15T13:36:11,459  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_24/imd/ds=part2
2023-02-15T13:36:11,474  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.imd	
2023-02-15T13:36:11,476  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_24/imd/ds=part3
2023-02-15T13:36:11,504  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.imd	
2023-02-15T13:36:11,507  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_24/imd/ds=part4
2023-02-15T13:36:11,541  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.imd	
2023-02-15T13:36:11,543  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_24/imd/ds=part5
2023-02-15T13:36:11,571  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.imd	
2023-02-15T13:36:11,573  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_24/imd/ds=part6
2023-02-15T13:36:11,594  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.imd	
2023-02-15T13:36:11,595  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_24/imd/ds=part7
2023-02-15T13:36:11,611  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.imd	
2023-02-15T13:36:11,612  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_24/imd/ds=part8
2023-02-15T13:36:11,629  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.imd	
2023-02-15T13:36:11,630  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_24/imd/ds=part9
2023-02-15T13:36:11,644  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=add_partition : tbl=hive.default.imd	
2023-02-15T13:36:11,645  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_24/imd/ds=part10
2023-02-15T13:36:11,667  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]) with min_open_txn: 1
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 21
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 22
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 23
2023-02-15T13:36:11,670  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=imd (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])
2023-02-15T13:36:11,672  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:36:11,674  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,675  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:36:11,677  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2023-02-15T13:36:11,678  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,678  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2023-02-15T13:36:11,680  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:36:11,682  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,682  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:36:11,683  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2023-02-15T13:36:11,685  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,685  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2023-02-15T13:36:11,686  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:36:11,688  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,688  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:36:11,690  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:36:11,691  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,691  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:36:11,693  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2023-02-15T13:36:11,695  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,695  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:36:11,696  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2023-02-15T13:36:11,698  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,698  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:36:11,699  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2023-02-15T13:36:11,701  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,701  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:36:11,703  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2023-02-15T13:36:11,704  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,704  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:36:11,706  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2023-02-15T13:36:11,707  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,707  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2023-02-15T13:36:11,709  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2023-02-15T13:36:11,711  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,711  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2023-02-15T13:36:11,712  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:13
2023-02-15T13:36:11,714  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,714  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2023-02-15T13:36:11,716  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:14
2023-02-15T13:36:11,717  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,717  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:14
2023-02-15T13:36:11,719  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2023-02-15T13:36:11,721  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,721  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2023-02-15T13:36:11,722  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2023-02-15T13:36:11,724  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,724  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:36:11,726  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2023-02-15T13:36:11,727  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,727  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:36:11,729  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2023-02-15T13:36:11,730  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,730  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:36:11,732  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2023-02-15T13:36:11,734  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,734  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:36:11,735  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2023-02-15T13:36:11,737  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,737  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:36:11,738  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:21
2023-02-15T13:36:11,740  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,740  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:21
2023-02-15T13:36:11,741  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:22
2023-02-15T13:36:11,743  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,743  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:22
2023-02-15T13:36:11,744  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:23
2023-02-15T13:36:11,746  INFO [main] txn.TxnHandler: Removed transactions: ([23]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,746  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:23
2023-02-15T13:36:11,749  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([24]) with min_open_txn: 1
2023-02-15T13:36:11,759  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 24
2023-02-15T13:36:11,759  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=imd (txnIds: [24])
2023-02-15T13:36:11,764  INFO [main] txn.TxnHandler: Removed transactions: ([24]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:11,764  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:24
2023-02-15T13:36:11,772  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:36:11,772  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:36:11,772  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:36:11,772  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:36:11,772  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:36:11,772  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:36:11,772  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:36:11,772  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:36:11,772  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:36:11,772  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:36:11,772  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:36:11,772  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:36:11,773  INFO [main] compactor.Initiator: Starting Initiator thread
2023-02-15T13:36:11,775  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410571774
2023-02-15T13:36:11,779  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Opening raw store with implementation class: org.apache.hadoop.hive.metastore.ObjectStore
2023-02-15T13:36:11,779  INFO [Initiator-executor-thread-1] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:36:11,779  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a5c5926, with PersistenceManager: null will be shutdown
2023-02-15T13:36:11,779  INFO [Initiator-executor-thread-1] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a5c5926, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@6fe63ae9 created in the thread with id: 2864
2023-02-15T13:36:11,787  INFO [Initiator-executor-thread-1] metastore.HMSHandler: Created RawStore: org.apache.hadoop.hive.metastore.ObjectStore@2a5c5926
2023-02-15T13:36:11,788  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.imd.ds=part9
2023-02-15T13:36:11,794  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.imd.ds=part10
2023-02-15T13:36:11,794  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.imd.ds=part7
2023-02-15T13:36:11,795  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.imd.ds=part8
2023-02-15T13:36:11,795  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.imd.ds=part1
2023-02-15T13:36:11,795  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.imd.ds=part2
2023-02-15T13:36:11,795  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.imd.ds=part5
2023-02-15T13:36:11,796  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.imd.ds=part6
2023-02-15T13:36:11,796  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.imd.ds=part3
2023-02-15T13:36:11,796  INFO [Initiator-executor-thread-1] compactor.Initiator: Checking to see if we should compact default.imd.ds=part4
2023-02-15T13:36:11,816  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:imd, partitionname:ds=part5, type:MAJOR, runas:rizky, initiatorId:labdas-2864)
2023-02-15T13:36:11,829  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:imd, partitionname:ds=part6, type:MAJOR, runas:rizky, initiatorId:labdas-2864)
2023-02-15T13:36:11,843  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:imd, partitionname:ds=part3, type:MAJOR, runas:rizky, initiatorId:labdas-2864)
2023-02-15T13:36:11,854  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:imd, partitionname:ds=part4, type:MAJOR, runas:rizky, initiatorId:labdas-2864)
2023-02-15T13:36:11,864  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:imd, partitionname:ds=part1, type:MAJOR, runas:rizky, initiatorId:labdas-2864)
2023-02-15T13:36:11,875  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:imd, partitionname:ds=part2, type:MAJOR, runas:rizky, initiatorId:labdas-2864)
2023-02-15T13:36:11,888  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:imd, partitionname:ds=part9, type:MAJOR, runas:rizky, initiatorId:labdas-2864)
2023-02-15T13:36:11,899  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:imd, partitionname:ds=part10, type:MAJOR, runas:rizky, initiatorId:labdas-2864)
2023-02-15T13:36:11,910  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:imd, partitionname:ds=part7, type:MAJOR, runas:rizky, initiatorId:labdas-2864)
2023-02-15T13:36:11,920  INFO [Initiator-executor-thread-1] compactor.Initiator: Requesting compaction: CompactionRequest(dbname:default, tablename:imd, partitionname:ds=part8, type:MAJOR, runas:rizky, initiatorId:labdas-2864)
2023-02-15T13:36:11,924  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410571923
2023-02-15T13:36:11,944  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:36:11,944  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:36:11,944  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:36:11,944  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:36:11,944  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:36:11,944  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:36:11,944  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:36:11,944  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:36:11,944  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:36:11,944  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:36:11,944  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:36:11,944  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:36:11,944  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:36:11,954  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:36:11,955  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:36:11,955  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:36:11,955  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@203855c2 will be shutdown
2023-02-15T13:36:11,955  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d6e7acc created in the thread with id: 1
2023-02-15T13:36:11,971  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:36:11,973  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:36:11,991  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=get_table : tbl=hive.default.dcamc	
2023-02-15T13:36:11,995  INFO [main] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=create_table_req: Table(tableName:dcamc, dbName:default, owner:me, createTime:0, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:a, type:varchar(25), comment:still no comment), FieldSchema(name:b, type:int, comment:comment)], location:file:/home/rizky/hive/ql/target/tmp/compactor_test_table_25/dcamc, inputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockInputFormat, outputFormat:org.apache.hadoop.hive.ql.txn.compactor.CompactorTest$MockOutputFormat, compressed:false, numBuckets:1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:null), bucketCols:[a], sortCols:null, parameters:null), partitionKeys:null, parameters:{transactional=true}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, catName:hive, ownerType:USER)	
2023-02-15T13:36:11,997  WARN [main] metastore.HMSHandler: Location: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_25/dcamc specified for non-external table:dcamc
2023-02-15T13:36:11,997  INFO [main] utils.FileUtils: Creating directory if it doesn't exist: file:/home/rizky/hive/ql/target/tmp/compactor_test_table_25/dcamc
2023-02-15T13:36:12,019  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]) with min_open_txn: 1
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 1 for txnId: 1
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 2 for txnId: 2
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 3 for txnId: 3
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 4 for txnId: 4
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 5 for txnId: 5
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 6 for txnId: 6
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 7 for txnId: 7
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 8 for txnId: 8
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 9 for txnId: 9
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 10 for txnId: 10
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 11 for txnId: 11
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 12 for txnId: 12
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 13 for txnId: 13
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 14 for txnId: 14
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 15 for txnId: 15
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 16 for txnId: 16
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 17 for txnId: 17
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 18 for txnId: 18
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 19 for txnId: 19
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 20 for txnId: 20
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 21 for txnId: 21
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 22 for txnId: 22
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 23 for txnId: 23
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated writeId: 24 for txnId: 24
2023-02-15T13:36:12,022  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=dcamc (txnIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24])
2023-02-15T13:36:12,024  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:1
2023-02-15T13:36:12,026  INFO [main] txn.TxnHandler: Removed transactions: ([1]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,026  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:1
2023-02-15T13:36:12,028  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:2
2023-02-15T13:36:12,030  INFO [main] txn.TxnHandler: Removed transactions: ([2]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,030  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:2
2023-02-15T13:36:12,032  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:3
2023-02-15T13:36:12,033  INFO [main] txn.TxnHandler: Removed transactions: ([3]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,033  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:3
2023-02-15T13:36:12,035  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:4
2023-02-15T13:36:12,037  INFO [main] txn.TxnHandler: Removed transactions: ([4]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,037  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:4
2023-02-15T13:36:12,038  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:5
2023-02-15T13:36:12,040  INFO [main] txn.TxnHandler: Removed transactions: ([5]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,040  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:5
2023-02-15T13:36:12,041  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:6
2023-02-15T13:36:12,043  INFO [main] txn.TxnHandler: Removed transactions: ([6]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,043  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:6
2023-02-15T13:36:12,045  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:7
2023-02-15T13:36:12,046  INFO [main] txn.TxnHandler: Removed transactions: ([7]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,046  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:7
2023-02-15T13:36:12,048  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:8
2023-02-15T13:36:12,050  INFO [main] txn.TxnHandler: Removed transactions: ([8]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,050  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:8
2023-02-15T13:36:12,051  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:9
2023-02-15T13:36:12,053  INFO [main] txn.TxnHandler: Removed transactions: ([9]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,053  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:9
2023-02-15T13:36:12,054  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:10
2023-02-15T13:36:12,056  INFO [main] txn.TxnHandler: Removed transactions: ([10]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,056  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:10
2023-02-15T13:36:12,057  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:11
2023-02-15T13:36:12,059  INFO [main] txn.TxnHandler: Removed transactions: ([11]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,059  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:11
2023-02-15T13:36:12,061  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:12
2023-02-15T13:36:12,062  INFO [main] txn.TxnHandler: Removed transactions: ([12]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,062  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:12
2023-02-15T13:36:12,064  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:13
2023-02-15T13:36:12,066  INFO [main] txn.TxnHandler: Removed transactions: ([13]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,066  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:13
2023-02-15T13:36:12,067  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:14
2023-02-15T13:36:12,069  INFO [main] txn.TxnHandler: Removed transactions: ([14]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,069  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:14
2023-02-15T13:36:12,070  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:15
2023-02-15T13:36:12,072  INFO [main] txn.TxnHandler: Removed transactions: ([15]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,072  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:15
2023-02-15T13:36:12,073  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:16
2023-02-15T13:36:12,075  INFO [main] txn.TxnHandler: Removed transactions: ([16]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,075  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:16
2023-02-15T13:36:12,077  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:17
2023-02-15T13:36:12,079  INFO [main] txn.TxnHandler: Removed transactions: ([17]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,079  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:17
2023-02-15T13:36:12,080  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:18
2023-02-15T13:36:12,082  INFO [main] txn.TxnHandler: Removed transactions: ([18]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,082  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:18
2023-02-15T13:36:12,083  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:19
2023-02-15T13:36:12,085  INFO [main] txn.TxnHandler: Removed transactions: ([19]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,085  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:19
2023-02-15T13:36:12,087  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:20
2023-02-15T13:36:12,088  INFO [main] txn.TxnHandler: Removed transactions: ([20]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,089  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:20
2023-02-15T13:36:12,090  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:21
2023-02-15T13:36:12,092  INFO [main] txn.TxnHandler: Removed transactions: ([21]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,092  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:21
2023-02-15T13:36:12,096  INFO [main] txn.TxnHandler: Added entries to MIN_HISTORY_LEVEL for current txns: ([25]) with min_open_txn: 1
2023-02-15T13:36:12,109  INFO [main] txn.TxnHandler: Removed transactions: ([22]) from MIN_HISTORY_LEVEL
2023-02-15T13:36:12,109  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:22
2023-02-15T13:36:13,117 ERROR [main] metrics.AcidMetricService: Cannot initialize delta file metrics mbean server. AcidMetricService initialization aborted.
javax.management.InstanceAlreadyExistsException: metrics:type=compaction,name=compaction_num_obsolete_deltas
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324) ~[?:1.8.0_352]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.initObjectsForMetrics(AcidMetricService.java:404) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.setConf(AcidMetricService.java:380) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runAcidMetricService(CompactorTest.java:165) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testDBMetrics(TestCompactionMetrics.java:687) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_352]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_352]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_352]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T13:36:13,240  WARN [main] metrics.AcidMetricService: Caught exception while trying to fetch compaction metrics from metastore backend db.
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.updateDeltaMBeanAndMetric(AcidMetricService.java:289) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.updateDeltaMetrics(AcidMetricService.java:270) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.run(AcidMetricService.java:119) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runAcidMetricService(CompactorTest.java:166) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testDBMetrics(TestCompactionMetrics.java:687) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_352]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_352]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_352]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T13:36:13,243  INFO [main] txn.CompactionTxnHandler: Removed 21 rows from TXN_TO_WRITE_ID with Txn Low-Water-Mark: 22
2023-02-15T13:36:13,243 ERROR [main] metrics.AcidMetricService: Cannot initialize delta file metrics mbean server. AcidMetricService initialization aborted.
javax.management.InstanceAlreadyExistsException: metrics:type=compaction,name=compaction_num_obsolete_deltas
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324) ~[?:1.8.0_352]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.initObjectsForMetrics(AcidMetricService.java:404) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.setConf(AcidMetricService.java:380) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runAcidMetricService(CompactorTest.java:165) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testDBMetrics(TestCompactionMetrics.java:716) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_352]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_352]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_352]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T13:36:13,243  WARN [main] metrics.AcidMetricService: Caught exception while trying to fetch compaction metrics from metastore backend db.
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.updateDeltaMBeanAndMetric(AcidMetricService.java:289) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.updateDeltaMetrics(AcidMetricService.java:270) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.run(AcidMetricService.java:119) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runAcidMetricService(CompactorTest.java:166) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testDBMetrics(TestCompactionMetrics.java:716) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_352]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_352]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_352]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T13:36:13,247  INFO [main] txn.TxnHandler: Allocated writeId: 25 for txnId: 26
2023-02-15T13:36:13,248  INFO [main] txn.TxnHandler: Allocated writeId: 26 for txnId: 27
2023-02-15T13:36:13,248  INFO [main] txn.TxnHandler: Allocated writeId: 27 for txnId: 28
2023-02-15T13:36:13,248  INFO [main] txn.TxnHandler: Allocated write ids for dbName=default, tblName=dcamc (txnIds: [26, 27, 28])
2023-02-15T13:36:13,250  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [26] due to none
2023-02-15T13:36:13,253  INFO [main] txn.TxnHandler: Expected to move at least one record from txn_components to completed_txn_components when committing txn! txnid:27
2023-02-15T13:36:13,255  WARN [main] txn.CompactionTxnHandler: No compaction queue record found for Compaction type transaction commit. txnId:27
2023-02-15T13:36:13,257  WARN [main] txn.TxnHandler: Aborted 1 transaction(s) [28] due to none
2023-02-15T13:36:14,258 ERROR [main] metrics.AcidMetricService: Cannot initialize delta file metrics mbean server. AcidMetricService initialization aborted.
javax.management.InstanceAlreadyExistsException: metrics:type=compaction,name=compaction_num_obsolete_deltas
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900) ~[?:1.8.0_352]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324) ~[?:1.8.0_352]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522) ~[?:1.8.0_352]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.initObjectsForMetrics(AcidMetricService.java:404) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.setConf(AcidMetricService.java:380) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runAcidMetricService(CompactorTest.java:165) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testDBMetrics(TestCompactionMetrics.java:724) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_352]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_352]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_352]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T13:36:14,262  WARN [main] metrics.AcidMetricService: Caught exception while trying to fetch compaction metrics from metastore backend db.
java.lang.NullPointerException: null
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.updateDeltaMBeanAndMetric(AcidMetricService.java:289) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.updateDeltaMetrics(AcidMetricService.java:270) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.metrics.AcidMetricService.run(AcidMetricService.java:119) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runAcidMetricService(CompactorTest.java:166) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testDBMetrics(TestCompactionMetrics.java:724) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_352]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_352]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_352]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T13:36:14,276  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:36:14,276  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:36:14,276  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:36:14,276  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:36:14,276  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:36:14,276  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:36:14,276  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:36:14,276  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:36:14,276  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:36:14,276  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:36:14,276  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:36:14,276  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:36:14,276  INFO [main] utils.TestTxnDbUtil: Cleaning transactional tables
2023-02-15T13:36:14,286  INFO [main] utils.TestTxnDbUtil: Creating transactional tables
2023-02-15T13:36:14,287  INFO [main] metastore.HiveMetaStoreClient: HMS client filtering is enabled.
2023-02-15T13:36:14,287  INFO [main] metastore.PersistenceManagerProvider: Configuration datanucleus.autoStartMechanismMode is not set. Defaulting to 'ignored'
2023-02-15T13:36:14,288  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@3d6e7acc will be shutdown
2023-02-15T13:36:14,288  INFO [main] metastore.ObjectStore: RawStore: org.apache.hadoop.hive.metastore.ObjectStore@e95595b, with PersistenceManager: org.datanucleus.api.jdo.JDOPersistenceManager@1364ca39 created in the thread with id: 1
2023-02-15T13:36:14,305  INFO [main] metastore.HMSHandler: HMS server filtering is disabled by configuration
2023-02-15T13:36:14,307  INFO [main] metrics.JsonReporter: Reporting metrics to /tmp/report.json
2023-02-15T13:36:14,335  WARN [main] conf.HiveConf: HiveConf of name hive.mapjoin.max.gc.time.percentage does not exist
2023-02-15T13:36:14,335  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.size does not exist
2023-02-15T13:36:14,335  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.override does not exist
2023-02-15T13:36:14,335  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.metadb.dir does not exist
2023-02-15T13:36:14,335  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.min does not exist
2023-02-15T13:36:14,335  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.hivesite does not exist
2023-02-15T13:36:14,335  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.alloc.max does not exist
2023-02-15T13:36:14,335  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.maxSize does not exist
2023-02-15T13:36:14,335  WARN [main] conf.HiveConf: HiveConf of name hive.dummyparam.test.server.specific.config.metastoresite does not exist
2023-02-15T13:36:14,335  WARN [main] conf.HiveConf: HiveConf of name hive.metastore.client.cache.recordStats does not exist
2023-02-15T13:36:14,335  WARN [main] conf.HiveConf: HiveConf of name hive.llap.io.cache.orc.arena.size does not exist
2023-02-15T13:36:14,335  WARN [main] conf.HiveConf: HiveConf of name hive.stats.key.prefix.reserve.length does not exist
2023-02-15T13:36:14,335  INFO [main] compactor.Initiator: Starting Initiator thread
2023-02-15T13:36:14,342  INFO [main] txn.CompactionTxnHandler: 0 compaction queue entries timed out, set back to initiated state. Latest valid start: 1676410574337
2023-02-15T13:36:19,328 ERROR [main] compactor.Initiator: Initiator loop caught unexpected exception this time through the loop
org.apache.hadoop.hive.metastore.api.MetaException: Unable to lock 'Initiator' due to: nulljava.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
	at java.util.concurrent.Semaphore.acquire(Semaphore.java:312)
	at org.apache.hadoop.hive.metastore.txn.TxnHandler.acquireLock(TxnHandler.java:6062)
	at org.apache.hadoop.hive.ql.txn.compactor.Initiator.run(Initiator.java:127)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runOneLoopOfCompactorThread(CompactorTest.java:383)
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.startInitiator(CompactorTest.java:151)
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testInitiatorAuxFailure(TestCompactionMetrics.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
	at java.util.Iterator.forEachRemaining(Iterator.java:116)
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)

	at org.apache.hadoop.hive.metastore.txn.TxnHandler.acquireLock(TxnHandler.java:6075) ~[hive-standalone-metastore-server-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.txn.compactor.Initiator.run(Initiator.java:127) ~[classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.runOneLoopOfCompactorThread(CompactorTest.java:383) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.CompactorTest.startInitiator(CompactorTest.java:151) ~[test-classes/:?]
	at org.apache.hadoop.hive.ql.txn.compactor.TestCompactionMetrics.testInitiatorAuxFailure(TestCompactionMetrics.java:254) ~[test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_352]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_352]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_352]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_352]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115) ~[junit-4.13.2.jar:4.13.2]
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:43) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ~[?:1.8.0_352]
	at java.util.Iterator.forEachRemaining(Iterator.java:116) ~[?:1.8.0_352]
	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ~[?:1.8.0_352]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ~[?:1.8.0_352]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ~[?:1.8.0_352]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ~[?:1.8.0_352]
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:82) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:73) ~[junit-vintage-engine-5.6.3.jar:5.6.3]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) ~[junit-platform-launcher-1.6.2.jar:1.6.2]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123) ~[surefire-junit-platform-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451) ~[surefire-booter-3.0.0-M4.jar:3.0.0-M4]
2023-02-15T13:36:19,329  WARN [main] compactor.CompactorThread: Possible org.apache.hadoop.hive.ql.txn.compactor.Initiator slowdown, loop took 1676496979 seconds to finish.
2023-02-15T13:36:19,349  INFO [shutdown-hook-0] HiveMetaStore.audit: ugi=rizky	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2023-02-15T13:36:19,349  INFO [shutdown-hook-0] metastore.HiveMetaStoreClient: Closed a connection to metastore, current connections: -6
2023-02-15T13:36:19,349  INFO [shutdown-hook-0] lockmgr.DbTxnManager: Shutting down Heartbeater thread pool.
2023-02-15T13:36:19,349  INFO [shutdown-hook-0] compactor.CompactionHeartbeatService: Shutting down compaction txn heartbeater service.
2023-02-15T13:36:19,351  INFO [shutdown-hook-0] compactor.CompactionHeartbeatService: Compaction txn heartbeater service is successfully stopped.
